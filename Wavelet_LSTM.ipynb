{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import newaxis\n",
        "\n",
        "def load_data(data_path,P,step):\n",
        "    num_logs = P+step\n",
        "    df = pd.read_csv(data_path)\n",
        "    \n",
        "\n",
        "    data_np = np.zeros((len(df),num_logs))\n",
        "    data_df_combined = pd.DataFrame(data_np)\n",
        "    data_df_combined.loc[:,0] = df['SYSLoad'].values\n",
        "\n",
        "    for i in range(1, num_logs):\n",
        "        data_df_combined.loc[:,i] = data_df_combined.shift(-i)\n",
        "\n",
        "    data_df_combined_clean = data_df_combined.dropna()\n",
        "    data_df_combined_clean = data_df_combined_clean.reset_index()\n",
        "    data_df_combined_clean.drop('index',axis=1,inplace=True)\n",
        "    data_combined_standardized = preprocessing.scale(data_df_combined_clean)\n",
        "\n",
        "    train_split = round(0.8 * data_combined_standardized.shape[0])\n",
        "    val_split = round(0.9 * data_combined_standardized.shape[0])\n",
        "    print(\"all len\",data_combined_standardized.shape[0])\n",
        "    print(\"train_split\",train_split)\n",
        "\n",
        "    X = data_combined_standardized[:,:P]\n",
        "    Y = data_combined_standardized[:,P:]\n",
        "\n",
        "    X_train = X[:train_split]\n",
        "    Y_train = Y[:train_split]\n",
        "    X_test = X[train_split:]\n",
        "    Y_test = Y[train_split:]\n",
        "\n",
        "    X_train = X_train.reshape((X_train.shape[0],X_train.shape[1],1))\n",
        "    Y_train = Y_train.reshape((Y_train.shape[0],Y_train.shape[1],1))\n",
        "    X_test = X_test.reshape((X_test.shape[0],X_test.shape[1],1))\n",
        "    Y_test = Y_test.reshape((Y_test.shape[0],Y_test.shape[1],1))\n",
        "\n",
        "    return X_train,Y_train,X_test,Y_test,data_df_combined_clean\n"
      ],
      "metadata": {
        "id": "sRsLojTLq4Zj"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "class TorchDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.x[idx], self.y[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "class TorchDataLoader:\n",
        "    def __init__(self,batch_size,shuffle = True):\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "    \n",
        "    def torch_dataloader(self,train_data,target_data):\n",
        "        torch_dataset = TorchDataset(train_data,target_data)\n",
        "        torch_loader = DataLoader(dataset = torch_dataset,\n",
        "                                batch_size = self.batch_size, \n",
        "                                shuffle = self.shuffle)\n",
        "        return torch_loader\n",
        "\n",
        "def plot_results(predicted_data, true_data):\n",
        "    # use in train.py \n",
        "    # plot evaluate result\n",
        "    fig = plt.figure(facecolor='white', figsize=(12, 6))\n",
        "    ax = fig.add_subplot(111)\n",
        "    ax.plot(true_data[-200:], label='True Data')\n",
        "    plt.plot(predicted_data[-200:], label='Prediction')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def ToVariable(x):\n",
        "    # use in train.py \n",
        "    # change from numpy.array to torch.variable   \n",
        "    tmp = torch.DoubleTensor(x)\n",
        "    return Variable(tmp)\n"
      ],
      "metadata": {
        "id": "p-HJRZQmUfqj"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "from torch.nn.parameter import Parameter\n",
        "import torch.nn.functional as F \n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "import numpy as np \n",
        "import h5py\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import pywt\n",
        "\n",
        "\n",
        "class Wavelet_LSTM(nn.Module):\n",
        "    def __init__(self,seq_len, hidden_size,output_size):\n",
        "        super(Wavelet_LSTM,self).__init__()\n",
        "        self.seq_len = seq_len\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        self.mWDN1_H = nn.Linear(seq_len,seq_len)\n",
        "        self.mWDN1_L = nn.Linear(seq_len,seq_len)\n",
        "        self.mWDN2_H = nn.Linear(int(seq_len/2),int(seq_len/2))\n",
        "        self.mWDN2_L = nn.Linear(int(seq_len/2),int(seq_len/2))\n",
        "        self.a_to_x = nn.AvgPool1d(2)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.lstm_xh1 = nn.LSTM(1,hidden_size,batch_first=True)\n",
        "        self.lstm_xh2 = nn.LSTM(1,hidden_size,batch_first=True)\n",
        "        self.lstm_xl2 = nn.LSTM(1,hidden_size,batch_first=True)\n",
        "        self.output = nn.Linear(hidden_size,output_size)\n",
        "        \n",
        "        wavelet = pywt.Wavelet('db4')\n",
        "        low = wavelet.dec_lo\n",
        "        high = wavelet.dec_hi\n",
        "        self.l_filter = low\n",
        "        self.h_filter = high\n",
        "\n",
        "        self.cmp_mWDN1_H = ToVariable(self.create_W(seq_len,False,is_comp=True))\n",
        "        self.cmp_mWDN1_L = ToVariable(self.create_W(seq_len,True,is_comp=True))\n",
        "        self.cmp_mWDN2_H = ToVariable(self.create_W(int(seq_len/2),False,is_comp=True))\n",
        "        self.cmp_mWDN2_L = ToVariable(self.create_W(int(seq_len/2),True,is_comp=True))\n",
        "\n",
        "        self.mWDN1_H.weight = torch.nn.Parameter(ToVariable(self.create_W(seq_len,False)))\n",
        "        self.mWDN1_L.weight = torch.nn.Parameter(ToVariable(self.create_W(seq_len,True)))\n",
        "        self.mWDN2_H.weight = torch.nn.Parameter(ToVariable(self.create_W(int(seq_len/2),False)))\n",
        "        self.mWDN2_L.weight = torch.nn.Parameter(ToVariable(self.create_W(int(seq_len/2),True)))\n",
        "\n",
        "    def forward(self,input,h1,c1,h2,c2,h3,c3):\n",
        "        input = input.view(input.shape[0],input.shape[1])\n",
        "        ah_1 = self.sigmoid(self.mWDN1_H(input))\n",
        "        al_1 = self.sigmoid(self.mWDN1_L(input))\n",
        "        xh_1 = self.a_to_x(ah_1.view(ah_1.shape[0],1,-1))\n",
        "        xl_1 = self.a_to_x(al_1.view(al_1.shape[0],1,-1))\n",
        "        \n",
        "        ah_2 = self.sigmoid(self.mWDN2_H(xl_1))\n",
        "        al_2 = self.sigmoid(self.mWDN2_L(xl_1))\n",
        "        \n",
        "        xh_2 = self.a_to_x(ah_2)\n",
        "        xl_2 = self.a_to_x(al_2)\n",
        "\n",
        "        xh_1 = xh_1.transpose(1,2)\n",
        "        xh_2 = xh_2.transpose(1,2)\n",
        "        xl_2 = xl_2.transpose(1,2)\n",
        "\n",
        "        level1_lstm,(h1,c1) = self.lstm_xh1(xh_1,(h1,c1))\n",
        "        level2_lstm_h,(h2,c2) = self.lstm_xh2(xh_2,(h2,c2))\n",
        "        level2_lstm_l,(h3,c3) = self.lstm_xl2(xl_2,(h3,c3))\n",
        "\n",
        "        output = self.output(torch.cat((level1_lstm,level2_lstm_h,level2_lstm_l), 1))\n",
        "        #output = output.view(-1,1)\n",
        "        return output,h1,c1,h2,c2,h3,c3\n",
        "\n",
        "    def init_state(self,batch_size):\n",
        "        h1 = Variable(torch.zeros(1,batch_size,self.hidden_size)).double()\n",
        "        c1 = Variable(torch.zeros(1,batch_size,self.hidden_size)).double()\n",
        "\n",
        "        h2 = Variable(torch.zeros(1,batch_size,self.hidden_size)).double()\n",
        "        c2 = Variable(torch.zeros(1,batch_size,self.hidden_size)).double()\n",
        "\n",
        "        h3 = Variable(torch.zeros(1,batch_size,self.hidden_size)).double()\n",
        "        c3 = Variable(torch.zeros(1,batch_size,self.hidden_size)).double()\n",
        "        return h1,c1,h2,c2,h3,c3\n",
        "\n",
        "    def create_W(self,P,is_l,is_comp=False):\n",
        "        if is_l : \n",
        "            filter_list = self.l_filter\n",
        "        else:\n",
        "            filter_list = self.h_filter\n",
        "\n",
        "        list_len = len(filter_list)\n",
        "\n",
        "        max_epsilon = np.min(np.abs(filter_list))\n",
        "        if is_comp:\n",
        "            weight_np = np.zeros((P,P))\n",
        "        else:\n",
        "            weight_np = np.random.randn(P,P)*0.1*max_epsilon\n",
        "\n",
        "        for i in range(0,P):\n",
        "            filter_index = 0\n",
        "            for j in range(i,P):\n",
        "                if filter_index < len(filter_list):\n",
        "                    weight_np[i][j] = filter_list[filter_index]\n",
        "                    filter_index += 1\n",
        "        return weight_np"
      ],
      "metadata": {
        "id": "usejEx9lUm6G"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "\n",
        "def train(model,x_train,y_train,epochs=10,batch_size=32,alpha=0.3,beta=0.3):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.008)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    torch_dataloader = TorchDataLoader(batch_size)\n",
        "    train_loader = torch_dataloader.torch_dataloader(x_train,y_train)\n",
        "\n",
        "    x_len = x_train.shape[1]\n",
        "    for epoch in range(0,epochs):\n",
        "        model.train()\n",
        "        for batch,(X,Y) in enumerate(train_loader):\n",
        "            h1,c1,h2,c2,h3,c3 = model.init_state(X.shape[0])\n",
        "            out_put,h1,c1,h2,c2,h3,c3 = model(X,h1,c1,h2,c2,h3,c3)\n",
        "\n",
        "            W_mWDN1_H = model.mWDN1_H.weight.data\n",
        "            W_mWDN1_L = model.mWDN1_L.weight.data\n",
        "            W_mWDN2_H = model.mWDN2_H.weight.data\n",
        "            W_mWDN2_L = model.mWDN2_L.weight.data\n",
        "            L_loss = torch.norm((W_mWDN1_L-model.cmp_mWDN1_L),2)+torch.norm((W_mWDN2_L-model.cmp_mWDN2_L),2)\n",
        "            H_loss = torch.norm((W_mWDN1_H-model.cmp_mWDN1_H),2)+torch.norm((W_mWDN2_H-model.cmp_mWDN2_H),2)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(out_put[:,-1,:], Y[:,-1,:]) + alpha*L_loss + beta*H_loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            print('Epoch: ', epoch+1, '| Batch: ',batch+1, '| Loss: ',loss.detach())\n",
        "\n",
        "    torch.save(model, '/content/drive/My Drive/thesis/preprocess/model.pkl')\n",
        "\n",
        "def test(model,x_test,y_test,data_df_combined_clean):\n",
        "    model = torch.load('/content/drive/My Drive/thesis/preprocess/model.pkl')\n",
        "    model.eval()\n",
        "    x_test = ToVariable(x_test).double()\n",
        "    h1,c1,h2,c2,h3,c3= model.init_state(x_test.shape[0])    \n",
        "    seq_len = x_test.shape[1]\n",
        "\n",
        "    pred_dat,h1,c1,h2,c2,h3,c3 =  model(x_test,h1,c1,h2,c2,h3,c3)\n",
        "        \n",
        "    pred_dat=np.array(pred_dat.detach().numpy())\n",
        "\n",
        "    #De-standardize predictions\n",
        "    preds_unstd = pred_dat * data_df_combined_clean.iloc[:,-1].std() + data_df_combined_clean.iloc[:,-1].mean()\n",
        "    y_test_unstd = y_test * data_df_combined_clean.iloc[:,-1].std() + data_df_combined_clean.iloc[:,-1].mean()\n",
        "\n",
        "    mrse = np.sqrt(((preds_unstd[:,-1,:] - y_test_unstd[:,-1,:]) ** 2)).mean(axis=0)\n",
        "    print('The mean square error is: %f' % mrse)\n",
        "    mape = np.mean(np.abs((y_test_unstd[:,-1,:] - preds_unstd[:,-1,:]) / y_test_unstd[:,-1,:])) * 100\n",
        "    print('MAPE is: %f' % mape)\n",
        "\n",
        "    plot_results(preds_unstd[:,-1,:],y_test_unstd[:,-1,:])"
      ],
      "metadata": {
        "id": "0ztGivjTU4uU"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def main():\n",
        "    data_path = '/content/drive/MyDrive/ausdata.csv'\n",
        "    P = 24  #sequence length\n",
        "    step = 6 #ahead predict steps\n",
        "\n",
        "    X_train,Y_train,X_test,Y_test,data_df_combined_clean = load_data(data_path,P=P,step=step)\n",
        "    print(X_train.shape)\n",
        "    print(Y_train.shape)\n",
        "    \n",
        "    model = Wavelet_LSTM(P,100,1)#seq_len, hidden_size,output_size\n",
        "    model = model.double()\n",
        "    train(model,X_train,Y_train,epochs=50)\n",
        "    test(model,X_test,Y_test,data_df_combined_clean)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Vu9s18N30bV7",
        "outputId": "2867caa6-83e5-4a6f-ef30-2dc7b8bdd567"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch:  48 | Batch:  1576 | Loss:  tensor(22.2140, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1577 | Loss:  tensor(22.1910, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1578 | Loss:  tensor(22.2033, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1579 | Loss:  tensor(22.2010, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1580 | Loss:  tensor(22.2086, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1581 | Loss:  tensor(22.2428, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1582 | Loss:  tensor(22.2052, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1583 | Loss:  tensor(22.2364, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1584 | Loss:  tensor(22.2064, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1585 | Loss:  tensor(22.2063, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1586 | Loss:  tensor(22.2215, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1587 | Loss:  tensor(22.2065, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1588 | Loss:  tensor(22.2005, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1589 | Loss:  tensor(22.1994, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1590 | Loss:  tensor(22.1980, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1591 | Loss:  tensor(22.1949, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1592 | Loss:  tensor(22.2072, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1593 | Loss:  tensor(22.2038, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1594 | Loss:  tensor(22.1828, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1595 | Loss:  tensor(22.2027, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1596 | Loss:  tensor(22.2001, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1597 | Loss:  tensor(22.1966, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1598 | Loss:  tensor(22.2172, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1599 | Loss:  tensor(22.2291, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1600 | Loss:  tensor(22.1919, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1601 | Loss:  tensor(22.2219, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1602 | Loss:  tensor(22.2179, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1603 | Loss:  tensor(22.1956, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1604 | Loss:  tensor(22.1925, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1605 | Loss:  tensor(22.1986, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1606 | Loss:  tensor(22.2020, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1607 | Loss:  tensor(22.2081, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1608 | Loss:  tensor(22.2132, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1609 | Loss:  tensor(22.2182, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1610 | Loss:  tensor(22.1921, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1611 | Loss:  tensor(22.2046, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1612 | Loss:  tensor(22.2109, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1613 | Loss:  tensor(22.2204, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1614 | Loss:  tensor(22.2003, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1615 | Loss:  tensor(22.2290, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1616 | Loss:  tensor(22.2343, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1617 | Loss:  tensor(22.2080, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1618 | Loss:  tensor(22.1997, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1619 | Loss:  tensor(22.2025, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1620 | Loss:  tensor(22.2015, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1621 | Loss:  tensor(22.2142, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1622 | Loss:  tensor(22.2122, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1623 | Loss:  tensor(22.2288, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1624 | Loss:  tensor(22.2040, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1625 | Loss:  tensor(22.2281, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1626 | Loss:  tensor(22.2098, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1627 | Loss:  tensor(22.2026, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1628 | Loss:  tensor(22.2297, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1629 | Loss:  tensor(22.2487, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1630 | Loss:  tensor(22.2151, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1631 | Loss:  tensor(22.2240, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1632 | Loss:  tensor(22.2192, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1633 | Loss:  tensor(22.2072, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1634 | Loss:  tensor(22.2028, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1635 | Loss:  tensor(22.2147, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1636 | Loss:  tensor(22.2034, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1637 | Loss:  tensor(22.2289, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1638 | Loss:  tensor(22.2041, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1639 | Loss:  tensor(22.2226, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1640 | Loss:  tensor(22.2061, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1641 | Loss:  tensor(22.2417, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1642 | Loss:  tensor(22.2046, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1643 | Loss:  tensor(22.2032, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1644 | Loss:  tensor(22.2130, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1645 | Loss:  tensor(22.2151, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1646 | Loss:  tensor(22.2199, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1647 | Loss:  tensor(22.2563, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1648 | Loss:  tensor(22.1940, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1649 | Loss:  tensor(22.2152, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1650 | Loss:  tensor(22.2199, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1651 | Loss:  tensor(22.1950, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1652 | Loss:  tensor(22.2196, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1653 | Loss:  tensor(22.2033, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1654 | Loss:  tensor(22.2024, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1655 | Loss:  tensor(22.2194, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1656 | Loss:  tensor(22.1920, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1657 | Loss:  tensor(22.2028, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1658 | Loss:  tensor(22.1865, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1659 | Loss:  tensor(22.2047, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1660 | Loss:  tensor(22.2150, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1661 | Loss:  tensor(22.2009, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1662 | Loss:  tensor(22.2288, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1663 | Loss:  tensor(22.1916, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1664 | Loss:  tensor(22.2051, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1665 | Loss:  tensor(22.2548, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1666 | Loss:  tensor(22.1864, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1667 | Loss:  tensor(22.1991, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1668 | Loss:  tensor(22.2168, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1669 | Loss:  tensor(22.1888, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1670 | Loss:  tensor(22.2014, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1671 | Loss:  tensor(22.2129, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1672 | Loss:  tensor(22.1970, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1673 | Loss:  tensor(22.2043, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1674 | Loss:  tensor(22.2231, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1675 | Loss:  tensor(22.1905, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1676 | Loss:  tensor(22.2055, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1677 | Loss:  tensor(22.2138, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1678 | Loss:  tensor(22.2099, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1679 | Loss:  tensor(22.2103, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1680 | Loss:  tensor(22.2130, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1681 | Loss:  tensor(22.2279, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1682 | Loss:  tensor(22.1987, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1683 | Loss:  tensor(22.2073, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1684 | Loss:  tensor(22.2406, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1685 | Loss:  tensor(22.2233, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1686 | Loss:  tensor(22.2062, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1687 | Loss:  tensor(22.2389, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1688 | Loss:  tensor(22.2077, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1689 | Loss:  tensor(22.2411, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1690 | Loss:  tensor(22.2306, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1691 | Loss:  tensor(22.2228, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1692 | Loss:  tensor(22.2184, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1693 | Loss:  tensor(22.2157, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1694 | Loss:  tensor(22.2313, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1695 | Loss:  tensor(22.2238, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1696 | Loss:  tensor(22.2222, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1697 | Loss:  tensor(22.2282, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1698 | Loss:  tensor(22.2029, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1699 | Loss:  tensor(22.2114, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1700 | Loss:  tensor(22.2241, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1701 | Loss:  tensor(22.2297, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1702 | Loss:  tensor(22.2154, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1703 | Loss:  tensor(22.2232, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1704 | Loss:  tensor(22.2069, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1705 | Loss:  tensor(22.2132, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1706 | Loss:  tensor(22.2333, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1707 | Loss:  tensor(22.2077, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1708 | Loss:  tensor(22.2096, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1709 | Loss:  tensor(22.1979, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1710 | Loss:  tensor(22.2070, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1711 | Loss:  tensor(22.2088, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1712 | Loss:  tensor(22.2153, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1713 | Loss:  tensor(22.2068, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1714 | Loss:  tensor(22.2255, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1715 | Loss:  tensor(22.2012, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1716 | Loss:  tensor(22.2050, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1717 | Loss:  tensor(22.2355, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1718 | Loss:  tensor(22.2158, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1719 | Loss:  tensor(22.2034, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1720 | Loss:  tensor(22.2069, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1721 | Loss:  tensor(22.2279, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1722 | Loss:  tensor(22.2150, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1723 | Loss:  tensor(22.2164, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1724 | Loss:  tensor(22.2060, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1725 | Loss:  tensor(22.2091, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1726 | Loss:  tensor(22.2173, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1727 | Loss:  tensor(22.2131, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1728 | Loss:  tensor(22.2481, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1729 | Loss:  tensor(22.2038, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1730 | Loss:  tensor(22.2134, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1731 | Loss:  tensor(22.2220, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1732 | Loss:  tensor(22.2002, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1733 | Loss:  tensor(22.1998, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1734 | Loss:  tensor(22.2079, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1735 | Loss:  tensor(22.2433, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1736 | Loss:  tensor(22.2186, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1737 | Loss:  tensor(22.2349, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1738 | Loss:  tensor(22.2430, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1739 | Loss:  tensor(22.2531, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1740 | Loss:  tensor(22.2118, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1741 | Loss:  tensor(22.2039, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1742 | Loss:  tensor(22.2191, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1743 | Loss:  tensor(22.2013, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1744 | Loss:  tensor(22.2331, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1745 | Loss:  tensor(22.2051, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1746 | Loss:  tensor(22.2150, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1747 | Loss:  tensor(22.2930, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1748 | Loss:  tensor(22.2067, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1749 | Loss:  tensor(22.2479, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1750 | Loss:  tensor(22.2193, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1751 | Loss:  tensor(22.2184, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1752 | Loss:  tensor(22.2377, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1753 | Loss:  tensor(22.2299, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1754 | Loss:  tensor(22.2378, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1755 | Loss:  tensor(22.2184, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1756 | Loss:  tensor(22.2248, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1757 | Loss:  tensor(22.2182, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1758 | Loss:  tensor(22.2171, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1759 | Loss:  tensor(22.2253, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1760 | Loss:  tensor(22.2088, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1761 | Loss:  tensor(22.2437, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1762 | Loss:  tensor(22.2047, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1763 | Loss:  tensor(22.2072, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1764 | Loss:  tensor(22.2143, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1765 | Loss:  tensor(22.2126, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1766 | Loss:  tensor(22.2107, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1767 | Loss:  tensor(22.2275, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1768 | Loss:  tensor(22.2095, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1769 | Loss:  tensor(22.2013, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1770 | Loss:  tensor(22.2081, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1771 | Loss:  tensor(22.2129, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1772 | Loss:  tensor(22.2114, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1773 | Loss:  tensor(22.2090, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1774 | Loss:  tensor(22.2280, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1775 | Loss:  tensor(22.2335, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1776 | Loss:  tensor(22.2280, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1777 | Loss:  tensor(22.2277, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1778 | Loss:  tensor(22.1998, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1779 | Loss:  tensor(22.2055, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1780 | Loss:  tensor(22.2099, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1781 | Loss:  tensor(22.2323, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1782 | Loss:  tensor(22.2050, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1783 | Loss:  tensor(22.2101, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1784 | Loss:  tensor(22.2203, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1785 | Loss:  tensor(22.2072, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1786 | Loss:  tensor(22.2259, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1787 | Loss:  tensor(22.2014, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1788 | Loss:  tensor(22.2287, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1789 | Loss:  tensor(22.2256, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1790 | Loss:  tensor(22.2216, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1791 | Loss:  tensor(22.2598, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1792 | Loss:  tensor(22.2188, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1793 | Loss:  tensor(22.2313, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1794 | Loss:  tensor(22.2081, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1795 | Loss:  tensor(22.2543, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1796 | Loss:  tensor(22.2634, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1797 | Loss:  tensor(22.2296, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1798 | Loss:  tensor(22.2250, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1799 | Loss:  tensor(22.2367, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1800 | Loss:  tensor(22.2145, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1801 | Loss:  tensor(22.2472, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1802 | Loss:  tensor(22.2327, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1803 | Loss:  tensor(22.2174, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1804 | Loss:  tensor(22.2759, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1805 | Loss:  tensor(22.2220, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1806 | Loss:  tensor(22.2121, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1807 | Loss:  tensor(22.2132, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1808 | Loss:  tensor(22.2158, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1809 | Loss:  tensor(22.2145, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1810 | Loss:  tensor(22.2403, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1811 | Loss:  tensor(22.2172, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1812 | Loss:  tensor(22.2104, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1813 | Loss:  tensor(22.2347, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1814 | Loss:  tensor(22.2223, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1815 | Loss:  tensor(22.2154, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1816 | Loss:  tensor(22.2396, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1817 | Loss:  tensor(22.2413, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1818 | Loss:  tensor(22.2606, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1819 | Loss:  tensor(22.2271, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1820 | Loss:  tensor(22.2255, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1821 | Loss:  tensor(22.2656, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1822 | Loss:  tensor(22.2475, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1823 | Loss:  tensor(22.2133, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1824 | Loss:  tensor(22.2450, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1825 | Loss:  tensor(22.2701, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1826 | Loss:  tensor(22.2219, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1827 | Loss:  tensor(22.2412, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1828 | Loss:  tensor(22.2375, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1829 | Loss:  tensor(22.2248, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1830 | Loss:  tensor(22.2401, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1831 | Loss:  tensor(22.2266, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1832 | Loss:  tensor(22.2674, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1833 | Loss:  tensor(22.2797, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1834 | Loss:  tensor(22.2296, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1835 | Loss:  tensor(22.2208, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1836 | Loss:  tensor(22.2185, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1837 | Loss:  tensor(22.2351, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1838 | Loss:  tensor(22.2241, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1839 | Loss:  tensor(22.2283, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1840 | Loss:  tensor(22.2597, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1841 | Loss:  tensor(22.2426, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1842 | Loss:  tensor(22.2484, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1843 | Loss:  tensor(22.2151, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1844 | Loss:  tensor(22.2401, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1845 | Loss:  tensor(22.2246, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1846 | Loss:  tensor(22.2546, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1847 | Loss:  tensor(22.2297, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1848 | Loss:  tensor(22.2381, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1849 | Loss:  tensor(22.2290, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1850 | Loss:  tensor(22.2278, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1851 | Loss:  tensor(22.2092, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1852 | Loss:  tensor(22.2150, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1853 | Loss:  tensor(22.2230, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1854 | Loss:  tensor(22.2186, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1855 | Loss:  tensor(22.2326, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1856 | Loss:  tensor(22.2282, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1857 | Loss:  tensor(22.2538, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1858 | Loss:  tensor(22.2219, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1859 | Loss:  tensor(22.2277, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1860 | Loss:  tensor(22.2317, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1861 | Loss:  tensor(22.2265, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1862 | Loss:  tensor(22.2313, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1863 | Loss:  tensor(22.2170, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1864 | Loss:  tensor(22.2287, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1865 | Loss:  tensor(22.2364, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1866 | Loss:  tensor(22.2133, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1867 | Loss:  tensor(22.2377, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1868 | Loss:  tensor(22.2427, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1869 | Loss:  tensor(22.2261, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1870 | Loss:  tensor(22.2211, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1871 | Loss:  tensor(22.2354, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1872 | Loss:  tensor(22.2336, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1873 | Loss:  tensor(22.2407, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1874 | Loss:  tensor(22.2317, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1875 | Loss:  tensor(22.2353, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1876 | Loss:  tensor(22.2401, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1877 | Loss:  tensor(22.2363, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1878 | Loss:  tensor(22.2400, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1879 | Loss:  tensor(22.2365, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1880 | Loss:  tensor(22.2724, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1881 | Loss:  tensor(22.2609, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1882 | Loss:  tensor(22.2433, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1883 | Loss:  tensor(22.2389, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1884 | Loss:  tensor(22.2360, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1885 | Loss:  tensor(22.2369, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1886 | Loss:  tensor(22.2281, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1887 | Loss:  tensor(22.2539, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1888 | Loss:  tensor(22.2558, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1889 | Loss:  tensor(22.2390, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1890 | Loss:  tensor(22.2397, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1891 | Loss:  tensor(22.2323, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1892 | Loss:  tensor(22.2478, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1893 | Loss:  tensor(22.2290, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1894 | Loss:  tensor(22.2316, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1895 | Loss:  tensor(22.2313, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1896 | Loss:  tensor(22.2496, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1897 | Loss:  tensor(22.2292, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1898 | Loss:  tensor(22.2883, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1899 | Loss:  tensor(22.2305, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1900 | Loss:  tensor(22.2267, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1901 | Loss:  tensor(22.2472, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1902 | Loss:  tensor(22.2417, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1903 | Loss:  tensor(22.2441, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1904 | Loss:  tensor(22.2236, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1905 | Loss:  tensor(22.2305, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1906 | Loss:  tensor(22.2331, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1907 | Loss:  tensor(22.2267, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1908 | Loss:  tensor(22.2543, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1909 | Loss:  tensor(22.2313, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1910 | Loss:  tensor(22.2073, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1911 | Loss:  tensor(22.2375, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1912 | Loss:  tensor(22.2266, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1913 | Loss:  tensor(22.2140, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1914 | Loss:  tensor(22.2180, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1915 | Loss:  tensor(22.2449, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1916 | Loss:  tensor(22.2264, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1917 | Loss:  tensor(22.2361, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1918 | Loss:  tensor(22.2150, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1919 | Loss:  tensor(22.2180, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1920 | Loss:  tensor(22.2221, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1921 | Loss:  tensor(22.2217, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1922 | Loss:  tensor(22.2092, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1923 | Loss:  tensor(22.2476, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1924 | Loss:  tensor(22.2372, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1925 | Loss:  tensor(22.2275, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1926 | Loss:  tensor(22.2319, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1927 | Loss:  tensor(22.2330, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1928 | Loss:  tensor(22.2286, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1929 | Loss:  tensor(22.2279, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1930 | Loss:  tensor(22.2408, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1931 | Loss:  tensor(22.2630, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1932 | Loss:  tensor(22.2222, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1933 | Loss:  tensor(22.2359, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1934 | Loss:  tensor(22.2462, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1935 | Loss:  tensor(22.2501, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1936 | Loss:  tensor(22.2305, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1937 | Loss:  tensor(22.2211, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1938 | Loss:  tensor(22.2265, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1939 | Loss:  tensor(22.2174, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1940 | Loss:  tensor(22.2463, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1941 | Loss:  tensor(22.2370, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1942 | Loss:  tensor(22.2464, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1943 | Loss:  tensor(22.2585, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1944 | Loss:  tensor(22.2372, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1945 | Loss:  tensor(22.2660, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1946 | Loss:  tensor(22.2210, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1947 | Loss:  tensor(22.2306, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1948 | Loss:  tensor(22.2457, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1949 | Loss:  tensor(22.2289, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1950 | Loss:  tensor(22.2151, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1951 | Loss:  tensor(22.2264, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1952 | Loss:  tensor(22.2261, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1953 | Loss:  tensor(22.2318, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1954 | Loss:  tensor(22.2330, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1955 | Loss:  tensor(22.2243, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1956 | Loss:  tensor(22.2714, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1957 | Loss:  tensor(22.2345, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1958 | Loss:  tensor(22.2409, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1959 | Loss:  tensor(22.2659, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1960 | Loss:  tensor(22.2550, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1961 | Loss:  tensor(22.2411, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1962 | Loss:  tensor(22.2329, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1963 | Loss:  tensor(22.2543, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1964 | Loss:  tensor(22.2232, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1965 | Loss:  tensor(22.2463, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1966 | Loss:  tensor(22.2302, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1967 | Loss:  tensor(22.2232, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1968 | Loss:  tensor(22.2590, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1969 | Loss:  tensor(22.2369, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1970 | Loss:  tensor(22.2221, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1971 | Loss:  tensor(22.2470, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1972 | Loss:  tensor(22.2276, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1973 | Loss:  tensor(22.2477, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1974 | Loss:  tensor(22.2360, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1975 | Loss:  tensor(22.2359, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1976 | Loss:  tensor(22.2209, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1977 | Loss:  tensor(22.2284, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1978 | Loss:  tensor(22.2258, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1979 | Loss:  tensor(22.2497, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1980 | Loss:  tensor(22.2325, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1981 | Loss:  tensor(22.2480, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1982 | Loss:  tensor(22.2454, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1983 | Loss:  tensor(22.2334, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1984 | Loss:  tensor(22.2338, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1985 | Loss:  tensor(22.2300, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1986 | Loss:  tensor(22.2327, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1987 | Loss:  tensor(22.2372, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1988 | Loss:  tensor(22.2163, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1989 | Loss:  tensor(22.2402, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1990 | Loss:  tensor(22.2362, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1991 | Loss:  tensor(22.2421, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1992 | Loss:  tensor(22.2346, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1993 | Loss:  tensor(22.2431, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1994 | Loss:  tensor(22.2524, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1995 | Loss:  tensor(22.2265, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1996 | Loss:  tensor(22.2533, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1997 | Loss:  tensor(22.2414, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1998 | Loss:  tensor(22.2630, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  1999 | Loss:  tensor(22.2383, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2000 | Loss:  tensor(22.2278, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2001 | Loss:  tensor(22.2345, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2002 | Loss:  tensor(22.2415, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2003 | Loss:  tensor(22.2255, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2004 | Loss:  tensor(22.2469, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2005 | Loss:  tensor(22.2593, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2006 | Loss:  tensor(22.2381, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2007 | Loss:  tensor(22.2343, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2008 | Loss:  tensor(22.2343, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2009 | Loss:  tensor(22.2875, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2010 | Loss:  tensor(22.2381, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2011 | Loss:  tensor(22.2682, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2012 | Loss:  tensor(22.2693, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2013 | Loss:  tensor(22.2501, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2014 | Loss:  tensor(22.2471, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2015 | Loss:  tensor(22.2352, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2016 | Loss:  tensor(22.2382, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2017 | Loss:  tensor(22.2513, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2018 | Loss:  tensor(22.2554, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2019 | Loss:  tensor(22.2444, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2020 | Loss:  tensor(22.2421, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2021 | Loss:  tensor(22.2524, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2022 | Loss:  tensor(22.2218, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2023 | Loss:  tensor(22.2311, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2024 | Loss:  tensor(22.2349, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2025 | Loss:  tensor(22.2263, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2026 | Loss:  tensor(22.2298, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2027 | Loss:  tensor(22.2365, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2028 | Loss:  tensor(22.2325, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2029 | Loss:  tensor(22.2306, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2030 | Loss:  tensor(22.2262, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2031 | Loss:  tensor(22.2298, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2032 | Loss:  tensor(22.2305, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2033 | Loss:  tensor(22.2681, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2034 | Loss:  tensor(22.2223, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2035 | Loss:  tensor(22.2417, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2036 | Loss:  tensor(22.2582, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2037 | Loss:  tensor(22.2837, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2038 | Loss:  tensor(22.2322, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2039 | Loss:  tensor(22.2616, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2040 | Loss:  tensor(22.2333, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2041 | Loss:  tensor(22.2353, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2042 | Loss:  tensor(22.2385, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2043 | Loss:  tensor(22.2258, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2044 | Loss:  tensor(22.2301, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2045 | Loss:  tensor(22.2349, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2046 | Loss:  tensor(22.2208, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2047 | Loss:  tensor(22.2448, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2048 | Loss:  tensor(22.2334, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2049 | Loss:  tensor(22.2513, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2050 | Loss:  tensor(22.2339, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2051 | Loss:  tensor(22.2244, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2052 | Loss:  tensor(22.2352, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2053 | Loss:  tensor(22.2562, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2054 | Loss:  tensor(22.2283, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2055 | Loss:  tensor(22.2397, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2056 | Loss:  tensor(22.2559, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2057 | Loss:  tensor(22.2479, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2058 | Loss:  tensor(22.2501, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2059 | Loss:  tensor(22.2610, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2060 | Loss:  tensor(22.2291, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2061 | Loss:  tensor(22.2244, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2062 | Loss:  tensor(22.2599, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2063 | Loss:  tensor(22.2488, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2064 | Loss:  tensor(22.2562, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2065 | Loss:  tensor(22.2304, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2066 | Loss:  tensor(22.2377, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2067 | Loss:  tensor(22.2460, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2068 | Loss:  tensor(22.2466, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2069 | Loss:  tensor(22.2623, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2070 | Loss:  tensor(22.2616, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2071 | Loss:  tensor(22.2597, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2072 | Loss:  tensor(22.2549, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2073 | Loss:  tensor(22.2590, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2074 | Loss:  tensor(22.2408, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2075 | Loss:  tensor(22.2415, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2076 | Loss:  tensor(22.2340, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2077 | Loss:  tensor(22.2547, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2078 | Loss:  tensor(22.2442, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2079 | Loss:  tensor(22.2624, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2080 | Loss:  tensor(22.2619, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2081 | Loss:  tensor(22.2341, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2082 | Loss:  tensor(22.2588, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2083 | Loss:  tensor(22.2643, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2084 | Loss:  tensor(22.2409, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2085 | Loss:  tensor(22.2557, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2086 | Loss:  tensor(22.2481, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2087 | Loss:  tensor(22.2972, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2088 | Loss:  tensor(22.2630, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2089 | Loss:  tensor(22.2529, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2090 | Loss:  tensor(22.2403, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2091 | Loss:  tensor(22.2467, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2092 | Loss:  tensor(22.2514, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2093 | Loss:  tensor(22.2568, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2094 | Loss:  tensor(22.2340, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2095 | Loss:  tensor(22.2483, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2096 | Loss:  tensor(22.2532, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2097 | Loss:  tensor(22.2440, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2098 | Loss:  tensor(22.2724, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2099 | Loss:  tensor(22.2665, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2100 | Loss:  tensor(22.2477, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2101 | Loss:  tensor(22.2568, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2102 | Loss:  tensor(22.2497, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2103 | Loss:  tensor(22.2468, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2104 | Loss:  tensor(22.2565, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2105 | Loss:  tensor(22.2597, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2106 | Loss:  tensor(22.2575, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2107 | Loss:  tensor(22.2530, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2108 | Loss:  tensor(22.2340, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2109 | Loss:  tensor(22.2316, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2110 | Loss:  tensor(22.2381, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2111 | Loss:  tensor(22.2564, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2112 | Loss:  tensor(22.3073, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2113 | Loss:  tensor(22.2415, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2114 | Loss:  tensor(22.2536, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2115 | Loss:  tensor(22.2505, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2116 | Loss:  tensor(22.2594, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2117 | Loss:  tensor(22.2667, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2118 | Loss:  tensor(22.2722, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2119 | Loss:  tensor(22.2604, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2120 | Loss:  tensor(22.2581, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2121 | Loss:  tensor(22.2560, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2122 | Loss:  tensor(22.2719, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2123 | Loss:  tensor(22.2783, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2124 | Loss:  tensor(22.2446, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2125 | Loss:  tensor(22.2454, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2126 | Loss:  tensor(22.2612, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2127 | Loss:  tensor(22.2443, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2128 | Loss:  tensor(22.2671, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2129 | Loss:  tensor(22.2903, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2130 | Loss:  tensor(22.2460, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2131 | Loss:  tensor(22.2400, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2132 | Loss:  tensor(22.2463, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2133 | Loss:  tensor(22.2617, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2134 | Loss:  tensor(22.2499, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2135 | Loss:  tensor(22.2419, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2136 | Loss:  tensor(22.2358, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2137 | Loss:  tensor(22.2668, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2138 | Loss:  tensor(22.2474, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2139 | Loss:  tensor(22.2653, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2140 | Loss:  tensor(22.2378, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2141 | Loss:  tensor(22.2722, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2142 | Loss:  tensor(22.2705, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2143 | Loss:  tensor(22.2515, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2144 | Loss:  tensor(22.2318, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2145 | Loss:  tensor(22.2383, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2146 | Loss:  tensor(22.2339, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2147 | Loss:  tensor(22.2365, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2148 | Loss:  tensor(22.2424, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2149 | Loss:  tensor(22.2503, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2150 | Loss:  tensor(22.2413, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2151 | Loss:  tensor(22.2397, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2152 | Loss:  tensor(22.2764, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2153 | Loss:  tensor(22.2589, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2154 | Loss:  tensor(22.2691, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2155 | Loss:  tensor(22.2523, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2156 | Loss:  tensor(22.2750, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2157 | Loss:  tensor(22.2875, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2158 | Loss:  tensor(22.2511, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2159 | Loss:  tensor(22.2471, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2160 | Loss:  tensor(22.2452, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2161 | Loss:  tensor(22.2532, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2162 | Loss:  tensor(22.2644, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2163 | Loss:  tensor(22.2477, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2164 | Loss:  tensor(22.2618, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2165 | Loss:  tensor(22.2894, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2166 | Loss:  tensor(22.2438, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2167 | Loss:  tensor(22.2623, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2168 | Loss:  tensor(22.2737, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2169 | Loss:  tensor(22.2793, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2170 | Loss:  tensor(22.2514, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2171 | Loss:  tensor(22.2493, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2172 | Loss:  tensor(22.2442, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2173 | Loss:  tensor(22.2728, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2174 | Loss:  tensor(22.2674, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2175 | Loss:  tensor(22.2749, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2176 | Loss:  tensor(22.2899, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2177 | Loss:  tensor(22.2569, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2178 | Loss:  tensor(22.2760, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2179 | Loss:  tensor(22.2542, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2180 | Loss:  tensor(22.2428, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2181 | Loss:  tensor(22.2578, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2182 | Loss:  tensor(22.2656, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2183 | Loss:  tensor(22.2542, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2184 | Loss:  tensor(22.2576, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2185 | Loss:  tensor(22.2662, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2186 | Loss:  tensor(22.2619, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2187 | Loss:  tensor(22.2562, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2188 | Loss:  tensor(22.2978, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2189 | Loss:  tensor(22.2661, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2190 | Loss:  tensor(22.2738, dtype=torch.float64)\n",
            "Epoch:  48 | Batch:  2191 | Loss:  tensor(22.2575, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1 | Loss:  tensor(22.2568, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2 | Loss:  tensor(22.2621, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  3 | Loss:  tensor(22.2689, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  4 | Loss:  tensor(22.2596, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  5 | Loss:  tensor(22.2618, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  6 | Loss:  tensor(22.2562, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  7 | Loss:  tensor(22.2393, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  8 | Loss:  tensor(22.2607, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  9 | Loss:  tensor(22.2411, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  10 | Loss:  tensor(22.2360, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  11 | Loss:  tensor(22.2563, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  12 | Loss:  tensor(22.2708, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  13 | Loss:  tensor(22.2687, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  14 | Loss:  tensor(22.2613, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  15 | Loss:  tensor(22.2638, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  16 | Loss:  tensor(22.2511, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  17 | Loss:  tensor(22.2683, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  18 | Loss:  tensor(22.2695, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  19 | Loss:  tensor(22.2623, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  20 | Loss:  tensor(22.2560, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  21 | Loss:  tensor(22.2541, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  22 | Loss:  tensor(22.2722, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  23 | Loss:  tensor(22.2368, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  24 | Loss:  tensor(22.2505, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  25 | Loss:  tensor(22.2422, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  26 | Loss:  tensor(22.2623, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  27 | Loss:  tensor(22.2391, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  28 | Loss:  tensor(22.2434, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  29 | Loss:  tensor(22.2611, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  30 | Loss:  tensor(22.2538, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  31 | Loss:  tensor(22.2559, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  32 | Loss:  tensor(22.2420, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  33 | Loss:  tensor(22.2585, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  34 | Loss:  tensor(22.2522, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  35 | Loss:  tensor(22.2337, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  36 | Loss:  tensor(22.2782, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  37 | Loss:  tensor(22.2620, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  38 | Loss:  tensor(22.2595, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  39 | Loss:  tensor(22.2551, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  40 | Loss:  tensor(22.2633, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  41 | Loss:  tensor(22.3143, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  42 | Loss:  tensor(22.2474, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  43 | Loss:  tensor(22.2614, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  44 | Loss:  tensor(22.2595, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  45 | Loss:  tensor(22.2499, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  46 | Loss:  tensor(22.2460, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  47 | Loss:  tensor(22.2758, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  48 | Loss:  tensor(22.2350, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  49 | Loss:  tensor(22.2335, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  50 | Loss:  tensor(22.2408, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  51 | Loss:  tensor(22.2545, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  52 | Loss:  tensor(22.2517, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  53 | Loss:  tensor(22.2614, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  54 | Loss:  tensor(22.2697, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  55 | Loss:  tensor(22.2558, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  56 | Loss:  tensor(22.2616, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  57 | Loss:  tensor(22.2548, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  58 | Loss:  tensor(22.2411, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  59 | Loss:  tensor(22.2751, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  60 | Loss:  tensor(22.2598, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  61 | Loss:  tensor(22.2823, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  62 | Loss:  tensor(22.2654, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  63 | Loss:  tensor(22.2549, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  64 | Loss:  tensor(22.2843, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  65 | Loss:  tensor(22.2537, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  66 | Loss:  tensor(22.2868, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  67 | Loss:  tensor(22.2524, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  68 | Loss:  tensor(22.2591, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  69 | Loss:  tensor(22.2633, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  70 | Loss:  tensor(22.2544, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  71 | Loss:  tensor(22.2779, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  72 | Loss:  tensor(22.2836, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  73 | Loss:  tensor(22.2782, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  74 | Loss:  tensor(22.2593, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  75 | Loss:  tensor(22.2548, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  76 | Loss:  tensor(22.2683, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  77 | Loss:  tensor(22.2658, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  78 | Loss:  tensor(22.2534, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  79 | Loss:  tensor(22.2479, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  80 | Loss:  tensor(22.2800, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  81 | Loss:  tensor(22.2524, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  82 | Loss:  tensor(22.2495, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  83 | Loss:  tensor(22.2481, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  84 | Loss:  tensor(22.2492, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  85 | Loss:  tensor(22.2724, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  86 | Loss:  tensor(22.2683, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  87 | Loss:  tensor(22.2539, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  88 | Loss:  tensor(22.2732, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  89 | Loss:  tensor(22.2600, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  90 | Loss:  tensor(22.2859, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  91 | Loss:  tensor(22.2813, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  92 | Loss:  tensor(22.2560, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  93 | Loss:  tensor(22.2505, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  94 | Loss:  tensor(22.2876, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  95 | Loss:  tensor(22.2736, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  96 | Loss:  tensor(22.2641, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  97 | Loss:  tensor(22.2631, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  98 | Loss:  tensor(22.2756, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  99 | Loss:  tensor(22.2608, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  100 | Loss:  tensor(22.2569, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  101 | Loss:  tensor(22.2722, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  102 | Loss:  tensor(22.2819, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  103 | Loss:  tensor(22.2856, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  104 | Loss:  tensor(22.2587, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  105 | Loss:  tensor(22.2752, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  106 | Loss:  tensor(22.2559, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  107 | Loss:  tensor(22.2742, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  108 | Loss:  tensor(22.2634, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  109 | Loss:  tensor(22.2626, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  110 | Loss:  tensor(22.2753, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  111 | Loss:  tensor(22.2798, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  112 | Loss:  tensor(22.2735, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  113 | Loss:  tensor(22.2743, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  114 | Loss:  tensor(22.2791, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  115 | Loss:  tensor(22.3078, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  116 | Loss:  tensor(22.2594, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  117 | Loss:  tensor(22.2655, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  118 | Loss:  tensor(22.2599, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  119 | Loss:  tensor(22.2675, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  120 | Loss:  tensor(22.3060, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  121 | Loss:  tensor(22.2590, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  122 | Loss:  tensor(22.2786, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  123 | Loss:  tensor(22.2589, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  124 | Loss:  tensor(22.2551, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  125 | Loss:  tensor(22.2829, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  126 | Loss:  tensor(22.2597, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  127 | Loss:  tensor(22.2767, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  128 | Loss:  tensor(22.2624, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  129 | Loss:  tensor(22.2591, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  130 | Loss:  tensor(22.2618, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  131 | Loss:  tensor(22.2639, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  132 | Loss:  tensor(22.3019, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  133 | Loss:  tensor(22.2403, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  134 | Loss:  tensor(22.2489, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  135 | Loss:  tensor(22.2815, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  136 | Loss:  tensor(22.2644, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  137 | Loss:  tensor(22.2940, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  138 | Loss:  tensor(22.2623, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  139 | Loss:  tensor(22.2621, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  140 | Loss:  tensor(22.2503, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  141 | Loss:  tensor(22.2916, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  142 | Loss:  tensor(22.2591, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  143 | Loss:  tensor(22.2538, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  144 | Loss:  tensor(22.2780, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  145 | Loss:  tensor(22.2638, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  146 | Loss:  tensor(22.2814, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  147 | Loss:  tensor(22.2640, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  148 | Loss:  tensor(22.2495, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  149 | Loss:  tensor(22.2536, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  150 | Loss:  tensor(22.2635, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  151 | Loss:  tensor(22.2660, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  152 | Loss:  tensor(22.2596, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  153 | Loss:  tensor(22.2545, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  154 | Loss:  tensor(22.2511, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  155 | Loss:  tensor(22.2544, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  156 | Loss:  tensor(22.2632, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  157 | Loss:  tensor(22.2594, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  158 | Loss:  tensor(22.2558, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  159 | Loss:  tensor(22.2761, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  160 | Loss:  tensor(22.2838, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  161 | Loss:  tensor(22.2690, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  162 | Loss:  tensor(22.2784, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  163 | Loss:  tensor(22.2578, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  164 | Loss:  tensor(22.2730, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  165 | Loss:  tensor(22.2593, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  166 | Loss:  tensor(22.2639, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  167 | Loss:  tensor(22.2735, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  168 | Loss:  tensor(22.2938, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  169 | Loss:  tensor(22.2619, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  170 | Loss:  tensor(22.2695, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  171 | Loss:  tensor(22.2620, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  172 | Loss:  tensor(22.2597, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  173 | Loss:  tensor(22.2964, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  174 | Loss:  tensor(22.2577, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  175 | Loss:  tensor(22.2639, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  176 | Loss:  tensor(22.2840, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  177 | Loss:  tensor(22.2702, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  178 | Loss:  tensor(22.2739, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  179 | Loss:  tensor(22.2801, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  180 | Loss:  tensor(22.2960, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  181 | Loss:  tensor(22.2537, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  182 | Loss:  tensor(22.2485, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  183 | Loss:  tensor(22.2707, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  184 | Loss:  tensor(22.2600, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  185 | Loss:  tensor(22.2611, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  186 | Loss:  tensor(22.2773, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  187 | Loss:  tensor(22.2600, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  188 | Loss:  tensor(22.2921, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  189 | Loss:  tensor(22.2777, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  190 | Loss:  tensor(22.3180, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  191 | Loss:  tensor(22.2533, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  192 | Loss:  tensor(22.2596, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  193 | Loss:  tensor(22.2973, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  194 | Loss:  tensor(22.2659, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  195 | Loss:  tensor(22.2691, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  196 | Loss:  tensor(22.2903, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  197 | Loss:  tensor(22.2735, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  198 | Loss:  tensor(22.2748, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  199 | Loss:  tensor(22.2800, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  200 | Loss:  tensor(22.2641, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  201 | Loss:  tensor(22.2818, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  202 | Loss:  tensor(22.2684, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  203 | Loss:  tensor(22.2810, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  204 | Loss:  tensor(22.2594, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  205 | Loss:  tensor(22.2716, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  206 | Loss:  tensor(22.2697, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  207 | Loss:  tensor(22.2608, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  208 | Loss:  tensor(22.2748, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  209 | Loss:  tensor(22.2710, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  210 | Loss:  tensor(22.2781, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  211 | Loss:  tensor(22.2928, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  212 | Loss:  tensor(22.2948, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  213 | Loss:  tensor(22.2641, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  214 | Loss:  tensor(22.2816, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  215 | Loss:  tensor(22.2818, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  216 | Loss:  tensor(22.2800, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  217 | Loss:  tensor(22.2928, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  218 | Loss:  tensor(22.2799, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  219 | Loss:  tensor(22.2644, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  220 | Loss:  tensor(22.2786, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  221 | Loss:  tensor(22.2818, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  222 | Loss:  tensor(22.2982, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  223 | Loss:  tensor(22.3328, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  224 | Loss:  tensor(22.2898, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  225 | Loss:  tensor(22.3094, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  226 | Loss:  tensor(22.3100, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  227 | Loss:  tensor(22.3286, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  228 | Loss:  tensor(22.2717, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  229 | Loss:  tensor(22.2718, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  230 | Loss:  tensor(22.2884, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  231 | Loss:  tensor(22.2977, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  232 | Loss:  tensor(22.2815, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  233 | Loss:  tensor(22.2851, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  234 | Loss:  tensor(22.2784, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  235 | Loss:  tensor(22.2722, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  236 | Loss:  tensor(22.2758, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  237 | Loss:  tensor(22.2745, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  238 | Loss:  tensor(22.2770, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  239 | Loss:  tensor(22.3084, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  240 | Loss:  tensor(22.2786, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  241 | Loss:  tensor(22.2957, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  242 | Loss:  tensor(22.2736, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  243 | Loss:  tensor(22.2866, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  244 | Loss:  tensor(22.2980, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  245 | Loss:  tensor(22.2739, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  246 | Loss:  tensor(22.2775, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  247 | Loss:  tensor(22.3102, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  248 | Loss:  tensor(22.2785, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  249 | Loss:  tensor(22.2696, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  250 | Loss:  tensor(22.2777, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  251 | Loss:  tensor(22.3010, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  252 | Loss:  tensor(22.2811, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  253 | Loss:  tensor(22.2923, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  254 | Loss:  tensor(22.2752, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  255 | Loss:  tensor(22.2849, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  256 | Loss:  tensor(22.2832, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  257 | Loss:  tensor(22.2817, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  258 | Loss:  tensor(22.3224, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  259 | Loss:  tensor(22.2910, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  260 | Loss:  tensor(22.3087, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  261 | Loss:  tensor(22.2934, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  262 | Loss:  tensor(22.3030, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  263 | Loss:  tensor(22.3098, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  264 | Loss:  tensor(22.3089, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  265 | Loss:  tensor(22.2843, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  266 | Loss:  tensor(22.2794, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  267 | Loss:  tensor(22.2993, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  268 | Loss:  tensor(22.2899, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  269 | Loss:  tensor(22.2836, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  270 | Loss:  tensor(22.2967, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  271 | Loss:  tensor(22.2726, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  272 | Loss:  tensor(22.3036, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  273 | Loss:  tensor(22.2984, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  274 | Loss:  tensor(22.3019, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  275 | Loss:  tensor(22.3105, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  276 | Loss:  tensor(22.2865, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  277 | Loss:  tensor(22.3076, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  278 | Loss:  tensor(22.3025, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  279 | Loss:  tensor(22.2894, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  280 | Loss:  tensor(22.3085, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  281 | Loss:  tensor(22.3515, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  282 | Loss:  tensor(22.2785, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  283 | Loss:  tensor(22.2837, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  284 | Loss:  tensor(22.2947, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  285 | Loss:  tensor(22.2834, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  286 | Loss:  tensor(22.2893, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  287 | Loss:  tensor(22.3022, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  288 | Loss:  tensor(22.3031, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  289 | Loss:  tensor(22.3298, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  290 | Loss:  tensor(22.2864, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  291 | Loss:  tensor(22.2683, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  292 | Loss:  tensor(22.2944, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  293 | Loss:  tensor(22.3007, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  294 | Loss:  tensor(22.2814, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  295 | Loss:  tensor(22.3315, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  296 | Loss:  tensor(22.2733, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  297 | Loss:  tensor(22.2882, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  298 | Loss:  tensor(22.2745, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  299 | Loss:  tensor(22.2853, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  300 | Loss:  tensor(22.2787, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  301 | Loss:  tensor(22.2919, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  302 | Loss:  tensor(22.2690, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  303 | Loss:  tensor(22.2781, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  304 | Loss:  tensor(22.2708, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  305 | Loss:  tensor(22.2731, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  306 | Loss:  tensor(22.2871, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  307 | Loss:  tensor(22.2891, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  308 | Loss:  tensor(22.2805, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  309 | Loss:  tensor(22.2749, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  310 | Loss:  tensor(22.2738, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  311 | Loss:  tensor(22.2863, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  312 | Loss:  tensor(22.2842, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  313 | Loss:  tensor(22.2645, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  314 | Loss:  tensor(22.3016, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  315 | Loss:  tensor(22.2768, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  316 | Loss:  tensor(22.2676, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  317 | Loss:  tensor(22.2877, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  318 | Loss:  tensor(22.2741, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  319 | Loss:  tensor(22.2937, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  320 | Loss:  tensor(22.2717, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  321 | Loss:  tensor(22.2681, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  322 | Loss:  tensor(22.2714, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  323 | Loss:  tensor(22.2738, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  324 | Loss:  tensor(22.2795, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  325 | Loss:  tensor(22.2786, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  326 | Loss:  tensor(22.2841, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  327 | Loss:  tensor(22.2988, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  328 | Loss:  tensor(22.2676, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  329 | Loss:  tensor(22.2995, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  330 | Loss:  tensor(22.3015, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  331 | Loss:  tensor(22.3002, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  332 | Loss:  tensor(22.2681, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  333 | Loss:  tensor(22.2889, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  334 | Loss:  tensor(22.2819, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  335 | Loss:  tensor(22.2871, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  336 | Loss:  tensor(22.2938, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  337 | Loss:  tensor(22.2884, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  338 | Loss:  tensor(22.2970, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  339 | Loss:  tensor(22.3042, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  340 | Loss:  tensor(22.2870, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  341 | Loss:  tensor(22.2835, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  342 | Loss:  tensor(22.2821, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  343 | Loss:  tensor(22.2902, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  344 | Loss:  tensor(22.3016, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  345 | Loss:  tensor(22.2739, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  346 | Loss:  tensor(22.2786, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  347 | Loss:  tensor(22.2775, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  348 | Loss:  tensor(22.2916, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  349 | Loss:  tensor(22.2755, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  350 | Loss:  tensor(22.2777, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  351 | Loss:  tensor(22.2993, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  352 | Loss:  tensor(22.2635, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  353 | Loss:  tensor(22.2726, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  354 | Loss:  tensor(22.2721, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  355 | Loss:  tensor(22.2729, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  356 | Loss:  tensor(22.2742, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  357 | Loss:  tensor(22.2697, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  358 | Loss:  tensor(22.2869, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  359 | Loss:  tensor(22.3198, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  360 | Loss:  tensor(22.2626, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  361 | Loss:  tensor(22.2778, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  362 | Loss:  tensor(22.2924, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  363 | Loss:  tensor(22.3055, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  364 | Loss:  tensor(22.2792, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  365 | Loss:  tensor(22.2861, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  366 | Loss:  tensor(22.2731, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  367 | Loss:  tensor(22.3010, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  368 | Loss:  tensor(22.2690, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  369 | Loss:  tensor(22.2791, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  370 | Loss:  tensor(22.2773, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  371 | Loss:  tensor(22.2833, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  372 | Loss:  tensor(22.2748, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  373 | Loss:  tensor(22.2751, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  374 | Loss:  tensor(22.2903, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  375 | Loss:  tensor(22.2769, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  376 | Loss:  tensor(22.2862, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  377 | Loss:  tensor(22.2927, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  378 | Loss:  tensor(22.2932, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  379 | Loss:  tensor(22.2829, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  380 | Loss:  tensor(22.2992, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  381 | Loss:  tensor(22.2803, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  382 | Loss:  tensor(22.2791, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  383 | Loss:  tensor(22.2777, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  384 | Loss:  tensor(22.2811, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  385 | Loss:  tensor(22.2764, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  386 | Loss:  tensor(22.2659, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  387 | Loss:  tensor(22.3004, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  388 | Loss:  tensor(22.2821, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  389 | Loss:  tensor(22.2939, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  390 | Loss:  tensor(22.2873, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  391 | Loss:  tensor(22.2757, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  392 | Loss:  tensor(22.2835, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  393 | Loss:  tensor(22.2846, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  394 | Loss:  tensor(22.2883, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  395 | Loss:  tensor(22.2885, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  396 | Loss:  tensor(22.2712, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  397 | Loss:  tensor(22.2959, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  398 | Loss:  tensor(22.2829, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  399 | Loss:  tensor(22.2737, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  400 | Loss:  tensor(22.2729, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  401 | Loss:  tensor(22.2532, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  402 | Loss:  tensor(22.2968, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  403 | Loss:  tensor(22.3049, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  404 | Loss:  tensor(22.2826, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  405 | Loss:  tensor(22.2958, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  406 | Loss:  tensor(22.2698, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  407 | Loss:  tensor(22.2683, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  408 | Loss:  tensor(22.2868, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  409 | Loss:  tensor(22.2891, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  410 | Loss:  tensor(22.2635, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  411 | Loss:  tensor(22.2731, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  412 | Loss:  tensor(22.2683, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  413 | Loss:  tensor(22.2854, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  414 | Loss:  tensor(22.2812, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  415 | Loss:  tensor(22.2574, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  416 | Loss:  tensor(22.2771, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  417 | Loss:  tensor(22.2742, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  418 | Loss:  tensor(22.2593, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  419 | Loss:  tensor(22.2570, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  420 | Loss:  tensor(22.2997, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  421 | Loss:  tensor(22.2779, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  422 | Loss:  tensor(22.2711, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  423 | Loss:  tensor(22.2969, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  424 | Loss:  tensor(22.2891, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  425 | Loss:  tensor(22.2713, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  426 | Loss:  tensor(22.2813, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  427 | Loss:  tensor(22.2896, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  428 | Loss:  tensor(22.2825, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  429 | Loss:  tensor(22.3006, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  430 | Loss:  tensor(22.2654, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  431 | Loss:  tensor(22.3069, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  432 | Loss:  tensor(22.2869, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  433 | Loss:  tensor(22.2580, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  434 | Loss:  tensor(22.2907, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  435 | Loss:  tensor(22.2634, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  436 | Loss:  tensor(22.2709, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  437 | Loss:  tensor(22.2835, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  438 | Loss:  tensor(22.2862, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  439 | Loss:  tensor(22.2676, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  440 | Loss:  tensor(22.2588, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  441 | Loss:  tensor(22.2689, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  442 | Loss:  tensor(22.2595, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  443 | Loss:  tensor(22.2962, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  444 | Loss:  tensor(22.3001, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  445 | Loss:  tensor(22.2871, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  446 | Loss:  tensor(22.2805, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  447 | Loss:  tensor(22.2670, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  448 | Loss:  tensor(22.2698, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  449 | Loss:  tensor(22.3123, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  450 | Loss:  tensor(22.2927, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  451 | Loss:  tensor(22.3115, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  452 | Loss:  tensor(22.2905, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  453 | Loss:  tensor(22.2748, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  454 | Loss:  tensor(22.2827, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  455 | Loss:  tensor(22.2731, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  456 | Loss:  tensor(22.2713, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  457 | Loss:  tensor(22.2695, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  458 | Loss:  tensor(22.2669, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  459 | Loss:  tensor(22.2659, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  460 | Loss:  tensor(22.2778, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  461 | Loss:  tensor(22.2754, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  462 | Loss:  tensor(22.3199, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  463 | Loss:  tensor(22.2699, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  464 | Loss:  tensor(22.2755, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  465 | Loss:  tensor(22.3063, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  466 | Loss:  tensor(22.2621, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  467 | Loss:  tensor(22.2723, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  468 | Loss:  tensor(22.2767, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  469 | Loss:  tensor(22.2663, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  470 | Loss:  tensor(22.2645, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  471 | Loss:  tensor(22.2685, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  472 | Loss:  tensor(22.2605, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  473 | Loss:  tensor(22.2701, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  474 | Loss:  tensor(22.2627, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  475 | Loss:  tensor(22.2828, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  476 | Loss:  tensor(22.2975, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  477 | Loss:  tensor(22.2731, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  478 | Loss:  tensor(22.2891, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  479 | Loss:  tensor(22.2801, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  480 | Loss:  tensor(22.3045, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  481 | Loss:  tensor(22.2651, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  482 | Loss:  tensor(22.2945, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  483 | Loss:  tensor(22.2854, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  484 | Loss:  tensor(22.2828, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  485 | Loss:  tensor(22.2915, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  486 | Loss:  tensor(22.2737, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  487 | Loss:  tensor(22.2880, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  488 | Loss:  tensor(22.2922, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  489 | Loss:  tensor(22.2771, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  490 | Loss:  tensor(22.2672, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  491 | Loss:  tensor(22.2940, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  492 | Loss:  tensor(22.2668, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  493 | Loss:  tensor(22.2783, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  494 | Loss:  tensor(22.2630, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  495 | Loss:  tensor(22.2823, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  496 | Loss:  tensor(22.2801, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  497 | Loss:  tensor(22.2927, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  498 | Loss:  tensor(22.2643, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  499 | Loss:  tensor(22.2964, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  500 | Loss:  tensor(22.2657, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  501 | Loss:  tensor(22.2733, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  502 | Loss:  tensor(22.3048, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  503 | Loss:  tensor(22.2799, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  504 | Loss:  tensor(22.2604, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  505 | Loss:  tensor(22.2730, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  506 | Loss:  tensor(22.3141, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  507 | Loss:  tensor(22.2783, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  508 | Loss:  tensor(22.2718, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  509 | Loss:  tensor(22.3035, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  510 | Loss:  tensor(22.2921, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  511 | Loss:  tensor(22.2797, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  512 | Loss:  tensor(22.2792, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  513 | Loss:  tensor(22.2798, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  514 | Loss:  tensor(22.2922, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  515 | Loss:  tensor(22.2872, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  516 | Loss:  tensor(22.2895, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  517 | Loss:  tensor(22.2638, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  518 | Loss:  tensor(22.2860, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  519 | Loss:  tensor(22.2749, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  520 | Loss:  tensor(22.2807, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  521 | Loss:  tensor(22.2662, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  522 | Loss:  tensor(22.2732, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  523 | Loss:  tensor(22.2768, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  524 | Loss:  tensor(22.2675, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  525 | Loss:  tensor(22.2697, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  526 | Loss:  tensor(22.2744, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  527 | Loss:  tensor(22.2758, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  528 | Loss:  tensor(22.2763, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  529 | Loss:  tensor(22.3391, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  530 | Loss:  tensor(22.2899, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  531 | Loss:  tensor(22.2710, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  532 | Loss:  tensor(22.3006, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  533 | Loss:  tensor(22.2758, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  534 | Loss:  tensor(22.3016, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  535 | Loss:  tensor(22.2904, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  536 | Loss:  tensor(22.3000, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  537 | Loss:  tensor(22.2920, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  538 | Loss:  tensor(22.3336, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  539 | Loss:  tensor(22.3066, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  540 | Loss:  tensor(22.2980, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  541 | Loss:  tensor(22.2992, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  542 | Loss:  tensor(22.3154, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  543 | Loss:  tensor(22.3111, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  544 | Loss:  tensor(22.2922, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  545 | Loss:  tensor(22.3639, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  546 | Loss:  tensor(22.3077, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  547 | Loss:  tensor(22.3147, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  548 | Loss:  tensor(22.2990, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  549 | Loss:  tensor(22.3243, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  550 | Loss:  tensor(22.2932, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  551 | Loss:  tensor(22.2871, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  552 | Loss:  tensor(22.2987, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  553 | Loss:  tensor(22.3164, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  554 | Loss:  tensor(22.3126, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  555 | Loss:  tensor(22.2858, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  556 | Loss:  tensor(22.3062, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  557 | Loss:  tensor(22.3191, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  558 | Loss:  tensor(22.2938, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  559 | Loss:  tensor(22.2878, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  560 | Loss:  tensor(22.2887, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  561 | Loss:  tensor(22.3119, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  562 | Loss:  tensor(22.3353, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  563 | Loss:  tensor(22.2983, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  564 | Loss:  tensor(22.2991, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  565 | Loss:  tensor(22.2948, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  566 | Loss:  tensor(22.2892, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  567 | Loss:  tensor(22.2998, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  568 | Loss:  tensor(22.3011, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  569 | Loss:  tensor(22.3195, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  570 | Loss:  tensor(22.2918, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  571 | Loss:  tensor(22.2928, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  572 | Loss:  tensor(22.3036, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  573 | Loss:  tensor(22.2948, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  574 | Loss:  tensor(22.2924, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  575 | Loss:  tensor(22.2879, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  576 | Loss:  tensor(22.2780, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  577 | Loss:  tensor(22.3113, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  578 | Loss:  tensor(22.3120, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  579 | Loss:  tensor(22.2931, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  580 | Loss:  tensor(22.2968, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  581 | Loss:  tensor(22.2889, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  582 | Loss:  tensor(22.2878, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  583 | Loss:  tensor(22.2866, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  584 | Loss:  tensor(22.2975, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  585 | Loss:  tensor(22.3324, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  586 | Loss:  tensor(22.2881, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  587 | Loss:  tensor(22.3037, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  588 | Loss:  tensor(22.3197, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  589 | Loss:  tensor(22.3002, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  590 | Loss:  tensor(22.2903, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  591 | Loss:  tensor(22.3035, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  592 | Loss:  tensor(22.2979, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  593 | Loss:  tensor(22.3206, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  594 | Loss:  tensor(22.3019, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  595 | Loss:  tensor(22.3015, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  596 | Loss:  tensor(22.3084, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  597 | Loss:  tensor(22.3209, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  598 | Loss:  tensor(22.3049, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  599 | Loss:  tensor(22.3176, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  600 | Loss:  tensor(22.3059, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  601 | Loss:  tensor(22.3217, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  602 | Loss:  tensor(22.3024, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  603 | Loss:  tensor(22.2996, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  604 | Loss:  tensor(22.3012, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  605 | Loss:  tensor(22.3081, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  606 | Loss:  tensor(22.2935, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  607 | Loss:  tensor(22.3095, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  608 | Loss:  tensor(22.2956, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  609 | Loss:  tensor(22.2866, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  610 | Loss:  tensor(22.3088, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  611 | Loss:  tensor(22.3415, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  612 | Loss:  tensor(22.3137, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  613 | Loss:  tensor(22.3043, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  614 | Loss:  tensor(22.3102, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  615 | Loss:  tensor(22.3094, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  616 | Loss:  tensor(22.2988, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  617 | Loss:  tensor(22.3538, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  618 | Loss:  tensor(22.3129, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  619 | Loss:  tensor(22.2960, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  620 | Loss:  tensor(22.3032, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  621 | Loss:  tensor(22.3120, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  622 | Loss:  tensor(22.3071, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  623 | Loss:  tensor(22.2913, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  624 | Loss:  tensor(22.3095, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  625 | Loss:  tensor(22.3032, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  626 | Loss:  tensor(22.3045, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  627 | Loss:  tensor(22.2840, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  628 | Loss:  tensor(22.3102, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  629 | Loss:  tensor(22.2944, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  630 | Loss:  tensor(22.2955, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  631 | Loss:  tensor(22.2935, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  632 | Loss:  tensor(22.3030, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  633 | Loss:  tensor(22.3017, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  634 | Loss:  tensor(22.3311, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  635 | Loss:  tensor(22.3141, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  636 | Loss:  tensor(22.3162, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  637 | Loss:  tensor(22.3206, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  638 | Loss:  tensor(22.3006, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  639 | Loss:  tensor(22.2982, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  640 | Loss:  tensor(22.3136, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  641 | Loss:  tensor(22.2990, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  642 | Loss:  tensor(22.2991, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  643 | Loss:  tensor(22.2900, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  644 | Loss:  tensor(22.3293, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  645 | Loss:  tensor(22.3144, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  646 | Loss:  tensor(22.3048, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  647 | Loss:  tensor(22.3014, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  648 | Loss:  tensor(22.3181, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  649 | Loss:  tensor(22.3229, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  650 | Loss:  tensor(22.2965, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  651 | Loss:  tensor(22.3678, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  652 | Loss:  tensor(22.3309, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  653 | Loss:  tensor(22.3074, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  654 | Loss:  tensor(22.2880, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  655 | Loss:  tensor(22.3008, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  656 | Loss:  tensor(22.3400, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  657 | Loss:  tensor(22.3159, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  658 | Loss:  tensor(22.3280, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  659 | Loss:  tensor(22.3311, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  660 | Loss:  tensor(22.3336, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  661 | Loss:  tensor(22.3411, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  662 | Loss:  tensor(22.2944, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  663 | Loss:  tensor(22.2951, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  664 | Loss:  tensor(22.2971, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  665 | Loss:  tensor(22.3915, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  666 | Loss:  tensor(22.3010, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  667 | Loss:  tensor(22.3163, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  668 | Loss:  tensor(22.3130, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  669 | Loss:  tensor(22.3023, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  670 | Loss:  tensor(22.3069, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  671 | Loss:  tensor(22.3089, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  672 | Loss:  tensor(22.3171, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  673 | Loss:  tensor(22.3004, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  674 | Loss:  tensor(22.3105, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  675 | Loss:  tensor(22.3030, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  676 | Loss:  tensor(22.3088, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  677 | Loss:  tensor(22.2944, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  678 | Loss:  tensor(22.3001, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  679 | Loss:  tensor(22.3153, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  680 | Loss:  tensor(22.3458, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  681 | Loss:  tensor(22.3133, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  682 | Loss:  tensor(22.3055, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  683 | Loss:  tensor(22.3167, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  684 | Loss:  tensor(22.3122, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  685 | Loss:  tensor(22.3250, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  686 | Loss:  tensor(22.3145, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  687 | Loss:  tensor(22.2976, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  688 | Loss:  tensor(22.3187, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  689 | Loss:  tensor(22.3340, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  690 | Loss:  tensor(22.3726, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  691 | Loss:  tensor(22.3107, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  692 | Loss:  tensor(22.3069, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  693 | Loss:  tensor(22.3023, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  694 | Loss:  tensor(22.3183, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  695 | Loss:  tensor(22.3109, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  696 | Loss:  tensor(22.3135, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  697 | Loss:  tensor(22.3232, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  698 | Loss:  tensor(22.3265, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  699 | Loss:  tensor(22.3313, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  700 | Loss:  tensor(22.3217, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  701 | Loss:  tensor(22.3073, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  702 | Loss:  tensor(22.3260, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  703 | Loss:  tensor(22.3264, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  704 | Loss:  tensor(22.3032, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  705 | Loss:  tensor(22.3230, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  706 | Loss:  tensor(22.2950, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  707 | Loss:  tensor(22.3183, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  708 | Loss:  tensor(22.2983, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  709 | Loss:  tensor(22.3325, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  710 | Loss:  tensor(22.3183, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  711 | Loss:  tensor(22.3181, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  712 | Loss:  tensor(22.3273, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  713 | Loss:  tensor(22.3455, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  714 | Loss:  tensor(22.3482, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  715 | Loss:  tensor(22.3145, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  716 | Loss:  tensor(22.3062, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  717 | Loss:  tensor(22.3152, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  718 | Loss:  tensor(22.3217, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  719 | Loss:  tensor(22.3275, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  720 | Loss:  tensor(22.3227, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  721 | Loss:  tensor(22.3188, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  722 | Loss:  tensor(22.3140, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  723 | Loss:  tensor(22.3297, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  724 | Loss:  tensor(22.3171, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  725 | Loss:  tensor(22.3254, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  726 | Loss:  tensor(22.3270, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  727 | Loss:  tensor(22.3181, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  728 | Loss:  tensor(22.3117, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  729 | Loss:  tensor(22.2992, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  730 | Loss:  tensor(22.2956, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  731 | Loss:  tensor(22.2944, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  732 | Loss:  tensor(22.3116, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  733 | Loss:  tensor(22.3085, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  734 | Loss:  tensor(22.3175, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  735 | Loss:  tensor(22.3012, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  736 | Loss:  tensor(22.3085, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  737 | Loss:  tensor(22.2854, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  738 | Loss:  tensor(22.3024, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  739 | Loss:  tensor(22.3309, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  740 | Loss:  tensor(22.3178, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  741 | Loss:  tensor(22.3006, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  742 | Loss:  tensor(22.3001, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  743 | Loss:  tensor(22.3155, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  744 | Loss:  tensor(22.3110, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  745 | Loss:  tensor(22.3112, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  746 | Loss:  tensor(22.3016, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  747 | Loss:  tensor(22.2912, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  748 | Loss:  tensor(22.3299, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  749 | Loss:  tensor(22.3155, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  750 | Loss:  tensor(22.3295, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  751 | Loss:  tensor(22.3052, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  752 | Loss:  tensor(22.3170, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  753 | Loss:  tensor(22.3046, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  754 | Loss:  tensor(22.3062, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  755 | Loss:  tensor(22.3083, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  756 | Loss:  tensor(22.3081, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  757 | Loss:  tensor(22.3105, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  758 | Loss:  tensor(22.3098, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  759 | Loss:  tensor(22.3124, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  760 | Loss:  tensor(22.3258, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  761 | Loss:  tensor(22.3220, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  762 | Loss:  tensor(22.3331, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  763 | Loss:  tensor(22.3131, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  764 | Loss:  tensor(22.3256, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  765 | Loss:  tensor(22.3004, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  766 | Loss:  tensor(22.3101, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  767 | Loss:  tensor(22.3263, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  768 | Loss:  tensor(22.3293, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  769 | Loss:  tensor(22.3087, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  770 | Loss:  tensor(22.3002, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  771 | Loss:  tensor(22.3181, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  772 | Loss:  tensor(22.3149, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  773 | Loss:  tensor(22.3002, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  774 | Loss:  tensor(22.3386, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  775 | Loss:  tensor(22.3375, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  776 | Loss:  tensor(22.3337, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  777 | Loss:  tensor(22.3090, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  778 | Loss:  tensor(22.3086, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  779 | Loss:  tensor(22.3136, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  780 | Loss:  tensor(22.3420, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  781 | Loss:  tensor(22.3167, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  782 | Loss:  tensor(22.3427, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  783 | Loss:  tensor(22.3123, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  784 | Loss:  tensor(22.3200, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  785 | Loss:  tensor(22.3265, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  786 | Loss:  tensor(22.3092, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  787 | Loss:  tensor(22.3161, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  788 | Loss:  tensor(22.3144, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  789 | Loss:  tensor(22.3305, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  790 | Loss:  tensor(22.3181, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  791 | Loss:  tensor(22.3317, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  792 | Loss:  tensor(22.3160, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  793 | Loss:  tensor(22.3054, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  794 | Loss:  tensor(22.3261, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  795 | Loss:  tensor(22.3103, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  796 | Loss:  tensor(22.3499, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  797 | Loss:  tensor(22.3377, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  798 | Loss:  tensor(22.3159, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  799 | Loss:  tensor(22.3448, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  800 | Loss:  tensor(22.3271, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  801 | Loss:  tensor(22.3215, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  802 | Loss:  tensor(22.3058, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  803 | Loss:  tensor(22.3280, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  804 | Loss:  tensor(22.3189, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  805 | Loss:  tensor(22.3182, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  806 | Loss:  tensor(22.3403, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  807 | Loss:  tensor(22.3297, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  808 | Loss:  tensor(22.3336, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  809 | Loss:  tensor(22.3257, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  810 | Loss:  tensor(22.3116, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  811 | Loss:  tensor(22.3297, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  812 | Loss:  tensor(22.3275, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  813 | Loss:  tensor(22.3264, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  814 | Loss:  tensor(22.3238, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  815 | Loss:  tensor(22.3471, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  816 | Loss:  tensor(22.3513, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  817 | Loss:  tensor(22.3592, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  818 | Loss:  tensor(22.3119, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  819 | Loss:  tensor(22.3444, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  820 | Loss:  tensor(22.3126, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  821 | Loss:  tensor(22.3377, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  822 | Loss:  tensor(22.3277, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  823 | Loss:  tensor(22.3126, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  824 | Loss:  tensor(22.3219, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  825 | Loss:  tensor(22.3694, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  826 | Loss:  tensor(22.3444, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  827 | Loss:  tensor(22.3241, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  828 | Loss:  tensor(22.3177, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  829 | Loss:  tensor(22.3296, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  830 | Loss:  tensor(22.3514, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  831 | Loss:  tensor(22.3103, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  832 | Loss:  tensor(22.3178, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  833 | Loss:  tensor(22.3307, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  834 | Loss:  tensor(22.3391, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  835 | Loss:  tensor(22.3183, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  836 | Loss:  tensor(22.3179, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  837 | Loss:  tensor(22.3334, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  838 | Loss:  tensor(22.3195, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  839 | Loss:  tensor(22.3363, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  840 | Loss:  tensor(22.3201, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  841 | Loss:  tensor(22.3247, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  842 | Loss:  tensor(22.3303, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  843 | Loss:  tensor(22.3140, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  844 | Loss:  tensor(22.3201, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  845 | Loss:  tensor(22.3265, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  846 | Loss:  tensor(22.3194, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  847 | Loss:  tensor(22.3341, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  848 | Loss:  tensor(22.3130, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  849 | Loss:  tensor(22.3557, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  850 | Loss:  tensor(22.3105, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  851 | Loss:  tensor(22.3305, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  852 | Loss:  tensor(22.3423, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  853 | Loss:  tensor(22.3371, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  854 | Loss:  tensor(22.3289, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  855 | Loss:  tensor(22.3277, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  856 | Loss:  tensor(22.3287, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  857 | Loss:  tensor(22.3181, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  858 | Loss:  tensor(22.3425, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  859 | Loss:  tensor(22.3325, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  860 | Loss:  tensor(22.3233, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  861 | Loss:  tensor(22.3513, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  862 | Loss:  tensor(22.3219, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  863 | Loss:  tensor(22.3327, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  864 | Loss:  tensor(22.3270, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  865 | Loss:  tensor(22.3465, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  866 | Loss:  tensor(22.3312, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  867 | Loss:  tensor(22.3268, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  868 | Loss:  tensor(22.3185, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  869 | Loss:  tensor(22.3274, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  870 | Loss:  tensor(22.3165, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  871 | Loss:  tensor(22.3380, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  872 | Loss:  tensor(22.3073, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  873 | Loss:  tensor(22.3451, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  874 | Loss:  tensor(22.3088, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  875 | Loss:  tensor(22.3270, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  876 | Loss:  tensor(22.3184, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  877 | Loss:  tensor(22.3210, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  878 | Loss:  tensor(22.3236, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  879 | Loss:  tensor(22.3368, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  880 | Loss:  tensor(22.3308, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  881 | Loss:  tensor(22.3071, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  882 | Loss:  tensor(22.3757, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  883 | Loss:  tensor(22.3227, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  884 | Loss:  tensor(22.3334, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  885 | Loss:  tensor(22.3262, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  886 | Loss:  tensor(22.3232, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  887 | Loss:  tensor(22.3392, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  888 | Loss:  tensor(22.3236, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  889 | Loss:  tensor(22.3221, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  890 | Loss:  tensor(22.3184, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  891 | Loss:  tensor(22.3353, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  892 | Loss:  tensor(22.3468, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  893 | Loss:  tensor(22.3290, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  894 | Loss:  tensor(22.3212, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  895 | Loss:  tensor(22.3255, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  896 | Loss:  tensor(22.3074, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  897 | Loss:  tensor(22.3023, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  898 | Loss:  tensor(22.3481, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  899 | Loss:  tensor(22.3332, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  900 | Loss:  tensor(22.3261, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  901 | Loss:  tensor(22.3176, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  902 | Loss:  tensor(22.3311, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  903 | Loss:  tensor(22.3331, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  904 | Loss:  tensor(22.3403, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  905 | Loss:  tensor(22.3367, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  906 | Loss:  tensor(22.3211, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  907 | Loss:  tensor(22.3317, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  908 | Loss:  tensor(22.3277, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  909 | Loss:  tensor(22.3328, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  910 | Loss:  tensor(22.3157, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  911 | Loss:  tensor(22.3482, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  912 | Loss:  tensor(22.3162, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  913 | Loss:  tensor(22.3322, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  914 | Loss:  tensor(22.3155, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  915 | Loss:  tensor(22.3415, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  916 | Loss:  tensor(22.3208, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  917 | Loss:  tensor(22.3083, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  918 | Loss:  tensor(22.3369, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  919 | Loss:  tensor(22.3025, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  920 | Loss:  tensor(22.3344, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  921 | Loss:  tensor(22.3092, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  922 | Loss:  tensor(22.3096, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  923 | Loss:  tensor(22.3289, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  924 | Loss:  tensor(22.3185, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  925 | Loss:  tensor(22.3165, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  926 | Loss:  tensor(22.3144, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  927 | Loss:  tensor(22.3081, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  928 | Loss:  tensor(22.3028, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  929 | Loss:  tensor(22.3263, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  930 | Loss:  tensor(22.3002, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  931 | Loss:  tensor(22.3183, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  932 | Loss:  tensor(22.3248, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  933 | Loss:  tensor(22.2993, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  934 | Loss:  tensor(22.3191, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  935 | Loss:  tensor(22.3149, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  936 | Loss:  tensor(22.3308, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  937 | Loss:  tensor(22.3307, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  938 | Loss:  tensor(22.3193, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  939 | Loss:  tensor(22.3554, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  940 | Loss:  tensor(22.3101, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  941 | Loss:  tensor(22.3413, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  942 | Loss:  tensor(22.3141, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  943 | Loss:  tensor(22.3212, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  944 | Loss:  tensor(22.3278, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  945 | Loss:  tensor(22.3215, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  946 | Loss:  tensor(22.3453, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  947 | Loss:  tensor(22.3333, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  948 | Loss:  tensor(22.3365, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  949 | Loss:  tensor(22.3187, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  950 | Loss:  tensor(22.3577, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  951 | Loss:  tensor(22.3765, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  952 | Loss:  tensor(22.3129, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  953 | Loss:  tensor(22.3069, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  954 | Loss:  tensor(22.3316, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  955 | Loss:  tensor(22.3313, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  956 | Loss:  tensor(22.3412, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  957 | Loss:  tensor(22.2951, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  958 | Loss:  tensor(22.3267, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  959 | Loss:  tensor(22.3067, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  960 | Loss:  tensor(22.3106, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  961 | Loss:  tensor(22.3192, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  962 | Loss:  tensor(22.3079, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  963 | Loss:  tensor(22.3122, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  964 | Loss:  tensor(22.3342, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  965 | Loss:  tensor(22.3192, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  966 | Loss:  tensor(22.3654, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  967 | Loss:  tensor(22.3318, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  968 | Loss:  tensor(22.3111, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  969 | Loss:  tensor(22.3464, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  970 | Loss:  tensor(22.3273, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  971 | Loss:  tensor(22.3220, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  972 | Loss:  tensor(22.3148, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  973 | Loss:  tensor(22.3556, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  974 | Loss:  tensor(22.3698, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  975 | Loss:  tensor(22.3241, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  976 | Loss:  tensor(22.3686, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  977 | Loss:  tensor(22.3808, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  978 | Loss:  tensor(22.3152, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  979 | Loss:  tensor(22.3238, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  980 | Loss:  tensor(22.3524, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  981 | Loss:  tensor(22.3162, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  982 | Loss:  tensor(22.3218, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  983 | Loss:  tensor(22.3282, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  984 | Loss:  tensor(22.3206, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  985 | Loss:  tensor(22.3264, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  986 | Loss:  tensor(22.3193, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  987 | Loss:  tensor(22.3211, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  988 | Loss:  tensor(22.3197, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  989 | Loss:  tensor(22.3327, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  990 | Loss:  tensor(22.3209, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  991 | Loss:  tensor(22.3513, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  992 | Loss:  tensor(22.3268, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  993 | Loss:  tensor(22.3336, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  994 | Loss:  tensor(22.3100, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  995 | Loss:  tensor(22.3317, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  996 | Loss:  tensor(22.3003, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  997 | Loss:  tensor(22.3105, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  998 | Loss:  tensor(22.3128, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  999 | Loss:  tensor(22.3138, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1000 | Loss:  tensor(22.3271, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1001 | Loss:  tensor(22.3062, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1002 | Loss:  tensor(22.3298, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1003 | Loss:  tensor(22.3641, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1004 | Loss:  tensor(22.3140, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1005 | Loss:  tensor(22.3355, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1006 | Loss:  tensor(22.3398, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1007 | Loss:  tensor(22.3267, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1008 | Loss:  tensor(22.3125, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1009 | Loss:  tensor(22.3345, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1010 | Loss:  tensor(22.3135, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1011 | Loss:  tensor(22.3105, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1012 | Loss:  tensor(22.3206, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1013 | Loss:  tensor(22.3374, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1014 | Loss:  tensor(22.3242, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1015 | Loss:  tensor(22.3785, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1016 | Loss:  tensor(22.3299, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1017 | Loss:  tensor(22.3553, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1018 | Loss:  tensor(22.3164, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1019 | Loss:  tensor(22.3388, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1020 | Loss:  tensor(22.3109, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1021 | Loss:  tensor(22.3197, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1022 | Loss:  tensor(22.3150, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1023 | Loss:  tensor(22.3119, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1024 | Loss:  tensor(22.3187, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1025 | Loss:  tensor(22.3513, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1026 | Loss:  tensor(22.3352, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1027 | Loss:  tensor(22.3007, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1028 | Loss:  tensor(22.3145, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1029 | Loss:  tensor(22.3236, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1030 | Loss:  tensor(22.3211, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1031 | Loss:  tensor(22.3036, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1032 | Loss:  tensor(22.3156, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1033 | Loss:  tensor(22.3166, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1034 | Loss:  tensor(22.3182, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1035 | Loss:  tensor(22.3215, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1036 | Loss:  tensor(22.3208, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1037 | Loss:  tensor(22.3062, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1038 | Loss:  tensor(22.3064, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1039 | Loss:  tensor(22.3159, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1040 | Loss:  tensor(22.3409, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1041 | Loss:  tensor(22.3258, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1042 | Loss:  tensor(22.3089, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1043 | Loss:  tensor(22.3207, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1044 | Loss:  tensor(22.3419, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1045 | Loss:  tensor(22.3110, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1046 | Loss:  tensor(22.3120, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1047 | Loss:  tensor(22.3457, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1048 | Loss:  tensor(22.3230, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1049 | Loss:  tensor(22.3447, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1050 | Loss:  tensor(22.3089, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1051 | Loss:  tensor(22.2980, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1052 | Loss:  tensor(22.3318, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1053 | Loss:  tensor(22.3271, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1054 | Loss:  tensor(22.3156, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1055 | Loss:  tensor(22.3267, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1056 | Loss:  tensor(22.3144, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1057 | Loss:  tensor(22.3230, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1058 | Loss:  tensor(22.3162, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1059 | Loss:  tensor(22.2945, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1060 | Loss:  tensor(22.3433, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1061 | Loss:  tensor(22.3371, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1062 | Loss:  tensor(22.3242, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1063 | Loss:  tensor(22.3203, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1064 | Loss:  tensor(22.3138, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1065 | Loss:  tensor(22.3410, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1066 | Loss:  tensor(22.3123, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1067 | Loss:  tensor(22.3021, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1068 | Loss:  tensor(22.3520, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1069 | Loss:  tensor(22.3045, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1070 | Loss:  tensor(22.3290, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1071 | Loss:  tensor(22.3376, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1072 | Loss:  tensor(22.3262, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1073 | Loss:  tensor(22.3211, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1074 | Loss:  tensor(22.3287, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1075 | Loss:  tensor(22.3300, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1076 | Loss:  tensor(22.3192, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1077 | Loss:  tensor(22.3135, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1078 | Loss:  tensor(22.3070, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1079 | Loss:  tensor(22.3159, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1080 | Loss:  tensor(22.3298, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1081 | Loss:  tensor(22.3059, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1082 | Loss:  tensor(22.3109, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1083 | Loss:  tensor(22.3470, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1084 | Loss:  tensor(22.3026, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1085 | Loss:  tensor(22.2989, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1086 | Loss:  tensor(22.3155, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1087 | Loss:  tensor(22.3205, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1088 | Loss:  tensor(22.3191, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1089 | Loss:  tensor(22.3385, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1090 | Loss:  tensor(22.3191, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1091 | Loss:  tensor(22.3196, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1092 | Loss:  tensor(22.3237, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1093 | Loss:  tensor(22.3436, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1094 | Loss:  tensor(22.3508, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1095 | Loss:  tensor(22.3313, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1096 | Loss:  tensor(22.3174, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1097 | Loss:  tensor(22.3369, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1098 | Loss:  tensor(22.3219, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1099 | Loss:  tensor(22.3157, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1100 | Loss:  tensor(22.3057, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1101 | Loss:  tensor(22.3302, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1102 | Loss:  tensor(22.3056, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1103 | Loss:  tensor(22.3140, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1104 | Loss:  tensor(22.3693, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1105 | Loss:  tensor(22.3028, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1106 | Loss:  tensor(22.3425, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1107 | Loss:  tensor(22.3313, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1108 | Loss:  tensor(22.3153, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1109 | Loss:  tensor(22.3125, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1110 | Loss:  tensor(22.3202, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1111 | Loss:  tensor(22.3259, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1112 | Loss:  tensor(22.3211, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1113 | Loss:  tensor(22.3197, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1114 | Loss:  tensor(22.3191, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1115 | Loss:  tensor(22.3293, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1116 | Loss:  tensor(22.3043, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1117 | Loss:  tensor(22.3316, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1118 | Loss:  tensor(22.3271, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1119 | Loss:  tensor(22.3337, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1120 | Loss:  tensor(22.3353, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1121 | Loss:  tensor(22.3436, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1122 | Loss:  tensor(22.3193, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1123 | Loss:  tensor(22.3251, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1124 | Loss:  tensor(22.3323, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1125 | Loss:  tensor(22.3291, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1126 | Loss:  tensor(22.3235, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1127 | Loss:  tensor(22.3199, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1128 | Loss:  tensor(22.3346, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1129 | Loss:  tensor(22.3261, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1130 | Loss:  tensor(22.3214, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1131 | Loss:  tensor(22.3349, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1132 | Loss:  tensor(22.3260, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1133 | Loss:  tensor(22.3481, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1134 | Loss:  tensor(22.3511, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1135 | Loss:  tensor(22.3167, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1136 | Loss:  tensor(22.3301, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1137 | Loss:  tensor(22.3284, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1138 | Loss:  tensor(22.3159, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1139 | Loss:  tensor(22.3194, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1140 | Loss:  tensor(22.3219, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1141 | Loss:  tensor(22.3159, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1142 | Loss:  tensor(22.3260, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1143 | Loss:  tensor(22.3257, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1144 | Loss:  tensor(22.3513, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1145 | Loss:  tensor(22.3351, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1146 | Loss:  tensor(22.3285, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1147 | Loss:  tensor(22.3183, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1148 | Loss:  tensor(22.3258, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1149 | Loss:  tensor(22.3437, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1150 | Loss:  tensor(22.3249, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1151 | Loss:  tensor(22.3029, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1152 | Loss:  tensor(22.3376, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1153 | Loss:  tensor(22.3267, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1154 | Loss:  tensor(22.3185, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1155 | Loss:  tensor(22.3070, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1156 | Loss:  tensor(22.3178, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1157 | Loss:  tensor(22.3073, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1158 | Loss:  tensor(22.3253, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1159 | Loss:  tensor(22.3207, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1160 | Loss:  tensor(22.3437, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1161 | Loss:  tensor(22.3177, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1162 | Loss:  tensor(22.3379, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1163 | Loss:  tensor(22.3257, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1164 | Loss:  tensor(22.3345, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1165 | Loss:  tensor(22.3256, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1166 | Loss:  tensor(22.3192, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1167 | Loss:  tensor(22.3082, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1168 | Loss:  tensor(22.3300, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1169 | Loss:  tensor(22.3224, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1170 | Loss:  tensor(22.3042, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1171 | Loss:  tensor(22.3370, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1172 | Loss:  tensor(22.3181, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1173 | Loss:  tensor(22.3213, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1174 | Loss:  tensor(22.3448, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1175 | Loss:  tensor(22.3218, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1176 | Loss:  tensor(22.3237, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1177 | Loss:  tensor(22.3401, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1178 | Loss:  tensor(22.3126, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1179 | Loss:  tensor(22.3238, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1180 | Loss:  tensor(22.3634, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1181 | Loss:  tensor(22.3342, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1182 | Loss:  tensor(22.3228, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1183 | Loss:  tensor(22.3256, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1184 | Loss:  tensor(22.3257, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1185 | Loss:  tensor(22.3450, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1186 | Loss:  tensor(22.3314, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1187 | Loss:  tensor(22.3324, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1188 | Loss:  tensor(22.3141, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1189 | Loss:  tensor(22.3240, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1190 | Loss:  tensor(22.3446, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1191 | Loss:  tensor(22.3294, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1192 | Loss:  tensor(22.3276, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1193 | Loss:  tensor(22.3374, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1194 | Loss:  tensor(22.3681, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1195 | Loss:  tensor(22.3292, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1196 | Loss:  tensor(22.3340, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1197 | Loss:  tensor(22.3491, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1198 | Loss:  tensor(22.3370, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1199 | Loss:  tensor(22.3431, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1200 | Loss:  tensor(22.3306, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1201 | Loss:  tensor(22.3383, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1202 | Loss:  tensor(22.3365, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1203 | Loss:  tensor(22.3331, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1204 | Loss:  tensor(22.3269, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1205 | Loss:  tensor(22.3178, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1206 | Loss:  tensor(22.3287, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1207 | Loss:  tensor(22.3800, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1208 | Loss:  tensor(22.3784, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1209 | Loss:  tensor(22.3306, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1210 | Loss:  tensor(22.3339, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1211 | Loss:  tensor(22.3437, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1212 | Loss:  tensor(22.3750, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1213 | Loss:  tensor(22.3273, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1214 | Loss:  tensor(22.3480, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1215 | Loss:  tensor(22.3160, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1216 | Loss:  tensor(22.3596, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1217 | Loss:  tensor(22.3515, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1218 | Loss:  tensor(22.3302, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1219 | Loss:  tensor(22.3323, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1220 | Loss:  tensor(22.3625, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1221 | Loss:  tensor(22.3258, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1222 | Loss:  tensor(22.3267, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1223 | Loss:  tensor(22.3525, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1224 | Loss:  tensor(22.3475, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1225 | Loss:  tensor(22.3501, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1226 | Loss:  tensor(22.3559, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1227 | Loss:  tensor(22.3359, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1228 | Loss:  tensor(22.3308, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1229 | Loss:  tensor(22.3316, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1230 | Loss:  tensor(22.3561, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1231 | Loss:  tensor(22.3760, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1232 | Loss:  tensor(22.3436, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1233 | Loss:  tensor(22.3311, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1234 | Loss:  tensor(22.3335, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1235 | Loss:  tensor(22.3403, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1236 | Loss:  tensor(22.3498, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1237 | Loss:  tensor(22.3309, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1238 | Loss:  tensor(22.3355, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1239 | Loss:  tensor(22.3366, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1240 | Loss:  tensor(22.3601, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1241 | Loss:  tensor(22.3289, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1242 | Loss:  tensor(22.3454, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1243 | Loss:  tensor(22.3533, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1244 | Loss:  tensor(22.3254, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1245 | Loss:  tensor(22.3534, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1246 | Loss:  tensor(22.3451, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1247 | Loss:  tensor(22.3488, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1248 | Loss:  tensor(22.3416, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1249 | Loss:  tensor(22.3315, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1250 | Loss:  tensor(22.3326, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1251 | Loss:  tensor(22.3380, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1252 | Loss:  tensor(22.3378, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1253 | Loss:  tensor(22.3369, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1254 | Loss:  tensor(22.3205, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1255 | Loss:  tensor(22.3381, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1256 | Loss:  tensor(22.3172, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1257 | Loss:  tensor(22.3471, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1258 | Loss:  tensor(22.3342, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1259 | Loss:  tensor(22.3492, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1260 | Loss:  tensor(22.3340, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1261 | Loss:  tensor(22.3496, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1262 | Loss:  tensor(22.3321, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1263 | Loss:  tensor(22.3457, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1264 | Loss:  tensor(22.3375, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1265 | Loss:  tensor(22.3538, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1266 | Loss:  tensor(22.3393, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1267 | Loss:  tensor(22.3501, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1268 | Loss:  tensor(22.3300, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1269 | Loss:  tensor(22.3364, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1270 | Loss:  tensor(22.3293, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1271 | Loss:  tensor(22.3340, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1272 | Loss:  tensor(22.3338, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1273 | Loss:  tensor(22.3475, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1274 | Loss:  tensor(22.4238, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1275 | Loss:  tensor(22.3480, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1276 | Loss:  tensor(22.3538, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1277 | Loss:  tensor(22.3404, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1278 | Loss:  tensor(22.3393, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1279 | Loss:  tensor(22.3402, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1280 | Loss:  tensor(22.3390, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1281 | Loss:  tensor(22.3418, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1282 | Loss:  tensor(22.3318, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1283 | Loss:  tensor(22.3377, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1284 | Loss:  tensor(22.3585, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1285 | Loss:  tensor(22.3215, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1286 | Loss:  tensor(22.3763, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1287 | Loss:  tensor(22.3666, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1288 | Loss:  tensor(22.3465, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1289 | Loss:  tensor(22.3272, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1290 | Loss:  tensor(22.3403, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1291 | Loss:  tensor(22.3320, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1292 | Loss:  tensor(22.3528, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1293 | Loss:  tensor(22.3460, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1294 | Loss:  tensor(22.3419, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1295 | Loss:  tensor(22.3498, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1296 | Loss:  tensor(22.3375, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1297 | Loss:  tensor(22.3461, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1298 | Loss:  tensor(22.3502, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1299 | Loss:  tensor(22.3180, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1300 | Loss:  tensor(22.3351, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1301 | Loss:  tensor(22.3295, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1302 | Loss:  tensor(22.3261, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1303 | Loss:  tensor(22.3392, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1304 | Loss:  tensor(22.3672, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1305 | Loss:  tensor(22.3618, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1306 | Loss:  tensor(22.3593, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1307 | Loss:  tensor(22.3329, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1308 | Loss:  tensor(22.3372, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1309 | Loss:  tensor(22.3307, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1310 | Loss:  tensor(22.3557, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1311 | Loss:  tensor(22.3502, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1312 | Loss:  tensor(22.3188, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1313 | Loss:  tensor(22.3366, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1314 | Loss:  tensor(22.3244, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1315 | Loss:  tensor(22.3412, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1316 | Loss:  tensor(22.3154, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1317 | Loss:  tensor(22.3273, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1318 | Loss:  tensor(22.3397, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1319 | Loss:  tensor(22.3385, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1320 | Loss:  tensor(22.3265, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1321 | Loss:  tensor(22.3599, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1322 | Loss:  tensor(22.3678, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1323 | Loss:  tensor(22.3461, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1324 | Loss:  tensor(22.3263, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1325 | Loss:  tensor(22.3264, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1326 | Loss:  tensor(22.3504, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1327 | Loss:  tensor(22.3269, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1328 | Loss:  tensor(22.3530, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1329 | Loss:  tensor(22.3459, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1330 | Loss:  tensor(22.3423, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1331 | Loss:  tensor(22.3326, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1332 | Loss:  tensor(22.3386, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1333 | Loss:  tensor(22.3180, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1334 | Loss:  tensor(22.3284, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1335 | Loss:  tensor(22.3240, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1336 | Loss:  tensor(22.3634, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1337 | Loss:  tensor(22.3362, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1338 | Loss:  tensor(22.3390, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1339 | Loss:  tensor(22.3384, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1340 | Loss:  tensor(22.3226, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1341 | Loss:  tensor(22.3630, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1342 | Loss:  tensor(22.3377, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1343 | Loss:  tensor(22.3859, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1344 | Loss:  tensor(22.3538, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1345 | Loss:  tensor(22.3185, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1346 | Loss:  tensor(22.3454, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1347 | Loss:  tensor(22.3295, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1348 | Loss:  tensor(22.3433, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1349 | Loss:  tensor(22.3333, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1350 | Loss:  tensor(22.3439, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1351 | Loss:  tensor(22.3977, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1352 | Loss:  tensor(22.3624, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1353 | Loss:  tensor(22.3251, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1354 | Loss:  tensor(22.3496, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1355 | Loss:  tensor(22.3283, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1356 | Loss:  tensor(22.3419, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1357 | Loss:  tensor(22.3439, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1358 | Loss:  tensor(22.3481, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1359 | Loss:  tensor(22.4707, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1360 | Loss:  tensor(22.3505, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1361 | Loss:  tensor(22.3502, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1362 | Loss:  tensor(22.3195, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1363 | Loss:  tensor(22.3500, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1364 | Loss:  tensor(22.3292, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1365 | Loss:  tensor(22.3368, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1366 | Loss:  tensor(22.3432, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1367 | Loss:  tensor(22.3317, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1368 | Loss:  tensor(22.3631, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1369 | Loss:  tensor(22.3440, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1370 | Loss:  tensor(22.3421, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1371 | Loss:  tensor(22.3232, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1372 | Loss:  tensor(22.3189, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1373 | Loss:  tensor(22.3424, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1374 | Loss:  tensor(22.3538, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1375 | Loss:  tensor(22.3303, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1376 | Loss:  tensor(22.3195, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1377 | Loss:  tensor(22.3336, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1378 | Loss:  tensor(22.3271, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1379 | Loss:  tensor(22.3249, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1380 | Loss:  tensor(22.3197, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1381 | Loss:  tensor(22.3277, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1382 | Loss:  tensor(22.3379, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1383 | Loss:  tensor(22.3262, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1384 | Loss:  tensor(22.3263, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1385 | Loss:  tensor(22.3592, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1386 | Loss:  tensor(22.3412, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1387 | Loss:  tensor(22.3489, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1388 | Loss:  tensor(22.3304, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1389 | Loss:  tensor(22.3437, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1390 | Loss:  tensor(22.3544, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1391 | Loss:  tensor(22.3424, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1392 | Loss:  tensor(22.3168, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1393 | Loss:  tensor(22.3302, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1394 | Loss:  tensor(22.3351, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1395 | Loss:  tensor(22.3546, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1396 | Loss:  tensor(22.3355, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1397 | Loss:  tensor(22.3372, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1398 | Loss:  tensor(22.3362, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1399 | Loss:  tensor(22.3466, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1400 | Loss:  tensor(22.3721, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1401 | Loss:  tensor(22.3266, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1402 | Loss:  tensor(22.3303, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1403 | Loss:  tensor(22.3245, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1404 | Loss:  tensor(22.3313, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1405 | Loss:  tensor(22.3437, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1406 | Loss:  tensor(22.3404, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1407 | Loss:  tensor(22.3331, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1408 | Loss:  tensor(22.3351, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1409 | Loss:  tensor(22.3597, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1410 | Loss:  tensor(22.3436, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1411 | Loss:  tensor(22.3430, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1412 | Loss:  tensor(22.3627, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1413 | Loss:  tensor(22.3495, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1414 | Loss:  tensor(22.3719, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1415 | Loss:  tensor(22.3348, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1416 | Loss:  tensor(22.3652, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1417 | Loss:  tensor(22.3276, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1418 | Loss:  tensor(22.3216, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1419 | Loss:  tensor(22.3366, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1420 | Loss:  tensor(22.3397, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1421 | Loss:  tensor(22.3380, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1422 | Loss:  tensor(22.3341, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1423 | Loss:  tensor(22.3464, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1424 | Loss:  tensor(22.3500, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1425 | Loss:  tensor(22.3673, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1426 | Loss:  tensor(22.3402, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1427 | Loss:  tensor(22.3297, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1428 | Loss:  tensor(22.3553, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1429 | Loss:  tensor(22.3395, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1430 | Loss:  tensor(22.3387, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1431 | Loss:  tensor(22.3558, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1432 | Loss:  tensor(22.3326, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1433 | Loss:  tensor(22.3530, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1434 | Loss:  tensor(22.3452, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1435 | Loss:  tensor(22.3666, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1436 | Loss:  tensor(22.3310, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1437 | Loss:  tensor(22.3408, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1438 | Loss:  tensor(22.3348, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1439 | Loss:  tensor(22.3370, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1440 | Loss:  tensor(22.3369, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1441 | Loss:  tensor(22.3383, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1442 | Loss:  tensor(22.3498, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1443 | Loss:  tensor(22.3653, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1444 | Loss:  tensor(22.3566, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1445 | Loss:  tensor(22.3576, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1446 | Loss:  tensor(22.3583, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1447 | Loss:  tensor(22.3786, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1448 | Loss:  tensor(22.3283, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1449 | Loss:  tensor(22.3668, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1450 | Loss:  tensor(22.3396, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1451 | Loss:  tensor(22.3329, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1452 | Loss:  tensor(22.3488, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1453 | Loss:  tensor(22.3305, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1454 | Loss:  tensor(22.3180, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1455 | Loss:  tensor(22.3452, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1456 | Loss:  tensor(22.3327, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1457 | Loss:  tensor(22.3397, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1458 | Loss:  tensor(22.3577, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1459 | Loss:  tensor(22.3530, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1460 | Loss:  tensor(22.3553, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1461 | Loss:  tensor(22.3571, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1462 | Loss:  tensor(22.3314, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1463 | Loss:  tensor(22.3268, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1464 | Loss:  tensor(22.3281, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1465 | Loss:  tensor(22.3735, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1466 | Loss:  tensor(22.3394, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1467 | Loss:  tensor(22.3413, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1468 | Loss:  tensor(22.3446, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1469 | Loss:  tensor(22.3322, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1470 | Loss:  tensor(22.3560, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1471 | Loss:  tensor(22.3804, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1472 | Loss:  tensor(22.3631, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1473 | Loss:  tensor(22.3450, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1474 | Loss:  tensor(22.3349, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1475 | Loss:  tensor(22.3606, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1476 | Loss:  tensor(22.3624, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1477 | Loss:  tensor(22.3361, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1478 | Loss:  tensor(22.3556, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1479 | Loss:  tensor(22.3509, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1480 | Loss:  tensor(22.3532, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1481 | Loss:  tensor(22.3444, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1482 | Loss:  tensor(22.3851, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1483 | Loss:  tensor(22.3395, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1484 | Loss:  tensor(22.3561, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1485 | Loss:  tensor(22.3604, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1486 | Loss:  tensor(22.3439, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1487 | Loss:  tensor(22.3453, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1488 | Loss:  tensor(22.3815, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1489 | Loss:  tensor(22.3682, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1490 | Loss:  tensor(22.3500, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1491 | Loss:  tensor(22.3497, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1492 | Loss:  tensor(22.3560, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1493 | Loss:  tensor(22.3555, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1494 | Loss:  tensor(22.3386, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1495 | Loss:  tensor(22.3701, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1496 | Loss:  tensor(22.3916, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1497 | Loss:  tensor(22.3388, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1498 | Loss:  tensor(22.3481, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1499 | Loss:  tensor(22.3531, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1500 | Loss:  tensor(22.3514, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1501 | Loss:  tensor(22.3591, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1502 | Loss:  tensor(22.3453, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1503 | Loss:  tensor(22.3444, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1504 | Loss:  tensor(22.3526, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1505 | Loss:  tensor(22.3413, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1506 | Loss:  tensor(22.3598, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1507 | Loss:  tensor(22.3525, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1508 | Loss:  tensor(22.3347, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1509 | Loss:  tensor(22.3681, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1510 | Loss:  tensor(22.3471, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1511 | Loss:  tensor(22.3442, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1512 | Loss:  tensor(22.3594, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1513 | Loss:  tensor(22.3435, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1514 | Loss:  tensor(22.3423, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1515 | Loss:  tensor(22.3449, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1516 | Loss:  tensor(22.3442, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1517 | Loss:  tensor(22.3523, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1518 | Loss:  tensor(22.3605, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1519 | Loss:  tensor(22.3410, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1520 | Loss:  tensor(22.3567, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1521 | Loss:  tensor(22.3464, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1522 | Loss:  tensor(22.3787, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1523 | Loss:  tensor(22.3559, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1524 | Loss:  tensor(22.3539, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1525 | Loss:  tensor(22.3646, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1526 | Loss:  tensor(22.3470, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1527 | Loss:  tensor(22.3541, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1528 | Loss:  tensor(22.3728, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1529 | Loss:  tensor(22.3474, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1530 | Loss:  tensor(22.3750, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1531 | Loss:  tensor(22.3596, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1532 | Loss:  tensor(22.3504, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1533 | Loss:  tensor(22.3583, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1534 | Loss:  tensor(22.3654, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1535 | Loss:  tensor(22.3521, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1536 | Loss:  tensor(22.3684, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1537 | Loss:  tensor(22.3449, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1538 | Loss:  tensor(22.3593, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1539 | Loss:  tensor(22.3567, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1540 | Loss:  tensor(22.3680, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1541 | Loss:  tensor(22.3685, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1542 | Loss:  tensor(22.4547, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1543 | Loss:  tensor(22.3594, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1544 | Loss:  tensor(22.3667, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1545 | Loss:  tensor(22.3562, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1546 | Loss:  tensor(22.3517, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1547 | Loss:  tensor(22.3680, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1548 | Loss:  tensor(22.3488, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1549 | Loss:  tensor(22.3518, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1550 | Loss:  tensor(22.3575, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1551 | Loss:  tensor(22.3742, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1552 | Loss:  tensor(22.3724, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1553 | Loss:  tensor(22.3499, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1554 | Loss:  tensor(22.3539, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1555 | Loss:  tensor(22.3609, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1556 | Loss:  tensor(22.3642, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1557 | Loss:  tensor(22.3783, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1558 | Loss:  tensor(22.3647, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1559 | Loss:  tensor(22.3957, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1560 | Loss:  tensor(22.3537, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1561 | Loss:  tensor(22.3680, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1562 | Loss:  tensor(22.3503, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1563 | Loss:  tensor(22.3491, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1564 | Loss:  tensor(22.3512, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1565 | Loss:  tensor(22.3526, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1566 | Loss:  tensor(22.3486, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1567 | Loss:  tensor(22.3493, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1568 | Loss:  tensor(22.3487, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1569 | Loss:  tensor(22.3494, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1570 | Loss:  tensor(22.3680, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1571 | Loss:  tensor(22.3505, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1572 | Loss:  tensor(22.3454, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1573 | Loss:  tensor(22.3514, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1574 | Loss:  tensor(22.3378, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1575 | Loss:  tensor(22.3652, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1576 | Loss:  tensor(22.3495, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1577 | Loss:  tensor(22.3548, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1578 | Loss:  tensor(22.3621, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1579 | Loss:  tensor(22.3495, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1580 | Loss:  tensor(22.3656, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1581 | Loss:  tensor(22.3604, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1582 | Loss:  tensor(22.3456, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1583 | Loss:  tensor(22.3471, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1584 | Loss:  tensor(22.3692, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1585 | Loss:  tensor(22.3492, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1586 | Loss:  tensor(22.3933, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1587 | Loss:  tensor(22.3543, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1588 | Loss:  tensor(22.3508, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1589 | Loss:  tensor(22.3822, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1590 | Loss:  tensor(22.3405, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1591 | Loss:  tensor(22.3754, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1592 | Loss:  tensor(22.3455, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1593 | Loss:  tensor(22.3627, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1594 | Loss:  tensor(22.3806, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1595 | Loss:  tensor(22.3712, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1596 | Loss:  tensor(22.4139, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1597 | Loss:  tensor(22.3566, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1598 | Loss:  tensor(22.3650, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1599 | Loss:  tensor(22.3603, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1600 | Loss:  tensor(22.3632, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1601 | Loss:  tensor(22.3637, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1602 | Loss:  tensor(22.3753, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1603 | Loss:  tensor(22.3595, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1604 | Loss:  tensor(22.3627, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1605 | Loss:  tensor(22.3593, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1606 | Loss:  tensor(22.3790, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1607 | Loss:  tensor(22.3549, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1608 | Loss:  tensor(22.3685, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1609 | Loss:  tensor(22.3511, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1610 | Loss:  tensor(22.3658, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1611 | Loss:  tensor(22.3761, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1612 | Loss:  tensor(22.3528, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1613 | Loss:  tensor(22.3821, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1614 | Loss:  tensor(22.3433, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1615 | Loss:  tensor(22.3843, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1616 | Loss:  tensor(22.4644, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1617 | Loss:  tensor(22.3546, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1618 | Loss:  tensor(22.3634, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1619 | Loss:  tensor(22.3773, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1620 | Loss:  tensor(22.3809, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1621 | Loss:  tensor(22.3572, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1622 | Loss:  tensor(22.3713, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1623 | Loss:  tensor(22.3876, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1624 | Loss:  tensor(22.3628, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1625 | Loss:  tensor(22.3619, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1626 | Loss:  tensor(22.3827, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1627 | Loss:  tensor(22.3563, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1628 | Loss:  tensor(22.3603, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1629 | Loss:  tensor(22.3730, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1630 | Loss:  tensor(22.3616, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1631 | Loss:  tensor(22.3711, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1632 | Loss:  tensor(22.3621, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1633 | Loss:  tensor(22.3963, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1634 | Loss:  tensor(22.3552, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1635 | Loss:  tensor(22.3672, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1636 | Loss:  tensor(22.3605, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1637 | Loss:  tensor(22.3671, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1638 | Loss:  tensor(22.3699, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1639 | Loss:  tensor(22.3663, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1640 | Loss:  tensor(22.3854, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1641 | Loss:  tensor(22.3786, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1642 | Loss:  tensor(22.4204, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1643 | Loss:  tensor(22.3481, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1644 | Loss:  tensor(22.3896, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1645 | Loss:  tensor(22.3467, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1646 | Loss:  tensor(22.3476, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1647 | Loss:  tensor(22.3717, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1648 | Loss:  tensor(22.3424, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1649 | Loss:  tensor(22.3570, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1650 | Loss:  tensor(22.3808, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1651 | Loss:  tensor(22.3922, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1652 | Loss:  tensor(22.3514, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1653 | Loss:  tensor(22.3742, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1654 | Loss:  tensor(22.3880, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1655 | Loss:  tensor(22.3520, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1656 | Loss:  tensor(22.3479, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1657 | Loss:  tensor(22.3799, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1658 | Loss:  tensor(22.3459, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1659 | Loss:  tensor(22.3925, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1660 | Loss:  tensor(22.3572, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1661 | Loss:  tensor(22.3743, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1662 | Loss:  tensor(22.3508, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1663 | Loss:  tensor(22.3597, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1664 | Loss:  tensor(22.3751, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1665 | Loss:  tensor(22.3661, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1666 | Loss:  tensor(22.3698, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1667 | Loss:  tensor(22.3572, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1668 | Loss:  tensor(22.3623, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1669 | Loss:  tensor(22.3657, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1670 | Loss:  tensor(22.4055, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1671 | Loss:  tensor(22.3469, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1672 | Loss:  tensor(22.3526, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1673 | Loss:  tensor(22.4069, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1674 | Loss:  tensor(22.3768, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1675 | Loss:  tensor(22.4094, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1676 | Loss:  tensor(22.3665, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1677 | Loss:  tensor(22.3697, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1678 | Loss:  tensor(22.3628, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1679 | Loss:  tensor(22.3660, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1680 | Loss:  tensor(22.3549, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1681 | Loss:  tensor(22.3564, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1682 | Loss:  tensor(22.3496, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1683 | Loss:  tensor(22.3585, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1684 | Loss:  tensor(22.3731, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1685 | Loss:  tensor(22.3828, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1686 | Loss:  tensor(22.3799, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1687 | Loss:  tensor(22.3913, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1688 | Loss:  tensor(22.3973, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1689 | Loss:  tensor(22.3602, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1690 | Loss:  tensor(22.3669, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1691 | Loss:  tensor(22.3630, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1692 | Loss:  tensor(22.3574, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1693 | Loss:  tensor(22.3757, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1694 | Loss:  tensor(22.3602, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1695 | Loss:  tensor(22.3611, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1696 | Loss:  tensor(22.3958, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1697 | Loss:  tensor(22.4166, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1698 | Loss:  tensor(22.3646, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1699 | Loss:  tensor(22.3687, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1700 | Loss:  tensor(22.3996, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1701 | Loss:  tensor(22.3544, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1702 | Loss:  tensor(22.3824, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1703 | Loss:  tensor(22.3743, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1704 | Loss:  tensor(22.3617, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1705 | Loss:  tensor(22.3949, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1706 | Loss:  tensor(22.3833, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1707 | Loss:  tensor(22.3759, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1708 | Loss:  tensor(22.3604, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1709 | Loss:  tensor(22.3784, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1710 | Loss:  tensor(22.3737, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1711 | Loss:  tensor(22.3894, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1712 | Loss:  tensor(22.3746, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1713 | Loss:  tensor(22.3873, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1714 | Loss:  tensor(22.3700, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1715 | Loss:  tensor(22.3970, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1716 | Loss:  tensor(22.3935, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1717 | Loss:  tensor(22.3670, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1718 | Loss:  tensor(22.3956, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1719 | Loss:  tensor(22.3735, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1720 | Loss:  tensor(22.3924, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1721 | Loss:  tensor(22.3877, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1722 | Loss:  tensor(22.3881, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1723 | Loss:  tensor(22.3702, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1724 | Loss:  tensor(22.3789, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1725 | Loss:  tensor(22.4116, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1726 | Loss:  tensor(22.3916, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1727 | Loss:  tensor(22.4036, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1728 | Loss:  tensor(22.3726, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1729 | Loss:  tensor(22.3664, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1730 | Loss:  tensor(22.3673, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1731 | Loss:  tensor(22.3674, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1732 | Loss:  tensor(22.3862, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1733 | Loss:  tensor(22.3736, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1734 | Loss:  tensor(22.3682, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1735 | Loss:  tensor(22.3722, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1736 | Loss:  tensor(22.3637, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1737 | Loss:  tensor(22.3800, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1738 | Loss:  tensor(22.3635, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1739 | Loss:  tensor(22.3776, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1740 | Loss:  tensor(22.3773, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1741 | Loss:  tensor(22.3720, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1742 | Loss:  tensor(22.3900, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1743 | Loss:  tensor(22.3628, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1744 | Loss:  tensor(22.3827, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1745 | Loss:  tensor(22.4230, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1746 | Loss:  tensor(22.3820, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1747 | Loss:  tensor(22.3703, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1748 | Loss:  tensor(22.3768, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1749 | Loss:  tensor(22.3765, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1750 | Loss:  tensor(22.3569, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1751 | Loss:  tensor(22.3640, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1752 | Loss:  tensor(22.3573, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1753 | Loss:  tensor(22.3942, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1754 | Loss:  tensor(22.3804, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1755 | Loss:  tensor(22.3661, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1756 | Loss:  tensor(22.3688, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1757 | Loss:  tensor(22.3735, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1758 | Loss:  tensor(22.3810, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1759 | Loss:  tensor(22.3641, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1760 | Loss:  tensor(22.3799, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1761 | Loss:  tensor(22.3957, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1762 | Loss:  tensor(22.3716, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1763 | Loss:  tensor(22.3651, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1764 | Loss:  tensor(22.3723, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1765 | Loss:  tensor(22.3595, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1766 | Loss:  tensor(22.3959, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1767 | Loss:  tensor(22.4133, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1768 | Loss:  tensor(22.3710, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1769 | Loss:  tensor(22.3652, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1770 | Loss:  tensor(22.3597, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1771 | Loss:  tensor(22.3564, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1772 | Loss:  tensor(22.3663, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1773 | Loss:  tensor(22.3682, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1774 | Loss:  tensor(22.3716, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1775 | Loss:  tensor(22.3585, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1776 | Loss:  tensor(22.3693, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1777 | Loss:  tensor(22.3914, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1778 | Loss:  tensor(22.3653, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1779 | Loss:  tensor(22.3663, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1780 | Loss:  tensor(22.3785, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1781 | Loss:  tensor(22.3990, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1782 | Loss:  tensor(22.3914, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1783 | Loss:  tensor(22.4025, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1784 | Loss:  tensor(22.3777, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1785 | Loss:  tensor(22.3868, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1786 | Loss:  tensor(22.3876, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1787 | Loss:  tensor(22.3734, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1788 | Loss:  tensor(22.4084, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1789 | Loss:  tensor(22.3565, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1790 | Loss:  tensor(22.3775, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1791 | Loss:  tensor(22.3946, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1792 | Loss:  tensor(22.3695, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1793 | Loss:  tensor(22.3762, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1794 | Loss:  tensor(22.3903, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1795 | Loss:  tensor(22.3803, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1796 | Loss:  tensor(22.3527, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1797 | Loss:  tensor(22.4292, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1798 | Loss:  tensor(22.3735, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1799 | Loss:  tensor(22.3848, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1800 | Loss:  tensor(22.3662, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1801 | Loss:  tensor(22.3826, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1802 | Loss:  tensor(22.3613, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1803 | Loss:  tensor(22.4082, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1804 | Loss:  tensor(22.3743, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1805 | Loss:  tensor(22.3705, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1806 | Loss:  tensor(22.4125, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1807 | Loss:  tensor(22.3805, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1808 | Loss:  tensor(22.3696, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1809 | Loss:  tensor(22.3706, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1810 | Loss:  tensor(22.3623, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1811 | Loss:  tensor(22.3795, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1812 | Loss:  tensor(22.3755, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1813 | Loss:  tensor(22.3624, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1814 | Loss:  tensor(22.3675, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1815 | Loss:  tensor(22.3522, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1816 | Loss:  tensor(22.3736, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1817 | Loss:  tensor(22.3573, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1818 | Loss:  tensor(22.3621, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1819 | Loss:  tensor(22.3649, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1820 | Loss:  tensor(22.3976, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1821 | Loss:  tensor(22.3967, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1822 | Loss:  tensor(22.3717, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1823 | Loss:  tensor(22.3684, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1824 | Loss:  tensor(22.3760, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1825 | Loss:  tensor(22.4172, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1826 | Loss:  tensor(22.3897, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1827 | Loss:  tensor(22.3789, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1828 | Loss:  tensor(22.4156, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1829 | Loss:  tensor(22.4043, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1830 | Loss:  tensor(22.3851, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1831 | Loss:  tensor(22.3762, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1832 | Loss:  tensor(22.3729, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1833 | Loss:  tensor(22.4279, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1834 | Loss:  tensor(22.3933, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1835 | Loss:  tensor(22.3785, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1836 | Loss:  tensor(22.3948, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1837 | Loss:  tensor(22.4006, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1838 | Loss:  tensor(22.4010, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1839 | Loss:  tensor(22.3876, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1840 | Loss:  tensor(22.3759, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1841 | Loss:  tensor(22.3842, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1842 | Loss:  tensor(22.3755, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1843 | Loss:  tensor(22.3747, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1844 | Loss:  tensor(22.3645, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1845 | Loss:  tensor(22.3798, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1846 | Loss:  tensor(22.3925, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1847 | Loss:  tensor(22.3683, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1848 | Loss:  tensor(22.3794, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1849 | Loss:  tensor(22.3658, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1850 | Loss:  tensor(22.3966, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1851 | Loss:  tensor(22.3707, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1852 | Loss:  tensor(22.3945, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1853 | Loss:  tensor(22.4385, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1854 | Loss:  tensor(22.3712, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1855 | Loss:  tensor(22.3763, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1856 | Loss:  tensor(22.4065, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1857 | Loss:  tensor(22.3822, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1858 | Loss:  tensor(22.3896, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1859 | Loss:  tensor(22.3884, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1860 | Loss:  tensor(22.3901, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1861 | Loss:  tensor(22.3686, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1862 | Loss:  tensor(22.3701, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1863 | Loss:  tensor(22.4196, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1864 | Loss:  tensor(22.3788, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1865 | Loss:  tensor(22.3789, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1866 | Loss:  tensor(22.3845, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1867 | Loss:  tensor(22.3890, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1868 | Loss:  tensor(22.3979, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1869 | Loss:  tensor(22.3848, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1870 | Loss:  tensor(22.3774, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1871 | Loss:  tensor(22.3834, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1872 | Loss:  tensor(22.3965, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1873 | Loss:  tensor(22.4181, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1874 | Loss:  tensor(22.4136, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1875 | Loss:  tensor(22.3929, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1876 | Loss:  tensor(22.4338, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1877 | Loss:  tensor(22.3982, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1878 | Loss:  tensor(22.3846, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1879 | Loss:  tensor(22.3886, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1880 | Loss:  tensor(22.4046, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1881 | Loss:  tensor(22.3882, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1882 | Loss:  tensor(22.3800, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1883 | Loss:  tensor(22.3945, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1884 | Loss:  tensor(22.3872, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1885 | Loss:  tensor(22.3979, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1886 | Loss:  tensor(22.3933, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1887 | Loss:  tensor(22.4438, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1888 | Loss:  tensor(22.3864, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1889 | Loss:  tensor(22.3935, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1890 | Loss:  tensor(22.3939, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1891 | Loss:  tensor(22.3950, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1892 | Loss:  tensor(22.4173, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1893 | Loss:  tensor(22.3791, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1894 | Loss:  tensor(22.4115, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1895 | Loss:  tensor(22.3907, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1896 | Loss:  tensor(22.4010, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1897 | Loss:  tensor(22.3870, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1898 | Loss:  tensor(22.3811, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1899 | Loss:  tensor(22.3959, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1900 | Loss:  tensor(22.3813, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1901 | Loss:  tensor(22.3889, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1902 | Loss:  tensor(22.3916, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1903 | Loss:  tensor(22.3939, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1904 | Loss:  tensor(22.4008, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1905 | Loss:  tensor(22.4432, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1906 | Loss:  tensor(22.3854, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1907 | Loss:  tensor(22.3809, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1908 | Loss:  tensor(22.3906, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1909 | Loss:  tensor(22.3874, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1910 | Loss:  tensor(22.3851, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1911 | Loss:  tensor(22.3836, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1912 | Loss:  tensor(22.4000, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1913 | Loss:  tensor(22.4014, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1914 | Loss:  tensor(22.3950, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1915 | Loss:  tensor(22.3906, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1916 | Loss:  tensor(22.3822, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1917 | Loss:  tensor(22.3913, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1918 | Loss:  tensor(22.3662, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1919 | Loss:  tensor(22.3947, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1920 | Loss:  tensor(22.4084, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1921 | Loss:  tensor(22.4350, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1922 | Loss:  tensor(22.4006, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1923 | Loss:  tensor(22.3745, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1924 | Loss:  tensor(22.3961, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1925 | Loss:  tensor(22.4091, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1926 | Loss:  tensor(22.4060, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1927 | Loss:  tensor(22.4091, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1928 | Loss:  tensor(22.3878, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1929 | Loss:  tensor(22.4155, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1930 | Loss:  tensor(22.4051, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1931 | Loss:  tensor(22.3953, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1932 | Loss:  tensor(22.4067, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1933 | Loss:  tensor(22.3846, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1934 | Loss:  tensor(22.3915, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1935 | Loss:  tensor(22.3989, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1936 | Loss:  tensor(22.3870, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1937 | Loss:  tensor(22.4131, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1938 | Loss:  tensor(22.4084, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1939 | Loss:  tensor(22.3963, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1940 | Loss:  tensor(22.3972, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1941 | Loss:  tensor(22.4202, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1942 | Loss:  tensor(22.3909, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1943 | Loss:  tensor(22.4046, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1944 | Loss:  tensor(22.4001, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1945 | Loss:  tensor(22.4161, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1946 | Loss:  tensor(22.3927, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1947 | Loss:  tensor(22.3829, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1948 | Loss:  tensor(22.3781, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1949 | Loss:  tensor(22.3904, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1950 | Loss:  tensor(22.3833, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1951 | Loss:  tensor(22.3906, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1952 | Loss:  tensor(22.3885, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1953 | Loss:  tensor(22.3805, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1954 | Loss:  tensor(22.3887, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1955 | Loss:  tensor(22.3902, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1956 | Loss:  tensor(22.3818, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1957 | Loss:  tensor(22.3976, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1958 | Loss:  tensor(22.3963, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1959 | Loss:  tensor(22.3982, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1960 | Loss:  tensor(22.3960, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1961 | Loss:  tensor(22.3938, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1962 | Loss:  tensor(22.4079, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1963 | Loss:  tensor(22.4223, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1964 | Loss:  tensor(22.3935, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1965 | Loss:  tensor(22.3784, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1966 | Loss:  tensor(22.3908, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1967 | Loss:  tensor(22.4145, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1968 | Loss:  tensor(22.4387, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1969 | Loss:  tensor(22.4085, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1970 | Loss:  tensor(22.3976, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1971 | Loss:  tensor(22.4145, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1972 | Loss:  tensor(22.3876, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1973 | Loss:  tensor(22.4029, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1974 | Loss:  tensor(22.3965, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1975 | Loss:  tensor(22.3973, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1976 | Loss:  tensor(22.4341, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1977 | Loss:  tensor(22.4079, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1978 | Loss:  tensor(22.3894, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1979 | Loss:  tensor(22.3901, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1980 | Loss:  tensor(22.3965, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1981 | Loss:  tensor(22.4320, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1982 | Loss:  tensor(22.4007, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1983 | Loss:  tensor(22.4179, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1984 | Loss:  tensor(22.3845, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1985 | Loss:  tensor(22.4061, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1986 | Loss:  tensor(22.3857, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1987 | Loss:  tensor(22.3971, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1988 | Loss:  tensor(22.4147, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1989 | Loss:  tensor(22.4170, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1990 | Loss:  tensor(22.4017, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1991 | Loss:  tensor(22.3942, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1992 | Loss:  tensor(22.3958, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1993 | Loss:  tensor(22.3967, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1994 | Loss:  tensor(22.4226, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1995 | Loss:  tensor(22.3917, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1996 | Loss:  tensor(22.4093, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1997 | Loss:  tensor(22.4287, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1998 | Loss:  tensor(22.4011, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  1999 | Loss:  tensor(22.4099, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2000 | Loss:  tensor(22.3918, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2001 | Loss:  tensor(22.4253, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2002 | Loss:  tensor(22.4513, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2003 | Loss:  tensor(22.3821, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2004 | Loss:  tensor(22.3924, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2005 | Loss:  tensor(22.3895, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2006 | Loss:  tensor(22.4241, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2007 | Loss:  tensor(22.4011, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2008 | Loss:  tensor(22.4017, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2009 | Loss:  tensor(22.4069, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2010 | Loss:  tensor(22.3953, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2011 | Loss:  tensor(22.3896, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2012 | Loss:  tensor(22.4288, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2013 | Loss:  tensor(22.4125, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2014 | Loss:  tensor(22.3960, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2015 | Loss:  tensor(22.4013, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2016 | Loss:  tensor(22.3950, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2017 | Loss:  tensor(22.4117, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2018 | Loss:  tensor(22.3918, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2019 | Loss:  tensor(22.4049, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2020 | Loss:  tensor(22.4168, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2021 | Loss:  tensor(22.4077, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2022 | Loss:  tensor(22.4082, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2023 | Loss:  tensor(22.3889, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2024 | Loss:  tensor(22.4070, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2025 | Loss:  tensor(22.3932, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2026 | Loss:  tensor(22.3906, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2027 | Loss:  tensor(22.3854, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2028 | Loss:  tensor(22.3877, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2029 | Loss:  tensor(22.3956, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2030 | Loss:  tensor(22.3827, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2031 | Loss:  tensor(22.4045, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2032 | Loss:  tensor(22.4066, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2033 | Loss:  tensor(22.4350, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2034 | Loss:  tensor(22.3913, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2035 | Loss:  tensor(22.3838, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2036 | Loss:  tensor(22.4044, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2037 | Loss:  tensor(22.3967, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2038 | Loss:  tensor(22.3820, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2039 | Loss:  tensor(22.4083, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2040 | Loss:  tensor(22.3844, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2041 | Loss:  tensor(22.4026, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2042 | Loss:  tensor(22.4040, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2043 | Loss:  tensor(22.3852, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2044 | Loss:  tensor(22.3977, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2045 | Loss:  tensor(22.3933, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2046 | Loss:  tensor(22.4039, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2047 | Loss:  tensor(22.3864, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2048 | Loss:  tensor(22.3894, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2049 | Loss:  tensor(22.3944, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2050 | Loss:  tensor(22.4266, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2051 | Loss:  tensor(22.4068, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2052 | Loss:  tensor(22.4134, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2053 | Loss:  tensor(22.4034, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2054 | Loss:  tensor(22.4154, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2055 | Loss:  tensor(22.4046, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2056 | Loss:  tensor(22.4132, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2057 | Loss:  tensor(22.4100, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2058 | Loss:  tensor(22.4150, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2059 | Loss:  tensor(22.4170, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2060 | Loss:  tensor(22.4154, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2061 | Loss:  tensor(22.4277, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2062 | Loss:  tensor(22.3901, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2063 | Loss:  tensor(22.3889, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2064 | Loss:  tensor(22.4031, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2065 | Loss:  tensor(22.4045, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2066 | Loss:  tensor(22.4413, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2067 | Loss:  tensor(22.4018, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2068 | Loss:  tensor(22.4102, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2069 | Loss:  tensor(22.4159, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2070 | Loss:  tensor(22.3837, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2071 | Loss:  tensor(22.4178, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2072 | Loss:  tensor(22.3943, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2073 | Loss:  tensor(22.4211, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2074 | Loss:  tensor(22.4369, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2075 | Loss:  tensor(22.4087, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2076 | Loss:  tensor(22.4220, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2077 | Loss:  tensor(22.4074, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2078 | Loss:  tensor(22.3964, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2079 | Loss:  tensor(22.4138, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2080 | Loss:  tensor(22.4206, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2081 | Loss:  tensor(22.4066, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2082 | Loss:  tensor(22.4137, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2083 | Loss:  tensor(22.4224, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2084 | Loss:  tensor(22.4067, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2085 | Loss:  tensor(22.4264, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2086 | Loss:  tensor(22.4201, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2087 | Loss:  tensor(22.4273, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2088 | Loss:  tensor(22.4167, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2089 | Loss:  tensor(22.4074, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2090 | Loss:  tensor(22.4390, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2091 | Loss:  tensor(22.4521, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2092 | Loss:  tensor(22.4135, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2093 | Loss:  tensor(22.3981, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2094 | Loss:  tensor(22.4279, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2095 | Loss:  tensor(22.4037, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2096 | Loss:  tensor(22.4040, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2097 | Loss:  tensor(22.4235, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2098 | Loss:  tensor(22.4039, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2099 | Loss:  tensor(22.4046, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2100 | Loss:  tensor(22.4582, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2101 | Loss:  tensor(22.4017, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2102 | Loss:  tensor(22.4142, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2103 | Loss:  tensor(22.4242, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2104 | Loss:  tensor(22.4190, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2105 | Loss:  tensor(22.4243, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2106 | Loss:  tensor(22.4142, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2107 | Loss:  tensor(22.4028, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2108 | Loss:  tensor(22.4382, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2109 | Loss:  tensor(22.4164, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2110 | Loss:  tensor(22.4069, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2111 | Loss:  tensor(22.4192, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2112 | Loss:  tensor(22.4260, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2113 | Loss:  tensor(22.4675, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2114 | Loss:  tensor(22.4023, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2115 | Loss:  tensor(22.4325, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2116 | Loss:  tensor(22.3894, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2117 | Loss:  tensor(22.4298, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2118 | Loss:  tensor(22.4348, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2119 | Loss:  tensor(22.3982, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2120 | Loss:  tensor(22.4330, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2121 | Loss:  tensor(22.4263, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2122 | Loss:  tensor(22.4168, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2123 | Loss:  tensor(22.4312, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2124 | Loss:  tensor(22.4284, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2125 | Loss:  tensor(22.4077, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2126 | Loss:  tensor(22.4495, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2127 | Loss:  tensor(22.3897, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2128 | Loss:  tensor(22.3956, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2129 | Loss:  tensor(22.4308, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2130 | Loss:  tensor(22.3989, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2131 | Loss:  tensor(22.4105, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2132 | Loss:  tensor(22.4443, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2133 | Loss:  tensor(22.4237, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2134 | Loss:  tensor(22.4096, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2135 | Loss:  tensor(22.4079, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2136 | Loss:  tensor(22.4518, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2137 | Loss:  tensor(22.4033, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2138 | Loss:  tensor(22.4042, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2139 | Loss:  tensor(22.4137, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2140 | Loss:  tensor(22.4156, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2141 | Loss:  tensor(22.4439, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2142 | Loss:  tensor(22.4282, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2143 | Loss:  tensor(22.4143, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2144 | Loss:  tensor(22.4133, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2145 | Loss:  tensor(22.4185, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2146 | Loss:  tensor(22.4263, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2147 | Loss:  tensor(22.4136, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2148 | Loss:  tensor(22.4458, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2149 | Loss:  tensor(22.4865, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2150 | Loss:  tensor(22.4101, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2151 | Loss:  tensor(22.4063, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2152 | Loss:  tensor(22.4240, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2153 | Loss:  tensor(22.4164, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2154 | Loss:  tensor(22.4192, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2155 | Loss:  tensor(22.4239, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2156 | Loss:  tensor(22.4453, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2157 | Loss:  tensor(22.4182, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2158 | Loss:  tensor(22.3958, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2159 | Loss:  tensor(22.4091, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2160 | Loss:  tensor(22.4166, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2161 | Loss:  tensor(22.4302, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2162 | Loss:  tensor(22.4326, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2163 | Loss:  tensor(22.4026, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2164 | Loss:  tensor(22.4064, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2165 | Loss:  tensor(22.4033, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2166 | Loss:  tensor(22.4199, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2167 | Loss:  tensor(22.4173, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2168 | Loss:  tensor(22.4071, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2169 | Loss:  tensor(22.4293, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2170 | Loss:  tensor(22.4105, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2171 | Loss:  tensor(22.4135, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2172 | Loss:  tensor(22.4227, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2173 | Loss:  tensor(22.3986, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2174 | Loss:  tensor(22.3938, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2175 | Loss:  tensor(22.4238, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2176 | Loss:  tensor(22.4134, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2177 | Loss:  tensor(22.4018, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2178 | Loss:  tensor(22.4084, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2179 | Loss:  tensor(22.4014, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2180 | Loss:  tensor(22.4115, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2181 | Loss:  tensor(22.4593, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2182 | Loss:  tensor(22.4257, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2183 | Loss:  tensor(22.4104, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2184 | Loss:  tensor(22.4276, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2185 | Loss:  tensor(22.4257, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2186 | Loss:  tensor(22.4284, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2187 | Loss:  tensor(22.4200, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2188 | Loss:  tensor(22.4324, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2189 | Loss:  tensor(22.4214, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2190 | Loss:  tensor(22.4222, dtype=torch.float64)\n",
            "Epoch:  49 | Batch:  2191 | Loss:  tensor(22.4138, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1 | Loss:  tensor(22.4177, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2 | Loss:  tensor(22.4245, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  3 | Loss:  tensor(22.4125, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  4 | Loss:  tensor(22.4193, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  5 | Loss:  tensor(22.4584, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  6 | Loss:  tensor(22.4149, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  7 | Loss:  tensor(22.4228, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  8 | Loss:  tensor(22.4476, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  9 | Loss:  tensor(22.4107, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  10 | Loss:  tensor(22.4408, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  11 | Loss:  tensor(22.4266, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  12 | Loss:  tensor(22.4141, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  13 | Loss:  tensor(22.4086, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  14 | Loss:  tensor(22.4140, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  15 | Loss:  tensor(22.4278, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  16 | Loss:  tensor(22.4118, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  17 | Loss:  tensor(22.4668, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  18 | Loss:  tensor(22.4213, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  19 | Loss:  tensor(22.4268, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  20 | Loss:  tensor(22.4386, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  21 | Loss:  tensor(22.4358, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  22 | Loss:  tensor(22.4279, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  23 | Loss:  tensor(22.4158, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  24 | Loss:  tensor(22.4310, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  25 | Loss:  tensor(22.4072, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  26 | Loss:  tensor(22.4340, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  27 | Loss:  tensor(22.4849, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  28 | Loss:  tensor(22.4168, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  29 | Loss:  tensor(22.4235, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  30 | Loss:  tensor(22.4163, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  31 | Loss:  tensor(22.4434, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  32 | Loss:  tensor(22.4089, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  33 | Loss:  tensor(22.4053, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  34 | Loss:  tensor(22.4318, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  35 | Loss:  tensor(22.4237, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  36 | Loss:  tensor(22.4297, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  37 | Loss:  tensor(22.4141, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  38 | Loss:  tensor(22.4246, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  39 | Loss:  tensor(22.4274, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  40 | Loss:  tensor(22.4719, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  41 | Loss:  tensor(22.4127, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  42 | Loss:  tensor(22.4314, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  43 | Loss:  tensor(22.4383, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  44 | Loss:  tensor(22.4281, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  45 | Loss:  tensor(22.4276, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  46 | Loss:  tensor(22.4303, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  47 | Loss:  tensor(22.4304, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  48 | Loss:  tensor(22.4386, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  49 | Loss:  tensor(22.4397, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  50 | Loss:  tensor(22.4395, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  51 | Loss:  tensor(22.4544, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  52 | Loss:  tensor(22.4219, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  53 | Loss:  tensor(22.4318, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  54 | Loss:  tensor(22.4557, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  55 | Loss:  tensor(22.5187, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  56 | Loss:  tensor(22.4417, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  57 | Loss:  tensor(22.4345, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  58 | Loss:  tensor(22.4572, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  59 | Loss:  tensor(22.4609, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  60 | Loss:  tensor(22.4365, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  61 | Loss:  tensor(22.4688, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  62 | Loss:  tensor(22.5067, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  63 | Loss:  tensor(22.4701, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  64 | Loss:  tensor(22.4418, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  65 | Loss:  tensor(22.4574, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  66 | Loss:  tensor(22.4666, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  67 | Loss:  tensor(22.4285, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  68 | Loss:  tensor(22.4278, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  69 | Loss:  tensor(22.4887, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  70 | Loss:  tensor(22.4334, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  71 | Loss:  tensor(22.5040, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  72 | Loss:  tensor(22.4365, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  73 | Loss:  tensor(22.4348, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  74 | Loss:  tensor(22.4320, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  75 | Loss:  tensor(22.4503, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  76 | Loss:  tensor(22.4802, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  77 | Loss:  tensor(22.4304, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  78 | Loss:  tensor(22.4480, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  79 | Loss:  tensor(22.4269, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  80 | Loss:  tensor(22.4323, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  81 | Loss:  tensor(22.4208, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  82 | Loss:  tensor(22.4624, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  83 | Loss:  tensor(22.4134, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  84 | Loss:  tensor(22.4307, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  85 | Loss:  tensor(22.4226, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  86 | Loss:  tensor(22.4493, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  87 | Loss:  tensor(22.4325, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  88 | Loss:  tensor(22.4261, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  89 | Loss:  tensor(22.4288, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  90 | Loss:  tensor(22.4401, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  91 | Loss:  tensor(22.5027, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  92 | Loss:  tensor(22.4367, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  93 | Loss:  tensor(22.4157, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  94 | Loss:  tensor(22.4310, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  95 | Loss:  tensor(22.4550, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  96 | Loss:  tensor(22.4857, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  97 | Loss:  tensor(22.4258, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  98 | Loss:  tensor(22.4391, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  99 | Loss:  tensor(22.4508, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  100 | Loss:  tensor(22.4201, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  101 | Loss:  tensor(22.4330, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  102 | Loss:  tensor(22.4350, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  103 | Loss:  tensor(22.4336, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  104 | Loss:  tensor(22.4242, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  105 | Loss:  tensor(22.4309, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  106 | Loss:  tensor(22.4415, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  107 | Loss:  tensor(22.4514, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  108 | Loss:  tensor(22.4709, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  109 | Loss:  tensor(22.4461, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  110 | Loss:  tensor(22.4320, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  111 | Loss:  tensor(22.4890, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  112 | Loss:  tensor(22.4351, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  113 | Loss:  tensor(22.4431, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  114 | Loss:  tensor(22.4395, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  115 | Loss:  tensor(22.4346, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  116 | Loss:  tensor(22.4528, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  117 | Loss:  tensor(22.4256, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  118 | Loss:  tensor(22.4415, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  119 | Loss:  tensor(22.4335, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  120 | Loss:  tensor(22.4434, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  121 | Loss:  tensor(22.4513, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  122 | Loss:  tensor(22.4365, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  123 | Loss:  tensor(22.4479, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  124 | Loss:  tensor(22.4380, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  125 | Loss:  tensor(22.4403, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  126 | Loss:  tensor(22.4454, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  127 | Loss:  tensor(22.4337, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  128 | Loss:  tensor(22.4228, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  129 | Loss:  tensor(22.4430, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  130 | Loss:  tensor(22.4449, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  131 | Loss:  tensor(22.4744, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  132 | Loss:  tensor(22.4447, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  133 | Loss:  tensor(22.4406, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  134 | Loss:  tensor(22.4672, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  135 | Loss:  tensor(22.4707, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  136 | Loss:  tensor(22.4893, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  137 | Loss:  tensor(22.4569, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  138 | Loss:  tensor(22.4821, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  139 | Loss:  tensor(22.4409, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  140 | Loss:  tensor(22.4697, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  141 | Loss:  tensor(22.4482, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  142 | Loss:  tensor(22.4616, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  143 | Loss:  tensor(22.4691, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  144 | Loss:  tensor(22.4668, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  145 | Loss:  tensor(22.4350, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  146 | Loss:  tensor(22.4951, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  147 | Loss:  tensor(22.4477, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  148 | Loss:  tensor(22.4579, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  149 | Loss:  tensor(22.4578, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  150 | Loss:  tensor(22.4733, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  151 | Loss:  tensor(22.4287, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  152 | Loss:  tensor(22.4385, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  153 | Loss:  tensor(22.4274, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  154 | Loss:  tensor(22.4442, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  155 | Loss:  tensor(22.4606, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  156 | Loss:  tensor(22.4521, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  157 | Loss:  tensor(22.4316, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  158 | Loss:  tensor(22.4611, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  159 | Loss:  tensor(22.4575, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  160 | Loss:  tensor(22.4919, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  161 | Loss:  tensor(22.4460, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  162 | Loss:  tensor(22.4540, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  163 | Loss:  tensor(22.4359, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  164 | Loss:  tensor(22.4398, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  165 | Loss:  tensor(22.4371, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  166 | Loss:  tensor(22.4307, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  167 | Loss:  tensor(22.4545, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  168 | Loss:  tensor(22.4295, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  169 | Loss:  tensor(22.4255, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  170 | Loss:  tensor(22.4486, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  171 | Loss:  tensor(22.4599, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  172 | Loss:  tensor(22.4438, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  173 | Loss:  tensor(22.4562, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  174 | Loss:  tensor(22.4388, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  175 | Loss:  tensor(22.4582, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  176 | Loss:  tensor(22.4518, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  177 | Loss:  tensor(22.4605, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  178 | Loss:  tensor(22.4613, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  179 | Loss:  tensor(22.4483, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  180 | Loss:  tensor(22.4561, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  181 | Loss:  tensor(22.4759, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  182 | Loss:  tensor(22.4536, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  183 | Loss:  tensor(22.4387, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  184 | Loss:  tensor(22.4477, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  185 | Loss:  tensor(22.4637, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  186 | Loss:  tensor(22.4486, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  187 | Loss:  tensor(22.4687, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  188 | Loss:  tensor(22.4523, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  189 | Loss:  tensor(22.4740, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  190 | Loss:  tensor(22.4836, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  191 | Loss:  tensor(22.4502, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  192 | Loss:  tensor(22.4530, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  193 | Loss:  tensor(22.4570, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  194 | Loss:  tensor(22.4536, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  195 | Loss:  tensor(22.4503, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  196 | Loss:  tensor(22.4661, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  197 | Loss:  tensor(22.4608, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  198 | Loss:  tensor(22.4635, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  199 | Loss:  tensor(22.4678, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  200 | Loss:  tensor(22.4982, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  201 | Loss:  tensor(22.4640, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  202 | Loss:  tensor(22.4559, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  203 | Loss:  tensor(22.4517, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  204 | Loss:  tensor(22.4491, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  205 | Loss:  tensor(22.4547, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  206 | Loss:  tensor(22.4587, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  207 | Loss:  tensor(22.4442, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  208 | Loss:  tensor(22.4440, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  209 | Loss:  tensor(22.4615, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  210 | Loss:  tensor(22.4671, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  211 | Loss:  tensor(22.4524, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  212 | Loss:  tensor(22.4606, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  213 | Loss:  tensor(22.4398, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  214 | Loss:  tensor(22.4659, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  215 | Loss:  tensor(22.4976, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  216 | Loss:  tensor(22.4607, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  217 | Loss:  tensor(22.4532, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  218 | Loss:  tensor(22.4571, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  219 | Loss:  tensor(22.4591, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  220 | Loss:  tensor(22.4679, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  221 | Loss:  tensor(22.4567, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  222 | Loss:  tensor(22.4581, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  223 | Loss:  tensor(22.4570, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  224 | Loss:  tensor(22.4681, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  225 | Loss:  tensor(22.4811, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  226 | Loss:  tensor(22.4718, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  227 | Loss:  tensor(22.4452, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  228 | Loss:  tensor(22.4470, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  229 | Loss:  tensor(22.4535, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  230 | Loss:  tensor(22.4549, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  231 | Loss:  tensor(22.4706, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  232 | Loss:  tensor(22.4682, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  233 | Loss:  tensor(22.4502, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  234 | Loss:  tensor(22.4524, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  235 | Loss:  tensor(22.4440, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  236 | Loss:  tensor(22.4492, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  237 | Loss:  tensor(22.4518, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  238 | Loss:  tensor(22.4637, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  239 | Loss:  tensor(22.4648, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  240 | Loss:  tensor(22.4776, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  241 | Loss:  tensor(22.4536, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  242 | Loss:  tensor(22.4656, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  243 | Loss:  tensor(22.4565, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  244 | Loss:  tensor(22.5075, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  245 | Loss:  tensor(22.4477, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  246 | Loss:  tensor(22.4800, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  247 | Loss:  tensor(22.4508, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  248 | Loss:  tensor(22.4634, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  249 | Loss:  tensor(22.4495, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  250 | Loss:  tensor(22.4459, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  251 | Loss:  tensor(22.4512, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  252 | Loss:  tensor(22.4500, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  253 | Loss:  tensor(22.4781, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  254 | Loss:  tensor(22.4652, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  255 | Loss:  tensor(22.4627, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  256 | Loss:  tensor(22.4557, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  257 | Loss:  tensor(22.4629, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  258 | Loss:  tensor(22.4434, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  259 | Loss:  tensor(22.4371, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  260 | Loss:  tensor(22.4574, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  261 | Loss:  tensor(22.4337, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  262 | Loss:  tensor(22.4635, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  263 | Loss:  tensor(22.4580, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  264 | Loss:  tensor(22.4657, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  265 | Loss:  tensor(22.4468, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  266 | Loss:  tensor(22.4387, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  267 | Loss:  tensor(22.4708, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  268 | Loss:  tensor(22.4464, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  269 | Loss:  tensor(22.4381, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  270 | Loss:  tensor(22.4347, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  271 | Loss:  tensor(22.4644, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  272 | Loss:  tensor(22.4404, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  273 | Loss:  tensor(22.4776, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  274 | Loss:  tensor(22.4863, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  275 | Loss:  tensor(22.4748, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  276 | Loss:  tensor(22.4519, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  277 | Loss:  tensor(22.4650, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  278 | Loss:  tensor(22.4759, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  279 | Loss:  tensor(22.4554, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  280 | Loss:  tensor(22.4691, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  281 | Loss:  tensor(22.4759, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  282 | Loss:  tensor(22.4562, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  283 | Loss:  tensor(22.4705, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  284 | Loss:  tensor(22.4361, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  285 | Loss:  tensor(22.4403, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  286 | Loss:  tensor(22.4489, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  287 | Loss:  tensor(22.4606, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  288 | Loss:  tensor(22.4396, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  289 | Loss:  tensor(22.4453, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  290 | Loss:  tensor(22.4260, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  291 | Loss:  tensor(22.4651, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  292 | Loss:  tensor(22.4654, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  293 | Loss:  tensor(22.4541, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  294 | Loss:  tensor(22.4880, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  295 | Loss:  tensor(22.4400, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  296 | Loss:  tensor(22.4583, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  297 | Loss:  tensor(22.4640, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  298 | Loss:  tensor(22.4572, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  299 | Loss:  tensor(22.4428, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  300 | Loss:  tensor(22.4596, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  301 | Loss:  tensor(22.4339, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  302 | Loss:  tensor(22.4781, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  303 | Loss:  tensor(22.4438, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  304 | Loss:  tensor(22.4533, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  305 | Loss:  tensor(22.4470, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  306 | Loss:  tensor(22.4554, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  307 | Loss:  tensor(22.4669, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  308 | Loss:  tensor(22.4816, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  309 | Loss:  tensor(22.4948, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  310 | Loss:  tensor(22.4653, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  311 | Loss:  tensor(22.4671, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  312 | Loss:  tensor(22.4492, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  313 | Loss:  tensor(22.4710, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  314 | Loss:  tensor(22.4528, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  315 | Loss:  tensor(22.4688, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  316 | Loss:  tensor(22.4405, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  317 | Loss:  tensor(22.4616, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  318 | Loss:  tensor(22.4501, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  319 | Loss:  tensor(22.4640, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  320 | Loss:  tensor(22.4785, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  321 | Loss:  tensor(22.4395, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  322 | Loss:  tensor(22.4713, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  323 | Loss:  tensor(22.4657, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  324 | Loss:  tensor(22.4795, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  325 | Loss:  tensor(22.4695, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  326 | Loss:  tensor(22.4935, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  327 | Loss:  tensor(22.4705, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  328 | Loss:  tensor(22.4935, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  329 | Loss:  tensor(22.4632, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  330 | Loss:  tensor(22.4777, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  331 | Loss:  tensor(22.4534, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  332 | Loss:  tensor(22.4691, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  333 | Loss:  tensor(22.4516, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  334 | Loss:  tensor(22.4543, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  335 | Loss:  tensor(22.4904, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  336 | Loss:  tensor(22.4553, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  337 | Loss:  tensor(22.4801, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  338 | Loss:  tensor(22.4668, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  339 | Loss:  tensor(22.4546, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  340 | Loss:  tensor(22.4578, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  341 | Loss:  tensor(22.4831, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  342 | Loss:  tensor(22.4868, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  343 | Loss:  tensor(22.4793, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  344 | Loss:  tensor(22.4799, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  345 | Loss:  tensor(22.4717, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  346 | Loss:  tensor(22.4580, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  347 | Loss:  tensor(22.4518, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  348 | Loss:  tensor(22.4440, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  349 | Loss:  tensor(22.4661, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  350 | Loss:  tensor(22.4593, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  351 | Loss:  tensor(22.4782, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  352 | Loss:  tensor(22.4719, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  353 | Loss:  tensor(22.4640, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  354 | Loss:  tensor(22.4665, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  355 | Loss:  tensor(22.4697, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  356 | Loss:  tensor(22.4471, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  357 | Loss:  tensor(22.4665, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  358 | Loss:  tensor(22.4570, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  359 | Loss:  tensor(22.4881, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  360 | Loss:  tensor(22.4542, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  361 | Loss:  tensor(22.4761, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  362 | Loss:  tensor(22.4544, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  363 | Loss:  tensor(22.4633, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  364 | Loss:  tensor(22.4486, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  365 | Loss:  tensor(22.4622, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  366 | Loss:  tensor(22.4735, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  367 | Loss:  tensor(22.4471, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  368 | Loss:  tensor(22.4847, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  369 | Loss:  tensor(22.4744, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  370 | Loss:  tensor(22.4681, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  371 | Loss:  tensor(22.4598, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  372 | Loss:  tensor(22.4434, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  373 | Loss:  tensor(22.4768, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  374 | Loss:  tensor(22.4695, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  375 | Loss:  tensor(22.4644, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  376 | Loss:  tensor(22.4806, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  377 | Loss:  tensor(22.4792, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  378 | Loss:  tensor(22.4776, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  379 | Loss:  tensor(22.4539, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  380 | Loss:  tensor(22.4589, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  381 | Loss:  tensor(22.4652, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  382 | Loss:  tensor(22.4653, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  383 | Loss:  tensor(22.4410, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  384 | Loss:  tensor(22.4517, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  385 | Loss:  tensor(22.4702, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  386 | Loss:  tensor(22.4631, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  387 | Loss:  tensor(22.4701, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  388 | Loss:  tensor(22.4583, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  389 | Loss:  tensor(22.4627, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  390 | Loss:  tensor(22.4612, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  391 | Loss:  tensor(22.4746, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  392 | Loss:  tensor(22.4756, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  393 | Loss:  tensor(22.4574, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  394 | Loss:  tensor(22.4507, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  395 | Loss:  tensor(22.4507, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  396 | Loss:  tensor(22.4595, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  397 | Loss:  tensor(22.4438, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  398 | Loss:  tensor(22.4487, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  399 | Loss:  tensor(22.4426, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  400 | Loss:  tensor(22.4485, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  401 | Loss:  tensor(22.4780, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  402 | Loss:  tensor(22.4539, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  403 | Loss:  tensor(22.4679, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  404 | Loss:  tensor(22.4564, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  405 | Loss:  tensor(22.4704, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  406 | Loss:  tensor(22.4586, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  407 | Loss:  tensor(22.4798, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  408 | Loss:  tensor(22.4440, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  409 | Loss:  tensor(22.4512, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  410 | Loss:  tensor(22.4376, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  411 | Loss:  tensor(22.4649, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  412 | Loss:  tensor(22.4378, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  413 | Loss:  tensor(22.4938, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  414 | Loss:  tensor(22.4378, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  415 | Loss:  tensor(22.4662, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  416 | Loss:  tensor(22.4646, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  417 | Loss:  tensor(22.4860, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  418 | Loss:  tensor(22.4549, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  419 | Loss:  tensor(22.4585, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  420 | Loss:  tensor(22.4603, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  421 | Loss:  tensor(22.4548, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  422 | Loss:  tensor(22.5234, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  423 | Loss:  tensor(22.4525, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  424 | Loss:  tensor(22.4553, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  425 | Loss:  tensor(22.4723, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  426 | Loss:  tensor(22.4751, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  427 | Loss:  tensor(22.4528, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  428 | Loss:  tensor(22.4459, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  429 | Loss:  tensor(22.4767, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  430 | Loss:  tensor(22.4550, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  431 | Loss:  tensor(22.4549, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  432 | Loss:  tensor(22.4603, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  433 | Loss:  tensor(22.4578, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  434 | Loss:  tensor(22.4520, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  435 | Loss:  tensor(22.4698, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  436 | Loss:  tensor(22.4404, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  437 | Loss:  tensor(22.4469, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  438 | Loss:  tensor(22.4679, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  439 | Loss:  tensor(22.4400, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  440 | Loss:  tensor(22.4589, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  441 | Loss:  tensor(22.4602, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  442 | Loss:  tensor(22.4591, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  443 | Loss:  tensor(22.4421, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  444 | Loss:  tensor(22.4276, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  445 | Loss:  tensor(22.4467, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  446 | Loss:  tensor(22.4992, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  447 | Loss:  tensor(22.4501, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  448 | Loss:  tensor(22.4510, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  449 | Loss:  tensor(22.4600, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  450 | Loss:  tensor(22.4467, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  451 | Loss:  tensor(22.4705, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  452 | Loss:  tensor(22.4565, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  453 | Loss:  tensor(22.4643, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  454 | Loss:  tensor(22.4542, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  455 | Loss:  tensor(22.4563, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  456 | Loss:  tensor(22.4458, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  457 | Loss:  tensor(22.4509, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  458 | Loss:  tensor(22.4647, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  459 | Loss:  tensor(22.5079, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  460 | Loss:  tensor(22.4438, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  461 | Loss:  tensor(22.4529, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  462 | Loss:  tensor(22.4485, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  463 | Loss:  tensor(22.4884, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  464 | Loss:  tensor(22.4665, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  465 | Loss:  tensor(22.4600, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  466 | Loss:  tensor(22.4505, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  467 | Loss:  tensor(22.4482, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  468 | Loss:  tensor(22.4517, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  469 | Loss:  tensor(22.4633, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  470 | Loss:  tensor(22.4530, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  471 | Loss:  tensor(22.4583, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  472 | Loss:  tensor(22.4539, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  473 | Loss:  tensor(22.4467, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  474 | Loss:  tensor(22.4678, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  475 | Loss:  tensor(22.4749, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  476 | Loss:  tensor(22.4552, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  477 | Loss:  tensor(22.4530, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  478 | Loss:  tensor(22.4693, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  479 | Loss:  tensor(22.4405, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  480 | Loss:  tensor(22.4737, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  481 | Loss:  tensor(22.4660, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  482 | Loss:  tensor(22.4624, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  483 | Loss:  tensor(22.4340, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  484 | Loss:  tensor(22.4650, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  485 | Loss:  tensor(22.4498, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  486 | Loss:  tensor(22.4448, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  487 | Loss:  tensor(22.4421, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  488 | Loss:  tensor(22.4443, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  489 | Loss:  tensor(22.4450, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  490 | Loss:  tensor(22.4649, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  491 | Loss:  tensor(22.4627, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  492 | Loss:  tensor(22.4465, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  493 | Loss:  tensor(22.4635, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  494 | Loss:  tensor(22.4475, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  495 | Loss:  tensor(22.4481, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  496 | Loss:  tensor(22.4472, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  497 | Loss:  tensor(22.4507, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  498 | Loss:  tensor(22.4767, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  499 | Loss:  tensor(22.4466, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  500 | Loss:  tensor(22.4537, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  501 | Loss:  tensor(22.4788, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  502 | Loss:  tensor(22.4655, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  503 | Loss:  tensor(22.4616, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  504 | Loss:  tensor(22.4510, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  505 | Loss:  tensor(22.4381, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  506 | Loss:  tensor(22.4578, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  507 | Loss:  tensor(22.4445, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  508 | Loss:  tensor(22.4407, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  509 | Loss:  tensor(22.4753, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  510 | Loss:  tensor(22.4802, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  511 | Loss:  tensor(22.4800, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  512 | Loss:  tensor(22.4518, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  513 | Loss:  tensor(22.4572, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  514 | Loss:  tensor(22.4583, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  515 | Loss:  tensor(22.4502, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  516 | Loss:  tensor(22.4610, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  517 | Loss:  tensor(22.4542, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  518 | Loss:  tensor(22.4532, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  519 | Loss:  tensor(22.4564, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  520 | Loss:  tensor(22.4756, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  521 | Loss:  tensor(22.4719, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  522 | Loss:  tensor(22.4708, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  523 | Loss:  tensor(22.4670, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  524 | Loss:  tensor(22.4729, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  525 | Loss:  tensor(22.4596, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  526 | Loss:  tensor(22.4654, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  527 | Loss:  tensor(22.4408, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  528 | Loss:  tensor(22.4732, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  529 | Loss:  tensor(22.4833, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  530 | Loss:  tensor(22.4570, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  531 | Loss:  tensor(22.4654, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  532 | Loss:  tensor(22.4597, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  533 | Loss:  tensor(22.4568, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  534 | Loss:  tensor(22.4627, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  535 | Loss:  tensor(22.4803, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  536 | Loss:  tensor(22.4612, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  537 | Loss:  tensor(22.4614, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  538 | Loss:  tensor(22.4716, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  539 | Loss:  tensor(22.4633, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  540 | Loss:  tensor(22.4932, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  541 | Loss:  tensor(22.4806, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  542 | Loss:  tensor(22.4849, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  543 | Loss:  tensor(22.4775, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  544 | Loss:  tensor(22.4620, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  545 | Loss:  tensor(22.4780, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  546 | Loss:  tensor(22.4801, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  547 | Loss:  tensor(22.4894, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  548 | Loss:  tensor(22.4899, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  549 | Loss:  tensor(22.4702, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  550 | Loss:  tensor(22.5207, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  551 | Loss:  tensor(22.4939, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  552 | Loss:  tensor(22.5072, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  553 | Loss:  tensor(22.4929, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  554 | Loss:  tensor(22.4804, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  555 | Loss:  tensor(22.4869, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  556 | Loss:  tensor(22.4952, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  557 | Loss:  tensor(22.4755, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  558 | Loss:  tensor(22.5052, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  559 | Loss:  tensor(22.4737, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  560 | Loss:  tensor(22.4846, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  561 | Loss:  tensor(22.4671, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  562 | Loss:  tensor(22.4983, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  563 | Loss:  tensor(22.4826, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  564 | Loss:  tensor(22.4658, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  565 | Loss:  tensor(22.4601, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  566 | Loss:  tensor(22.4923, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  567 | Loss:  tensor(22.4577, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  568 | Loss:  tensor(22.4821, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  569 | Loss:  tensor(22.4735, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  570 | Loss:  tensor(22.4631, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  571 | Loss:  tensor(22.4665, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  572 | Loss:  tensor(22.4682, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  573 | Loss:  tensor(22.4695, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  574 | Loss:  tensor(22.4741, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  575 | Loss:  tensor(22.4799, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  576 | Loss:  tensor(22.4667, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  577 | Loss:  tensor(22.4532, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  578 | Loss:  tensor(22.4692, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  579 | Loss:  tensor(22.4837, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  580 | Loss:  tensor(22.4937, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  581 | Loss:  tensor(22.4544, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  582 | Loss:  tensor(22.4636, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  583 | Loss:  tensor(22.4655, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  584 | Loss:  tensor(22.4933, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  585 | Loss:  tensor(22.4775, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  586 | Loss:  tensor(22.5038, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  587 | Loss:  tensor(22.4927, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  588 | Loss:  tensor(22.4555, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  589 | Loss:  tensor(22.5141, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  590 | Loss:  tensor(22.4701, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  591 | Loss:  tensor(22.4861, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  592 | Loss:  tensor(22.4711, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  593 | Loss:  tensor(22.4618, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  594 | Loss:  tensor(22.4774, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  595 | Loss:  tensor(22.4626, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  596 | Loss:  tensor(22.4662, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  597 | Loss:  tensor(22.4681, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  598 | Loss:  tensor(22.4668, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  599 | Loss:  tensor(22.4721, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  600 | Loss:  tensor(22.4582, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  601 | Loss:  tensor(22.4586, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  602 | Loss:  tensor(22.4538, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  603 | Loss:  tensor(22.4755, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  604 | Loss:  tensor(22.4901, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  605 | Loss:  tensor(22.4728, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  606 | Loss:  tensor(22.4777, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  607 | Loss:  tensor(22.4635, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  608 | Loss:  tensor(22.4762, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  609 | Loss:  tensor(22.4813, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  610 | Loss:  tensor(22.4665, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  611 | Loss:  tensor(22.4658, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  612 | Loss:  tensor(22.4974, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  613 | Loss:  tensor(22.4602, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  614 | Loss:  tensor(22.4768, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  615 | Loss:  tensor(22.4754, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  616 | Loss:  tensor(22.4867, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  617 | Loss:  tensor(22.4657, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  618 | Loss:  tensor(22.4544, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  619 | Loss:  tensor(22.4799, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  620 | Loss:  tensor(22.4627, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  621 | Loss:  tensor(22.4693, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  622 | Loss:  tensor(22.4753, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  623 | Loss:  tensor(22.4713, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  624 | Loss:  tensor(22.4839, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  625 | Loss:  tensor(22.4956, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  626 | Loss:  tensor(22.4749, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  627 | Loss:  tensor(22.4651, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  628 | Loss:  tensor(22.4699, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  629 | Loss:  tensor(22.4670, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  630 | Loss:  tensor(22.4624, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  631 | Loss:  tensor(22.4777, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  632 | Loss:  tensor(22.4671, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  633 | Loss:  tensor(22.4668, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  634 | Loss:  tensor(22.4916, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  635 | Loss:  tensor(22.5050, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  636 | Loss:  tensor(22.4732, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  637 | Loss:  tensor(22.4921, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  638 | Loss:  tensor(22.4645, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  639 | Loss:  tensor(22.4860, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  640 | Loss:  tensor(22.4787, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  641 | Loss:  tensor(22.4688, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  642 | Loss:  tensor(22.4774, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  643 | Loss:  tensor(22.4634, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  644 | Loss:  tensor(22.5025, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  645 | Loss:  tensor(22.4563, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  646 | Loss:  tensor(22.4673, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  647 | Loss:  tensor(22.4658, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  648 | Loss:  tensor(22.4752, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  649 | Loss:  tensor(22.4783, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  650 | Loss:  tensor(22.5127, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  651 | Loss:  tensor(22.5029, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  652 | Loss:  tensor(22.4738, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  653 | Loss:  tensor(22.4733, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  654 | Loss:  tensor(22.5054, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  655 | Loss:  tensor(22.5037, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  656 | Loss:  tensor(22.4821, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  657 | Loss:  tensor(22.4605, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  658 | Loss:  tensor(22.4873, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  659 | Loss:  tensor(22.4623, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  660 | Loss:  tensor(22.4482, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  661 | Loss:  tensor(22.4757, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  662 | Loss:  tensor(22.4621, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  663 | Loss:  tensor(22.4787, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  664 | Loss:  tensor(22.4597, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  665 | Loss:  tensor(22.4431, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  666 | Loss:  tensor(22.4696, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  667 | Loss:  tensor(22.4443, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  668 | Loss:  tensor(22.4583, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  669 | Loss:  tensor(22.4375, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  670 | Loss:  tensor(22.4510, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  671 | Loss:  tensor(22.4467, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  672 | Loss:  tensor(22.5219, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  673 | Loss:  tensor(22.4988, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  674 | Loss:  tensor(22.4793, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  675 | Loss:  tensor(22.4863, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  676 | Loss:  tensor(22.4860, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  677 | Loss:  tensor(22.4744, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  678 | Loss:  tensor(22.4709, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  679 | Loss:  tensor(22.4540, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  680 | Loss:  tensor(22.4593, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  681 | Loss:  tensor(22.4786, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  682 | Loss:  tensor(22.4876, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  683 | Loss:  tensor(22.4692, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  684 | Loss:  tensor(22.4773, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  685 | Loss:  tensor(22.4544, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  686 | Loss:  tensor(22.4630, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  687 | Loss:  tensor(22.4664, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  688 | Loss:  tensor(22.4515, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  689 | Loss:  tensor(22.4661, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  690 | Loss:  tensor(22.4833, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  691 | Loss:  tensor(22.4688, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  692 | Loss:  tensor(22.4697, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  693 | Loss:  tensor(22.4484, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  694 | Loss:  tensor(22.4526, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  695 | Loss:  tensor(22.5009, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  696 | Loss:  tensor(22.4442, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  697 | Loss:  tensor(22.4661, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  698 | Loss:  tensor(22.5129, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  699 | Loss:  tensor(22.4691, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  700 | Loss:  tensor(22.4594, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  701 | Loss:  tensor(22.4844, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  702 | Loss:  tensor(22.4473, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  703 | Loss:  tensor(22.4434, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  704 | Loss:  tensor(22.4524, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  705 | Loss:  tensor(22.4817, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  706 | Loss:  tensor(22.4788, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  707 | Loss:  tensor(22.4804, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  708 | Loss:  tensor(22.4510, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  709 | Loss:  tensor(22.4813, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  710 | Loss:  tensor(22.4532, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  711 | Loss:  tensor(22.4682, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  712 | Loss:  tensor(22.4435, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  713 | Loss:  tensor(22.4727, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  714 | Loss:  tensor(22.4577, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  715 | Loss:  tensor(22.4963, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  716 | Loss:  tensor(22.4504, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  717 | Loss:  tensor(22.4619, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  718 | Loss:  tensor(22.4556, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  719 | Loss:  tensor(22.4594, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  720 | Loss:  tensor(22.4445, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  721 | Loss:  tensor(22.4476, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  722 | Loss:  tensor(22.4628, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  723 | Loss:  tensor(22.4518, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  724 | Loss:  tensor(22.4982, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  725 | Loss:  tensor(22.4629, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  726 | Loss:  tensor(22.4583, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  727 | Loss:  tensor(22.4714, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  728 | Loss:  tensor(22.6369, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  729 | Loss:  tensor(22.4644, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  730 | Loss:  tensor(22.4888, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  731 | Loss:  tensor(22.4533, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  732 | Loss:  tensor(22.4608, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  733 | Loss:  tensor(22.5032, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  734 | Loss:  tensor(22.4468, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  735 | Loss:  tensor(22.4576, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  736 | Loss:  tensor(22.4621, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  737 | Loss:  tensor(22.4600, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  738 | Loss:  tensor(22.4770, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  739 | Loss:  tensor(22.4644, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  740 | Loss:  tensor(22.4534, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  741 | Loss:  tensor(22.4495, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  742 | Loss:  tensor(22.4602, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  743 | Loss:  tensor(22.4461, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  744 | Loss:  tensor(22.4493, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  745 | Loss:  tensor(22.4482, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  746 | Loss:  tensor(22.4525, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  747 | Loss:  tensor(22.4349, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  748 | Loss:  tensor(22.4716, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  749 | Loss:  tensor(22.4507, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  750 | Loss:  tensor(22.4403, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  751 | Loss:  tensor(22.4577, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  752 | Loss:  tensor(22.4809, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  753 | Loss:  tensor(22.4574, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  754 | Loss:  tensor(22.4438, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  755 | Loss:  tensor(22.4717, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  756 | Loss:  tensor(22.4509, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  757 | Loss:  tensor(22.4841, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  758 | Loss:  tensor(22.4485, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  759 | Loss:  tensor(22.4377, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  760 | Loss:  tensor(22.4483, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  761 | Loss:  tensor(22.4991, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  762 | Loss:  tensor(22.4617, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  763 | Loss:  tensor(22.4376, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  764 | Loss:  tensor(22.4414, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  765 | Loss:  tensor(22.4410, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  766 | Loss:  tensor(22.4449, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  767 | Loss:  tensor(22.4614, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  768 | Loss:  tensor(22.4463, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  769 | Loss:  tensor(22.4688, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  770 | Loss:  tensor(22.4694, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  771 | Loss:  tensor(22.4490, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  772 | Loss:  tensor(22.4542, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  773 | Loss:  tensor(22.4521, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  774 | Loss:  tensor(22.4468, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  775 | Loss:  tensor(22.4442, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  776 | Loss:  tensor(22.4411, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  777 | Loss:  tensor(22.4492, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  778 | Loss:  tensor(22.4660, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  779 | Loss:  tensor(22.4577, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  780 | Loss:  tensor(22.4746, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  781 | Loss:  tensor(22.4504, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  782 | Loss:  tensor(22.4644, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  783 | Loss:  tensor(22.4615, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  784 | Loss:  tensor(22.5201, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  785 | Loss:  tensor(22.4654, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  786 | Loss:  tensor(22.4721, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  787 | Loss:  tensor(22.4680, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  788 | Loss:  tensor(22.4466, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  789 | Loss:  tensor(22.4455, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  790 | Loss:  tensor(22.4593, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  791 | Loss:  tensor(22.4457, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  792 | Loss:  tensor(22.4570, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  793 | Loss:  tensor(22.4549, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  794 | Loss:  tensor(22.4642, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  795 | Loss:  tensor(22.4539, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  796 | Loss:  tensor(22.4524, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  797 | Loss:  tensor(22.4489, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  798 | Loss:  tensor(22.4562, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  799 | Loss:  tensor(22.4334, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  800 | Loss:  tensor(22.4687, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  801 | Loss:  tensor(22.4469, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  802 | Loss:  tensor(22.4779, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  803 | Loss:  tensor(22.4456, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  804 | Loss:  tensor(22.4513, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  805 | Loss:  tensor(22.4732, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  806 | Loss:  tensor(22.4490, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  807 | Loss:  tensor(22.4560, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  808 | Loss:  tensor(22.4538, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  809 | Loss:  tensor(22.4456, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  810 | Loss:  tensor(22.4528, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  811 | Loss:  tensor(22.4681, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  812 | Loss:  tensor(22.4500, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  813 | Loss:  tensor(22.4479, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  814 | Loss:  tensor(22.4465, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  815 | Loss:  tensor(22.4571, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  816 | Loss:  tensor(22.4522, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  817 | Loss:  tensor(22.4806, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  818 | Loss:  tensor(22.4478, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  819 | Loss:  tensor(22.4483, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  820 | Loss:  tensor(22.4510, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  821 | Loss:  tensor(22.4533, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  822 | Loss:  tensor(22.4669, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  823 | Loss:  tensor(22.4621, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  824 | Loss:  tensor(22.4740, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  825 | Loss:  tensor(22.4818, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  826 | Loss:  tensor(22.4609, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  827 | Loss:  tensor(22.4945, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  828 | Loss:  tensor(22.4523, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  829 | Loss:  tensor(22.4931, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  830 | Loss:  tensor(22.4841, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  831 | Loss:  tensor(22.5026, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  832 | Loss:  tensor(22.4705, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  833 | Loss:  tensor(22.4515, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  834 | Loss:  tensor(22.4722, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  835 | Loss:  tensor(22.4848, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  836 | Loss:  tensor(22.4641, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  837 | Loss:  tensor(22.5076, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  838 | Loss:  tensor(22.4705, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  839 | Loss:  tensor(22.4581, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  840 | Loss:  tensor(22.4818, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  841 | Loss:  tensor(22.4612, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  842 | Loss:  tensor(22.4710, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  843 | Loss:  tensor(22.4728, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  844 | Loss:  tensor(22.4697, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  845 | Loss:  tensor(22.5022, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  846 | Loss:  tensor(22.4635, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  847 | Loss:  tensor(22.4653, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  848 | Loss:  tensor(22.4842, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  849 | Loss:  tensor(22.4712, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  850 | Loss:  tensor(22.4794, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  851 | Loss:  tensor(22.4956, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  852 | Loss:  tensor(22.4704, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  853 | Loss:  tensor(22.4650, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  854 | Loss:  tensor(22.4658, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  855 | Loss:  tensor(22.4759, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  856 | Loss:  tensor(22.4688, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  857 | Loss:  tensor(22.4595, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  858 | Loss:  tensor(22.4719, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  859 | Loss:  tensor(22.4770, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  860 | Loss:  tensor(22.4928, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  861 | Loss:  tensor(22.5051, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  862 | Loss:  tensor(22.4943, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  863 | Loss:  tensor(22.4880, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  864 | Loss:  tensor(22.4661, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  865 | Loss:  tensor(22.4621, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  866 | Loss:  tensor(22.4589, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  867 | Loss:  tensor(22.4768, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  868 | Loss:  tensor(22.4745, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  869 | Loss:  tensor(22.4609, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  870 | Loss:  tensor(22.4962, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  871 | Loss:  tensor(22.4636, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  872 | Loss:  tensor(22.5046, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  873 | Loss:  tensor(22.4963, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  874 | Loss:  tensor(22.4958, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  875 | Loss:  tensor(22.4721, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  876 | Loss:  tensor(22.5217, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  877 | Loss:  tensor(22.4814, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  878 | Loss:  tensor(22.5092, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  879 | Loss:  tensor(22.4938, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  880 | Loss:  tensor(22.4775, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  881 | Loss:  tensor(22.4853, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  882 | Loss:  tensor(22.4979, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  883 | Loss:  tensor(22.4812, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  884 | Loss:  tensor(22.4826, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  885 | Loss:  tensor(22.4928, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  886 | Loss:  tensor(22.4871, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  887 | Loss:  tensor(22.4819, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  888 | Loss:  tensor(22.4927, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  889 | Loss:  tensor(22.4816, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  890 | Loss:  tensor(22.4755, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  891 | Loss:  tensor(22.4904, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  892 | Loss:  tensor(22.5100, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  893 | Loss:  tensor(22.4761, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  894 | Loss:  tensor(22.4676, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  895 | Loss:  tensor(22.4827, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  896 | Loss:  tensor(22.4957, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  897 | Loss:  tensor(22.4628, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  898 | Loss:  tensor(22.4942, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  899 | Loss:  tensor(22.4733, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  900 | Loss:  tensor(22.4653, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  901 | Loss:  tensor(22.4929, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  902 | Loss:  tensor(22.5031, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  903 | Loss:  tensor(22.4632, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  904 | Loss:  tensor(22.4771, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  905 | Loss:  tensor(22.4559, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  906 | Loss:  tensor(22.4593, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  907 | Loss:  tensor(22.4831, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  908 | Loss:  tensor(22.4871, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  909 | Loss:  tensor(22.5058, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  910 | Loss:  tensor(22.4831, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  911 | Loss:  tensor(22.4951, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  912 | Loss:  tensor(22.4826, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  913 | Loss:  tensor(22.4819, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  914 | Loss:  tensor(22.4764, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  915 | Loss:  tensor(22.4657, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  916 | Loss:  tensor(22.4707, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  917 | Loss:  tensor(22.4981, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  918 | Loss:  tensor(22.5422, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  919 | Loss:  tensor(22.4949, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  920 | Loss:  tensor(22.5258, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  921 | Loss:  tensor(22.4754, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  922 | Loss:  tensor(22.4973, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  923 | Loss:  tensor(22.4958, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  924 | Loss:  tensor(22.4951, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  925 | Loss:  tensor(22.4791, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  926 | Loss:  tensor(22.4738, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  927 | Loss:  tensor(22.4780, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  928 | Loss:  tensor(22.4860, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  929 | Loss:  tensor(22.4871, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  930 | Loss:  tensor(22.4824, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  931 | Loss:  tensor(22.4904, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  932 | Loss:  tensor(22.4831, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  933 | Loss:  tensor(22.5032, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  934 | Loss:  tensor(22.5123, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  935 | Loss:  tensor(22.5022, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  936 | Loss:  tensor(22.4897, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  937 | Loss:  tensor(22.4945, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  938 | Loss:  tensor(22.5014, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  939 | Loss:  tensor(22.4911, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  940 | Loss:  tensor(22.4825, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  941 | Loss:  tensor(22.4783, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  942 | Loss:  tensor(22.5284, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  943 | Loss:  tensor(22.4825, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  944 | Loss:  tensor(22.4996, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  945 | Loss:  tensor(22.4903, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  946 | Loss:  tensor(22.4877, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  947 | Loss:  tensor(22.4691, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  948 | Loss:  tensor(22.4910, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  949 | Loss:  tensor(22.5028, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  950 | Loss:  tensor(22.4935, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  951 | Loss:  tensor(22.4744, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  952 | Loss:  tensor(22.4597, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  953 | Loss:  tensor(22.4756, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  954 | Loss:  tensor(22.5025, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  955 | Loss:  tensor(22.5040, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  956 | Loss:  tensor(22.4757, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  957 | Loss:  tensor(22.4757, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  958 | Loss:  tensor(22.5022, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  959 | Loss:  tensor(22.4848, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  960 | Loss:  tensor(22.4922, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  961 | Loss:  tensor(22.5198, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  962 | Loss:  tensor(22.4786, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  963 | Loss:  tensor(22.4762, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  964 | Loss:  tensor(22.4725, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  965 | Loss:  tensor(22.4865, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  966 | Loss:  tensor(22.4872, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  967 | Loss:  tensor(22.4822, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  968 | Loss:  tensor(22.4704, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  969 | Loss:  tensor(22.4819, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  970 | Loss:  tensor(22.5430, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  971 | Loss:  tensor(22.4676, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  972 | Loss:  tensor(22.5049, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  973 | Loss:  tensor(22.4877, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  974 | Loss:  tensor(22.4864, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  975 | Loss:  tensor(22.4860, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  976 | Loss:  tensor(22.4754, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  977 | Loss:  tensor(22.4860, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  978 | Loss:  tensor(22.4869, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  979 | Loss:  tensor(22.5031, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  980 | Loss:  tensor(22.4837, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  981 | Loss:  tensor(22.4796, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  982 | Loss:  tensor(22.5102, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  983 | Loss:  tensor(22.4851, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  984 | Loss:  tensor(22.5043, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  985 | Loss:  tensor(22.4807, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  986 | Loss:  tensor(22.4747, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  987 | Loss:  tensor(22.4865, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  988 | Loss:  tensor(22.4728, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  989 | Loss:  tensor(22.4765, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  990 | Loss:  tensor(22.4817, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  991 | Loss:  tensor(22.4983, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  992 | Loss:  tensor(22.5001, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  993 | Loss:  tensor(22.4841, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  994 | Loss:  tensor(22.4703, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  995 | Loss:  tensor(22.4904, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  996 | Loss:  tensor(22.5362, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  997 | Loss:  tensor(22.5142, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  998 | Loss:  tensor(22.4750, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  999 | Loss:  tensor(22.5282, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1000 | Loss:  tensor(22.4797, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1001 | Loss:  tensor(22.4994, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1002 | Loss:  tensor(22.4829, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1003 | Loss:  tensor(22.4668, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1004 | Loss:  tensor(22.4847, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1005 | Loss:  tensor(22.4600, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1006 | Loss:  tensor(22.4729, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1007 | Loss:  tensor(22.4700, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1008 | Loss:  tensor(22.4626, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1009 | Loss:  tensor(22.4668, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1010 | Loss:  tensor(22.4756, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1011 | Loss:  tensor(22.4573, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1012 | Loss:  tensor(22.4673, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1013 | Loss:  tensor(22.4825, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1014 | Loss:  tensor(22.5166, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1015 | Loss:  tensor(22.4869, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1016 | Loss:  tensor(22.4960, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1017 | Loss:  tensor(22.4730, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1018 | Loss:  tensor(22.4903, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1019 | Loss:  tensor(22.4645, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1020 | Loss:  tensor(22.4614, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1021 | Loss:  tensor(22.4895, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1022 | Loss:  tensor(22.4819, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1023 | Loss:  tensor(22.4734, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1024 | Loss:  tensor(22.4732, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1025 | Loss:  tensor(22.4765, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1026 | Loss:  tensor(22.4913, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1027 | Loss:  tensor(22.4790, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1028 | Loss:  tensor(22.4795, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1029 | Loss:  tensor(22.4738, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1030 | Loss:  tensor(22.4741, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1031 | Loss:  tensor(22.5176, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1032 | Loss:  tensor(22.5057, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1033 | Loss:  tensor(22.5024, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1034 | Loss:  tensor(22.4708, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1035 | Loss:  tensor(22.4952, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1036 | Loss:  tensor(22.4778, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1037 | Loss:  tensor(22.4943, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1038 | Loss:  tensor(22.4729, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1039 | Loss:  tensor(22.4922, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1040 | Loss:  tensor(22.4747, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1041 | Loss:  tensor(22.4937, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1042 | Loss:  tensor(22.4674, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1043 | Loss:  tensor(22.4788, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1044 | Loss:  tensor(22.4816, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1045 | Loss:  tensor(22.5071, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1046 | Loss:  tensor(22.4827, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1047 | Loss:  tensor(22.4906, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1048 | Loss:  tensor(22.5150, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1049 | Loss:  tensor(22.4918, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1050 | Loss:  tensor(22.4789, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1051 | Loss:  tensor(22.5069, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1052 | Loss:  tensor(22.5055, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1053 | Loss:  tensor(22.4890, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1054 | Loss:  tensor(22.4786, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1055 | Loss:  tensor(22.4734, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1056 | Loss:  tensor(22.4712, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1057 | Loss:  tensor(22.4983, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1058 | Loss:  tensor(22.4879, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1059 | Loss:  tensor(22.4826, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1060 | Loss:  tensor(22.4936, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1061 | Loss:  tensor(22.5025, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1062 | Loss:  tensor(22.4816, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1063 | Loss:  tensor(22.4760, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1064 | Loss:  tensor(22.4833, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1065 | Loss:  tensor(22.4749, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1066 | Loss:  tensor(22.4845, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1067 | Loss:  tensor(22.4719, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1068 | Loss:  tensor(22.4673, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1069 | Loss:  tensor(22.4823, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1070 | Loss:  tensor(22.4876, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1071 | Loss:  tensor(22.4892, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1072 | Loss:  tensor(22.4744, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1073 | Loss:  tensor(22.4865, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1074 | Loss:  tensor(22.4644, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1075 | Loss:  tensor(22.4883, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1076 | Loss:  tensor(22.4653, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1077 | Loss:  tensor(22.4669, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1078 | Loss:  tensor(22.4613, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1079 | Loss:  tensor(22.5372, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1080 | Loss:  tensor(22.4748, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1081 | Loss:  tensor(22.4842, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1082 | Loss:  tensor(22.4700, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1083 | Loss:  tensor(22.4731, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1084 | Loss:  tensor(22.5109, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1085 | Loss:  tensor(22.4941, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1086 | Loss:  tensor(22.4929, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1087 | Loss:  tensor(22.4802, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1088 | Loss:  tensor(22.4713, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1089 | Loss:  tensor(22.4881, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1090 | Loss:  tensor(22.5095, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1091 | Loss:  tensor(22.4805, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1092 | Loss:  tensor(22.4806, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1093 | Loss:  tensor(22.4697, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1094 | Loss:  tensor(22.4859, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1095 | Loss:  tensor(22.4729, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1096 | Loss:  tensor(22.4840, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1097 | Loss:  tensor(22.4906, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1098 | Loss:  tensor(22.4944, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1099 | Loss:  tensor(22.4959, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1100 | Loss:  tensor(22.4812, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1101 | Loss:  tensor(22.4890, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1102 | Loss:  tensor(22.5201, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1103 | Loss:  tensor(22.4889, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1104 | Loss:  tensor(22.4912, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1105 | Loss:  tensor(22.4866, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1106 | Loss:  tensor(22.5119, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1107 | Loss:  tensor(22.4979, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1108 | Loss:  tensor(22.4772, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1109 | Loss:  tensor(22.5038, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1110 | Loss:  tensor(22.5084, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1111 | Loss:  tensor(22.5034, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1112 | Loss:  tensor(22.4807, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1113 | Loss:  tensor(22.5166, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1114 | Loss:  tensor(22.4755, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1115 | Loss:  tensor(22.4821, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1116 | Loss:  tensor(22.4994, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1117 | Loss:  tensor(22.4754, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1118 | Loss:  tensor(22.4892, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1119 | Loss:  tensor(22.4907, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1120 | Loss:  tensor(22.5111, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1121 | Loss:  tensor(22.4816, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1122 | Loss:  tensor(22.4950, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1123 | Loss:  tensor(22.4751, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1124 | Loss:  tensor(22.4782, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1125 | Loss:  tensor(22.4706, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1126 | Loss:  tensor(22.4805, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1127 | Loss:  tensor(22.4776, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1128 | Loss:  tensor(22.4897, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1129 | Loss:  tensor(22.4739, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1130 | Loss:  tensor(22.4843, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1131 | Loss:  tensor(22.4876, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1132 | Loss:  tensor(22.4745, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1133 | Loss:  tensor(22.5019, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1134 | Loss:  tensor(22.4786, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1135 | Loss:  tensor(22.5036, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1136 | Loss:  tensor(22.5024, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1137 | Loss:  tensor(22.4682, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1138 | Loss:  tensor(22.5011, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1139 | Loss:  tensor(22.4755, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1140 | Loss:  tensor(22.4789, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1141 | Loss:  tensor(22.4749, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1142 | Loss:  tensor(22.5274, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1143 | Loss:  tensor(22.4830, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1144 | Loss:  tensor(22.4936, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1145 | Loss:  tensor(22.4786, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1146 | Loss:  tensor(22.5020, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1147 | Loss:  tensor(22.4815, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1148 | Loss:  tensor(22.4975, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1149 | Loss:  tensor(22.5046, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1150 | Loss:  tensor(22.5015, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1151 | Loss:  tensor(22.4941, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1152 | Loss:  tensor(22.4879, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1153 | Loss:  tensor(22.4819, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1154 | Loss:  tensor(22.5524, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1155 | Loss:  tensor(22.4870, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1156 | Loss:  tensor(22.4830, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1157 | Loss:  tensor(22.4809, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1158 | Loss:  tensor(22.4880, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1159 | Loss:  tensor(22.5169, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1160 | Loss:  tensor(22.4954, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1161 | Loss:  tensor(22.5033, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1162 | Loss:  tensor(22.4935, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1163 | Loss:  tensor(22.4936, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1164 | Loss:  tensor(22.4865, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1165 | Loss:  tensor(22.5134, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1166 | Loss:  tensor(22.4894, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1167 | Loss:  tensor(22.5003, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1168 | Loss:  tensor(22.4825, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1169 | Loss:  tensor(22.4934, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1170 | Loss:  tensor(22.4799, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1171 | Loss:  tensor(22.4905, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1172 | Loss:  tensor(22.5144, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1173 | Loss:  tensor(22.4896, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1174 | Loss:  tensor(22.4816, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1175 | Loss:  tensor(22.4996, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1176 | Loss:  tensor(22.4789, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1177 | Loss:  tensor(22.4904, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1178 | Loss:  tensor(22.4916, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1179 | Loss:  tensor(22.5260, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1180 | Loss:  tensor(22.4993, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1181 | Loss:  tensor(22.4759, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1182 | Loss:  tensor(22.5458, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1183 | Loss:  tensor(22.5009, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1184 | Loss:  tensor(22.5023, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1185 | Loss:  tensor(22.5013, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1186 | Loss:  tensor(22.5081, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1187 | Loss:  tensor(22.5182, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1188 | Loss:  tensor(22.5090, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1189 | Loss:  tensor(22.5011, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1190 | Loss:  tensor(22.4957, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1191 | Loss:  tensor(22.4917, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1192 | Loss:  tensor(22.4917, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1193 | Loss:  tensor(22.4964, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1194 | Loss:  tensor(22.5130, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1195 | Loss:  tensor(22.5138, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1196 | Loss:  tensor(22.4854, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1197 | Loss:  tensor(22.4888, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1198 | Loss:  tensor(22.5221, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1199 | Loss:  tensor(22.4944, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1200 | Loss:  tensor(22.5216, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1201 | Loss:  tensor(22.5060, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1202 | Loss:  tensor(22.5246, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1203 | Loss:  tensor(22.5201, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1204 | Loss:  tensor(22.4984, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1205 | Loss:  tensor(22.4822, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1206 | Loss:  tensor(22.4896, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1207 | Loss:  tensor(22.4928, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1208 | Loss:  tensor(22.4889, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1209 | Loss:  tensor(22.4930, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1210 | Loss:  tensor(22.5072, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1211 | Loss:  tensor(22.5275, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1212 | Loss:  tensor(22.4955, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1213 | Loss:  tensor(22.4951, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1214 | Loss:  tensor(22.5011, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1215 | Loss:  tensor(22.4941, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1216 | Loss:  tensor(22.4842, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1217 | Loss:  tensor(22.4795, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1218 | Loss:  tensor(22.4941, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1219 | Loss:  tensor(22.5110, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1220 | Loss:  tensor(22.5038, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1221 | Loss:  tensor(22.4880, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1222 | Loss:  tensor(22.5276, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1223 | Loss:  tensor(22.5132, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1224 | Loss:  tensor(22.4932, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1225 | Loss:  tensor(22.4870, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1226 | Loss:  tensor(22.5029, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1227 | Loss:  tensor(22.5422, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1228 | Loss:  tensor(22.4842, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1229 | Loss:  tensor(22.4799, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1230 | Loss:  tensor(22.5018, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1231 | Loss:  tensor(22.4844, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1232 | Loss:  tensor(22.4825, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1233 | Loss:  tensor(22.5067, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1234 | Loss:  tensor(22.4978, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1235 | Loss:  tensor(22.5369, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1236 | Loss:  tensor(22.5181, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1237 | Loss:  tensor(22.5052, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1238 | Loss:  tensor(22.4927, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1239 | Loss:  tensor(22.5289, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1240 | Loss:  tensor(22.4835, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1241 | Loss:  tensor(22.4986, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1242 | Loss:  tensor(22.5262, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1243 | Loss:  tensor(22.5271, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1244 | Loss:  tensor(22.5010, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1245 | Loss:  tensor(22.4876, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1246 | Loss:  tensor(22.4765, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1247 | Loss:  tensor(22.4953, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1248 | Loss:  tensor(22.4946, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1249 | Loss:  tensor(22.4912, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1250 | Loss:  tensor(22.4928, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1251 | Loss:  tensor(22.5052, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1252 | Loss:  tensor(22.5078, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1253 | Loss:  tensor(22.4801, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1254 | Loss:  tensor(22.5034, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1255 | Loss:  tensor(22.4950, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1256 | Loss:  tensor(22.4957, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1257 | Loss:  tensor(22.4892, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1258 | Loss:  tensor(22.5068, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1259 | Loss:  tensor(22.4948, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1260 | Loss:  tensor(22.5106, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1261 | Loss:  tensor(22.5113, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1262 | Loss:  tensor(22.4915, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1263 | Loss:  tensor(22.5036, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1264 | Loss:  tensor(22.4988, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1265 | Loss:  tensor(22.5033, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1266 | Loss:  tensor(22.5211, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1267 | Loss:  tensor(22.5120, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1268 | Loss:  tensor(22.4917, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1269 | Loss:  tensor(22.5081, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1270 | Loss:  tensor(22.4851, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1271 | Loss:  tensor(22.4964, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1272 | Loss:  tensor(22.5187, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1273 | Loss:  tensor(22.5125, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1274 | Loss:  tensor(22.5301, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1275 | Loss:  tensor(22.5106, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1276 | Loss:  tensor(22.5007, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1277 | Loss:  tensor(22.4918, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1278 | Loss:  tensor(22.5024, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1279 | Loss:  tensor(22.4994, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1280 | Loss:  tensor(22.4995, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1281 | Loss:  tensor(22.5189, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1282 | Loss:  tensor(22.5051, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1283 | Loss:  tensor(22.5007, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1284 | Loss:  tensor(22.5191, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1285 | Loss:  tensor(22.5401, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1286 | Loss:  tensor(22.5001, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1287 | Loss:  tensor(22.5290, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1288 | Loss:  tensor(22.5098, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1289 | Loss:  tensor(22.5196, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1290 | Loss:  tensor(22.5047, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1291 | Loss:  tensor(22.5231, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1292 | Loss:  tensor(22.5211, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1293 | Loss:  tensor(22.5387, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1294 | Loss:  tensor(22.4941, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1295 | Loss:  tensor(22.5138, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1296 | Loss:  tensor(22.5141, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1297 | Loss:  tensor(22.5014, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1298 | Loss:  tensor(22.4854, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1299 | Loss:  tensor(22.5035, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1300 | Loss:  tensor(22.5007, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1301 | Loss:  tensor(22.5058, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1302 | Loss:  tensor(22.5007, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1303 | Loss:  tensor(22.5057, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1304 | Loss:  tensor(22.4884, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1305 | Loss:  tensor(22.5614, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1306 | Loss:  tensor(22.5079, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1307 | Loss:  tensor(22.5074, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1308 | Loss:  tensor(22.4925, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1309 | Loss:  tensor(22.5137, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1310 | Loss:  tensor(22.5030, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1311 | Loss:  tensor(22.5108, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1312 | Loss:  tensor(22.5046, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1313 | Loss:  tensor(22.5093, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1314 | Loss:  tensor(22.4930, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1315 | Loss:  tensor(22.5294, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1316 | Loss:  tensor(22.4881, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1317 | Loss:  tensor(22.5209, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1318 | Loss:  tensor(22.5083, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1319 | Loss:  tensor(22.5367, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1320 | Loss:  tensor(22.4901, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1321 | Loss:  tensor(22.5142, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1322 | Loss:  tensor(22.4940, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1323 | Loss:  tensor(22.5069, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1324 | Loss:  tensor(22.5129, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1325 | Loss:  tensor(22.5018, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1326 | Loss:  tensor(22.4954, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1327 | Loss:  tensor(22.4987, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1328 | Loss:  tensor(22.5332, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1329 | Loss:  tensor(22.5183, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1330 | Loss:  tensor(22.5159, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1331 | Loss:  tensor(22.5083, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1332 | Loss:  tensor(22.5182, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1333 | Loss:  tensor(22.4927, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1334 | Loss:  tensor(22.5052, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1335 | Loss:  tensor(22.4994, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1336 | Loss:  tensor(22.4832, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1337 | Loss:  tensor(22.5110, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1338 | Loss:  tensor(22.4960, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1339 | Loss:  tensor(22.4994, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1340 | Loss:  tensor(22.5143, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1341 | Loss:  tensor(22.5369, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1342 | Loss:  tensor(22.5179, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1343 | Loss:  tensor(22.5051, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1344 | Loss:  tensor(22.5130, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1345 | Loss:  tensor(22.4985, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1346 | Loss:  tensor(22.5016, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1347 | Loss:  tensor(22.4933, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1348 | Loss:  tensor(22.5047, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1349 | Loss:  tensor(22.5218, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1350 | Loss:  tensor(22.5093, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1351 | Loss:  tensor(22.4968, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1352 | Loss:  tensor(22.5012, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1353 | Loss:  tensor(22.5706, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1354 | Loss:  tensor(22.5010, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1355 | Loss:  tensor(22.5061, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1356 | Loss:  tensor(22.5189, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1357 | Loss:  tensor(22.4990, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1358 | Loss:  tensor(22.4859, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1359 | Loss:  tensor(22.4974, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1360 | Loss:  tensor(22.4946, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1361 | Loss:  tensor(22.5083, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1362 | Loss:  tensor(22.4984, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1363 | Loss:  tensor(22.5035, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1364 | Loss:  tensor(22.5092, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1365 | Loss:  tensor(22.5031, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1366 | Loss:  tensor(22.4844, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1367 | Loss:  tensor(22.5110, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1368 | Loss:  tensor(22.5054, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1369 | Loss:  tensor(22.5149, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1370 | Loss:  tensor(22.5204, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1371 | Loss:  tensor(22.5305, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1372 | Loss:  tensor(22.5009, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1373 | Loss:  tensor(22.5034, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1374 | Loss:  tensor(22.4988, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1375 | Loss:  tensor(22.5137, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1376 | Loss:  tensor(22.4853, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1377 | Loss:  tensor(22.5058, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1378 | Loss:  tensor(22.5090, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1379 | Loss:  tensor(22.5037, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1380 | Loss:  tensor(22.5024, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1381 | Loss:  tensor(22.5000, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1382 | Loss:  tensor(22.5170, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1383 | Loss:  tensor(22.5238, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1384 | Loss:  tensor(22.5034, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1385 | Loss:  tensor(22.4869, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1386 | Loss:  tensor(22.5245, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1387 | Loss:  tensor(22.5085, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1388 | Loss:  tensor(22.4989, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1389 | Loss:  tensor(22.5198, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1390 | Loss:  tensor(22.5228, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1391 | Loss:  tensor(22.4915, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1392 | Loss:  tensor(22.5544, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1393 | Loss:  tensor(22.4926, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1394 | Loss:  tensor(22.5213, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1395 | Loss:  tensor(22.5385, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1396 | Loss:  tensor(22.5517, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1397 | Loss:  tensor(22.5040, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1398 | Loss:  tensor(22.5037, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1399 | Loss:  tensor(22.5146, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1400 | Loss:  tensor(22.4947, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1401 | Loss:  tensor(22.5106, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1402 | Loss:  tensor(22.5220, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1403 | Loss:  tensor(22.4821, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1404 | Loss:  tensor(22.4994, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1405 | Loss:  tensor(22.5068, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1406 | Loss:  tensor(22.5037, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1407 | Loss:  tensor(22.4960, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1408 | Loss:  tensor(22.5321, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1409 | Loss:  tensor(22.4952, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1410 | Loss:  tensor(22.5078, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1411 | Loss:  tensor(22.5010, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1412 | Loss:  tensor(22.4980, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1413 | Loss:  tensor(22.5454, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1414 | Loss:  tensor(22.4973, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1415 | Loss:  tensor(22.5171, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1416 | Loss:  tensor(22.5242, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1417 | Loss:  tensor(22.5135, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1418 | Loss:  tensor(22.5230, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1419 | Loss:  tensor(22.4992, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1420 | Loss:  tensor(22.5151, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1421 | Loss:  tensor(22.5134, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1422 | Loss:  tensor(22.5323, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1423 | Loss:  tensor(22.4960, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1424 | Loss:  tensor(22.5004, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1425 | Loss:  tensor(22.5258, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1426 | Loss:  tensor(22.4995, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1427 | Loss:  tensor(22.5271, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1428 | Loss:  tensor(22.4931, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1429 | Loss:  tensor(22.5084, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1430 | Loss:  tensor(22.5253, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1431 | Loss:  tensor(22.5271, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1432 | Loss:  tensor(22.5062, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1433 | Loss:  tensor(22.5064, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1434 | Loss:  tensor(22.5169, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1435 | Loss:  tensor(22.4995, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1436 | Loss:  tensor(22.4976, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1437 | Loss:  tensor(22.5164, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1438 | Loss:  tensor(22.5286, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1439 | Loss:  tensor(22.5244, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1440 | Loss:  tensor(22.4963, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1441 | Loss:  tensor(22.5155, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1442 | Loss:  tensor(22.4949, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1443 | Loss:  tensor(22.5183, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1444 | Loss:  tensor(22.4954, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1445 | Loss:  tensor(22.5271, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1446 | Loss:  tensor(22.5164, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1447 | Loss:  tensor(22.5405, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1448 | Loss:  tensor(22.4982, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1449 | Loss:  tensor(22.5041, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1450 | Loss:  tensor(22.5133, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1451 | Loss:  tensor(22.4947, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1452 | Loss:  tensor(22.5143, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1453 | Loss:  tensor(22.4926, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1454 | Loss:  tensor(22.5027, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1455 | Loss:  tensor(22.5141, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1456 | Loss:  tensor(22.5000, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1457 | Loss:  tensor(22.5130, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1458 | Loss:  tensor(22.5043, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1459 | Loss:  tensor(22.5109, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1460 | Loss:  tensor(22.5155, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1461 | Loss:  tensor(22.4941, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1462 | Loss:  tensor(22.4957, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1463 | Loss:  tensor(22.4894, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1464 | Loss:  tensor(22.5269, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1465 | Loss:  tensor(22.4866, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1466 | Loss:  tensor(22.5069, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1467 | Loss:  tensor(22.5000, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1468 | Loss:  tensor(22.5197, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1469 | Loss:  tensor(22.4888, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1470 | Loss:  tensor(22.5215, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1471 | Loss:  tensor(22.4974, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1472 | Loss:  tensor(22.4880, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1473 | Loss:  tensor(22.5001, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1474 | Loss:  tensor(22.5153, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1475 | Loss:  tensor(22.4812, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1476 | Loss:  tensor(22.5402, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1477 | Loss:  tensor(22.5037, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1478 | Loss:  tensor(22.4884, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1479 | Loss:  tensor(22.5099, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1480 | Loss:  tensor(22.5075, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1481 | Loss:  tensor(22.4980, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1482 | Loss:  tensor(22.5016, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1483 | Loss:  tensor(22.4971, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1484 | Loss:  tensor(22.5188, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1485 | Loss:  tensor(22.4979, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1486 | Loss:  tensor(22.5567, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1487 | Loss:  tensor(22.5079, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1488 | Loss:  tensor(22.5283, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1489 | Loss:  tensor(22.5074, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1490 | Loss:  tensor(22.4876, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1491 | Loss:  tensor(22.5043, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1492 | Loss:  tensor(22.4928, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1493 | Loss:  tensor(22.5437, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1494 | Loss:  tensor(22.5053, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1495 | Loss:  tensor(22.5140, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1496 | Loss:  tensor(22.5250, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1497 | Loss:  tensor(22.5267, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1498 | Loss:  tensor(22.5094, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1499 | Loss:  tensor(22.5155, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1500 | Loss:  tensor(22.5169, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1501 | Loss:  tensor(22.5205, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1502 | Loss:  tensor(22.5091, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1503 | Loss:  tensor(22.5001, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1504 | Loss:  tensor(22.5084, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1505 | Loss:  tensor(22.4990, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1506 | Loss:  tensor(22.5095, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1507 | Loss:  tensor(22.5166, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1508 | Loss:  tensor(22.5077, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1509 | Loss:  tensor(22.5454, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1510 | Loss:  tensor(22.5651, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1511 | Loss:  tensor(22.4946, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1512 | Loss:  tensor(22.5253, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1513 | Loss:  tensor(22.5090, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1514 | Loss:  tensor(22.5043, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1515 | Loss:  tensor(22.4983, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1516 | Loss:  tensor(22.5234, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1517 | Loss:  tensor(22.5277, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1518 | Loss:  tensor(22.5163, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1519 | Loss:  tensor(22.5171, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1520 | Loss:  tensor(22.5082, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1521 | Loss:  tensor(22.5142, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1522 | Loss:  tensor(22.5049, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1523 | Loss:  tensor(22.5112, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1524 | Loss:  tensor(22.5025, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1525 | Loss:  tensor(22.5092, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1526 | Loss:  tensor(22.4912, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1527 | Loss:  tensor(22.5148, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1528 | Loss:  tensor(22.5915, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1529 | Loss:  tensor(22.5031, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1530 | Loss:  tensor(22.5099, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1531 | Loss:  tensor(22.4949, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1532 | Loss:  tensor(22.5376, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1533 | Loss:  tensor(22.5390, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1534 | Loss:  tensor(22.5305, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1535 | Loss:  tensor(22.5301, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1536 | Loss:  tensor(22.5382, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1537 | Loss:  tensor(22.5382, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1538 | Loss:  tensor(22.5151, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1539 | Loss:  tensor(22.5423, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1540 | Loss:  tensor(22.5233, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1541 | Loss:  tensor(22.5189, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1542 | Loss:  tensor(22.5230, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1543 | Loss:  tensor(22.5323, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1544 | Loss:  tensor(22.5133, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1545 | Loss:  tensor(22.5261, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1546 | Loss:  tensor(22.5271, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1547 | Loss:  tensor(22.5159, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1548 | Loss:  tensor(22.5152, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1549 | Loss:  tensor(22.5049, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1550 | Loss:  tensor(22.5055, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1551 | Loss:  tensor(22.5037, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1552 | Loss:  tensor(22.5084, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1553 | Loss:  tensor(22.5145, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1554 | Loss:  tensor(22.5180, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1555 | Loss:  tensor(22.5091, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1556 | Loss:  tensor(22.5168, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1557 | Loss:  tensor(22.5198, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1558 | Loss:  tensor(22.5143, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1559 | Loss:  tensor(22.5304, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1560 | Loss:  tensor(22.5793, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1561 | Loss:  tensor(22.5609, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1562 | Loss:  tensor(22.5232, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1563 | Loss:  tensor(22.5256, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1564 | Loss:  tensor(22.5367, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1565 | Loss:  tensor(22.5109, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1566 | Loss:  tensor(22.5068, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1567 | Loss:  tensor(22.5614, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1568 | Loss:  tensor(22.5121, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1569 | Loss:  tensor(22.5025, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1570 | Loss:  tensor(22.5390, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1571 | Loss:  tensor(22.5519, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1572 | Loss:  tensor(22.5201, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1573 | Loss:  tensor(22.5032, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1574 | Loss:  tensor(22.5330, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1575 | Loss:  tensor(22.5262, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1576 | Loss:  tensor(22.5293, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1577 | Loss:  tensor(22.5182, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1578 | Loss:  tensor(22.5374, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1579 | Loss:  tensor(22.5156, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1580 | Loss:  tensor(22.5164, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1581 | Loss:  tensor(22.5617, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1582 | Loss:  tensor(22.5185, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1583 | Loss:  tensor(22.5327, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1584 | Loss:  tensor(22.5089, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1585 | Loss:  tensor(22.4947, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1586 | Loss:  tensor(22.5170, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1587 | Loss:  tensor(22.5049, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1588 | Loss:  tensor(22.5060, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1589 | Loss:  tensor(22.5224, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1590 | Loss:  tensor(22.5110, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1591 | Loss:  tensor(22.5034, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1592 | Loss:  tensor(22.5005, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1593 | Loss:  tensor(22.5227, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1594 | Loss:  tensor(22.5463, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1595 | Loss:  tensor(22.5075, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1596 | Loss:  tensor(22.5135, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1597 | Loss:  tensor(22.5086, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1598 | Loss:  tensor(22.5153, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1599 | Loss:  tensor(22.5095, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1600 | Loss:  tensor(22.5309, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1601 | Loss:  tensor(22.5162, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1602 | Loss:  tensor(22.5165, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1603 | Loss:  tensor(22.5137, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1604 | Loss:  tensor(22.5676, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1605 | Loss:  tensor(22.5142, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1606 | Loss:  tensor(22.5157, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1607 | Loss:  tensor(22.5463, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1608 | Loss:  tensor(22.5028, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1609 | Loss:  tensor(22.5101, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1610 | Loss:  tensor(22.5376, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1611 | Loss:  tensor(22.5391, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1612 | Loss:  tensor(22.5354, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1613 | Loss:  tensor(22.5288, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1614 | Loss:  tensor(22.5480, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1615 | Loss:  tensor(22.5364, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1616 | Loss:  tensor(22.5133, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1617 | Loss:  tensor(22.5094, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1618 | Loss:  tensor(22.5267, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1619 | Loss:  tensor(22.5395, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1620 | Loss:  tensor(22.5323, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1621 | Loss:  tensor(22.5416, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1622 | Loss:  tensor(22.5240, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1623 | Loss:  tensor(22.5261, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1624 | Loss:  tensor(22.5141, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1625 | Loss:  tensor(22.5079, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1626 | Loss:  tensor(22.4989, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1627 | Loss:  tensor(22.5510, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1628 | Loss:  tensor(22.5073, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1629 | Loss:  tensor(22.4966, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1630 | Loss:  tensor(22.5126, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1631 | Loss:  tensor(22.5068, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1632 | Loss:  tensor(22.4977, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1633 | Loss:  tensor(22.5221, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1634 | Loss:  tensor(22.5019, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1635 | Loss:  tensor(22.5008, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1636 | Loss:  tensor(22.5114, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1637 | Loss:  tensor(22.5324, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1638 | Loss:  tensor(22.5319, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1639 | Loss:  tensor(22.5145, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1640 | Loss:  tensor(22.5113, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1641 | Loss:  tensor(22.5263, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1642 | Loss:  tensor(22.5179, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1643 | Loss:  tensor(22.5196, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1644 | Loss:  tensor(22.5170, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1645 | Loss:  tensor(22.4979, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1646 | Loss:  tensor(22.5540, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1647 | Loss:  tensor(22.5053, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1648 | Loss:  tensor(22.5051, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1649 | Loss:  tensor(22.5223, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1650 | Loss:  tensor(22.5222, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1651 | Loss:  tensor(22.5018, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1652 | Loss:  tensor(22.5108, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1653 | Loss:  tensor(22.5002, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1654 | Loss:  tensor(22.5141, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1655 | Loss:  tensor(22.5121, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1656 | Loss:  tensor(22.5054, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1657 | Loss:  tensor(22.5105, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1658 | Loss:  tensor(22.5090, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1659 | Loss:  tensor(22.4956, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1660 | Loss:  tensor(22.4905, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1661 | Loss:  tensor(22.5124, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1662 | Loss:  tensor(22.5558, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1663 | Loss:  tensor(22.5069, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1664 | Loss:  tensor(22.5098, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1665 | Loss:  tensor(22.5005, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1666 | Loss:  tensor(22.4983, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1667 | Loss:  tensor(22.5053, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1668 | Loss:  tensor(22.5268, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1669 | Loss:  tensor(22.4964, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1670 | Loss:  tensor(22.5163, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1671 | Loss:  tensor(22.5078, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1672 | Loss:  tensor(22.5079, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1673 | Loss:  tensor(22.5485, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1674 | Loss:  tensor(22.5085, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1675 | Loss:  tensor(22.5419, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1676 | Loss:  tensor(22.5570, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1677 | Loss:  tensor(22.5025, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1678 | Loss:  tensor(22.5250, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1679 | Loss:  tensor(22.5180, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1680 | Loss:  tensor(22.5372, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1681 | Loss:  tensor(22.5187, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1682 | Loss:  tensor(22.5284, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1683 | Loss:  tensor(22.5687, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1684 | Loss:  tensor(22.5147, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1685 | Loss:  tensor(22.4992, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1686 | Loss:  tensor(22.5250, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1687 | Loss:  tensor(22.5187, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1688 | Loss:  tensor(22.5326, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1689 | Loss:  tensor(22.5408, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1690 | Loss:  tensor(22.5231, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1691 | Loss:  tensor(22.5143, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1692 | Loss:  tensor(22.5184, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1693 | Loss:  tensor(22.5113, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1694 | Loss:  tensor(22.5246, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1695 | Loss:  tensor(22.5188, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1696 | Loss:  tensor(22.5767, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1697 | Loss:  tensor(22.5222, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1698 | Loss:  tensor(22.5178, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1699 | Loss:  tensor(22.5270, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1700 | Loss:  tensor(22.5182, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1701 | Loss:  tensor(22.5386, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1702 | Loss:  tensor(22.5644, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1703 | Loss:  tensor(22.5381, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1704 | Loss:  tensor(22.5223, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1705 | Loss:  tensor(22.5223, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1706 | Loss:  tensor(22.5379, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1707 | Loss:  tensor(22.5249, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1708 | Loss:  tensor(22.5790, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1709 | Loss:  tensor(22.5600, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1710 | Loss:  tensor(22.5240, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1711 | Loss:  tensor(22.5185, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1712 | Loss:  tensor(22.5755, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1713 | Loss:  tensor(22.5258, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1714 | Loss:  tensor(22.5457, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1715 | Loss:  tensor(22.5224, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1716 | Loss:  tensor(22.5367, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1717 | Loss:  tensor(22.5508, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1718 | Loss:  tensor(22.5306, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1719 | Loss:  tensor(22.5224, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1720 | Loss:  tensor(22.5272, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1721 | Loss:  tensor(22.5180, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1722 | Loss:  tensor(22.5323, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1723 | Loss:  tensor(22.5250, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1724 | Loss:  tensor(22.5104, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1725 | Loss:  tensor(22.5083, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1726 | Loss:  tensor(22.5377, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1727 | Loss:  tensor(22.5152, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1728 | Loss:  tensor(22.5323, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1729 | Loss:  tensor(22.5252, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1730 | Loss:  tensor(22.5168, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1731 | Loss:  tensor(22.5275, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1732 | Loss:  tensor(22.5068, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1733 | Loss:  tensor(22.5469, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1734 | Loss:  tensor(22.5411, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1735 | Loss:  tensor(22.5140, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1736 | Loss:  tensor(22.5297, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1737 | Loss:  tensor(22.5750, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1738 | Loss:  tensor(22.5192, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1739 | Loss:  tensor(22.5114, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1740 | Loss:  tensor(22.5259, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1741 | Loss:  tensor(22.5152, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1742 | Loss:  tensor(22.5092, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1743 | Loss:  tensor(22.5264, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1744 | Loss:  tensor(22.5299, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1745 | Loss:  tensor(22.5071, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1746 | Loss:  tensor(22.5149, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1747 | Loss:  tensor(22.5182, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1748 | Loss:  tensor(22.5145, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1749 | Loss:  tensor(22.5175, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1750 | Loss:  tensor(22.5101, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1751 | Loss:  tensor(22.5229, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1752 | Loss:  tensor(22.5162, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1753 | Loss:  tensor(22.5177, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1754 | Loss:  tensor(22.5399, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1755 | Loss:  tensor(22.5172, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1756 | Loss:  tensor(22.5524, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1757 | Loss:  tensor(22.5455, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1758 | Loss:  tensor(22.5428, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1759 | Loss:  tensor(22.5326, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1760 | Loss:  tensor(22.5191, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1761 | Loss:  tensor(22.5454, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1762 | Loss:  tensor(22.5212, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1763 | Loss:  tensor(22.5129, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1764 | Loss:  tensor(22.5364, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1765 | Loss:  tensor(22.5279, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1766 | Loss:  tensor(22.5265, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1767 | Loss:  tensor(22.5329, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1768 | Loss:  tensor(22.5387, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1769 | Loss:  tensor(22.5627, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1770 | Loss:  tensor(22.5184, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1771 | Loss:  tensor(22.5318, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1772 | Loss:  tensor(22.5343, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1773 | Loss:  tensor(22.5243, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1774 | Loss:  tensor(22.5202, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1775 | Loss:  tensor(22.5199, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1776 | Loss:  tensor(22.5327, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1777 | Loss:  tensor(22.5328, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1778 | Loss:  tensor(22.5387, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1779 | Loss:  tensor(22.5205, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1780 | Loss:  tensor(22.5332, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1781 | Loss:  tensor(22.5463, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1782 | Loss:  tensor(22.5412, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1783 | Loss:  tensor(22.5281, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1784 | Loss:  tensor(22.5238, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1785 | Loss:  tensor(22.5252, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1786 | Loss:  tensor(22.5167, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1787 | Loss:  tensor(22.5253, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1788 | Loss:  tensor(22.5292, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1789 | Loss:  tensor(22.5624, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1790 | Loss:  tensor(22.5496, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1791 | Loss:  tensor(22.5185, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1792 | Loss:  tensor(22.5438, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1793 | Loss:  tensor(22.5358, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1794 | Loss:  tensor(22.5242, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1795 | Loss:  tensor(22.5567, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1796 | Loss:  tensor(22.5344, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1797 | Loss:  tensor(22.5329, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1798 | Loss:  tensor(22.5353, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1799 | Loss:  tensor(22.5557, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1800 | Loss:  tensor(22.5389, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1801 | Loss:  tensor(22.5471, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1802 | Loss:  tensor(22.5509, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1803 | Loss:  tensor(22.5287, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1804 | Loss:  tensor(22.5334, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1805 | Loss:  tensor(22.5533, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1806 | Loss:  tensor(22.5494, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1807 | Loss:  tensor(22.5362, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1808 | Loss:  tensor(22.5312, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1809 | Loss:  tensor(22.5793, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1810 | Loss:  tensor(22.5528, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1811 | Loss:  tensor(22.5339, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1812 | Loss:  tensor(22.5370, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1813 | Loss:  tensor(22.5303, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1814 | Loss:  tensor(22.5301, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1815 | Loss:  tensor(22.5440, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1816 | Loss:  tensor(22.5248, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1817 | Loss:  tensor(22.5191, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1818 | Loss:  tensor(22.5583, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1819 | Loss:  tensor(22.5369, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1820 | Loss:  tensor(22.5427, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1821 | Loss:  tensor(22.5444, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1822 | Loss:  tensor(22.5512, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1823 | Loss:  tensor(22.5472, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1824 | Loss:  tensor(22.5276, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1825 | Loss:  tensor(22.5463, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1826 | Loss:  tensor(22.5501, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1827 | Loss:  tensor(22.5346, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1828 | Loss:  tensor(22.5267, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1829 | Loss:  tensor(22.5499, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1830 | Loss:  tensor(22.5401, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1831 | Loss:  tensor(22.5383, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1832 | Loss:  tensor(22.5465, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1833 | Loss:  tensor(22.5600, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1834 | Loss:  tensor(22.5323, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1835 | Loss:  tensor(22.5314, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1836 | Loss:  tensor(22.5363, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1837 | Loss:  tensor(22.5343, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1838 | Loss:  tensor(22.5300, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1839 | Loss:  tensor(22.5326, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1840 | Loss:  tensor(22.5743, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1841 | Loss:  tensor(22.5147, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1842 | Loss:  tensor(22.5353, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1843 | Loss:  tensor(22.5250, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1844 | Loss:  tensor(22.5576, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1845 | Loss:  tensor(22.5308, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1846 | Loss:  tensor(22.5420, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1847 | Loss:  tensor(22.5333, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1848 | Loss:  tensor(22.5474, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1849 | Loss:  tensor(22.5463, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1850 | Loss:  tensor(22.5321, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1851 | Loss:  tensor(22.5497, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1852 | Loss:  tensor(22.5429, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1853 | Loss:  tensor(22.5494, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1854 | Loss:  tensor(22.5436, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1855 | Loss:  tensor(22.5459, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1856 | Loss:  tensor(22.5350, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1857 | Loss:  tensor(22.5408, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1858 | Loss:  tensor(22.5595, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1859 | Loss:  tensor(22.5313, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1860 | Loss:  tensor(22.5311, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1861 | Loss:  tensor(22.5318, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1862 | Loss:  tensor(22.5325, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1863 | Loss:  tensor(22.5512, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1864 | Loss:  tensor(22.5291, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1865 | Loss:  tensor(22.5360, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1866 | Loss:  tensor(22.5469, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1867 | Loss:  tensor(22.5298, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1868 | Loss:  tensor(22.5498, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1869 | Loss:  tensor(22.5711, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1870 | Loss:  tensor(22.5515, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1871 | Loss:  tensor(22.5194, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1872 | Loss:  tensor(22.5376, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1873 | Loss:  tensor(22.5607, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1874 | Loss:  tensor(22.5530, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1875 | Loss:  tensor(22.5261, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1876 | Loss:  tensor(22.5537, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1877 | Loss:  tensor(22.5281, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1878 | Loss:  tensor(22.5270, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1879 | Loss:  tensor(22.5325, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1880 | Loss:  tensor(22.5261, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1881 | Loss:  tensor(22.5442, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1882 | Loss:  tensor(22.5412, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1883 | Loss:  tensor(22.5438, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1884 | Loss:  tensor(22.5389, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1885 | Loss:  tensor(22.5334, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1886 | Loss:  tensor(22.5362, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1887 | Loss:  tensor(22.5367, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1888 | Loss:  tensor(22.5457, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1889 | Loss:  tensor(22.5421, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1890 | Loss:  tensor(22.5436, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1891 | Loss:  tensor(22.5343, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1892 | Loss:  tensor(22.5440, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1893 | Loss:  tensor(22.5513, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1894 | Loss:  tensor(22.5529, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1895 | Loss:  tensor(22.5559, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1896 | Loss:  tensor(22.5471, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1897 | Loss:  tensor(22.5594, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1898 | Loss:  tensor(22.5507, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1899 | Loss:  tensor(22.5461, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1900 | Loss:  tensor(22.5501, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1901 | Loss:  tensor(22.5476, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1902 | Loss:  tensor(22.5315, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1903 | Loss:  tensor(22.5804, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1904 | Loss:  tensor(22.5458, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1905 | Loss:  tensor(22.6258, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1906 | Loss:  tensor(22.5409, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1907 | Loss:  tensor(22.5619, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1908 | Loss:  tensor(22.5386, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1909 | Loss:  tensor(22.5666, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1910 | Loss:  tensor(22.5962, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1911 | Loss:  tensor(22.5648, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1912 | Loss:  tensor(22.5538, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1913 | Loss:  tensor(22.5503, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1914 | Loss:  tensor(22.5610, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1915 | Loss:  tensor(22.5515, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1916 | Loss:  tensor(22.5617, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1917 | Loss:  tensor(22.5546, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1918 | Loss:  tensor(22.5541, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1919 | Loss:  tensor(22.5372, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1920 | Loss:  tensor(22.5515, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1921 | Loss:  tensor(22.5346, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1922 | Loss:  tensor(22.5319, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1923 | Loss:  tensor(22.5544, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1924 | Loss:  tensor(22.5595, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1925 | Loss:  tensor(22.5581, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1926 | Loss:  tensor(22.5452, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1927 | Loss:  tensor(22.5492, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1928 | Loss:  tensor(22.5860, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1929 | Loss:  tensor(22.5241, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1930 | Loss:  tensor(22.5715, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1931 | Loss:  tensor(22.5750, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1932 | Loss:  tensor(22.5589, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1933 | Loss:  tensor(22.5509, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1934 | Loss:  tensor(22.5415, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1935 | Loss:  tensor(22.5679, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1936 | Loss:  tensor(22.5793, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1937 | Loss:  tensor(22.5827, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1938 | Loss:  tensor(22.5582, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1939 | Loss:  tensor(22.5738, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1940 | Loss:  tensor(22.5509, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1941 | Loss:  tensor(22.5517, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1942 | Loss:  tensor(22.5513, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1943 | Loss:  tensor(22.5353, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1944 | Loss:  tensor(22.5324, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1945 | Loss:  tensor(22.5712, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1946 | Loss:  tensor(22.5891, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1947 | Loss:  tensor(22.5491, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1948 | Loss:  tensor(22.6214, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1949 | Loss:  tensor(22.5438, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1950 | Loss:  tensor(22.5519, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1951 | Loss:  tensor(22.5395, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1952 | Loss:  tensor(22.5620, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1953 | Loss:  tensor(22.5299, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1954 | Loss:  tensor(22.5500, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1955 | Loss:  tensor(22.5568, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1956 | Loss:  tensor(22.5341, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1957 | Loss:  tensor(22.5606, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1958 | Loss:  tensor(22.5567, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1959 | Loss:  tensor(22.5548, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1960 | Loss:  tensor(22.5716, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1961 | Loss:  tensor(22.5417, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1962 | Loss:  tensor(22.5487, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1963 | Loss:  tensor(22.5379, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1964 | Loss:  tensor(22.5579, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1965 | Loss:  tensor(22.6118, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1966 | Loss:  tensor(22.5535, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1967 | Loss:  tensor(22.5667, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1968 | Loss:  tensor(22.5344, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1969 | Loss:  tensor(22.5880, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1970 | Loss:  tensor(22.5346, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1971 | Loss:  tensor(22.5315, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1972 | Loss:  tensor(22.5414, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1973 | Loss:  tensor(22.5422, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1974 | Loss:  tensor(22.5527, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1975 | Loss:  tensor(22.5518, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1976 | Loss:  tensor(22.5643, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1977 | Loss:  tensor(22.5467, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1978 | Loss:  tensor(22.5447, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1979 | Loss:  tensor(22.5356, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1980 | Loss:  tensor(22.5459, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1981 | Loss:  tensor(22.5821, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1982 | Loss:  tensor(22.5458, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1983 | Loss:  tensor(22.5423, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1984 | Loss:  tensor(22.5510, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1985 | Loss:  tensor(22.5327, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1986 | Loss:  tensor(22.5390, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1987 | Loss:  tensor(22.5373, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1988 | Loss:  tensor(22.5496, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1989 | Loss:  tensor(22.5612, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1990 | Loss:  tensor(22.5419, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1991 | Loss:  tensor(22.5401, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1992 | Loss:  tensor(22.5481, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1993 | Loss:  tensor(22.5612, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1994 | Loss:  tensor(22.5415, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1995 | Loss:  tensor(22.5740, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1996 | Loss:  tensor(22.5385, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1997 | Loss:  tensor(22.5468, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1998 | Loss:  tensor(22.5386, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  1999 | Loss:  tensor(22.5324, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2000 | Loss:  tensor(22.5579, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2001 | Loss:  tensor(22.5417, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2002 | Loss:  tensor(22.5576, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2003 | Loss:  tensor(22.5553, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2004 | Loss:  tensor(22.5567, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2005 | Loss:  tensor(22.5459, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2006 | Loss:  tensor(22.5487, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2007 | Loss:  tensor(22.5383, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2008 | Loss:  tensor(22.5649, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2009 | Loss:  tensor(22.5506, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2010 | Loss:  tensor(22.5683, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2011 | Loss:  tensor(22.5517, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2012 | Loss:  tensor(22.5820, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2013 | Loss:  tensor(22.5480, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2014 | Loss:  tensor(22.5477, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2015 | Loss:  tensor(22.5597, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2016 | Loss:  tensor(22.5565, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2017 | Loss:  tensor(22.5426, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2018 | Loss:  tensor(22.5460, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2019 | Loss:  tensor(22.5451, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2020 | Loss:  tensor(22.5631, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2021 | Loss:  tensor(22.5629, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2022 | Loss:  tensor(22.5429, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2023 | Loss:  tensor(22.5399, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2024 | Loss:  tensor(22.5663, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2025 | Loss:  tensor(22.5464, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2026 | Loss:  tensor(22.5601, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2027 | Loss:  tensor(22.5726, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2028 | Loss:  tensor(22.5475, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2029 | Loss:  tensor(22.5366, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2030 | Loss:  tensor(22.5509, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2031 | Loss:  tensor(22.5365, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2032 | Loss:  tensor(22.5525, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2033 | Loss:  tensor(22.5509, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2034 | Loss:  tensor(22.5389, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2035 | Loss:  tensor(22.5480, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2036 | Loss:  tensor(22.5480, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2037 | Loss:  tensor(22.5703, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2038 | Loss:  tensor(22.5777, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2039 | Loss:  tensor(22.5429, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2040 | Loss:  tensor(22.5435, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2041 | Loss:  tensor(22.5593, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2042 | Loss:  tensor(22.5413, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2043 | Loss:  tensor(22.6046, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2044 | Loss:  tensor(22.5664, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2045 | Loss:  tensor(22.5568, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2046 | Loss:  tensor(22.5686, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2047 | Loss:  tensor(22.5784, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2048 | Loss:  tensor(22.5580, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2049 | Loss:  tensor(22.5694, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2050 | Loss:  tensor(22.5455, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2051 | Loss:  tensor(22.5709, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2052 | Loss:  tensor(22.5710, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2053 | Loss:  tensor(22.5326, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2054 | Loss:  tensor(22.5275, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2055 | Loss:  tensor(22.5339, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2056 | Loss:  tensor(22.5324, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2057 | Loss:  tensor(22.5444, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2058 | Loss:  tensor(22.5551, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2059 | Loss:  tensor(22.5600, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2060 | Loss:  tensor(22.5500, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2061 | Loss:  tensor(22.5671, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2062 | Loss:  tensor(22.5475, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2063 | Loss:  tensor(22.5328, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2064 | Loss:  tensor(22.5377, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2065 | Loss:  tensor(22.5336, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2066 | Loss:  tensor(22.5427, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2067 | Loss:  tensor(22.5476, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2068 | Loss:  tensor(22.5314, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2069 | Loss:  tensor(22.5440, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2070 | Loss:  tensor(22.5558, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2071 | Loss:  tensor(22.5477, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2072 | Loss:  tensor(22.5443, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2073 | Loss:  tensor(22.5430, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2074 | Loss:  tensor(22.5412, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2075 | Loss:  tensor(22.5586, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2076 | Loss:  tensor(22.5398, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2077 | Loss:  tensor(22.5358, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2078 | Loss:  tensor(22.5581, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2079 | Loss:  tensor(22.5638, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2080 | Loss:  tensor(22.5519, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2081 | Loss:  tensor(22.5737, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2082 | Loss:  tensor(22.5504, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2083 | Loss:  tensor(22.5434, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2084 | Loss:  tensor(22.5527, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2085 | Loss:  tensor(22.5542, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2086 | Loss:  tensor(22.5720, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2087 | Loss:  tensor(22.5312, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2088 | Loss:  tensor(22.5610, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2089 | Loss:  tensor(22.5341, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2090 | Loss:  tensor(22.5379, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2091 | Loss:  tensor(22.5529, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2092 | Loss:  tensor(22.5666, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2093 | Loss:  tensor(22.5405, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2094 | Loss:  tensor(22.5389, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2095 | Loss:  tensor(22.5517, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2096 | Loss:  tensor(22.5588, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2097 | Loss:  tensor(22.5846, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2098 | Loss:  tensor(22.5400, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2099 | Loss:  tensor(22.5470, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2100 | Loss:  tensor(22.5613, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2101 | Loss:  tensor(22.5672, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2102 | Loss:  tensor(22.5479, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2103 | Loss:  tensor(22.5647, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2104 | Loss:  tensor(22.5762, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2105 | Loss:  tensor(22.5467, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2106 | Loss:  tensor(22.5733, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2107 | Loss:  tensor(22.5826, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2108 | Loss:  tensor(22.5495, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2109 | Loss:  tensor(22.5482, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2110 | Loss:  tensor(22.5591, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2111 | Loss:  tensor(22.5745, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2112 | Loss:  tensor(22.5868, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2113 | Loss:  tensor(22.5718, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2114 | Loss:  tensor(22.5626, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2115 | Loss:  tensor(22.5560, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2116 | Loss:  tensor(22.5440, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2117 | Loss:  tensor(22.5519, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2118 | Loss:  tensor(22.5716, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2119 | Loss:  tensor(22.5553, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2120 | Loss:  tensor(22.5527, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2121 | Loss:  tensor(22.5460, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2122 | Loss:  tensor(22.5683, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2123 | Loss:  tensor(22.5568, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2124 | Loss:  tensor(22.5633, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2125 | Loss:  tensor(22.5494, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2126 | Loss:  tensor(22.5602, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2127 | Loss:  tensor(22.5514, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2128 | Loss:  tensor(22.5546, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2129 | Loss:  tensor(22.5447, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2130 | Loss:  tensor(22.5551, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2131 | Loss:  tensor(22.5806, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2132 | Loss:  tensor(22.5555, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2133 | Loss:  tensor(22.5701, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2134 | Loss:  tensor(22.5602, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2135 | Loss:  tensor(22.5475, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2136 | Loss:  tensor(22.5463, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2137 | Loss:  tensor(22.5398, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2138 | Loss:  tensor(22.5529, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2139 | Loss:  tensor(22.5485, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2140 | Loss:  tensor(22.5602, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2141 | Loss:  tensor(22.5512, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2142 | Loss:  tensor(22.5586, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2143 | Loss:  tensor(22.5537, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2144 | Loss:  tensor(22.5521, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2145 | Loss:  tensor(22.5566, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2146 | Loss:  tensor(22.5615, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2147 | Loss:  tensor(22.5834, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2148 | Loss:  tensor(22.5554, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2149 | Loss:  tensor(22.5630, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2150 | Loss:  tensor(22.5736, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2151 | Loss:  tensor(22.5656, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2152 | Loss:  tensor(22.5717, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2153 | Loss:  tensor(22.5612, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2154 | Loss:  tensor(22.5551, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2155 | Loss:  tensor(22.5725, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2156 | Loss:  tensor(22.5525, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2157 | Loss:  tensor(22.5770, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2158 | Loss:  tensor(22.5636, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2159 | Loss:  tensor(22.5679, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2160 | Loss:  tensor(22.5682, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2161 | Loss:  tensor(22.5467, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2162 | Loss:  tensor(22.5673, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2163 | Loss:  tensor(22.5687, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2164 | Loss:  tensor(22.5670, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2165 | Loss:  tensor(22.5773, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2166 | Loss:  tensor(22.5732, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2167 | Loss:  tensor(22.5620, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2168 | Loss:  tensor(22.5664, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2169 | Loss:  tensor(22.5566, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2170 | Loss:  tensor(22.5613, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2171 | Loss:  tensor(22.5482, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2172 | Loss:  tensor(22.5614, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2173 | Loss:  tensor(22.5441, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2174 | Loss:  tensor(22.5704, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2175 | Loss:  tensor(22.5557, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2176 | Loss:  tensor(22.5626, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2177 | Loss:  tensor(22.5609, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2178 | Loss:  tensor(22.5571, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2179 | Loss:  tensor(22.5736, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2180 | Loss:  tensor(22.5615, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2181 | Loss:  tensor(22.5727, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2182 | Loss:  tensor(22.5782, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2183 | Loss:  tensor(22.5477, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2184 | Loss:  tensor(22.5596, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2185 | Loss:  tensor(22.5584, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2186 | Loss:  tensor(22.5749, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2187 | Loss:  tensor(22.5467, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2188 | Loss:  tensor(22.5593, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2189 | Loss:  tensor(22.5482, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2190 | Loss:  tensor(22.5678, dtype=torch.float64)\n",
            "Epoch:  50 | Batch:  2191 | Loss:  tensor(22.5766, dtype=torch.float64)\n",
            "The mean square error is: 211.535343\n",
            "MAPE is: 2.424917\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mTDpnH1rJGEa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}