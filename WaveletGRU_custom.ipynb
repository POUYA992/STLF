{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXLQ4sUA35bB",
        "outputId": "aa53fa53-d39a-4e1a-87e8-bb331ea2a2d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import newaxis\n",
        "\n",
        "def load_data(data_path,P,step):\n",
        "    num_logs = P+step\n",
        "    df = pd.read_csv(data_path)\n",
        "\n",
        "\n",
        "    data_np = np.zeros((len(df),num_logs))\n",
        "    data_df_combined = pd.DataFrame(data_np)\n",
        "    data_df_combined.loc[:,0] = df['SYSLoad'].values\n",
        "\n",
        "    for i in range(1, num_logs):\n",
        "        data_df_combined.loc[:,i] = data_df_combined.shift(-i)\n",
        "\n",
        "    data_df_combined_clean = data_df_combined.dropna()\n",
        "    data_df_combined_clean = data_df_combined_clean.reset_index()\n",
        "    data_df_combined_clean.drop('index',axis=1,inplace=True)\n",
        "    data_combined_standardized = preprocessing.scale(data_df_combined_clean)\n",
        "\n",
        "    train_split = round(0.8 * data_combined_standardized.shape[0])\n",
        "    val_split = round(0.9 * data_combined_standardized.shape[0])\n",
        "    #print(\"all len\",data_combined_standardized.shape[0])\n",
        "    #print(\"train_split\",train_split)\n",
        "\n",
        "    X = data_combined_standardized[:,:P]\n",
        "    Y = data_combined_standardized[:,P:]\n",
        "\n",
        "    X_train = X[:train_split]\n",
        "    Y_train = Y[:train_split]\n",
        "    X_test = X[train_split:]\n",
        "    Y_test = Y[train_split:]\n",
        "\n",
        "    X_train = X_train.reshape((X_train.shape[0],X_train.shape[1],1))\n",
        "    Y_train = Y_train.reshape((Y_train.shape[0],Y_train.shape[1],1))\n",
        "    X_test = X_test.reshape((X_test.shape[0],X_test.shape[1],1))\n",
        "    Y_test = Y_test.reshape((Y_test.shape[0],Y_test.shape[1],1))\n",
        "\n",
        "    return X_train,Y_train,X_test,Y_test,data_df_combined_clean\n"
      ],
      "metadata": {
        "id": "NOSMRlBJ37bQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "class TorchDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.x[idx], self.y[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "class TorchDataLoader:\n",
        "    def __init__(self,batch_size,shuffle = True):\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "\n",
        "    def torch_dataloader(self,train_data,target_data):\n",
        "        torch_dataset = TorchDataset(train_data,target_data)\n",
        "        torch_loader = DataLoader(dataset = torch_dataset,\n",
        "                                batch_size = self.batch_size,\n",
        "                                shuffle = self.shuffle)\n",
        "        return torch_loader\n",
        "\n",
        "def plot_results(predicted_data, true_data):\n",
        "    # use in train.py\n",
        "    # plot evaluate result\n",
        "    fig = plt.figure(facecolor='white', figsize=(12, 6))\n",
        "    ax = fig.add_subplot(111)\n",
        "    ax.plot(true_data[-200:], label='True Data')\n",
        "    plt.plot(predicted_data[-200:], label='Prediction')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def ToVariable(x):\n",
        "    # use in train.py\n",
        "    # change from numpy.array to torch.variable\n",
        "    tmp = torch.DoubleTensor(x)\n",
        "    return Variable(tmp)\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "2UY36i2h4Am6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "from torch.nn.parameter import Parameter\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import h5py\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import pywt\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Wavelet_GRU(nn.Module):\n",
        "    def __init__(self, seq_len, hidden_size, output_size, num_rnn_levels):\n",
        "        super(Wavelet_GRU, self).__init__()\n",
        "\n",
        "        self.seq_len = seq_len\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.num_rnn_levels = num_rnn_levels\n",
        "\n",
        "        self.rnns = nn.ModuleList([nn.GRU(1, hidden_size, batch_first=True) for _ in range(num_rnn_levels)])\n",
        "        self.mWDNs = nn.ModuleList([nn.Linear(int(seq_len / (2 ** i)), int(seq_len / (2 ** i))) for i in range(num_rnn_levels)])\n",
        "\n",
        "        self.a_to_x = nn.AvgPool1d(2)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.output = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "        wavelet = pywt.Wavelet('db4')\n",
        "        low = wavelet.dec_lo\n",
        "        high = wavelet.dec_hi\n",
        "        self.l_filter = low\n",
        "        self.h_filter = high\n",
        "\n",
        "        self.cmp_mWDNs_H = nn.ParameterList([nn.Parameter(torch.tensor(self.create_W(int(seq_len / (2 ** i)), False, is_comp=True)).double()) for i in range(num_rnn_levels)])\n",
        "        self.cmp_mWDNs_L = nn.ParameterList([nn.Parameter(torch.tensor(self.create_W(int(seq_len / (2 ** i)), True, is_comp=True)).double()) for i in range(num_rnn_levels)])\n",
        "\n",
        "        self.mWDNs_H = nn.ModuleList([nn.Linear(int(seq_len / (2 ** i)), int(seq_len / (2 ** i))) for i in range(num_rnn_levels)])\n",
        "        self.mWDNs_L = nn.ModuleList([nn.Linear(int(seq_len / (2 ** i)), int(seq_len / (2 ** i))) for i in range(num_rnn_levels)])\n",
        "\n",
        "        for i in range(num_rnn_levels):\n",
        "            self.mWDNs_H[i].weight = nn.Parameter(torch.tensor(self.create_W(int(seq_len / (2 ** i)), False)).double())\n",
        "            self.mWDNs_L[i].weight = nn.Parameter(torch.tensor(self.create_W(int(seq_len / (2 ** i)), True)).double())\n",
        "\n",
        "    def forward(self, input, hidden_states):\n",
        "        input = input.view(input.shape[0], input.shape[1])\n",
        "        hidden_states = [hidden_states[i].to(input.device) for i in range(self.num_rnn_levels)]\n",
        "        al = []\n",
        "        ah = []\n",
        "        xl =[]\n",
        "        xh =[]\n",
        "        # Wavelet decomposition layers\n",
        "        ah.append(self.sigmoid(self.mWDNs_H[0](input)))\n",
        "        al.append(self.sigmoid(self.mWDNs_L[0](input)))\n",
        "        xh.append(self.a_to_x(ah[0].view(ah[0].shape[0],1,-1)))\n",
        "        xl.append(self.a_to_x(al[0].view(al[0].shape[0],1,-1)))\n",
        "        for i in range(1,self.num_rnn_levels):\n",
        "            ah.append(self.sigmoid(self.mWDNs_H[i](xl[i-1])))\n",
        "            al.append(self.sigmoid(self.mWDNs_L[i](xl[i-1])))\n",
        "            xh.append(self.a_to_x(ah[i]))\n",
        "            xl.append(self.a_to_x(al[i]))\n",
        "\n",
        "        # Transpose and apply RNN layers\n",
        "        xh = [x.transpose(1, 2) for x in xh]\n",
        "        xl = [x.transpose(1, 2) for x in xl]\n",
        "        rnn_outputs = []\n",
        "        for i in range(self.num_rnn_levels):\n",
        "            rnn_output, _ = self.rnns[i](xh[i], hidden_states[i])\n",
        "            rnn_outputs.append(rnn_output)\n",
        "\n",
        "        rnn_outputs = torch.cat(rnn_outputs, 1)\n",
        "\n",
        "        output = self.output(rnn_outputs)\n",
        "        return output\n",
        "\n",
        "    def init_state(self, batch_size):\n",
        "        hidden_states = [Variable(torch.zeros(1, batch_size, self.hidden_size)).double()\n",
        "                         for _ in range(self.num_rnn_levels)]\n",
        "        return hidden_states\n",
        "\n",
        "    def create_W(self, P, is_l, is_comp=False):\n",
        "        if is_l:\n",
        "            filter_list = self.l_filter\n",
        "        else:\n",
        "            filter_list = self.h_filter\n",
        "\n",
        "        list_len = len(filter_list)\n",
        "\n",
        "        max_epsilon = np.min(np.abs(filter_list))\n",
        "        if is_comp:\n",
        "            weight_np = np.zeros((P, P))\n",
        "        else:\n",
        "            weight_np = np.random.randn(P, P) * 0.1 * max_epsilon\n",
        "\n",
        "        for i in range(0, P):\n",
        "            filter_index = 0\n",
        "            for j in range(i, P):\n",
        "                if filter_index < len(filter_list):\n",
        "                    weight_np[i][j] = filter_list[filter_index]\n",
        "                    filter_index += 1\n",
        "        return weight_np\n"
      ],
      "metadata": {
        "id": "tVAdvfrx4C_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, x_train, y_train, epochs=10, batch_size=32, alpha=0.3, beta=0.3):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.008)\n",
        "    criterion = nn.L1Loss()\n",
        "\n",
        "    torch_dataloader = TorchDataLoader(batch_size)\n",
        "    train_loader = torch_dataloader.torch_dataloader(x_train, y_train)\n",
        "\n",
        "    x_len = x_train.shape[1]\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for batch, (X, Y) in enumerate(train_loader):\n",
        "            hidden_states = model.init_state(X.shape[0])\n",
        "            output = model(X, hidden_states)\n",
        "\n",
        "            loss = criterion(output[:, -1, :], Y[:, -1, :])\n",
        "\n",
        "            # Calculate wavelet loss\n",
        "            L_loss = 0\n",
        "            H_loss = 0\n",
        "\n",
        "            W_mWDNs_H = [model.mWDNs_H[i].weight for i in range(model.num_rnn_levels)]\n",
        "            W_mWDNs_L = [model.mWDNs_L[i].weight for i in range(model.num_rnn_levels)]\n",
        "            for i in range(model.num_rnn_levels):\n",
        "                L_loss += torch.norm((W_mWDNs_L[i] - model.cmp_mWDNs_L[i]), 2)\n",
        "                H_loss += torch.norm((W_mWDNs_H[i] - model.cmp_mWDNs_H[i]), 2)\n",
        "\n",
        "            loss += alpha * L_loss + beta * H_loss\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            print('Epoch:', epoch + 1, '| Batch:', batch + 1, '| Loss:', loss.item())\n",
        "\n",
        "    torch.save(model.state_dict(), '/content/drive/My Drive/thesis/preprocess/modelGRU_C.pth')\n",
        "\n",
        "\n",
        "def test(model, x_test, y_test, data_df_combined_clean):\n",
        "    model.load_state_dict(torch.load('/content/drive/My Drive/thesis/preprocess/modelGRU_C.pth'))\n",
        "    model.eval()\n",
        "    x_test = ToVariable(x_test).double()\n",
        "    hiddens_states = model.init_state(x_test.shape[0])\n",
        "\n",
        "    pred_dat = model(x_test, hiddens_states)\n",
        "\n",
        "    pred_dat = np.array(pred_dat.detach().numpy())\n",
        "\n",
        "    # De-standardize predictions\n",
        "    preds_unstd = pred_dat * data_df_combined_clean.iloc[:, -1].std() + data_df_combined_clean.iloc[:, -1].mean()\n",
        "    y_test_unstd = y_test * data_df_combined_clean.iloc[:, -1].std() + data_df_combined_clean.iloc[:, -1].mean()\n",
        "\n",
        "    mrse = np.sqrt(((preds_unstd[:, -1, :] - y_test_unstd[:, -1, :]) ** 2)).mean(axis=0)\n",
        "    print('The mean square error is: %f' % mrse)\n",
        "    mape = np.mean(np.abs((y_test_unstd[:, -1, :] - preds_unstd[:, -1, :]) / y_test_unstd[:, -1, :])) * 100\n",
        "    print('MAPE is: %f' % mape)\n",
        "\n",
        "    plot_results(preds_unstd[:, -1, :], y_test_unstd[:, -1, :])\n"
      ],
      "metadata": {
        "id": "LxPkQmP-4Wbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/drive/MyDrive/ausdata.csv'\n",
        "P = 24  # sequence length\n",
        "step = 6  # ahead predict steps\n",
        "\n",
        "X_train, Y_train, X_test, Y_test, data_df_combined_clean = load_data(data_path, P=P, step=step)\n",
        "\n",
        "#print(X_train.shape)\n",
        "#print(Y_train.shape)\n",
        "\n",
        "model = Wavelet_GRU(P, 100, 1, num_rnn_levels=2)  # seq_len, hidden_size, output_size\n",
        "model = model.double()\n",
        "\n",
        "X_train = torch.from_numpy(X_train)\n",
        "Y_train = torch.from_numpy(Y_train)\n",
        "train(model, X_train, Y_train, epochs=50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvNYuASK4q0u",
        "outputId": "0f81196c-782f-4c55-ed73-706df0016a3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch: 48 | Batch: 1574 | Loss: 0.2531907937861569\n",
            "Epoch: 48 | Batch: 1575 | Loss: 0.17419433621873376\n",
            "Epoch: 48 | Batch: 1576 | Loss: 0.14585326538018215\n",
            "Epoch: 48 | Batch: 1577 | Loss: 0.1470131216573259\n",
            "Epoch: 48 | Batch: 1578 | Loss: 0.16350921131847024\n",
            "Epoch: 48 | Batch: 1579 | Loss: 0.1409448588391913\n",
            "Epoch: 48 | Batch: 1580 | Loss: 0.16556270115299632\n",
            "Epoch: 48 | Batch: 1581 | Loss: 0.161308300060008\n",
            "Epoch: 48 | Batch: 1582 | Loss: 0.16348945769291912\n",
            "Epoch: 48 | Batch: 1583 | Loss: 0.1328698102404458\n",
            "Epoch: 48 | Batch: 1584 | Loss: 0.25623608657489183\n",
            "Epoch: 48 | Batch: 1585 | Loss: 0.1528040904934833\n",
            "Epoch: 48 | Batch: 1586 | Loss: 0.18646420477967582\n",
            "Epoch: 48 | Batch: 1587 | Loss: 0.22266896124717647\n",
            "Epoch: 48 | Batch: 1588 | Loss: 0.16554091834390725\n",
            "Epoch: 48 | Batch: 1589 | Loss: 0.20695572483151461\n",
            "Epoch: 48 | Batch: 1590 | Loss: 0.1350272597758384\n",
            "Epoch: 48 | Batch: 1591 | Loss: 0.20161364496124676\n",
            "Epoch: 48 | Batch: 1592 | Loss: 0.17652929138042195\n",
            "Epoch: 48 | Batch: 1593 | Loss: 0.20618923798246613\n",
            "Epoch: 48 | Batch: 1594 | Loss: 0.14186351185498794\n",
            "Epoch: 48 | Batch: 1595 | Loss: 0.14874367962047638\n",
            "Epoch: 48 | Batch: 1596 | Loss: 0.16771434999030738\n",
            "Epoch: 48 | Batch: 1597 | Loss: 0.1622368512594832\n",
            "Epoch: 48 | Batch: 1598 | Loss: 0.24543996231550733\n",
            "Epoch: 48 | Batch: 1599 | Loss: 0.21141832444976288\n",
            "Epoch: 48 | Batch: 1600 | Loss: 0.17428148478554756\n",
            "Epoch: 48 | Batch: 1601 | Loss: 0.18019179242459635\n",
            "Epoch: 48 | Batch: 1602 | Loss: 0.18763218288287295\n",
            "Epoch: 48 | Batch: 1603 | Loss: 0.1738877869152305\n",
            "Epoch: 48 | Batch: 1604 | Loss: 0.13509028776823342\n",
            "Epoch: 48 | Batch: 1605 | Loss: 0.10315691181042047\n",
            "Epoch: 48 | Batch: 1606 | Loss: 0.154774504423123\n",
            "Epoch: 48 | Batch: 1607 | Loss: 0.16110412081199382\n",
            "Epoch: 48 | Batch: 1608 | Loss: 0.159435357242756\n",
            "Epoch: 48 | Batch: 1609 | Loss: 0.17824788850295376\n",
            "Epoch: 48 | Batch: 1610 | Loss: 0.15205807094234797\n",
            "Epoch: 48 | Batch: 1611 | Loss: 0.15786950320330725\n",
            "Epoch: 48 | Batch: 1612 | Loss: 0.13020601036853216\n",
            "Epoch: 48 | Batch: 1613 | Loss: 0.16610937104953244\n",
            "Epoch: 48 | Batch: 1614 | Loss: 0.1846509409767237\n",
            "Epoch: 48 | Batch: 1615 | Loss: 0.13151502901447995\n",
            "Epoch: 48 | Batch: 1616 | Loss: 0.1321692813545107\n",
            "Epoch: 48 | Batch: 1617 | Loss: 0.1708277879668173\n",
            "Epoch: 48 | Batch: 1618 | Loss: 0.15620154764480176\n",
            "Epoch: 48 | Batch: 1619 | Loss: 0.13929012688643344\n",
            "Epoch: 48 | Batch: 1620 | Loss: 0.19041218285040454\n",
            "Epoch: 48 | Batch: 1621 | Loss: 0.1759497242886343\n",
            "Epoch: 48 | Batch: 1622 | Loss: 0.1271988963460558\n",
            "Epoch: 48 | Batch: 1623 | Loss: 0.18772047414085977\n",
            "Epoch: 48 | Batch: 1624 | Loss: 0.20068006979288988\n",
            "Epoch: 48 | Batch: 1625 | Loss: 0.15629638570490834\n",
            "Epoch: 48 | Batch: 1626 | Loss: 0.1567233750747311\n",
            "Epoch: 48 | Batch: 1627 | Loss: 0.09967215265525439\n",
            "Epoch: 48 | Batch: 1628 | Loss: 0.1559932680274718\n",
            "Epoch: 48 | Batch: 1629 | Loss: 0.12315934697020998\n",
            "Epoch: 48 | Batch: 1630 | Loss: 0.19871247654391208\n",
            "Epoch: 48 | Batch: 1631 | Loss: 0.1453719178178848\n",
            "Epoch: 48 | Batch: 1632 | Loss: 0.17241492660351335\n",
            "Epoch: 48 | Batch: 1633 | Loss: 0.13181073966664023\n",
            "Epoch: 48 | Batch: 1634 | Loss: 0.1644086571074108\n",
            "Epoch: 48 | Batch: 1635 | Loss: 0.15750841142901742\n",
            "Epoch: 48 | Batch: 1636 | Loss: 0.17922146440229617\n",
            "Epoch: 48 | Batch: 1637 | Loss: 0.15775791720519014\n",
            "Epoch: 48 | Batch: 1638 | Loss: 0.19923350935655912\n",
            "Epoch: 48 | Batch: 1639 | Loss: 0.13509687807659193\n",
            "Epoch: 48 | Batch: 1640 | Loss: 0.13872406277602162\n",
            "Epoch: 48 | Batch: 1641 | Loss: 0.2155169840334641\n",
            "Epoch: 48 | Batch: 1642 | Loss: 0.19150396648729398\n",
            "Epoch: 48 | Batch: 1643 | Loss: 0.16312822807948793\n",
            "Epoch: 48 | Batch: 1644 | Loss: 0.21017248667250713\n",
            "Epoch: 48 | Batch: 1645 | Loss: 0.1533613688259229\n",
            "Epoch: 48 | Batch: 1646 | Loss: 0.15923638171046872\n",
            "Epoch: 48 | Batch: 1647 | Loss: 0.17037867268621937\n",
            "Epoch: 48 | Batch: 1648 | Loss: 0.12112894153079808\n",
            "Epoch: 48 | Batch: 1649 | Loss: 0.21125568179210402\n",
            "Epoch: 48 | Batch: 1650 | Loss: 0.20609981994917118\n",
            "Epoch: 48 | Batch: 1651 | Loss: 0.15349801965334692\n",
            "Epoch: 48 | Batch: 1652 | Loss: 0.14740703975830027\n",
            "Epoch: 48 | Batch: 1653 | Loss: 0.11205023299348132\n",
            "Epoch: 48 | Batch: 1654 | Loss: 0.15515548899137765\n",
            "Epoch: 48 | Batch: 1655 | Loss: 0.19753872175778145\n",
            "Epoch: 48 | Batch: 1656 | Loss: 0.2128916014022636\n",
            "Epoch: 48 | Batch: 1657 | Loss: 0.14257245466430107\n",
            "Epoch: 48 | Batch: 1658 | Loss: 0.1859315680787138\n",
            "Epoch: 48 | Batch: 1659 | Loss: 0.13514161532383936\n",
            "Epoch: 48 | Batch: 1660 | Loss: 0.17316669284508793\n",
            "Epoch: 48 | Batch: 1661 | Loss: 0.152239941987204\n",
            "Epoch: 48 | Batch: 1662 | Loss: 0.12294591095431054\n",
            "Epoch: 48 | Batch: 1663 | Loss: 0.14557004045821972\n",
            "Epoch: 48 | Batch: 1664 | Loss: 0.13885762453846248\n",
            "Epoch: 48 | Batch: 1665 | Loss: 0.1664334863767738\n",
            "Epoch: 48 | Batch: 1666 | Loss: 0.15688926136662282\n",
            "Epoch: 48 | Batch: 1667 | Loss: 0.14501097985698075\n",
            "Epoch: 48 | Batch: 1668 | Loss: 0.14926279057380312\n",
            "Epoch: 48 | Batch: 1669 | Loss: 0.15565459960260009\n",
            "Epoch: 48 | Batch: 1670 | Loss: 0.13850876124372175\n",
            "Epoch: 48 | Batch: 1671 | Loss: 0.16877395474116588\n",
            "Epoch: 48 | Batch: 1672 | Loss: 0.15662805115827566\n",
            "Epoch: 48 | Batch: 1673 | Loss: 0.15086789185255278\n",
            "Epoch: 48 | Batch: 1674 | Loss: 0.14168875782749596\n",
            "Epoch: 48 | Batch: 1675 | Loss: 0.14398787511421587\n",
            "Epoch: 48 | Batch: 1676 | Loss: 0.15645760090168778\n",
            "Epoch: 48 | Batch: 1677 | Loss: 0.1381279703424828\n",
            "Epoch: 48 | Batch: 1678 | Loss: 0.13810186937597035\n",
            "Epoch: 48 | Batch: 1679 | Loss: 0.15647505488889035\n",
            "Epoch: 48 | Batch: 1680 | Loss: 0.13929588325491044\n",
            "Epoch: 48 | Batch: 1681 | Loss: 0.19113266723949834\n",
            "Epoch: 48 | Batch: 1682 | Loss: 0.15562152659361306\n",
            "Epoch: 48 | Batch: 1683 | Loss: 0.1601454404981319\n",
            "Epoch: 48 | Batch: 1684 | Loss: 0.16886546315894185\n",
            "Epoch: 48 | Batch: 1685 | Loss: 0.1375556264740792\n",
            "Epoch: 48 | Batch: 1686 | Loss: 0.19169904394486284\n",
            "Epoch: 48 | Batch: 1687 | Loss: 0.15951634264393427\n",
            "Epoch: 48 | Batch: 1688 | Loss: 0.1772381632101565\n",
            "Epoch: 48 | Batch: 1689 | Loss: 0.16226920619656865\n",
            "Epoch: 48 | Batch: 1690 | Loss: 0.21528795114039107\n",
            "Epoch: 48 | Batch: 1691 | Loss: 0.19372125043790547\n",
            "Epoch: 48 | Batch: 1692 | Loss: 0.1879100416835453\n",
            "Epoch: 48 | Batch: 1693 | Loss: 0.14314025004031444\n",
            "Epoch: 48 | Batch: 1694 | Loss: 0.17426899347654726\n",
            "Epoch: 48 | Batch: 1695 | Loss: 0.14908259544350133\n",
            "Epoch: 48 | Batch: 1696 | Loss: 0.18799258505272023\n",
            "Epoch: 48 | Batch: 1697 | Loss: 0.18812069208962443\n",
            "Epoch: 48 | Batch: 1698 | Loss: 0.18584690570790596\n",
            "Epoch: 48 | Batch: 1699 | Loss: 0.17586395435300578\n",
            "Epoch: 48 | Batch: 1700 | Loss: 0.20365499648286198\n",
            "Epoch: 48 | Batch: 1701 | Loss: 0.19172595822998942\n",
            "Epoch: 48 | Batch: 1702 | Loss: 0.17936012233310897\n",
            "Epoch: 48 | Batch: 1703 | Loss: 0.18487665539258635\n",
            "Epoch: 48 | Batch: 1704 | Loss: 0.14856761714161534\n",
            "Epoch: 48 | Batch: 1705 | Loss: 0.14370647093613798\n",
            "Epoch: 48 | Batch: 1706 | Loss: 0.21816249080856498\n",
            "Epoch: 48 | Batch: 1707 | Loss: 0.12080204070564461\n",
            "Epoch: 48 | Batch: 1708 | Loss: 0.12768636224173222\n",
            "Epoch: 48 | Batch: 1709 | Loss: 0.15872562351930447\n",
            "Epoch: 48 | Batch: 1710 | Loss: 0.18615278096589255\n",
            "Epoch: 48 | Batch: 1711 | Loss: 0.2011599920975169\n",
            "Epoch: 48 | Batch: 1712 | Loss: 0.15239425294701844\n",
            "Epoch: 48 | Batch: 1713 | Loss: 0.2022983313724007\n",
            "Epoch: 48 | Batch: 1714 | Loss: 0.18598907897832323\n",
            "Epoch: 48 | Batch: 1715 | Loss: 0.18865413896045505\n",
            "Epoch: 48 | Batch: 1716 | Loss: 0.17804561664527174\n",
            "Epoch: 48 | Batch: 1717 | Loss: 0.19842482923767263\n",
            "Epoch: 48 | Batch: 1718 | Loss: 0.17647707281863947\n",
            "Epoch: 48 | Batch: 1719 | Loss: 0.16757531338751278\n",
            "Epoch: 48 | Batch: 1720 | Loss: 0.16120531252135695\n",
            "Epoch: 48 | Batch: 1721 | Loss: 0.17250291233358175\n",
            "Epoch: 48 | Batch: 1722 | Loss: 0.14425120391845445\n",
            "Epoch: 48 | Batch: 1723 | Loss: 0.14227252134382953\n",
            "Epoch: 48 | Batch: 1724 | Loss: 0.1543731562541442\n",
            "Epoch: 48 | Batch: 1725 | Loss: 0.2105454312549132\n",
            "Epoch: 48 | Batch: 1726 | Loss: 0.13737990182581977\n",
            "Epoch: 48 | Batch: 1727 | Loss: 0.1295901374421263\n",
            "Epoch: 48 | Batch: 1728 | Loss: 0.18471306303916485\n",
            "Epoch: 48 | Batch: 1729 | Loss: 0.2045113772281263\n",
            "Epoch: 48 | Batch: 1730 | Loss: 0.14021503391006004\n",
            "Epoch: 48 | Batch: 1731 | Loss: 0.14948692555731466\n",
            "Epoch: 48 | Batch: 1732 | Loss: 0.1516317333949755\n",
            "Epoch: 48 | Batch: 1733 | Loss: 0.14706321912790984\n",
            "Epoch: 48 | Batch: 1734 | Loss: 0.12417663942810006\n",
            "Epoch: 48 | Batch: 1735 | Loss: 0.16685709610280328\n",
            "Epoch: 48 | Batch: 1736 | Loss: 0.23000367394119373\n",
            "Epoch: 48 | Batch: 1737 | Loss: 0.14200346560595462\n",
            "Epoch: 48 | Batch: 1738 | Loss: 0.16652792319849158\n",
            "Epoch: 48 | Batch: 1739 | Loss: 0.14557173538597873\n",
            "Epoch: 48 | Batch: 1740 | Loss: 0.2075327508913561\n",
            "Epoch: 48 | Batch: 1741 | Loss: 0.18839741892607095\n",
            "Epoch: 48 | Batch: 1742 | Loss: 0.1746978378555527\n",
            "Epoch: 48 | Batch: 1743 | Loss: 0.1682207858854277\n",
            "Epoch: 48 | Batch: 1744 | Loss: 0.18996809880426604\n",
            "Epoch: 48 | Batch: 1745 | Loss: 0.10922242610666497\n",
            "Epoch: 48 | Batch: 1746 | Loss: 0.1984674272247951\n",
            "Epoch: 48 | Batch: 1747 | Loss: 0.14615312914909956\n",
            "Epoch: 48 | Batch: 1748 | Loss: 0.1824049198948287\n",
            "Epoch: 48 | Batch: 1749 | Loss: 0.17825296177055516\n",
            "Epoch: 48 | Batch: 1750 | Loss: 0.2145543334326509\n",
            "Epoch: 48 | Batch: 1751 | Loss: 0.1310624231896817\n",
            "Epoch: 48 | Batch: 1752 | Loss: 0.1752216191087909\n",
            "Epoch: 48 | Batch: 1753 | Loss: 0.13732277323606526\n",
            "Epoch: 48 | Batch: 1754 | Loss: 0.15766188942459886\n",
            "Epoch: 48 | Batch: 1755 | Loss: 0.1477055713126803\n",
            "Epoch: 48 | Batch: 1756 | Loss: 0.18986311003068324\n",
            "Epoch: 48 | Batch: 1757 | Loss: 0.1876355318108452\n",
            "Epoch: 48 | Batch: 1758 | Loss: 0.13674687486208792\n",
            "Epoch: 48 | Batch: 1759 | Loss: 0.15750260869977328\n",
            "Epoch: 48 | Batch: 1760 | Loss: 0.17960679194322265\n",
            "Epoch: 48 | Batch: 1761 | Loss: 0.1820857871595428\n",
            "Epoch: 48 | Batch: 1762 | Loss: 0.1779877374948754\n",
            "Epoch: 48 | Batch: 1763 | Loss: 0.1723854656953644\n",
            "Epoch: 48 | Batch: 1764 | Loss: 0.1692343354935247\n",
            "Epoch: 48 | Batch: 1765 | Loss: 0.16983541475857497\n",
            "Epoch: 48 | Batch: 1766 | Loss: 0.15353569260617472\n",
            "Epoch: 48 | Batch: 1767 | Loss: 0.22097180310543124\n",
            "Epoch: 48 | Batch: 1768 | Loss: 0.17595723005763264\n",
            "Epoch: 48 | Batch: 1769 | Loss: 0.15564351839374538\n",
            "Epoch: 48 | Batch: 1770 | Loss: 0.17838959734778548\n",
            "Epoch: 48 | Batch: 1771 | Loss: 0.17758809915740373\n",
            "Epoch: 48 | Batch: 1772 | Loss: 0.1464165050881484\n",
            "Epoch: 48 | Batch: 1773 | Loss: 0.15800434145120562\n",
            "Epoch: 48 | Batch: 1774 | Loss: 0.1531726222652782\n",
            "Epoch: 48 | Batch: 1775 | Loss: 0.17540312307643152\n",
            "Epoch: 48 | Batch: 1776 | Loss: 0.21762431371680047\n",
            "Epoch: 48 | Batch: 1777 | Loss: 0.1564077235764217\n",
            "Epoch: 48 | Batch: 1778 | Loss: 0.16592205034902494\n",
            "Epoch: 48 | Batch: 1779 | Loss: 0.16928620789996213\n",
            "Epoch: 48 | Batch: 1780 | Loss: 0.13058318580057704\n",
            "Epoch: 48 | Batch: 1781 | Loss: 0.20428158977076186\n",
            "Epoch: 48 | Batch: 1782 | Loss: 0.18498919228083968\n",
            "Epoch: 48 | Batch: 1783 | Loss: 0.18858412996995788\n",
            "Epoch: 48 | Batch: 1784 | Loss: 0.15208815577198184\n",
            "Epoch: 48 | Batch: 1785 | Loss: 0.25209463230411927\n",
            "Epoch: 48 | Batch: 1786 | Loss: 0.2156681304047806\n",
            "Epoch: 48 | Batch: 1787 | Loss: 0.20915748776653853\n",
            "Epoch: 48 | Batch: 1788 | Loss: 0.17744961685955726\n",
            "Epoch: 48 | Batch: 1789 | Loss: 0.20955072228206695\n",
            "Epoch: 48 | Batch: 1790 | Loss: 0.15346466177591325\n",
            "Epoch: 48 | Batch: 1791 | Loss: 0.17758672602557582\n",
            "Epoch: 48 | Batch: 1792 | Loss: 0.15043803179139337\n",
            "Epoch: 48 | Batch: 1793 | Loss: 0.1512035533914822\n",
            "Epoch: 48 | Batch: 1794 | Loss: 0.19612683649927323\n",
            "Epoch: 48 | Batch: 1795 | Loss: 0.2047545044838952\n",
            "Epoch: 48 | Batch: 1796 | Loss: 0.170611126594481\n",
            "Epoch: 48 | Batch: 1797 | Loss: 0.20676330827670805\n",
            "Epoch: 48 | Batch: 1798 | Loss: 0.1638476342475515\n",
            "Epoch: 48 | Batch: 1799 | Loss: 0.1583839336832569\n",
            "Epoch: 48 | Batch: 1800 | Loss: 0.19116754691924856\n",
            "Epoch: 48 | Batch: 1801 | Loss: 0.13095401420777528\n",
            "Epoch: 48 | Batch: 1802 | Loss: 0.21163106419411662\n",
            "Epoch: 48 | Batch: 1803 | Loss: 0.1424587155060258\n",
            "Epoch: 48 | Batch: 1804 | Loss: 0.17287955391656318\n",
            "Epoch: 48 | Batch: 1805 | Loss: 0.15463052483972634\n",
            "Epoch: 48 | Batch: 1806 | Loss: 0.16695761331463593\n",
            "Epoch: 48 | Batch: 1807 | Loss: 0.2352459756738861\n",
            "Epoch: 48 | Batch: 1808 | Loss: 0.12760886140724803\n",
            "Epoch: 48 | Batch: 1809 | Loss: 0.19645470304068527\n",
            "Epoch: 48 | Batch: 1810 | Loss: 0.16481382374995646\n",
            "Epoch: 48 | Batch: 1811 | Loss: 0.16291799163526735\n",
            "Epoch: 48 | Batch: 1812 | Loss: 0.19663589397773357\n",
            "Epoch: 48 | Batch: 1813 | Loss: 0.16616387188916043\n",
            "Epoch: 48 | Batch: 1814 | Loss: 0.20731264451629908\n",
            "Epoch: 48 | Batch: 1815 | Loss: 0.13962096846065175\n",
            "Epoch: 48 | Batch: 1816 | Loss: 0.18969351753436964\n",
            "Epoch: 48 | Batch: 1817 | Loss: 0.14645271526741616\n",
            "Epoch: 48 | Batch: 1818 | Loss: 0.13159224891752563\n",
            "Epoch: 48 | Batch: 1819 | Loss: 0.148191333747406\n",
            "Epoch: 48 | Batch: 1820 | Loss: 0.17658486838193121\n",
            "Epoch: 48 | Batch: 1821 | Loss: 0.1383874173790996\n",
            "Epoch: 48 | Batch: 1822 | Loss: 0.15471460098200185\n",
            "Epoch: 48 | Batch: 1823 | Loss: 0.14166253315412403\n",
            "Epoch: 48 | Batch: 1824 | Loss: 0.15062727586794883\n",
            "Epoch: 48 | Batch: 1825 | Loss: 0.1534694393006002\n",
            "Epoch: 48 | Batch: 1826 | Loss: 0.17795975303374628\n",
            "Epoch: 48 | Batch: 1827 | Loss: 0.18716355120658384\n",
            "Epoch: 48 | Batch: 1828 | Loss: 0.17212618726533602\n",
            "Epoch: 48 | Batch: 1829 | Loss: 0.2313097574088084\n",
            "Epoch: 48 | Batch: 1830 | Loss: 0.14955714284136679\n",
            "Epoch: 48 | Batch: 1831 | Loss: 0.17612909547963473\n",
            "Epoch: 48 | Batch: 1832 | Loss: 0.1528982009275464\n",
            "Epoch: 48 | Batch: 1833 | Loss: 0.16124574260575253\n",
            "Epoch: 48 | Batch: 1834 | Loss: 0.16388359390146556\n",
            "Epoch: 48 | Batch: 1835 | Loss: 0.17058042328465353\n",
            "Epoch: 48 | Batch: 1836 | Loss: 0.23597459171990104\n",
            "Epoch: 48 | Batch: 1837 | Loss: 0.22314647694135029\n",
            "Epoch: 48 | Batch: 1838 | Loss: 0.1468884235027943\n",
            "Epoch: 48 | Batch: 1839 | Loss: 0.15883933078195414\n",
            "Epoch: 48 | Batch: 1840 | Loss: 0.1919728440022454\n",
            "Epoch: 48 | Batch: 1841 | Loss: 0.1820949596615566\n",
            "Epoch: 48 | Batch: 1842 | Loss: 0.1750355433159149\n",
            "Epoch: 48 | Batch: 1843 | Loss: 0.17687168826957433\n",
            "Epoch: 48 | Batch: 1844 | Loss: 0.17150599069760042\n",
            "Epoch: 48 | Batch: 1845 | Loss: 0.1634221856462678\n",
            "Epoch: 48 | Batch: 1846 | Loss: 0.19620082810465383\n",
            "Epoch: 48 | Batch: 1847 | Loss: 0.18235399465638086\n",
            "Epoch: 48 | Batch: 1848 | Loss: 0.14583202890868227\n",
            "Epoch: 48 | Batch: 1849 | Loss: 0.17812064098616032\n",
            "Epoch: 48 | Batch: 1850 | Loss: 0.1647118311222276\n",
            "Epoch: 48 | Batch: 1851 | Loss: 0.1781924106488737\n",
            "Epoch: 48 | Batch: 1852 | Loss: 0.1317600798948216\n",
            "Epoch: 48 | Batch: 1853 | Loss: 0.1618595500810488\n",
            "Epoch: 48 | Batch: 1854 | Loss: 0.15602165059278927\n",
            "Epoch: 48 | Batch: 1855 | Loss: 0.16181936448808593\n",
            "Epoch: 48 | Batch: 1856 | Loss: 0.1790505909617473\n",
            "Epoch: 48 | Batch: 1857 | Loss: 0.19582107688684836\n",
            "Epoch: 48 | Batch: 1858 | Loss: 0.22027680965762553\n",
            "Epoch: 48 | Batch: 1859 | Loss: 0.17361068952153752\n",
            "Epoch: 48 | Batch: 1860 | Loss: 0.18538254286562303\n",
            "Epoch: 48 | Batch: 1861 | Loss: 0.1421291884899834\n",
            "Epoch: 48 | Batch: 1862 | Loss: 0.18146673587774265\n",
            "Epoch: 48 | Batch: 1863 | Loss: 0.21578495485502944\n",
            "Epoch: 48 | Batch: 1864 | Loss: 0.16541309346577282\n",
            "Epoch: 48 | Batch: 1865 | Loss: 0.17735824413566909\n",
            "Epoch: 48 | Batch: 1866 | Loss: 0.1464321968953356\n",
            "Epoch: 48 | Batch: 1867 | Loss: 0.18464995456820782\n",
            "Epoch: 48 | Batch: 1868 | Loss: 0.17362907633426533\n",
            "Epoch: 48 | Batch: 1869 | Loss: 0.14012788398858916\n",
            "Epoch: 48 | Batch: 1870 | Loss: 0.1469872951872539\n",
            "Epoch: 48 | Batch: 1871 | Loss: 0.1765546226034559\n",
            "Epoch: 48 | Batch: 1872 | Loss: 0.14654581882109957\n",
            "Epoch: 48 | Batch: 1873 | Loss: 0.1594322386310627\n",
            "Epoch: 48 | Batch: 1874 | Loss: 0.17538497010462356\n",
            "Epoch: 48 | Batch: 1875 | Loss: 0.12778472974261754\n",
            "Epoch: 48 | Batch: 1876 | Loss: 0.19613287571527482\n",
            "Epoch: 48 | Batch: 1877 | Loss: 0.17197486324752578\n",
            "Epoch: 48 | Batch: 1878 | Loss: 0.15352093074274456\n",
            "Epoch: 48 | Batch: 1879 | Loss: 0.19959325945914935\n",
            "Epoch: 48 | Batch: 1880 | Loss: 0.13789603245411472\n",
            "Epoch: 48 | Batch: 1881 | Loss: 0.14427839581426405\n",
            "Epoch: 48 | Batch: 1882 | Loss: 0.14579277394368154\n",
            "Epoch: 48 | Batch: 1883 | Loss: 0.16144343756469134\n",
            "Epoch: 48 | Batch: 1884 | Loss: 0.19400653395973289\n",
            "Epoch: 48 | Batch: 1885 | Loss: 0.1599293721066702\n",
            "Epoch: 48 | Batch: 1886 | Loss: 0.20653251075375367\n",
            "Epoch: 48 | Batch: 1887 | Loss: 0.19212114376594755\n",
            "Epoch: 48 | Batch: 1888 | Loss: 0.1402129893680163\n",
            "Epoch: 48 | Batch: 1889 | Loss: 0.14285579334378729\n",
            "Epoch: 48 | Batch: 1890 | Loss: 0.11942543732309016\n",
            "Epoch: 48 | Batch: 1891 | Loss: 0.13772124891955348\n",
            "Epoch: 48 | Batch: 1892 | Loss: 0.1882194651740306\n",
            "Epoch: 48 | Batch: 1893 | Loss: 0.17462879482851104\n",
            "Epoch: 48 | Batch: 1894 | Loss: 0.18318988692187452\n",
            "Epoch: 48 | Batch: 1895 | Loss: 0.14348776826630102\n",
            "Epoch: 48 | Batch: 1896 | Loss: 0.1934960688344586\n",
            "Epoch: 48 | Batch: 1897 | Loss: 0.19276614415299867\n",
            "Epoch: 48 | Batch: 1898 | Loss: 0.17702307705017165\n",
            "Epoch: 48 | Batch: 1899 | Loss: 0.16484943022176482\n",
            "Epoch: 48 | Batch: 1900 | Loss: 0.17453657390113583\n",
            "Epoch: 48 | Batch: 1901 | Loss: 0.15705575358813892\n",
            "Epoch: 48 | Batch: 1902 | Loss: 0.17825057360618912\n",
            "Epoch: 48 | Batch: 1903 | Loss: 0.17891768068149805\n",
            "Epoch: 48 | Batch: 1904 | Loss: 0.18272267699813666\n",
            "Epoch: 48 | Batch: 1905 | Loss: 0.13023437647842123\n",
            "Epoch: 48 | Batch: 1906 | Loss: 0.1875794831437109\n",
            "Epoch: 48 | Batch: 1907 | Loss: 0.18500950082705975\n",
            "Epoch: 48 | Batch: 1908 | Loss: 0.1551798830558869\n",
            "Epoch: 48 | Batch: 1909 | Loss: 0.22570653387322864\n",
            "Epoch: 48 | Batch: 1910 | Loss: 0.2429064830118471\n",
            "Epoch: 48 | Batch: 1911 | Loss: 0.1483669242145491\n",
            "Epoch: 48 | Batch: 1912 | Loss: 0.14669980102736538\n",
            "Epoch: 48 | Batch: 1913 | Loss: 0.2001523420152719\n",
            "Epoch: 48 | Batch: 1914 | Loss: 0.1643529813011986\n",
            "Epoch: 48 | Batch: 1915 | Loss: 0.158676929297871\n",
            "Epoch: 48 | Batch: 1916 | Loss: 0.1522470996669143\n",
            "Epoch: 48 | Batch: 1917 | Loss: 0.11684629294171567\n",
            "Epoch: 48 | Batch: 1918 | Loss: 0.15064379914052065\n",
            "Epoch: 48 | Batch: 1919 | Loss: 0.1677555571050777\n",
            "Epoch: 48 | Batch: 1920 | Loss: 0.12236969742587668\n",
            "Epoch: 48 | Batch: 1921 | Loss: 0.270896047933848\n",
            "Epoch: 48 | Batch: 1922 | Loss: 0.15337357758953818\n",
            "Epoch: 48 | Batch: 1923 | Loss: 0.1597868654522132\n",
            "Epoch: 48 | Batch: 1924 | Loss: 0.16351341788217355\n",
            "Epoch: 48 | Batch: 1925 | Loss: 0.15726380494277728\n",
            "Epoch: 48 | Batch: 1926 | Loss: 0.1782457996917118\n",
            "Epoch: 48 | Batch: 1927 | Loss: 0.18933893590632184\n",
            "Epoch: 48 | Batch: 1928 | Loss: 0.18258649821585757\n",
            "Epoch: 48 | Batch: 1929 | Loss: 0.11799521397107718\n",
            "Epoch: 48 | Batch: 1930 | Loss: 0.14771131304023505\n",
            "Epoch: 48 | Batch: 1931 | Loss: 0.19074588329041373\n",
            "Epoch: 48 | Batch: 1932 | Loss: 0.16504500790945648\n",
            "Epoch: 48 | Batch: 1933 | Loss: 0.17547091755823432\n",
            "Epoch: 48 | Batch: 1934 | Loss: 0.14906234173525396\n",
            "Epoch: 48 | Batch: 1935 | Loss: 0.14317147854768889\n",
            "Epoch: 48 | Batch: 1936 | Loss: 0.1484171481704475\n",
            "Epoch: 48 | Batch: 1937 | Loss: 0.1520035397353929\n",
            "Epoch: 48 | Batch: 1938 | Loss: 0.15002534935658957\n",
            "Epoch: 48 | Batch: 1939 | Loss: 0.14482807428047606\n",
            "Epoch: 48 | Batch: 1940 | Loss: 0.14377005974905377\n",
            "Epoch: 48 | Batch: 1941 | Loss: 0.14980246991685559\n",
            "Epoch: 48 | Batch: 1942 | Loss: 0.16617426923920264\n",
            "Epoch: 48 | Batch: 1943 | Loss: 0.15262285077642807\n",
            "Epoch: 48 | Batch: 1944 | Loss: 0.22872820486768902\n",
            "Epoch: 48 | Batch: 1945 | Loss: 0.18036070155281733\n",
            "Epoch: 48 | Batch: 1946 | Loss: 0.1419590753215057\n",
            "Epoch: 48 | Batch: 1947 | Loss: 0.1560477992212172\n",
            "Epoch: 48 | Batch: 1948 | Loss: 0.1786077010671518\n",
            "Epoch: 48 | Batch: 1949 | Loss: 0.14889685272352315\n",
            "Epoch: 48 | Batch: 1950 | Loss: 0.19471573624162927\n",
            "Epoch: 48 | Batch: 1951 | Loss: 0.17303931024019145\n",
            "Epoch: 48 | Batch: 1952 | Loss: 0.1728983834624248\n",
            "Epoch: 48 | Batch: 1953 | Loss: 0.17859682964718615\n",
            "Epoch: 48 | Batch: 1954 | Loss: 0.12154713004386049\n",
            "Epoch: 48 | Batch: 1955 | Loss: 0.16693496170719285\n",
            "Epoch: 48 | Batch: 1956 | Loss: 0.16565185765625695\n",
            "Epoch: 48 | Batch: 1957 | Loss: 0.1716210059946418\n",
            "Epoch: 48 | Batch: 1958 | Loss: 0.14201859704926453\n",
            "Epoch: 48 | Batch: 1959 | Loss: 0.18542701680187756\n",
            "Epoch: 48 | Batch: 1960 | Loss: 0.18741209977990805\n",
            "Epoch: 48 | Batch: 1961 | Loss: 0.1287504761137247\n",
            "Epoch: 48 | Batch: 1962 | Loss: 0.1452534491645693\n",
            "Epoch: 48 | Batch: 1963 | Loss: 0.13001738048726835\n",
            "Epoch: 48 | Batch: 1964 | Loss: 0.1749372475307137\n",
            "Epoch: 48 | Batch: 1965 | Loss: 0.13406503263413527\n",
            "Epoch: 48 | Batch: 1966 | Loss: 0.2409457617139435\n",
            "Epoch: 48 | Batch: 1967 | Loss: 0.1937890599772414\n",
            "Epoch: 48 | Batch: 1968 | Loss: 0.16103481934018063\n",
            "Epoch: 48 | Batch: 1969 | Loss: 0.14524412520865293\n",
            "Epoch: 48 | Batch: 1970 | Loss: 0.18713125788526214\n",
            "Epoch: 48 | Batch: 1971 | Loss: 0.22273762975882347\n",
            "Epoch: 48 | Batch: 1972 | Loss: 0.14536792284979191\n",
            "Epoch: 48 | Batch: 1973 | Loss: 0.16682415853346158\n",
            "Epoch: 48 | Batch: 1974 | Loss: 0.1626818404163732\n",
            "Epoch: 48 | Batch: 1975 | Loss: 0.17194573668677168\n",
            "Epoch: 48 | Batch: 1976 | Loss: 0.15498232449528365\n",
            "Epoch: 48 | Batch: 1977 | Loss: 0.16257584324904176\n",
            "Epoch: 48 | Batch: 1978 | Loss: 0.18446693240595294\n",
            "Epoch: 48 | Batch: 1979 | Loss: 0.1739228973478827\n",
            "Epoch: 48 | Batch: 1980 | Loss: 0.16351771234941592\n",
            "Epoch: 48 | Batch: 1981 | Loss: 0.14068641974935173\n",
            "Epoch: 48 | Batch: 1982 | Loss: 0.19138274224816162\n",
            "Epoch: 48 | Batch: 1983 | Loss: 0.13331877761257238\n",
            "Epoch: 48 | Batch: 1984 | Loss: 0.15258949845874936\n",
            "Epoch: 48 | Batch: 1985 | Loss: 0.13385566144484726\n",
            "Epoch: 48 | Batch: 1986 | Loss: 0.12931067766217716\n",
            "Epoch: 48 | Batch: 1987 | Loss: 0.17173221033835329\n",
            "Epoch: 48 | Batch: 1988 | Loss: 0.17343768558873274\n",
            "Epoch: 48 | Batch: 1989 | Loss: 0.17153240683177573\n",
            "Epoch: 48 | Batch: 1990 | Loss: 0.17402206539679443\n",
            "Epoch: 48 | Batch: 1991 | Loss: 0.14273784066788686\n",
            "Epoch: 48 | Batch: 1992 | Loss: 0.1631349013520114\n",
            "Epoch: 48 | Batch: 1993 | Loss: 0.18710866856800587\n",
            "Epoch: 48 | Batch: 1994 | Loss: 0.16367380766786505\n",
            "Epoch: 48 | Batch: 1995 | Loss: 0.19592157989942638\n",
            "Epoch: 48 | Batch: 1996 | Loss: 0.18337738161404774\n",
            "Epoch: 48 | Batch: 1997 | Loss: 0.17103957870849051\n",
            "Epoch: 48 | Batch: 1998 | Loss: 0.184373567405309\n",
            "Epoch: 48 | Batch: 1999 | Loss: 0.1640336137999663\n",
            "Epoch: 48 | Batch: 2000 | Loss: 0.16686952125676402\n",
            "Epoch: 48 | Batch: 2001 | Loss: 0.15238013782278295\n",
            "Epoch: 48 | Batch: 2002 | Loss: 0.13715916577331871\n",
            "Epoch: 48 | Batch: 2003 | Loss: 0.1811855235353026\n",
            "Epoch: 48 | Batch: 2004 | Loss: 0.15499791245151454\n",
            "Epoch: 48 | Batch: 2005 | Loss: 0.16944998921560628\n",
            "Epoch: 48 | Batch: 2006 | Loss: 0.17863789652761455\n",
            "Epoch: 48 | Batch: 2007 | Loss: 0.21318082595576388\n",
            "Epoch: 48 | Batch: 2008 | Loss: 0.2462836392197364\n",
            "Epoch: 48 | Batch: 2009 | Loss: 0.1934389422193282\n",
            "Epoch: 48 | Batch: 2010 | Loss: 0.17428497391702438\n",
            "Epoch: 48 | Batch: 2011 | Loss: 0.15377460204340485\n",
            "Epoch: 48 | Batch: 2012 | Loss: 0.144286225726468\n",
            "Epoch: 48 | Batch: 2013 | Loss: 0.16113240110237953\n",
            "Epoch: 48 | Batch: 2014 | Loss: 0.1720300993095502\n",
            "Epoch: 48 | Batch: 2015 | Loss: 0.19763777487216413\n",
            "Epoch: 48 | Batch: 2016 | Loss: 0.16188183921923766\n",
            "Epoch: 48 | Batch: 2017 | Loss: 0.12236359317394302\n",
            "Epoch: 48 | Batch: 2018 | Loss: 0.19208062201320025\n",
            "Epoch: 48 | Batch: 2019 | Loss: 0.1683132940310633\n",
            "Epoch: 48 | Batch: 2020 | Loss: 0.1905667601741037\n",
            "Epoch: 48 | Batch: 2021 | Loss: 0.1730228291637468\n",
            "Epoch: 48 | Batch: 2022 | Loss: 0.1507712065427989\n",
            "Epoch: 48 | Batch: 2023 | Loss: 0.1394137383689498\n",
            "Epoch: 48 | Batch: 2024 | Loss: 0.20528410770735123\n",
            "Epoch: 48 | Batch: 2025 | Loss: 0.17312623056923082\n",
            "Epoch: 48 | Batch: 2026 | Loss: 0.10740555608524718\n",
            "Epoch: 48 | Batch: 2027 | Loss: 0.12438916636391363\n",
            "Epoch: 48 | Batch: 2028 | Loss: 0.14345013248916696\n",
            "Epoch: 48 | Batch: 2029 | Loss: 0.15746918941653154\n",
            "Epoch: 48 | Batch: 2030 | Loss: 0.1368668198623728\n",
            "Epoch: 48 | Batch: 2031 | Loss: 0.21741049065127588\n",
            "Epoch: 48 | Batch: 2032 | Loss: 0.17212334347539004\n",
            "Epoch: 48 | Batch: 2033 | Loss: 0.15205130500784447\n",
            "Epoch: 48 | Batch: 2034 | Loss: 0.19688995743584892\n",
            "Epoch: 48 | Batch: 2035 | Loss: 0.14187461774637455\n",
            "Epoch: 48 | Batch: 2036 | Loss: 0.17918140027044338\n",
            "Epoch: 48 | Batch: 2037 | Loss: 0.165819044777677\n",
            "Epoch: 48 | Batch: 2038 | Loss: 0.19104133493188818\n",
            "Epoch: 48 | Batch: 2039 | Loss: 0.2306280923466385\n",
            "Epoch: 48 | Batch: 2040 | Loss: 0.139272870560621\n",
            "Epoch: 48 | Batch: 2041 | Loss: 0.19246052377249626\n",
            "Epoch: 48 | Batch: 2042 | Loss: 0.13764112777454535\n",
            "Epoch: 48 | Batch: 2043 | Loss: 0.16891608898826718\n",
            "Epoch: 48 | Batch: 2044 | Loss: 0.14527892043293303\n",
            "Epoch: 48 | Batch: 2045 | Loss: 0.14521409853298997\n",
            "Epoch: 48 | Batch: 2046 | Loss: 0.22257496145412878\n",
            "Epoch: 48 | Batch: 2047 | Loss: 0.1357145868196924\n",
            "Epoch: 48 | Batch: 2048 | Loss: 0.183752435109335\n",
            "Epoch: 48 | Batch: 2049 | Loss: 0.1178994274238451\n",
            "Epoch: 48 | Batch: 2050 | Loss: 0.16566793583604883\n",
            "Epoch: 48 | Batch: 2051 | Loss: 0.16218113406115747\n",
            "Epoch: 48 | Batch: 2052 | Loss: 0.1586013262604516\n",
            "Epoch: 48 | Batch: 2053 | Loss: 0.17288873254588996\n",
            "Epoch: 48 | Batch: 2054 | Loss: 0.13172944044893184\n",
            "Epoch: 48 | Batch: 2055 | Loss: 0.17337273604043008\n",
            "Epoch: 48 | Batch: 2056 | Loss: 0.16902327764722547\n",
            "Epoch: 48 | Batch: 2057 | Loss: 0.15328309144530833\n",
            "Epoch: 48 | Batch: 2058 | Loss: 0.15068030101346372\n",
            "Epoch: 48 | Batch: 2059 | Loss: 0.16690413645078803\n",
            "Epoch: 48 | Batch: 2060 | Loss: 0.18244079240185282\n",
            "Epoch: 48 | Batch: 2061 | Loss: 0.1906181463972885\n",
            "Epoch: 48 | Batch: 2062 | Loss: 0.17185180276225176\n",
            "Epoch: 48 | Batch: 2063 | Loss: 0.17186790746129374\n",
            "Epoch: 48 | Batch: 2064 | Loss: 0.1297511699636565\n",
            "Epoch: 48 | Batch: 2065 | Loss: 0.15611066790321823\n",
            "Epoch: 48 | Batch: 2066 | Loss: 0.14420505313503829\n",
            "Epoch: 48 | Batch: 2067 | Loss: 0.11003224955415505\n",
            "Epoch: 48 | Batch: 2068 | Loss: 0.13350520526569293\n",
            "Epoch: 48 | Batch: 2069 | Loss: 0.1444413122520191\n",
            "Epoch: 48 | Batch: 2070 | Loss: 0.15921825748048357\n",
            "Epoch: 48 | Batch: 2071 | Loss: 0.18056683699138515\n",
            "Epoch: 48 | Batch: 2072 | Loss: 0.1787063661409687\n",
            "Epoch: 48 | Batch: 2073 | Loss: 0.11779819281280923\n",
            "Epoch: 48 | Batch: 2074 | Loss: 0.1324928738469857\n",
            "Epoch: 48 | Batch: 2075 | Loss: 0.16201814574776285\n",
            "Epoch: 48 | Batch: 2076 | Loss: 0.1662079879079208\n",
            "Epoch: 48 | Batch: 2077 | Loss: 0.210421864950342\n",
            "Epoch: 48 | Batch: 2078 | Loss: 0.16152273770625797\n",
            "Epoch: 48 | Batch: 2079 | Loss: 0.14690881904675174\n",
            "Epoch: 48 | Batch: 2080 | Loss: 0.18252152864346696\n",
            "Epoch: 48 | Batch: 2081 | Loss: 0.12979499968569566\n",
            "Epoch: 48 | Batch: 2082 | Loss: 0.1131517409838691\n",
            "Epoch: 48 | Batch: 2083 | Loss: 0.15411644502454996\n",
            "Epoch: 48 | Batch: 2084 | Loss: 0.1674668091976784\n",
            "Epoch: 48 | Batch: 2085 | Loss: 0.1760966903367279\n",
            "Epoch: 48 | Batch: 2086 | Loss: 0.16476328286658243\n",
            "Epoch: 48 | Batch: 2087 | Loss: 0.15221737504279997\n",
            "Epoch: 48 | Batch: 2088 | Loss: 0.16487992695372325\n",
            "Epoch: 48 | Batch: 2089 | Loss: 0.13376851328472364\n",
            "Epoch: 48 | Batch: 2090 | Loss: 0.20964717180242606\n",
            "Epoch: 48 | Batch: 2091 | Loss: 0.15912882484474358\n",
            "Epoch: 48 | Batch: 2092 | Loss: 0.14809125376414276\n",
            "Epoch: 48 | Batch: 2093 | Loss: 0.15234380001771686\n",
            "Epoch: 48 | Batch: 2094 | Loss: 0.14032558670739242\n",
            "Epoch: 48 | Batch: 2095 | Loss: 0.21297842333531772\n",
            "Epoch: 48 | Batch: 2096 | Loss: 0.18010338087085093\n",
            "Epoch: 48 | Batch: 2097 | Loss: 0.21506060751101058\n",
            "Epoch: 48 | Batch: 2098 | Loss: 0.22832635415614488\n",
            "Epoch: 48 | Batch: 2099 | Loss: 0.1979500108222045\n",
            "Epoch: 48 | Batch: 2100 | Loss: 0.23694392860233432\n",
            "Epoch: 48 | Batch: 2101 | Loss: 0.14910574527842643\n",
            "Epoch: 48 | Batch: 2102 | Loss: 0.17719299806045014\n",
            "Epoch: 48 | Batch: 2103 | Loss: 0.20550715167324923\n",
            "Epoch: 48 | Batch: 2104 | Loss: 0.1170633258829144\n",
            "Epoch: 48 | Batch: 2105 | Loss: 0.16255144828488252\n",
            "Epoch: 48 | Batch: 2106 | Loss: 0.19388145134719137\n",
            "Epoch: 48 | Batch: 2107 | Loss: 0.14440774947814025\n",
            "Epoch: 48 | Batch: 2108 | Loss: 0.16585375782263106\n",
            "Epoch: 48 | Batch: 2109 | Loss: 0.1896068426189432\n",
            "Epoch: 48 | Batch: 2110 | Loss: 0.16660092197730275\n",
            "Epoch: 48 | Batch: 2111 | Loss: 0.18682140653972307\n",
            "Epoch: 48 | Batch: 2112 | Loss: 0.15024407149032226\n",
            "Epoch: 48 | Batch: 2113 | Loss: 0.1453701213556429\n",
            "Epoch: 48 | Batch: 2114 | Loss: 0.15250232544069967\n",
            "Epoch: 48 | Batch: 2115 | Loss: 0.15386023562498957\n",
            "Epoch: 48 | Batch: 2116 | Loss: 0.157658453267165\n",
            "Epoch: 48 | Batch: 2117 | Loss: 0.1621776813822939\n",
            "Epoch: 48 | Batch: 2118 | Loss: 0.14857807261977266\n",
            "Epoch: 48 | Batch: 2119 | Loss: 0.18122267803465367\n",
            "Epoch: 48 | Batch: 2120 | Loss: 0.1681671018420153\n",
            "Epoch: 48 | Batch: 2121 | Loss: 0.18191518627531159\n",
            "Epoch: 48 | Batch: 2122 | Loss: 0.17231074275277156\n",
            "Epoch: 48 | Batch: 2123 | Loss: 0.1569915933585545\n",
            "Epoch: 48 | Batch: 2124 | Loss: 0.19523791968782256\n",
            "Epoch: 48 | Batch: 2125 | Loss: 0.16614522369096432\n",
            "Epoch: 48 | Batch: 2126 | Loss: 0.2562374498464315\n",
            "Epoch: 48 | Batch: 2127 | Loss: 0.1707115723918001\n",
            "Epoch: 48 | Batch: 2128 | Loss: 0.16326469464841353\n",
            "Epoch: 48 | Batch: 2129 | Loss: 0.13874901986184052\n",
            "Epoch: 48 | Batch: 2130 | Loss: 0.14579202706198727\n",
            "Epoch: 48 | Batch: 2131 | Loss: 0.18862394639533994\n",
            "Epoch: 48 | Batch: 2132 | Loss: 0.1891288669328068\n",
            "Epoch: 48 | Batch: 2133 | Loss: 0.12815351399530725\n",
            "Epoch: 48 | Batch: 2134 | Loss: 0.13897316444751628\n",
            "Epoch: 48 | Batch: 2135 | Loss: 0.17833740829314046\n",
            "Epoch: 48 | Batch: 2136 | Loss: 0.16803832509648106\n",
            "Epoch: 48 | Batch: 2137 | Loss: 0.25566493745329694\n",
            "Epoch: 48 | Batch: 2138 | Loss: 0.19258744510501635\n",
            "Epoch: 48 | Batch: 2139 | Loss: 0.1629049975935529\n",
            "Epoch: 48 | Batch: 2140 | Loss: 0.12389409169512346\n",
            "Epoch: 48 | Batch: 2141 | Loss: 0.16748583497223624\n",
            "Epoch: 48 | Batch: 2142 | Loss: 0.11908801637633849\n",
            "Epoch: 48 | Batch: 2143 | Loss: 0.153446274729159\n",
            "Epoch: 48 | Batch: 2144 | Loss: 0.18255928913868164\n",
            "Epoch: 48 | Batch: 2145 | Loss: 0.15869211267978695\n",
            "Epoch: 48 | Batch: 2146 | Loss: 0.19449091341202338\n",
            "Epoch: 48 | Batch: 2147 | Loss: 0.11505970714589174\n",
            "Epoch: 48 | Batch: 2148 | Loss: 0.1600417243484736\n",
            "Epoch: 48 | Batch: 2149 | Loss: 0.15688612792166834\n",
            "Epoch: 48 | Batch: 2150 | Loss: 0.20250886970307613\n",
            "Epoch: 48 | Batch: 2151 | Loss: 0.15978413458927127\n",
            "Epoch: 48 | Batch: 2152 | Loss: 0.1623703640745223\n",
            "Epoch: 48 | Batch: 2153 | Loss: 0.14000889530546362\n",
            "Epoch: 48 | Batch: 2154 | Loss: 0.18178107191400278\n",
            "Epoch: 48 | Batch: 2155 | Loss: 0.14078543093892198\n",
            "Epoch: 48 | Batch: 2156 | Loss: 0.14276594295761813\n",
            "Epoch: 48 | Batch: 2157 | Loss: 0.19956565573430018\n",
            "Epoch: 48 | Batch: 2158 | Loss: 0.17147465857663424\n",
            "Epoch: 48 | Batch: 2159 | Loss: 0.18261402109387467\n",
            "Epoch: 48 | Batch: 2160 | Loss: 0.2096176791877162\n",
            "Epoch: 48 | Batch: 2161 | Loss: 0.2237791087354879\n",
            "Epoch: 48 | Batch: 2162 | Loss: 0.17756830527276435\n",
            "Epoch: 48 | Batch: 2163 | Loss: 0.1462203609135158\n",
            "Epoch: 48 | Batch: 2164 | Loss: 0.23312485274709835\n",
            "Epoch: 48 | Batch: 2165 | Loss: 0.16786279768301887\n",
            "Epoch: 48 | Batch: 2166 | Loss: 0.1892252255945191\n",
            "Epoch: 48 | Batch: 2167 | Loss: 0.15211600445661094\n",
            "Epoch: 48 | Batch: 2168 | Loss: 0.1543255818119186\n",
            "Epoch: 48 | Batch: 2169 | Loss: 0.186209553339025\n",
            "Epoch: 48 | Batch: 2170 | Loss: 0.13628012199680603\n",
            "Epoch: 48 | Batch: 2171 | Loss: 0.16361855168268616\n",
            "Epoch: 48 | Batch: 2172 | Loss: 0.17836811860172197\n",
            "Epoch: 48 | Batch: 2173 | Loss: 0.12676387739041095\n",
            "Epoch: 48 | Batch: 2174 | Loss: 0.1769261443085324\n",
            "Epoch: 48 | Batch: 2175 | Loss: 0.1489732196518773\n",
            "Epoch: 48 | Batch: 2176 | Loss: 0.16009335533125627\n",
            "Epoch: 48 | Batch: 2177 | Loss: 0.15277014952427698\n",
            "Epoch: 48 | Batch: 2178 | Loss: 0.16156841602740157\n",
            "Epoch: 48 | Batch: 2179 | Loss: 0.20197942142549424\n",
            "Epoch: 48 | Batch: 2180 | Loss: 0.16599593960112544\n",
            "Epoch: 48 | Batch: 2181 | Loss: 0.13545228986698782\n",
            "Epoch: 48 | Batch: 2182 | Loss: 0.1843116951687269\n",
            "Epoch: 48 | Batch: 2183 | Loss: 0.14528440595418957\n",
            "Epoch: 48 | Batch: 2184 | Loss: 0.2045244479738108\n",
            "Epoch: 48 | Batch: 2185 | Loss: 0.14165134043815167\n",
            "Epoch: 48 | Batch: 2186 | Loss: 0.2246034687730194\n",
            "Epoch: 48 | Batch: 2187 | Loss: 0.1453812950589805\n",
            "Epoch: 48 | Batch: 2188 | Loss: 0.20795694314205865\n",
            "Epoch: 48 | Batch: 2189 | Loss: 0.16719044517243564\n",
            "Epoch: 48 | Batch: 2190 | Loss: 0.19373273857098383\n",
            "Epoch: 48 | Batch: 2191 | Loss: 0.11530018603902095\n",
            "Epoch: 49 | Batch: 1 | Loss: 0.17976593022627707\n",
            "Epoch: 49 | Batch: 2 | Loss: 0.17217588794080865\n",
            "Epoch: 49 | Batch: 3 | Loss: 0.18814684544301347\n",
            "Epoch: 49 | Batch: 4 | Loss: 0.1641368026608574\n",
            "Epoch: 49 | Batch: 5 | Loss: 0.15320786928738783\n",
            "Epoch: 49 | Batch: 6 | Loss: 0.15199951874043055\n",
            "Epoch: 49 | Batch: 7 | Loss: 0.1780501972231207\n",
            "Epoch: 49 | Batch: 8 | Loss: 0.15313010918398423\n",
            "Epoch: 49 | Batch: 9 | Loss: 0.15450243493508944\n",
            "Epoch: 49 | Batch: 10 | Loss: 0.18356314260608905\n",
            "Epoch: 49 | Batch: 11 | Loss: 0.21203648934680397\n",
            "Epoch: 49 | Batch: 12 | Loss: 0.16120189071146035\n",
            "Epoch: 49 | Batch: 13 | Loss: 0.14701758057649267\n",
            "Epoch: 49 | Batch: 14 | Loss: 0.15041569462352983\n",
            "Epoch: 49 | Batch: 15 | Loss: 0.16211938885444474\n",
            "Epoch: 49 | Batch: 16 | Loss: 0.15880274743750591\n",
            "Epoch: 49 | Batch: 17 | Loss: 0.15346254373655188\n",
            "Epoch: 49 | Batch: 18 | Loss: 0.18229713703335929\n",
            "Epoch: 49 | Batch: 19 | Loss: 0.16729517749364772\n",
            "Epoch: 49 | Batch: 20 | Loss: 0.18470889196092596\n",
            "Epoch: 49 | Batch: 21 | Loss: 0.23714064641157506\n",
            "Epoch: 49 | Batch: 22 | Loss: 0.17371886773958542\n",
            "Epoch: 49 | Batch: 23 | Loss: 0.20815229858491513\n",
            "Epoch: 49 | Batch: 24 | Loss: 0.13929739009424952\n",
            "Epoch: 49 | Batch: 25 | Loss: 0.1667421042430847\n",
            "Epoch: 49 | Batch: 26 | Loss: 0.14274728402025819\n",
            "Epoch: 49 | Batch: 27 | Loss: 0.1159150304163033\n",
            "Epoch: 49 | Batch: 28 | Loss: 0.1576136964720629\n",
            "Epoch: 49 | Batch: 29 | Loss: 0.17307984880563632\n",
            "Epoch: 49 | Batch: 30 | Loss: 0.1513052478776925\n",
            "Epoch: 49 | Batch: 31 | Loss: 0.15158600436680816\n",
            "Epoch: 49 | Batch: 32 | Loss: 0.16865345403431717\n",
            "Epoch: 49 | Batch: 33 | Loss: 0.15817635704820615\n",
            "Epoch: 49 | Batch: 34 | Loss: 0.156569653043764\n",
            "Epoch: 49 | Batch: 35 | Loss: 0.1562748102304879\n",
            "Epoch: 49 | Batch: 36 | Loss: 0.20336300730704232\n",
            "Epoch: 49 | Batch: 37 | Loss: 0.13012445054522354\n",
            "Epoch: 49 | Batch: 38 | Loss: 0.14013484060890222\n",
            "Epoch: 49 | Batch: 39 | Loss: 0.18137192273086628\n",
            "Epoch: 49 | Batch: 40 | Loss: 0.2119011940784521\n",
            "Epoch: 49 | Batch: 41 | Loss: 0.16322770893020963\n",
            "Epoch: 49 | Batch: 42 | Loss: 0.24820319903493845\n",
            "Epoch: 49 | Batch: 43 | Loss: 0.18132876664278758\n",
            "Epoch: 49 | Batch: 44 | Loss: 0.16107388597936384\n",
            "Epoch: 49 | Batch: 45 | Loss: 0.15143423452602156\n",
            "Epoch: 49 | Batch: 46 | Loss: 0.23939326185329496\n",
            "Epoch: 49 | Batch: 47 | Loss: 0.14980460337766033\n",
            "Epoch: 49 | Batch: 48 | Loss: 0.16175806858508177\n",
            "Epoch: 49 | Batch: 49 | Loss: 0.1750584657295828\n",
            "Epoch: 49 | Batch: 50 | Loss: 0.16490914824272465\n",
            "Epoch: 49 | Batch: 51 | Loss: 0.13548394399992203\n",
            "Epoch: 49 | Batch: 52 | Loss: 0.18443018009427142\n",
            "Epoch: 49 | Batch: 53 | Loss: 0.17244453591287615\n",
            "Epoch: 49 | Batch: 54 | Loss: 0.15472820454249536\n",
            "Epoch: 49 | Batch: 55 | Loss: 0.16421988230676238\n",
            "Epoch: 49 | Batch: 56 | Loss: 0.1936649205166426\n",
            "Epoch: 49 | Batch: 57 | Loss: 0.20081897121350534\n",
            "Epoch: 49 | Batch: 58 | Loss: 0.15265767856705784\n",
            "Epoch: 49 | Batch: 59 | Loss: 0.18966188554692875\n",
            "Epoch: 49 | Batch: 60 | Loss: 0.16221759854900658\n",
            "Epoch: 49 | Batch: 61 | Loss: 0.16266710270990503\n",
            "Epoch: 49 | Batch: 62 | Loss: 0.16538931189408648\n",
            "Epoch: 49 | Batch: 63 | Loss: 0.14047187144329487\n",
            "Epoch: 49 | Batch: 64 | Loss: 0.15511483259065095\n",
            "Epoch: 49 | Batch: 65 | Loss: 0.16062559795912856\n",
            "Epoch: 49 | Batch: 66 | Loss: 0.14985412716712254\n",
            "Epoch: 49 | Batch: 67 | Loss: 0.18363144583393498\n",
            "Epoch: 49 | Batch: 68 | Loss: 0.23086698051783638\n",
            "Epoch: 49 | Batch: 69 | Loss: 0.195472142044282\n",
            "Epoch: 49 | Batch: 70 | Loss: 0.17626643628790084\n",
            "Epoch: 49 | Batch: 71 | Loss: 0.14726403139536837\n",
            "Epoch: 49 | Batch: 72 | Loss: 0.204628824197697\n",
            "Epoch: 49 | Batch: 73 | Loss: 0.20878777979430538\n",
            "Epoch: 49 | Batch: 74 | Loss: 0.19175542875495502\n",
            "Epoch: 49 | Batch: 75 | Loss: 0.17068435760789932\n",
            "Epoch: 49 | Batch: 76 | Loss: 0.21726332401708925\n",
            "Epoch: 49 | Batch: 77 | Loss: 0.1751356869394431\n",
            "Epoch: 49 | Batch: 78 | Loss: 0.16456677528833788\n",
            "Epoch: 49 | Batch: 79 | Loss: 0.18349100817230246\n",
            "Epoch: 49 | Batch: 80 | Loss: 0.14874662833976898\n",
            "Epoch: 49 | Batch: 81 | Loss: 0.19174802208280806\n",
            "Epoch: 49 | Batch: 82 | Loss: 0.1487261554286201\n",
            "Epoch: 49 | Batch: 83 | Loss: 0.18420359348603665\n",
            "Epoch: 49 | Batch: 84 | Loss: 0.14354759607533524\n",
            "Epoch: 49 | Batch: 85 | Loss: 0.22578295960512174\n",
            "Epoch: 49 | Batch: 86 | Loss: 0.14431651088586733\n",
            "Epoch: 49 | Batch: 87 | Loss: 0.1595581166347214\n",
            "Epoch: 49 | Batch: 88 | Loss: 0.22866549046036397\n",
            "Epoch: 49 | Batch: 89 | Loss: 0.15117761016244158\n",
            "Epoch: 49 | Batch: 90 | Loss: 0.14808175706727897\n",
            "Epoch: 49 | Batch: 91 | Loss: 0.12052606326053306\n",
            "Epoch: 49 | Batch: 92 | Loss: 0.1804682905942719\n",
            "Epoch: 49 | Batch: 93 | Loss: 0.17101393100187642\n",
            "Epoch: 49 | Batch: 94 | Loss: 0.21210031022348205\n",
            "Epoch: 49 | Batch: 95 | Loss: 0.19933984551673162\n",
            "Epoch: 49 | Batch: 96 | Loss: 0.17155834282955393\n",
            "Epoch: 49 | Batch: 97 | Loss: 0.17788195007981583\n",
            "Epoch: 49 | Batch: 98 | Loss: 0.16191643936775604\n",
            "Epoch: 49 | Batch: 99 | Loss: 0.14932211130235068\n",
            "Epoch: 49 | Batch: 100 | Loss: 0.1504305096181538\n",
            "Epoch: 49 | Batch: 101 | Loss: 0.17554277452067144\n",
            "Epoch: 49 | Batch: 102 | Loss: 0.18555654358138757\n",
            "Epoch: 49 | Batch: 103 | Loss: 0.1761770143457301\n",
            "Epoch: 49 | Batch: 104 | Loss: 0.16017669439571128\n",
            "Epoch: 49 | Batch: 105 | Loss: 0.15731785346547525\n",
            "Epoch: 49 | Batch: 106 | Loss: 0.10915948784608664\n",
            "Epoch: 49 | Batch: 107 | Loss: 0.17538219361915156\n",
            "Epoch: 49 | Batch: 108 | Loss: 0.18867764811841403\n",
            "Epoch: 49 | Batch: 109 | Loss: 0.1581651100820152\n",
            "Epoch: 49 | Batch: 110 | Loss: 0.18082730287625157\n",
            "Epoch: 49 | Batch: 111 | Loss: 0.1477515720346807\n",
            "Epoch: 49 | Batch: 112 | Loss: 0.13857922218735758\n",
            "Epoch: 49 | Batch: 113 | Loss: 0.14986725917108776\n",
            "Epoch: 49 | Batch: 114 | Loss: 0.1795898293582033\n",
            "Epoch: 49 | Batch: 115 | Loss: 0.1966710392315701\n",
            "Epoch: 49 | Batch: 116 | Loss: 0.20808414934560496\n",
            "Epoch: 49 | Batch: 117 | Loss: 0.21462795775894153\n",
            "Epoch: 49 | Batch: 118 | Loss: 0.16774859776268095\n",
            "Epoch: 49 | Batch: 119 | Loss: 0.1716109600976637\n",
            "Epoch: 49 | Batch: 120 | Loss: 0.15254373790429393\n",
            "Epoch: 49 | Batch: 121 | Loss: 0.22338163778901732\n",
            "Epoch: 49 | Batch: 122 | Loss: 0.1820147457953389\n",
            "Epoch: 49 | Batch: 123 | Loss: 0.142898681665565\n",
            "Epoch: 49 | Batch: 124 | Loss: 0.2512210768487831\n",
            "Epoch: 49 | Batch: 125 | Loss: 0.20362707311454992\n",
            "Epoch: 49 | Batch: 126 | Loss: 0.1588923213238176\n",
            "Epoch: 49 | Batch: 127 | Loss: 0.154522161580712\n",
            "Epoch: 49 | Batch: 128 | Loss: 0.144538724779072\n",
            "Epoch: 49 | Batch: 129 | Loss: 0.1482058489263359\n",
            "Epoch: 49 | Batch: 130 | Loss: 0.21824949632142784\n",
            "Epoch: 49 | Batch: 131 | Loss: 0.19793778331124867\n",
            "Epoch: 49 | Batch: 132 | Loss: 0.15786175246960993\n",
            "Epoch: 49 | Batch: 133 | Loss: 0.1870080010541534\n",
            "Epoch: 49 | Batch: 134 | Loss: 0.21108879554773338\n",
            "Epoch: 49 | Batch: 135 | Loss: 0.19204283961228524\n",
            "Epoch: 49 | Batch: 136 | Loss: 0.17545927063084532\n",
            "Epoch: 49 | Batch: 137 | Loss: 0.15891236757114902\n",
            "Epoch: 49 | Batch: 138 | Loss: 0.15979817802814594\n",
            "Epoch: 49 | Batch: 139 | Loss: 0.2509215727005592\n",
            "Epoch: 49 | Batch: 140 | Loss: 0.16649917943066225\n",
            "Epoch: 49 | Batch: 141 | Loss: 0.15696548791488385\n",
            "Epoch: 49 | Batch: 142 | Loss: 0.1553555390093945\n",
            "Epoch: 49 | Batch: 143 | Loss: 0.1336590822501208\n",
            "Epoch: 49 | Batch: 144 | Loss: 0.1461944488910272\n",
            "Epoch: 49 | Batch: 145 | Loss: 0.19187545932612826\n",
            "Epoch: 49 | Batch: 146 | Loss: 0.22763892626900017\n",
            "Epoch: 49 | Batch: 147 | Loss: 0.15097988343949753\n",
            "Epoch: 49 | Batch: 148 | Loss: 0.15709558017093536\n",
            "Epoch: 49 | Batch: 149 | Loss: 0.1799734277242569\n",
            "Epoch: 49 | Batch: 150 | Loss: 0.20663415905358912\n",
            "Epoch: 49 | Batch: 151 | Loss: 0.13325325388113676\n",
            "Epoch: 49 | Batch: 152 | Loss: 0.16948659604612096\n",
            "Epoch: 49 | Batch: 153 | Loss: 0.16503365035001272\n",
            "Epoch: 49 | Batch: 154 | Loss: 0.16459758646352987\n",
            "Epoch: 49 | Batch: 155 | Loss: 0.1546980226940591\n",
            "Epoch: 49 | Batch: 156 | Loss: 0.18828486164189187\n",
            "Epoch: 49 | Batch: 157 | Loss: 0.1556332451688252\n",
            "Epoch: 49 | Batch: 158 | Loss: 0.17343535809467417\n",
            "Epoch: 49 | Batch: 159 | Loss: 0.23163103011478145\n",
            "Epoch: 49 | Batch: 160 | Loss: 0.19905853078578578\n",
            "Epoch: 49 | Batch: 161 | Loss: 0.16072666189323975\n",
            "Epoch: 49 | Batch: 162 | Loss: 0.17541252368712162\n",
            "Epoch: 49 | Batch: 163 | Loss: 0.1198842184958167\n",
            "Epoch: 49 | Batch: 164 | Loss: 0.1491170011069627\n",
            "Epoch: 49 | Batch: 165 | Loss: 0.17390694491126335\n",
            "Epoch: 49 | Batch: 166 | Loss: 0.10403933550120135\n",
            "Epoch: 49 | Batch: 167 | Loss: 0.11364065922271427\n",
            "Epoch: 49 | Batch: 168 | Loss: 0.12566013195905287\n",
            "Epoch: 49 | Batch: 169 | Loss: 0.12185225231323887\n",
            "Epoch: 49 | Batch: 170 | Loss: 0.18041511670345262\n",
            "Epoch: 49 | Batch: 171 | Loss: 0.14560284956064562\n",
            "Epoch: 49 | Batch: 172 | Loss: 0.17359852366240677\n",
            "Epoch: 49 | Batch: 173 | Loss: 0.16968579402598064\n",
            "Epoch: 49 | Batch: 174 | Loss: 0.1442285227093525\n",
            "Epoch: 49 | Batch: 175 | Loss: 0.14821942755740183\n",
            "Epoch: 49 | Batch: 176 | Loss: 0.17485109235363505\n",
            "Epoch: 49 | Batch: 177 | Loss: 0.15634611563973838\n",
            "Epoch: 49 | Batch: 178 | Loss: 0.19767082346268344\n",
            "Epoch: 49 | Batch: 179 | Loss: 0.1997330300576156\n",
            "Epoch: 49 | Batch: 180 | Loss: 0.16903872724814206\n",
            "Epoch: 49 | Batch: 181 | Loss: 0.1340029226545446\n",
            "Epoch: 49 | Batch: 182 | Loss: 0.1493140161829115\n",
            "Epoch: 49 | Batch: 183 | Loss: 0.14618157361283943\n",
            "Epoch: 49 | Batch: 184 | Loss: 0.12131940225727202\n",
            "Epoch: 49 | Batch: 185 | Loss: 0.16783741427825485\n",
            "Epoch: 49 | Batch: 186 | Loss: 0.15347313674725624\n",
            "Epoch: 49 | Batch: 187 | Loss: 0.1675608606163982\n",
            "Epoch: 49 | Batch: 188 | Loss: 0.19934452924165258\n",
            "Epoch: 49 | Batch: 189 | Loss: 0.19354106284461475\n",
            "Epoch: 49 | Batch: 190 | Loss: 0.13150522940663778\n",
            "Epoch: 49 | Batch: 191 | Loss: 0.17737797071893976\n",
            "Epoch: 49 | Batch: 192 | Loss: 0.16370337215150485\n",
            "Epoch: 49 | Batch: 193 | Loss: 0.208277112309832\n",
            "Epoch: 49 | Batch: 194 | Loss: 0.15581966114517048\n",
            "Epoch: 49 | Batch: 195 | Loss: 0.176792037199777\n",
            "Epoch: 49 | Batch: 196 | Loss: 0.13461246700138157\n",
            "Epoch: 49 | Batch: 197 | Loss: 0.13707251738267326\n",
            "Epoch: 49 | Batch: 198 | Loss: 0.2088718662713407\n",
            "Epoch: 49 | Batch: 199 | Loss: 0.13755613942126466\n",
            "Epoch: 49 | Batch: 200 | Loss: 0.18867555335210615\n",
            "Epoch: 49 | Batch: 201 | Loss: 0.19713545009738287\n",
            "Epoch: 49 | Batch: 202 | Loss: 0.15549583663669486\n",
            "Epoch: 49 | Batch: 203 | Loss: 0.1378903991643927\n",
            "Epoch: 49 | Batch: 204 | Loss: 0.17474469336069318\n",
            "Epoch: 49 | Batch: 205 | Loss: 0.25097463741564646\n",
            "Epoch: 49 | Batch: 206 | Loss: 0.17995595858166769\n",
            "Epoch: 49 | Batch: 207 | Loss: 0.1443217882993673\n",
            "Epoch: 49 | Batch: 208 | Loss: 0.14588304578173567\n",
            "Epoch: 49 | Batch: 209 | Loss: 0.14755709970516298\n",
            "Epoch: 49 | Batch: 210 | Loss: 0.1692889287972412\n",
            "Epoch: 49 | Batch: 211 | Loss: 0.12679343558243217\n",
            "Epoch: 49 | Batch: 212 | Loss: 0.18525070051876857\n",
            "Epoch: 49 | Batch: 213 | Loss: 0.16933812379349603\n",
            "Epoch: 49 | Batch: 214 | Loss: 0.2125017985496415\n",
            "Epoch: 49 | Batch: 215 | Loss: 0.11561210833251548\n",
            "Epoch: 49 | Batch: 216 | Loss: 0.1304983207093982\n",
            "Epoch: 49 | Batch: 217 | Loss: 0.19601481514779653\n",
            "Epoch: 49 | Batch: 218 | Loss: 0.12540709967872996\n",
            "Epoch: 49 | Batch: 219 | Loss: 0.15156849044234558\n",
            "Epoch: 49 | Batch: 220 | Loss: 0.1259157217969788\n",
            "Epoch: 49 | Batch: 221 | Loss: 0.11564737990933446\n",
            "Epoch: 49 | Batch: 222 | Loss: 0.1971462669971852\n",
            "Epoch: 49 | Batch: 223 | Loss: 0.16302515367387152\n",
            "Epoch: 49 | Batch: 224 | Loss: 0.19643143213636516\n",
            "Epoch: 49 | Batch: 225 | Loss: 0.14921769455282577\n",
            "Epoch: 49 | Batch: 226 | Loss: 0.1555735939538179\n",
            "Epoch: 49 | Batch: 227 | Loss: 0.17892188483139096\n",
            "Epoch: 49 | Batch: 228 | Loss: 0.19081719770636146\n",
            "Epoch: 49 | Batch: 229 | Loss: 0.15233414121532543\n",
            "Epoch: 49 | Batch: 230 | Loss: 0.14068726322605749\n",
            "Epoch: 49 | Batch: 231 | Loss: 0.1534481670443149\n",
            "Epoch: 49 | Batch: 232 | Loss: 0.17465765707849448\n",
            "Epoch: 49 | Batch: 233 | Loss: 0.22918732571709968\n",
            "Epoch: 49 | Batch: 234 | Loss: 0.16153919595801697\n",
            "Epoch: 49 | Batch: 235 | Loss: 0.14092613598660328\n",
            "Epoch: 49 | Batch: 236 | Loss: 0.17349821207743735\n",
            "Epoch: 49 | Batch: 237 | Loss: 0.1695473763716095\n",
            "Epoch: 49 | Batch: 238 | Loss: 0.16376013432493577\n",
            "Epoch: 49 | Batch: 239 | Loss: 0.14711517950785225\n",
            "Epoch: 49 | Batch: 240 | Loss: 0.15702320117106836\n",
            "Epoch: 49 | Batch: 241 | Loss: 0.15494741448236674\n",
            "Epoch: 49 | Batch: 242 | Loss: 0.171458463879059\n",
            "Epoch: 49 | Batch: 243 | Loss: 0.21757394775866187\n",
            "Epoch: 49 | Batch: 244 | Loss: 0.16714339226580058\n",
            "Epoch: 49 | Batch: 245 | Loss: 0.13912865156758608\n",
            "Epoch: 49 | Batch: 246 | Loss: 0.19377607247410025\n",
            "Epoch: 49 | Batch: 247 | Loss: 0.13722892428319883\n",
            "Epoch: 49 | Batch: 248 | Loss: 0.19048585980665306\n",
            "Epoch: 49 | Batch: 249 | Loss: 0.18105018014824492\n",
            "Epoch: 49 | Batch: 250 | Loss: 0.18096721374686914\n",
            "Epoch: 49 | Batch: 251 | Loss: 0.17058304285587253\n",
            "Epoch: 49 | Batch: 252 | Loss: 0.22074209160392666\n",
            "Epoch: 49 | Batch: 253 | Loss: 0.17174909602925573\n",
            "Epoch: 49 | Batch: 254 | Loss: 0.18648948277629945\n",
            "Epoch: 49 | Batch: 255 | Loss: 0.1859553405716445\n",
            "Epoch: 49 | Batch: 256 | Loss: 0.13767679613297895\n",
            "Epoch: 49 | Batch: 257 | Loss: 0.12963339915609634\n",
            "Epoch: 49 | Batch: 258 | Loss: 0.14962459510177378\n",
            "Epoch: 49 | Batch: 259 | Loss: 0.1395758248154361\n",
            "Epoch: 49 | Batch: 260 | Loss: 0.15444002244651814\n",
            "Epoch: 49 | Batch: 261 | Loss: 0.17872825029221945\n",
            "Epoch: 49 | Batch: 262 | Loss: 0.13251046997246388\n",
            "Epoch: 49 | Batch: 263 | Loss: 0.1512868656237565\n",
            "Epoch: 49 | Batch: 264 | Loss: 0.1843138746019043\n",
            "Epoch: 49 | Batch: 265 | Loss: 0.13857867317981146\n",
            "Epoch: 49 | Batch: 266 | Loss: 0.1631762524131266\n",
            "Epoch: 49 | Batch: 267 | Loss: 0.1929632482602731\n",
            "Epoch: 49 | Batch: 268 | Loss: 0.1405911188542289\n",
            "Epoch: 49 | Batch: 269 | Loss: 0.1531045066455953\n",
            "Epoch: 49 | Batch: 270 | Loss: 0.1846597773647852\n",
            "Epoch: 49 | Batch: 271 | Loss: 0.1431548987937045\n",
            "Epoch: 49 | Batch: 272 | Loss: 0.1462984232470273\n",
            "Epoch: 49 | Batch: 273 | Loss: 0.14774749927430572\n",
            "Epoch: 49 | Batch: 274 | Loss: 0.18250527002339106\n",
            "Epoch: 49 | Batch: 275 | Loss: 0.159688620902445\n",
            "Epoch: 49 | Batch: 276 | Loss: 0.2005322004817029\n",
            "Epoch: 49 | Batch: 277 | Loss: 0.15286655763623166\n",
            "Epoch: 49 | Batch: 278 | Loss: 0.19185135048033158\n",
            "Epoch: 49 | Batch: 279 | Loss: 0.13787843797477645\n",
            "Epoch: 49 | Batch: 280 | Loss: 0.1428408758022359\n",
            "Epoch: 49 | Batch: 281 | Loss: 0.15544280791401385\n",
            "Epoch: 49 | Batch: 282 | Loss: 0.16833746030129776\n",
            "Epoch: 49 | Batch: 283 | Loss: 0.14767266816899047\n",
            "Epoch: 49 | Batch: 284 | Loss: 0.22212113786227133\n",
            "Epoch: 49 | Batch: 285 | Loss: 0.1810512005028417\n",
            "Epoch: 49 | Batch: 286 | Loss: 0.1374602737311231\n",
            "Epoch: 49 | Batch: 287 | Loss: 0.1393838835702562\n",
            "Epoch: 49 | Batch: 288 | Loss: 0.15647468206090376\n",
            "Epoch: 49 | Batch: 289 | Loss: 0.14838837334750615\n",
            "Epoch: 49 | Batch: 290 | Loss: 0.1767611352122765\n",
            "Epoch: 49 | Batch: 291 | Loss: 0.19536283517457964\n",
            "Epoch: 49 | Batch: 292 | Loss: 0.2190331366290615\n",
            "Epoch: 49 | Batch: 293 | Loss: 0.15164902135882374\n",
            "Epoch: 49 | Batch: 294 | Loss: 0.1836477213657454\n",
            "Epoch: 49 | Batch: 295 | Loss: 0.20338036774168258\n",
            "Epoch: 49 | Batch: 296 | Loss: 0.16645541374282213\n",
            "Epoch: 49 | Batch: 297 | Loss: 0.15534409063293372\n",
            "Epoch: 49 | Batch: 298 | Loss: 0.19621592825752165\n",
            "Epoch: 49 | Batch: 299 | Loss: 0.1276731143986284\n",
            "Epoch: 49 | Batch: 300 | Loss: 0.17802293496373886\n",
            "Epoch: 49 | Batch: 301 | Loss: 0.13826460326837597\n",
            "Epoch: 49 | Batch: 302 | Loss: 0.15169834073261798\n",
            "Epoch: 49 | Batch: 303 | Loss: 0.16964704230632616\n",
            "Epoch: 49 | Batch: 304 | Loss: 0.1258115714957114\n",
            "Epoch: 49 | Batch: 305 | Loss: 0.16997685657802847\n",
            "Epoch: 49 | Batch: 306 | Loss: 0.14051848168619846\n",
            "Epoch: 49 | Batch: 307 | Loss: 0.14789516044812226\n",
            "Epoch: 49 | Batch: 308 | Loss: 0.180888645250764\n",
            "Epoch: 49 | Batch: 309 | Loss: 0.18986448256172464\n",
            "Epoch: 49 | Batch: 310 | Loss: 0.21515168810863033\n",
            "Epoch: 49 | Batch: 311 | Loss: 0.16482685147583198\n",
            "Epoch: 49 | Batch: 312 | Loss: 0.24229314853827855\n",
            "Epoch: 49 | Batch: 313 | Loss: 0.13924994211651506\n",
            "Epoch: 49 | Batch: 314 | Loss: 0.15543481526869804\n",
            "Epoch: 49 | Batch: 315 | Loss: 0.12782758172031114\n",
            "Epoch: 49 | Batch: 316 | Loss: 0.1980012558742776\n",
            "Epoch: 49 | Batch: 317 | Loss: 0.18137244560467805\n",
            "Epoch: 49 | Batch: 318 | Loss: 0.11601985647934343\n",
            "Epoch: 49 | Batch: 319 | Loss: 0.1512206574898851\n",
            "Epoch: 49 | Batch: 320 | Loss: 0.1572226427135677\n",
            "Epoch: 49 | Batch: 321 | Loss: 0.12245960662572188\n",
            "Epoch: 49 | Batch: 322 | Loss: 0.1711388451879427\n",
            "Epoch: 49 | Batch: 323 | Loss: 0.15674024310922202\n",
            "Epoch: 49 | Batch: 324 | Loss: 0.1347623712163869\n",
            "Epoch: 49 | Batch: 325 | Loss: 0.19645975772944319\n",
            "Epoch: 49 | Batch: 326 | Loss: 0.17365159869198482\n",
            "Epoch: 49 | Batch: 327 | Loss: 0.14240296669530614\n",
            "Epoch: 49 | Batch: 328 | Loss: 0.1468392176593226\n",
            "Epoch: 49 | Batch: 329 | Loss: 0.17509842052296418\n",
            "Epoch: 49 | Batch: 330 | Loss: 0.18085059494535927\n",
            "Epoch: 49 | Batch: 331 | Loss: 0.15146787616162888\n",
            "Epoch: 49 | Batch: 332 | Loss: 0.20132109746156907\n",
            "Epoch: 49 | Batch: 333 | Loss: 0.17545643900948335\n",
            "Epoch: 49 | Batch: 334 | Loss: 0.15683443350924076\n",
            "Epoch: 49 | Batch: 335 | Loss: 0.16146338569375548\n",
            "Epoch: 49 | Batch: 336 | Loss: 0.15635374980343714\n",
            "Epoch: 49 | Batch: 337 | Loss: 0.14451035083949948\n",
            "Epoch: 49 | Batch: 338 | Loss: 0.16590655740426113\n",
            "Epoch: 49 | Batch: 339 | Loss: 0.14779542214369593\n",
            "Epoch: 49 | Batch: 340 | Loss: 0.1466032437075984\n",
            "Epoch: 49 | Batch: 341 | Loss: 0.19549337782505\n",
            "Epoch: 49 | Batch: 342 | Loss: 0.19839675812591398\n",
            "Epoch: 49 | Batch: 343 | Loss: 0.17947714375616736\n",
            "Epoch: 49 | Batch: 344 | Loss: 0.16842207181991964\n",
            "Epoch: 49 | Batch: 345 | Loss: 0.14475440342666815\n",
            "Epoch: 49 | Batch: 346 | Loss: 0.15283973895273859\n",
            "Epoch: 49 | Batch: 347 | Loss: 0.14678088877661238\n",
            "Epoch: 49 | Batch: 348 | Loss: 0.1596651853335205\n",
            "Epoch: 49 | Batch: 349 | Loss: 0.22010744126528325\n",
            "Epoch: 49 | Batch: 350 | Loss: 0.1473730237731423\n",
            "Epoch: 49 | Batch: 351 | Loss: 0.16039551451003833\n",
            "Epoch: 49 | Batch: 352 | Loss: 0.17776265478042158\n",
            "Epoch: 49 | Batch: 353 | Loss: 0.1690516935748994\n",
            "Epoch: 49 | Batch: 354 | Loss: 0.18107467683432535\n",
            "Epoch: 49 | Batch: 355 | Loss: 0.16231546493371662\n",
            "Epoch: 49 | Batch: 356 | Loss: 0.13867993274089577\n",
            "Epoch: 49 | Batch: 357 | Loss: 0.18351793484779821\n",
            "Epoch: 49 | Batch: 358 | Loss: 0.19450933264245418\n",
            "Epoch: 49 | Batch: 359 | Loss: 0.2327957502597612\n",
            "Epoch: 49 | Batch: 360 | Loss: 0.16672119548414743\n",
            "Epoch: 49 | Batch: 361 | Loss: 0.20879689388067071\n",
            "Epoch: 49 | Batch: 362 | Loss: 0.20246455245389983\n",
            "Epoch: 49 | Batch: 363 | Loss: 0.16093144181887675\n",
            "Epoch: 49 | Batch: 364 | Loss: 0.21136035113394128\n",
            "Epoch: 49 | Batch: 365 | Loss: 0.2295729849873733\n",
            "Epoch: 49 | Batch: 366 | Loss: 0.20536301771508972\n",
            "Epoch: 49 | Batch: 367 | Loss: 0.1537644953525486\n",
            "Epoch: 49 | Batch: 368 | Loss: 0.151293702885926\n",
            "Epoch: 49 | Batch: 369 | Loss: 0.1542527717126774\n",
            "Epoch: 49 | Batch: 370 | Loss: 0.20170067023464217\n",
            "Epoch: 49 | Batch: 371 | Loss: 0.13949601359892083\n",
            "Epoch: 49 | Batch: 372 | Loss: 0.20277950877535092\n",
            "Epoch: 49 | Batch: 373 | Loss: 0.16078217214561394\n",
            "Epoch: 49 | Batch: 374 | Loss: 0.15963385017177723\n",
            "Epoch: 49 | Batch: 375 | Loss: 0.16046598783420318\n",
            "Epoch: 49 | Batch: 376 | Loss: 0.1607680882835333\n",
            "Epoch: 49 | Batch: 377 | Loss: 0.153702428089719\n",
            "Epoch: 49 | Batch: 378 | Loss: 0.12802202616956715\n",
            "Epoch: 49 | Batch: 379 | Loss: 0.11939096185095732\n",
            "Epoch: 49 | Batch: 380 | Loss: 0.18016255293663302\n",
            "Epoch: 49 | Batch: 381 | Loss: 0.18328412545365413\n",
            "Epoch: 49 | Batch: 382 | Loss: 0.15406822316293062\n",
            "Epoch: 49 | Batch: 383 | Loss: 0.17657502867048205\n",
            "Epoch: 49 | Batch: 384 | Loss: 0.1656144631267501\n",
            "Epoch: 49 | Batch: 385 | Loss: 0.13831922220544246\n",
            "Epoch: 49 | Batch: 386 | Loss: 0.15523213564847763\n",
            "Epoch: 49 | Batch: 387 | Loss: 0.18427893315750335\n",
            "Epoch: 49 | Batch: 388 | Loss: 0.152005520576468\n",
            "Epoch: 49 | Batch: 389 | Loss: 0.1894642884005594\n",
            "Epoch: 49 | Batch: 390 | Loss: 0.16760013684164946\n",
            "Epoch: 49 | Batch: 391 | Loss: 0.14297931329639985\n",
            "Epoch: 49 | Batch: 392 | Loss: 0.18509901537827733\n",
            "Epoch: 49 | Batch: 393 | Loss: 0.13791782699369254\n",
            "Epoch: 49 | Batch: 394 | Loss: 0.1481205151687692\n",
            "Epoch: 49 | Batch: 395 | Loss: 0.15262046269026344\n",
            "Epoch: 49 | Batch: 396 | Loss: 0.20736280379807706\n",
            "Epoch: 49 | Batch: 397 | Loss: 0.11785807293114847\n",
            "Epoch: 49 | Batch: 398 | Loss: 0.17209338262413368\n",
            "Epoch: 49 | Batch: 399 | Loss: 0.14417049866727125\n",
            "Epoch: 49 | Batch: 400 | Loss: 0.16366627357834104\n",
            "Epoch: 49 | Batch: 401 | Loss: 0.14579534217811255\n",
            "Epoch: 49 | Batch: 402 | Loss: 0.17449631827997208\n",
            "Epoch: 49 | Batch: 403 | Loss: 0.12267156826234316\n",
            "Epoch: 49 | Batch: 404 | Loss: 0.15357819201678646\n",
            "Epoch: 49 | Batch: 405 | Loss: 0.20865930246622838\n",
            "Epoch: 49 | Batch: 406 | Loss: 0.2173926561287558\n",
            "Epoch: 49 | Batch: 407 | Loss: 0.17826085639253267\n",
            "Epoch: 49 | Batch: 408 | Loss: 0.13911130414245812\n",
            "Epoch: 49 | Batch: 409 | Loss: 0.19465865320205306\n",
            "Epoch: 49 | Batch: 410 | Loss: 0.18925073880633447\n",
            "Epoch: 49 | Batch: 411 | Loss: 0.22863644962829882\n",
            "Epoch: 49 | Batch: 412 | Loss: 0.15874950650343003\n",
            "Epoch: 49 | Batch: 413 | Loss: 0.14477978572090355\n",
            "Epoch: 49 | Batch: 414 | Loss: 0.14379362813862454\n",
            "Epoch: 49 | Batch: 415 | Loss: 0.18046468695231732\n",
            "Epoch: 49 | Batch: 416 | Loss: 0.2017631751907924\n",
            "Epoch: 49 | Batch: 417 | Loss: 0.1552208220527677\n",
            "Epoch: 49 | Batch: 418 | Loss: 0.15462915209778838\n",
            "Epoch: 49 | Batch: 419 | Loss: 0.16492243902134723\n",
            "Epoch: 49 | Batch: 420 | Loss: 0.16301565591852887\n",
            "Epoch: 49 | Batch: 421 | Loss: 0.17476348309645393\n",
            "Epoch: 49 | Batch: 422 | Loss: 0.1944301484866042\n",
            "Epoch: 49 | Batch: 423 | Loss: 0.17027416730129397\n",
            "Epoch: 49 | Batch: 424 | Loss: 0.19932696800189623\n",
            "Epoch: 49 | Batch: 425 | Loss: 0.17074528976486003\n",
            "Epoch: 49 | Batch: 426 | Loss: 0.1684144557344\n",
            "Epoch: 49 | Batch: 427 | Loss: 0.17963074575429147\n",
            "Epoch: 49 | Batch: 428 | Loss: 0.1769872888257504\n",
            "Epoch: 49 | Batch: 429 | Loss: 0.13529048890780684\n",
            "Epoch: 49 | Batch: 430 | Loss: 0.22123235335679722\n",
            "Epoch: 49 | Batch: 431 | Loss: 0.1445519348187831\n",
            "Epoch: 49 | Batch: 432 | Loss: 0.18802005918999348\n",
            "Epoch: 49 | Batch: 433 | Loss: 0.14264609456131266\n",
            "Epoch: 49 | Batch: 434 | Loss: 0.1372251435614739\n",
            "Epoch: 49 | Batch: 435 | Loss: 0.14759282813855626\n",
            "Epoch: 49 | Batch: 436 | Loss: 0.21024339492800284\n",
            "Epoch: 49 | Batch: 437 | Loss: 0.19859327432161608\n",
            "Epoch: 49 | Batch: 438 | Loss: 0.1699297279588274\n",
            "Epoch: 49 | Batch: 439 | Loss: 0.1578444534413106\n",
            "Epoch: 49 | Batch: 440 | Loss: 0.18768841022378105\n",
            "Epoch: 49 | Batch: 441 | Loss: 0.14754294945816238\n",
            "Epoch: 49 | Batch: 442 | Loss: 0.16072625853990047\n",
            "Epoch: 49 | Batch: 443 | Loss: 0.16886532184489803\n",
            "Epoch: 49 | Batch: 444 | Loss: 0.15358090286093354\n",
            "Epoch: 49 | Batch: 445 | Loss: 0.14719452952130344\n",
            "Epoch: 49 | Batch: 446 | Loss: 0.2195125866355494\n",
            "Epoch: 49 | Batch: 447 | Loss: 0.1605799303660366\n",
            "Epoch: 49 | Batch: 448 | Loss: 0.17420551280749566\n",
            "Epoch: 49 | Batch: 449 | Loss: 0.1574405625788097\n",
            "Epoch: 49 | Batch: 450 | Loss: 0.19660003020111516\n",
            "Epoch: 49 | Batch: 451 | Loss: 0.1445413295836916\n",
            "Epoch: 49 | Batch: 452 | Loss: 0.1425751698109858\n",
            "Epoch: 49 | Batch: 453 | Loss: 0.16672538516634014\n",
            "Epoch: 49 | Batch: 454 | Loss: 0.188032919653091\n",
            "Epoch: 49 | Batch: 455 | Loss: 0.1774474997086806\n",
            "Epoch: 49 | Batch: 456 | Loss: 0.18124022561234815\n",
            "Epoch: 49 | Batch: 457 | Loss: 0.14257979405514257\n",
            "Epoch: 49 | Batch: 458 | Loss: 0.16366248049667806\n",
            "Epoch: 49 | Batch: 459 | Loss: 0.17480447123721526\n",
            "Epoch: 49 | Batch: 460 | Loss: 0.1367603384174421\n",
            "Epoch: 49 | Batch: 461 | Loss: 0.13012732758750872\n",
            "Epoch: 49 | Batch: 462 | Loss: 0.1781665422140417\n",
            "Epoch: 49 | Batch: 463 | Loss: 0.1407214233015346\n",
            "Epoch: 49 | Batch: 464 | Loss: 0.145748313809091\n",
            "Epoch: 49 | Batch: 465 | Loss: 0.14720083621414556\n",
            "Epoch: 49 | Batch: 466 | Loss: 0.17466873815313003\n",
            "Epoch: 49 | Batch: 467 | Loss: 0.14686285365462673\n",
            "Epoch: 49 | Batch: 468 | Loss: 0.14276669020209642\n",
            "Epoch: 49 | Batch: 469 | Loss: 0.1811516376986853\n",
            "Epoch: 49 | Batch: 470 | Loss: 0.16565044262603576\n",
            "Epoch: 49 | Batch: 471 | Loss: 0.16560973433554538\n",
            "Epoch: 49 | Batch: 472 | Loss: 0.21353356974764462\n",
            "Epoch: 49 | Batch: 473 | Loss: 0.1955263345297273\n",
            "Epoch: 49 | Batch: 474 | Loss: 0.15957298994711125\n",
            "Epoch: 49 | Batch: 475 | Loss: 0.14191764771471088\n",
            "Epoch: 49 | Batch: 476 | Loss: 0.14485022518760238\n",
            "Epoch: 49 | Batch: 477 | Loss: 0.14341266956115936\n",
            "Epoch: 49 | Batch: 478 | Loss: 0.16694567423998719\n",
            "Epoch: 49 | Batch: 479 | Loss: 0.20562880611797998\n",
            "Epoch: 49 | Batch: 480 | Loss: 0.1145053118096666\n",
            "Epoch: 49 | Batch: 481 | Loss: 0.16445337676607436\n",
            "Epoch: 49 | Batch: 482 | Loss: 0.12571487230445563\n",
            "Epoch: 49 | Batch: 483 | Loss: 0.1816955718286236\n",
            "Epoch: 49 | Batch: 484 | Loss: 0.12051444070416224\n",
            "Epoch: 49 | Batch: 485 | Loss: 0.15023871425908789\n",
            "Epoch: 49 | Batch: 486 | Loss: 0.16348687852017463\n",
            "Epoch: 49 | Batch: 487 | Loss: 0.19029013941258233\n",
            "Epoch: 49 | Batch: 488 | Loss: 0.13542215353161882\n",
            "Epoch: 49 | Batch: 489 | Loss: 0.17531058894106327\n",
            "Epoch: 49 | Batch: 490 | Loss: 0.17357958395425416\n",
            "Epoch: 49 | Batch: 491 | Loss: 0.165395728753342\n",
            "Epoch: 49 | Batch: 492 | Loss: 0.1605829641304426\n",
            "Epoch: 49 | Batch: 493 | Loss: 0.20872428919313202\n",
            "Epoch: 49 | Batch: 494 | Loss: 0.17984473892991154\n",
            "Epoch: 49 | Batch: 495 | Loss: 0.17140109410947962\n",
            "Epoch: 49 | Batch: 496 | Loss: 0.15405012741802748\n",
            "Epoch: 49 | Batch: 497 | Loss: 0.15135975560669476\n",
            "Epoch: 49 | Batch: 498 | Loss: 0.11612622773260978\n",
            "Epoch: 49 | Batch: 499 | Loss: 0.17371204408501584\n",
            "Epoch: 49 | Batch: 500 | Loss: 0.19426953912263334\n",
            "Epoch: 49 | Batch: 501 | Loss: 0.16074468745149417\n",
            "Epoch: 49 | Batch: 502 | Loss: 0.1282039041654741\n",
            "Epoch: 49 | Batch: 503 | Loss: 0.19730746191727544\n",
            "Epoch: 49 | Batch: 504 | Loss: 0.19434930475540027\n",
            "Epoch: 49 | Batch: 505 | Loss: 0.14033018046366627\n",
            "Epoch: 49 | Batch: 506 | Loss: 0.15030760809370416\n",
            "Epoch: 49 | Batch: 507 | Loss: 0.16839056883912268\n",
            "Epoch: 49 | Batch: 508 | Loss: 0.1803386601116097\n",
            "Epoch: 49 | Batch: 509 | Loss: 0.14997810588100474\n",
            "Epoch: 49 | Batch: 510 | Loss: 0.17738524581240023\n",
            "Epoch: 49 | Batch: 511 | Loss: 0.17336011575111646\n",
            "Epoch: 49 | Batch: 512 | Loss: 0.18770466122510654\n",
            "Epoch: 49 | Batch: 513 | Loss: 0.16864719405739884\n",
            "Epoch: 49 | Batch: 514 | Loss: 0.1481113308726985\n",
            "Epoch: 49 | Batch: 515 | Loss: 0.15308117941638055\n",
            "Epoch: 49 | Batch: 516 | Loss: 0.1679828066535049\n",
            "Epoch: 49 | Batch: 517 | Loss: 0.1765253266751625\n",
            "Epoch: 49 | Batch: 518 | Loss: 0.15535535003659634\n",
            "Epoch: 49 | Batch: 519 | Loss: 0.19649741407849408\n",
            "Epoch: 49 | Batch: 520 | Loss: 0.19401656320201724\n",
            "Epoch: 49 | Batch: 521 | Loss: 0.1704664262982219\n",
            "Epoch: 49 | Batch: 522 | Loss: 0.16781095240411684\n",
            "Epoch: 49 | Batch: 523 | Loss: 0.12756901708479118\n",
            "Epoch: 49 | Batch: 524 | Loss: 0.20004357897294853\n",
            "Epoch: 49 | Batch: 525 | Loss: 0.15325877765538834\n",
            "Epoch: 49 | Batch: 526 | Loss: 0.18431938119209484\n",
            "Epoch: 49 | Batch: 527 | Loss: 0.13228889005043934\n",
            "Epoch: 49 | Batch: 528 | Loss: 0.14621533006476398\n",
            "Epoch: 49 | Batch: 529 | Loss: 0.19465171563297287\n",
            "Epoch: 49 | Batch: 530 | Loss: 0.151863220943251\n",
            "Epoch: 49 | Batch: 531 | Loss: 0.16727730973529337\n",
            "Epoch: 49 | Batch: 532 | Loss: 0.18835815855025395\n",
            "Epoch: 49 | Batch: 533 | Loss: 0.14597247205143213\n",
            "Epoch: 49 | Batch: 534 | Loss: 0.15587468412337704\n",
            "Epoch: 49 | Batch: 535 | Loss: 0.1596799658290441\n",
            "Epoch: 49 | Batch: 536 | Loss: 0.16860420131878334\n",
            "Epoch: 49 | Batch: 537 | Loss: 0.15317324850222247\n",
            "Epoch: 49 | Batch: 538 | Loss: 0.1499803852975043\n",
            "Epoch: 49 | Batch: 539 | Loss: 0.24015308088248943\n",
            "Epoch: 49 | Batch: 540 | Loss: 0.24359677300936622\n",
            "Epoch: 49 | Batch: 541 | Loss: 0.19564432347086216\n",
            "Epoch: 49 | Batch: 542 | Loss: 0.2489202099458582\n",
            "Epoch: 49 | Batch: 543 | Loss: 0.1488493612094813\n",
            "Epoch: 49 | Batch: 544 | Loss: 0.23129965973315286\n",
            "Epoch: 49 | Batch: 545 | Loss: 0.19002754856775395\n",
            "Epoch: 49 | Batch: 546 | Loss: 0.16121558037865213\n",
            "Epoch: 49 | Batch: 547 | Loss: 0.18180195589123374\n",
            "Epoch: 49 | Batch: 548 | Loss: 0.1712203869285956\n",
            "Epoch: 49 | Batch: 549 | Loss: 0.2002303647617089\n",
            "Epoch: 49 | Batch: 550 | Loss: 0.1981867926390699\n",
            "Epoch: 49 | Batch: 551 | Loss: 0.15996030891609234\n",
            "Epoch: 49 | Batch: 552 | Loss: 0.14226236426034794\n",
            "Epoch: 49 | Batch: 553 | Loss: 0.1671554098968271\n",
            "Epoch: 49 | Batch: 554 | Loss: 0.1997629311916228\n",
            "Epoch: 49 | Batch: 555 | Loss: 0.15068736501168067\n",
            "Epoch: 49 | Batch: 556 | Loss: 0.15015863300462193\n",
            "Epoch: 49 | Batch: 557 | Loss: 0.12919091993847867\n",
            "Epoch: 49 | Batch: 558 | Loss: 0.21413377694920124\n",
            "Epoch: 49 | Batch: 559 | Loss: 0.16966816502030757\n",
            "Epoch: 49 | Batch: 560 | Loss: 0.22206943338264254\n",
            "Epoch: 49 | Batch: 561 | Loss: 0.1764632312870592\n",
            "Epoch: 49 | Batch: 562 | Loss: 0.15040612540577905\n",
            "Epoch: 49 | Batch: 563 | Loss: 0.19427374319914748\n",
            "Epoch: 49 | Batch: 564 | Loss: 0.1591933287886139\n",
            "Epoch: 49 | Batch: 565 | Loss: 0.21745535510995367\n",
            "Epoch: 49 | Batch: 566 | Loss: 0.16054091505849435\n",
            "Epoch: 49 | Batch: 567 | Loss: 0.18357610834705088\n",
            "Epoch: 49 | Batch: 568 | Loss: 0.1615078235074835\n",
            "Epoch: 49 | Batch: 569 | Loss: 0.18767226496759096\n",
            "Epoch: 49 | Batch: 570 | Loss: 0.178011717524291\n",
            "Epoch: 49 | Batch: 571 | Loss: 0.14096286024749313\n",
            "Epoch: 49 | Batch: 572 | Loss: 0.16427314900350298\n",
            "Epoch: 49 | Batch: 573 | Loss: 0.19173788079983584\n",
            "Epoch: 49 | Batch: 574 | Loss: 0.19390354314039654\n",
            "Epoch: 49 | Batch: 575 | Loss: 0.22767544328706163\n",
            "Epoch: 49 | Batch: 576 | Loss: 0.16827929027088226\n",
            "Epoch: 49 | Batch: 577 | Loss: 0.11855283733846717\n",
            "Epoch: 49 | Batch: 578 | Loss: 0.16716852279102967\n",
            "Epoch: 49 | Batch: 579 | Loss: 0.1338414994364311\n",
            "Epoch: 49 | Batch: 580 | Loss: 0.18687788024236734\n",
            "Epoch: 49 | Batch: 581 | Loss: 0.2138755276331671\n",
            "Epoch: 49 | Batch: 582 | Loss: 0.17280209557899373\n",
            "Epoch: 49 | Batch: 583 | Loss: 0.1793609664671328\n",
            "Epoch: 49 | Batch: 584 | Loss: 0.12476721458165745\n",
            "Epoch: 49 | Batch: 585 | Loss: 0.22047383400450274\n",
            "Epoch: 49 | Batch: 586 | Loss: 0.16454826857367447\n",
            "Epoch: 49 | Batch: 587 | Loss: 0.19247985735809653\n",
            "Epoch: 49 | Batch: 588 | Loss: 0.17324953604182128\n",
            "Epoch: 49 | Batch: 589 | Loss: 0.17358641938705552\n",
            "Epoch: 49 | Batch: 590 | Loss: 0.2051845247940865\n",
            "Epoch: 49 | Batch: 591 | Loss: 0.1611119861826954\n",
            "Epoch: 49 | Batch: 592 | Loss: 0.16814369765423304\n",
            "Epoch: 49 | Batch: 593 | Loss: 0.20361557441715003\n",
            "Epoch: 49 | Batch: 594 | Loss: 0.1725153093781193\n",
            "Epoch: 49 | Batch: 595 | Loss: 0.17388971614417487\n",
            "Epoch: 49 | Batch: 596 | Loss: 0.13657782285782186\n",
            "Epoch: 49 | Batch: 597 | Loss: 0.17104526119216587\n",
            "Epoch: 49 | Batch: 598 | Loss: 0.15449545798492345\n",
            "Epoch: 49 | Batch: 599 | Loss: 0.19705978912983102\n",
            "Epoch: 49 | Batch: 600 | Loss: 0.14457212138144657\n",
            "Epoch: 49 | Batch: 601 | Loss: 0.15257389460341725\n",
            "Epoch: 49 | Batch: 602 | Loss: 0.14993992041964976\n",
            "Epoch: 49 | Batch: 603 | Loss: 0.15751263480807004\n",
            "Epoch: 49 | Batch: 604 | Loss: 0.13652376265218946\n",
            "Epoch: 49 | Batch: 605 | Loss: 0.15478658112868365\n",
            "Epoch: 49 | Batch: 606 | Loss: 0.15258400725752408\n",
            "Epoch: 49 | Batch: 607 | Loss: 0.14132382946678973\n",
            "Epoch: 49 | Batch: 608 | Loss: 0.16782504858149092\n",
            "Epoch: 49 | Batch: 609 | Loss: 0.1465164376088573\n",
            "Epoch: 49 | Batch: 610 | Loss: 0.17075528112740349\n",
            "Epoch: 49 | Batch: 611 | Loss: 0.1550002725092282\n",
            "Epoch: 49 | Batch: 612 | Loss: 0.1354320437383889\n",
            "Epoch: 49 | Batch: 613 | Loss: 0.12590602848465493\n",
            "Epoch: 49 | Batch: 614 | Loss: 0.1916310085327586\n",
            "Epoch: 49 | Batch: 615 | Loss: 0.11324822467998358\n",
            "Epoch: 49 | Batch: 616 | Loss: 0.17379534841967878\n",
            "Epoch: 49 | Batch: 617 | Loss: 0.18531603010120823\n",
            "Epoch: 49 | Batch: 618 | Loss: 0.1635374644824192\n",
            "Epoch: 49 | Batch: 619 | Loss: 0.18153309667837708\n",
            "Epoch: 49 | Batch: 620 | Loss: 0.14174738485873398\n",
            "Epoch: 49 | Batch: 621 | Loss: 0.15729597176687082\n",
            "Epoch: 49 | Batch: 622 | Loss: 0.13129659690903756\n",
            "Epoch: 49 | Batch: 623 | Loss: 0.2037530688213408\n",
            "Epoch: 49 | Batch: 624 | Loss: 0.17461065247721594\n",
            "Epoch: 49 | Batch: 625 | Loss: 0.16843810329431402\n",
            "Epoch: 49 | Batch: 626 | Loss: 0.13206024352413487\n",
            "Epoch: 49 | Batch: 627 | Loss: 0.23138083299441609\n",
            "Epoch: 49 | Batch: 628 | Loss: 0.15020207240786737\n",
            "Epoch: 49 | Batch: 629 | Loss: 0.2252963787107588\n",
            "Epoch: 49 | Batch: 630 | Loss: 0.16628113835095198\n",
            "Epoch: 49 | Batch: 631 | Loss: 0.13654024013209354\n",
            "Epoch: 49 | Batch: 632 | Loss: 0.15548149407006528\n",
            "Epoch: 49 | Batch: 633 | Loss: 0.17624009332235838\n",
            "Epoch: 49 | Batch: 634 | Loss: 0.15037755911679826\n",
            "Epoch: 49 | Batch: 635 | Loss: 0.18117733116405182\n",
            "Epoch: 49 | Batch: 636 | Loss: 0.18140380389757688\n",
            "Epoch: 49 | Batch: 637 | Loss: 0.19365130397535163\n",
            "Epoch: 49 | Batch: 638 | Loss: 0.17412669907291983\n",
            "Epoch: 49 | Batch: 639 | Loss: 0.15024218516453694\n",
            "Epoch: 49 | Batch: 640 | Loss: 0.16404186496289325\n",
            "Epoch: 49 | Batch: 641 | Loss: 0.16142771041435222\n",
            "Epoch: 49 | Batch: 642 | Loss: 0.24801022503217507\n",
            "Epoch: 49 | Batch: 643 | Loss: 0.17828201278667372\n",
            "Epoch: 49 | Batch: 644 | Loss: 0.18321130551610693\n",
            "Epoch: 49 | Batch: 645 | Loss: 0.22321625102374892\n",
            "Epoch: 49 | Batch: 646 | Loss: 0.15722112734279697\n",
            "Epoch: 49 | Batch: 647 | Loss: 0.14420180570307356\n",
            "Epoch: 49 | Batch: 648 | Loss: 0.21083517347127329\n",
            "Epoch: 49 | Batch: 649 | Loss: 0.17920527496459526\n",
            "Epoch: 49 | Batch: 650 | Loss: 0.1195623962852948\n",
            "Epoch: 49 | Batch: 651 | Loss: 0.20416884792219173\n",
            "Epoch: 49 | Batch: 652 | Loss: 0.15857633912358926\n",
            "Epoch: 49 | Batch: 653 | Loss: 0.167169260715937\n",
            "Epoch: 49 | Batch: 654 | Loss: 0.17433712515997746\n",
            "Epoch: 49 | Batch: 655 | Loss: 0.14578047559042667\n",
            "Epoch: 49 | Batch: 656 | Loss: 0.14749061812899392\n",
            "Epoch: 49 | Batch: 657 | Loss: 0.20417178856502946\n",
            "Epoch: 49 | Batch: 658 | Loss: 0.17488537415543187\n",
            "Epoch: 49 | Batch: 659 | Loss: 0.14392848927972235\n",
            "Epoch: 49 | Batch: 660 | Loss: 0.14722052478275116\n",
            "Epoch: 49 | Batch: 661 | Loss: 0.12821550046704677\n",
            "Epoch: 49 | Batch: 662 | Loss: 0.22103236868430973\n",
            "Epoch: 49 | Batch: 663 | Loss: 0.134340579194709\n",
            "Epoch: 49 | Batch: 664 | Loss: 0.14009302684968356\n",
            "Epoch: 49 | Batch: 665 | Loss: 0.15874601002916738\n",
            "Epoch: 49 | Batch: 666 | Loss: 0.18413904447761628\n",
            "Epoch: 49 | Batch: 667 | Loss: 0.1292538084892088\n",
            "Epoch: 49 | Batch: 668 | Loss: 0.1887642051393066\n",
            "Epoch: 49 | Batch: 669 | Loss: 0.18136653758786717\n",
            "Epoch: 49 | Batch: 670 | Loss: 0.18445821006866386\n",
            "Epoch: 49 | Batch: 671 | Loss: 0.14885204961589743\n",
            "Epoch: 49 | Batch: 672 | Loss: 0.20748627980839157\n",
            "Epoch: 49 | Batch: 673 | Loss: 0.14872886840814778\n",
            "Epoch: 49 | Batch: 674 | Loss: 0.1633659776985278\n",
            "Epoch: 49 | Batch: 675 | Loss: 0.17982668162951387\n",
            "Epoch: 49 | Batch: 676 | Loss: 0.15273095342248877\n",
            "Epoch: 49 | Batch: 677 | Loss: 0.11620306926909514\n",
            "Epoch: 49 | Batch: 678 | Loss: 0.17807892370848266\n",
            "Epoch: 49 | Batch: 679 | Loss: 0.15767184574897603\n",
            "Epoch: 49 | Batch: 680 | Loss: 0.2167826143296958\n",
            "Epoch: 49 | Batch: 681 | Loss: 0.15448035753966932\n",
            "Epoch: 49 | Batch: 682 | Loss: 0.1790583319196126\n",
            "Epoch: 49 | Batch: 683 | Loss: 0.16068466578893217\n",
            "Epoch: 49 | Batch: 684 | Loss: 0.1880331903906096\n",
            "Epoch: 49 | Batch: 685 | Loss: 0.1828626608798588\n",
            "Epoch: 49 | Batch: 686 | Loss: 0.1891847376314524\n",
            "Epoch: 49 | Batch: 687 | Loss: 0.1448854537885165\n",
            "Epoch: 49 | Batch: 688 | Loss: 0.1395060383488433\n",
            "Epoch: 49 | Batch: 689 | Loss: 0.1820209104009046\n",
            "Epoch: 49 | Batch: 690 | Loss: 0.1762754886767836\n",
            "Epoch: 49 | Batch: 691 | Loss: 0.1725762080441313\n",
            "Epoch: 49 | Batch: 692 | Loss: 0.1410238601822698\n",
            "Epoch: 49 | Batch: 693 | Loss: 0.1748992359728042\n",
            "Epoch: 49 | Batch: 694 | Loss: 0.10857103441891557\n",
            "Epoch: 49 | Batch: 695 | Loss: 0.1785948141168346\n",
            "Epoch: 49 | Batch: 696 | Loss: 0.24266279077499264\n",
            "Epoch: 49 | Batch: 697 | Loss: 0.16346390915341155\n",
            "Epoch: 49 | Batch: 698 | Loss: 0.23350380510711322\n",
            "Epoch: 49 | Batch: 699 | Loss: 0.2327821570431989\n",
            "Epoch: 49 | Batch: 700 | Loss: 0.21769988876405924\n",
            "Epoch: 49 | Batch: 701 | Loss: 0.15941683729046896\n",
            "Epoch: 49 | Batch: 702 | Loss: 0.21367642939759712\n",
            "Epoch: 49 | Batch: 703 | Loss: 0.15216744818040473\n",
            "Epoch: 49 | Batch: 704 | Loss: 0.15542435807190286\n",
            "Epoch: 49 | Batch: 705 | Loss: 0.19343246085412494\n",
            "Epoch: 49 | Batch: 706 | Loss: 0.1731217922419313\n",
            "Epoch: 49 | Batch: 707 | Loss: 0.17162288194929215\n",
            "Epoch: 49 | Batch: 708 | Loss: 0.18928894213333208\n",
            "Epoch: 49 | Batch: 709 | Loss: 0.21120156597493744\n",
            "Epoch: 49 | Batch: 710 | Loss: 0.17469971509570534\n",
            "Epoch: 49 | Batch: 711 | Loss: 0.16855793716586043\n",
            "Epoch: 49 | Batch: 712 | Loss: 0.20083565636431905\n",
            "Epoch: 49 | Batch: 713 | Loss: 0.14965467460942447\n",
            "Epoch: 49 | Batch: 714 | Loss: 0.24336447967037972\n",
            "Epoch: 49 | Batch: 715 | Loss: 0.17971125478841982\n",
            "Epoch: 49 | Batch: 716 | Loss: 0.14933717734121726\n",
            "Epoch: 49 | Batch: 717 | Loss: 0.1926952238159222\n",
            "Epoch: 49 | Batch: 718 | Loss: 0.18268552349181272\n",
            "Epoch: 49 | Batch: 719 | Loss: 0.16681397618638721\n",
            "Epoch: 49 | Batch: 720 | Loss: 0.16754779644258638\n",
            "Epoch: 49 | Batch: 721 | Loss: 0.1912009466316793\n",
            "Epoch: 49 | Batch: 722 | Loss: 0.1373338368711698\n",
            "Epoch: 49 | Batch: 723 | Loss: 0.14727955371414816\n",
            "Epoch: 49 | Batch: 724 | Loss: 0.157878216045514\n",
            "Epoch: 49 | Batch: 725 | Loss: 0.13448254892976824\n",
            "Epoch: 49 | Batch: 726 | Loss: 0.20203318001630446\n",
            "Epoch: 49 | Batch: 727 | Loss: 0.1588989377997757\n",
            "Epoch: 49 | Batch: 728 | Loss: 0.17520960469264912\n",
            "Epoch: 49 | Batch: 729 | Loss: 0.17198903790437764\n",
            "Epoch: 49 | Batch: 730 | Loss: 0.16933547876450541\n",
            "Epoch: 49 | Batch: 731 | Loss: 0.14838995560394627\n",
            "Epoch: 49 | Batch: 732 | Loss: 0.16301224450421328\n",
            "Epoch: 49 | Batch: 733 | Loss: 0.15366945816085778\n",
            "Epoch: 49 | Batch: 734 | Loss: 0.17100251556802587\n",
            "Epoch: 49 | Batch: 735 | Loss: 0.1321272632165443\n",
            "Epoch: 49 | Batch: 736 | Loss: 0.16926341925251331\n",
            "Epoch: 49 | Batch: 737 | Loss: 0.17564846760554426\n",
            "Epoch: 49 | Batch: 738 | Loss: 0.18969817337207276\n",
            "Epoch: 49 | Batch: 739 | Loss: 0.17676700317606833\n",
            "Epoch: 49 | Batch: 740 | Loss: 0.1734688012728743\n",
            "Epoch: 49 | Batch: 741 | Loss: 0.18004891927041436\n",
            "Epoch: 49 | Batch: 742 | Loss: 0.1502176322779353\n",
            "Epoch: 49 | Batch: 743 | Loss: 0.1670528565576789\n",
            "Epoch: 49 | Batch: 744 | Loss: 0.1776591340841158\n",
            "Epoch: 49 | Batch: 745 | Loss: 0.22474170455287418\n",
            "Epoch: 49 | Batch: 746 | Loss: 0.163135622499173\n",
            "Epoch: 49 | Batch: 747 | Loss: 0.1970004454726898\n",
            "Epoch: 49 | Batch: 748 | Loss: 0.18894752661325656\n",
            "Epoch: 49 | Batch: 749 | Loss: 0.15037124056576545\n",
            "Epoch: 49 | Batch: 750 | Loss: 0.203194917843443\n",
            "Epoch: 49 | Batch: 751 | Loss: 0.1503127027443737\n",
            "Epoch: 49 | Batch: 752 | Loss: 0.1852796232652438\n",
            "Epoch: 49 | Batch: 753 | Loss: 0.12912460785007351\n",
            "Epoch: 49 | Batch: 754 | Loss: 0.14771397844206374\n",
            "Epoch: 49 | Batch: 755 | Loss: 0.15606627220003239\n",
            "Epoch: 49 | Batch: 756 | Loss: 0.18601228906327402\n",
            "Epoch: 49 | Batch: 757 | Loss: 0.1431504511200424\n",
            "Epoch: 49 | Batch: 758 | Loss: 0.1909901005678897\n",
            "Epoch: 49 | Batch: 759 | Loss: 0.15218970717410907\n",
            "Epoch: 49 | Batch: 760 | Loss: 0.16899759874468917\n",
            "Epoch: 49 | Batch: 761 | Loss: 0.19492689308548797\n",
            "Epoch: 49 | Batch: 762 | Loss: 0.14112497844544764\n",
            "Epoch: 49 | Batch: 763 | Loss: 0.1985444687069484\n",
            "Epoch: 49 | Batch: 764 | Loss: 0.20847369502187404\n",
            "Epoch: 49 | Batch: 765 | Loss: 0.14852708985126\n",
            "Epoch: 49 | Batch: 766 | Loss: 0.14117301581904676\n",
            "Epoch: 49 | Batch: 767 | Loss: 0.1865848698648575\n",
            "Epoch: 49 | Batch: 768 | Loss: 0.14255159998622524\n",
            "Epoch: 49 | Batch: 769 | Loss: 0.15263870157838044\n",
            "Epoch: 49 | Batch: 770 | Loss: 0.14161899448022292\n",
            "Epoch: 49 | Batch: 771 | Loss: 0.15030746010320897\n",
            "Epoch: 49 | Batch: 772 | Loss: 0.2246573478523703\n",
            "Epoch: 49 | Batch: 773 | Loss: 0.14413484951367614\n",
            "Epoch: 49 | Batch: 774 | Loss: 0.15562148804403686\n",
            "Epoch: 49 | Batch: 775 | Loss: 0.14648942189107628\n",
            "Epoch: 49 | Batch: 776 | Loss: 0.16781930735915648\n",
            "Epoch: 49 | Batch: 777 | Loss: 0.2043790990720455\n",
            "Epoch: 49 | Batch: 778 | Loss: 0.15943426213192008\n",
            "Epoch: 49 | Batch: 779 | Loss: 0.14206100374856814\n",
            "Epoch: 49 | Batch: 780 | Loss: 0.2128844974433444\n",
            "Epoch: 49 | Batch: 781 | Loss: 0.1365558342541063\n",
            "Epoch: 49 | Batch: 782 | Loss: 0.16047545575711405\n",
            "Epoch: 49 | Batch: 783 | Loss: 0.17530034935094257\n",
            "Epoch: 49 | Batch: 784 | Loss: 0.19033731442409216\n",
            "Epoch: 49 | Batch: 785 | Loss: 0.19200577994242207\n",
            "Epoch: 49 | Batch: 786 | Loss: 0.1923663600847504\n",
            "Epoch: 49 | Batch: 787 | Loss: 0.18204830779942993\n",
            "Epoch: 49 | Batch: 788 | Loss: 0.15421073557856058\n",
            "Epoch: 49 | Batch: 789 | Loss: 0.15712482014333082\n",
            "Epoch: 49 | Batch: 790 | Loss: 0.13610314198029824\n",
            "Epoch: 49 | Batch: 791 | Loss: 0.21142898870877175\n",
            "Epoch: 49 | Batch: 792 | Loss: 0.17464178194772928\n",
            "Epoch: 49 | Batch: 793 | Loss: 0.1435913248081844\n",
            "Epoch: 49 | Batch: 794 | Loss: 0.18245400347821533\n",
            "Epoch: 49 | Batch: 795 | Loss: 0.16835693274533098\n",
            "Epoch: 49 | Batch: 796 | Loss: 0.151638274395551\n",
            "Epoch: 49 | Batch: 797 | Loss: 0.15028501071292644\n",
            "Epoch: 49 | Batch: 798 | Loss: 0.17738395494053588\n",
            "Epoch: 49 | Batch: 799 | Loss: 0.1957377305563396\n",
            "Epoch: 49 | Batch: 800 | Loss: 0.17619766802093542\n",
            "Epoch: 49 | Batch: 801 | Loss: 0.1596079703420875\n",
            "Epoch: 49 | Batch: 802 | Loss: 0.13387384507336791\n",
            "Epoch: 49 | Batch: 803 | Loss: 0.15235981877775118\n",
            "Epoch: 49 | Batch: 804 | Loss: 0.16828627618964215\n",
            "Epoch: 49 | Batch: 805 | Loss: 0.1789554344834678\n",
            "Epoch: 49 | Batch: 806 | Loss: 0.15045323043720255\n",
            "Epoch: 49 | Batch: 807 | Loss: 0.17246164696096977\n",
            "Epoch: 49 | Batch: 808 | Loss: 0.16916641189919582\n",
            "Epoch: 49 | Batch: 809 | Loss: 0.21329497453641338\n",
            "Epoch: 49 | Batch: 810 | Loss: 0.21054889315501182\n",
            "Epoch: 49 | Batch: 811 | Loss: 0.16696243834193455\n",
            "Epoch: 49 | Batch: 812 | Loss: 0.16585558674940623\n",
            "Epoch: 49 | Batch: 813 | Loss: 0.15156956964187052\n",
            "Epoch: 49 | Batch: 814 | Loss: 0.20408411356663853\n",
            "Epoch: 49 | Batch: 815 | Loss: 0.13972782550793478\n",
            "Epoch: 49 | Batch: 816 | Loss: 0.21258566348781316\n",
            "Epoch: 49 | Batch: 817 | Loss: 0.16437718695020606\n",
            "Epoch: 49 | Batch: 818 | Loss: 0.17761533020454223\n",
            "Epoch: 49 | Batch: 819 | Loss: 0.1649130046424706\n",
            "Epoch: 49 | Batch: 820 | Loss: 0.14780279271245544\n",
            "Epoch: 49 | Batch: 821 | Loss: 0.19379179948004446\n",
            "Epoch: 49 | Batch: 822 | Loss: 0.19106009265324958\n",
            "Epoch: 49 | Batch: 823 | Loss: 0.12610836788176497\n",
            "Epoch: 49 | Batch: 824 | Loss: 0.14980327128848875\n",
            "Epoch: 49 | Batch: 825 | Loss: 0.15535771785332259\n",
            "Epoch: 49 | Batch: 826 | Loss: 0.17795484335116418\n",
            "Epoch: 49 | Batch: 827 | Loss: 0.16109941871388925\n",
            "Epoch: 49 | Batch: 828 | Loss: 0.1871673021913138\n",
            "Epoch: 49 | Batch: 829 | Loss: 0.19426874680812695\n",
            "Epoch: 49 | Batch: 830 | Loss: 0.12127104342847636\n",
            "Epoch: 49 | Batch: 831 | Loss: 0.14160553114435073\n",
            "Epoch: 49 | Batch: 832 | Loss: 0.1453830695765795\n",
            "Epoch: 49 | Batch: 833 | Loss: 0.17592202650840427\n",
            "Epoch: 49 | Batch: 834 | Loss: 0.1801856913570225\n",
            "Epoch: 49 | Batch: 835 | Loss: 0.1563807998347901\n",
            "Epoch: 49 | Batch: 836 | Loss: 0.16758901261728698\n",
            "Epoch: 49 | Batch: 837 | Loss: 0.12392930876158889\n",
            "Epoch: 49 | Batch: 838 | Loss: 0.11020252783422221\n",
            "Epoch: 49 | Batch: 839 | Loss: 0.13764654853912536\n",
            "Epoch: 49 | Batch: 840 | Loss: 0.1637413074528213\n",
            "Epoch: 49 | Batch: 841 | Loss: 0.14867672044090954\n",
            "Epoch: 49 | Batch: 842 | Loss: 0.1460242802143709\n",
            "Epoch: 49 | Batch: 843 | Loss: 0.16422715454249762\n",
            "Epoch: 49 | Batch: 844 | Loss: 0.15385727293400925\n",
            "Epoch: 49 | Batch: 845 | Loss: 0.15480208875888807\n",
            "Epoch: 49 | Batch: 846 | Loss: 0.19181003075710415\n",
            "Epoch: 49 | Batch: 847 | Loss: 0.1544126574715244\n",
            "Epoch: 49 | Batch: 848 | Loss: 0.14493393246709202\n",
            "Epoch: 49 | Batch: 849 | Loss: 0.18724015756377893\n",
            "Epoch: 49 | Batch: 850 | Loss: 0.13691246228674198\n",
            "Epoch: 49 | Batch: 851 | Loss: 0.16820480213240932\n",
            "Epoch: 49 | Batch: 852 | Loss: 0.2056122178555322\n",
            "Epoch: 49 | Batch: 853 | Loss: 0.2015599589985944\n",
            "Epoch: 49 | Batch: 854 | Loss: 0.1221022076794057\n",
            "Epoch: 49 | Batch: 855 | Loss: 0.22080017255813567\n",
            "Epoch: 49 | Batch: 856 | Loss: 0.17001863959731353\n",
            "Epoch: 49 | Batch: 857 | Loss: 0.23037183487361612\n",
            "Epoch: 49 | Batch: 858 | Loss: 0.23595554278910424\n",
            "Epoch: 49 | Batch: 859 | Loss: 0.11557370164559007\n",
            "Epoch: 49 | Batch: 860 | Loss: 0.14502800321978543\n",
            "Epoch: 49 | Batch: 861 | Loss: 0.15450519039015764\n",
            "Epoch: 49 | Batch: 862 | Loss: 0.1861711370351274\n",
            "Epoch: 49 | Batch: 863 | Loss: 0.1483431910654918\n",
            "Epoch: 49 | Batch: 864 | Loss: 0.208070591224951\n",
            "Epoch: 49 | Batch: 865 | Loss: 0.1406817505536157\n",
            "Epoch: 49 | Batch: 866 | Loss: 0.13203131028107426\n",
            "Epoch: 49 | Batch: 867 | Loss: 0.18276560363934144\n",
            "Epoch: 49 | Batch: 868 | Loss: 0.20129534215214337\n",
            "Epoch: 49 | Batch: 869 | Loss: 0.13197849807350234\n",
            "Epoch: 49 | Batch: 870 | Loss: 0.12880021238866196\n",
            "Epoch: 49 | Batch: 871 | Loss: 0.18452379395273943\n",
            "Epoch: 49 | Batch: 872 | Loss: 0.1646762169171546\n",
            "Epoch: 49 | Batch: 873 | Loss: 0.17688925221954094\n",
            "Epoch: 49 | Batch: 874 | Loss: 0.19654117177444277\n",
            "Epoch: 49 | Batch: 875 | Loss: 0.15640840127666872\n",
            "Epoch: 49 | Batch: 876 | Loss: 0.1236279957138778\n",
            "Epoch: 49 | Batch: 877 | Loss: 0.12323337227085912\n",
            "Epoch: 49 | Batch: 878 | Loss: 0.10414074033925273\n",
            "Epoch: 49 | Batch: 879 | Loss: 0.12078048177590886\n",
            "Epoch: 49 | Batch: 880 | Loss: 0.18199272230969166\n",
            "Epoch: 49 | Batch: 881 | Loss: 0.1904858090212475\n",
            "Epoch: 49 | Batch: 882 | Loss: 0.2051325074257626\n",
            "Epoch: 49 | Batch: 883 | Loss: 0.21528517280481693\n",
            "Epoch: 49 | Batch: 884 | Loss: 0.15085594062670052\n",
            "Epoch: 49 | Batch: 885 | Loss: 0.13313241088871175\n",
            "Epoch: 49 | Batch: 886 | Loss: 0.14375089347420528\n",
            "Epoch: 49 | Batch: 887 | Loss: 0.15989926404309387\n",
            "Epoch: 49 | Batch: 888 | Loss: 0.17363597265678093\n",
            "Epoch: 49 | Batch: 889 | Loss: 0.16268287074411308\n",
            "Epoch: 49 | Batch: 890 | Loss: 0.24299222962022798\n",
            "Epoch: 49 | Batch: 891 | Loss: 0.1713081869247858\n",
            "Epoch: 49 | Batch: 892 | Loss: 0.2168241371176559\n",
            "Epoch: 49 | Batch: 893 | Loss: 0.1781931303350168\n",
            "Epoch: 49 | Batch: 894 | Loss: 0.15383545700505857\n",
            "Epoch: 49 | Batch: 895 | Loss: 0.14395853251160617\n",
            "Epoch: 49 | Batch: 896 | Loss: 0.16574610779619853\n",
            "Epoch: 49 | Batch: 897 | Loss: 0.16807555576174274\n",
            "Epoch: 49 | Batch: 898 | Loss: 0.1599125324823316\n",
            "Epoch: 49 | Batch: 899 | Loss: 0.15669024579230864\n",
            "Epoch: 49 | Batch: 900 | Loss: 0.1359862629747465\n",
            "Epoch: 49 | Batch: 901 | Loss: 0.16103049479086906\n",
            "Epoch: 49 | Batch: 902 | Loss: 0.19600660984800455\n",
            "Epoch: 49 | Batch: 903 | Loss: 0.15703705961398443\n",
            "Epoch: 49 | Batch: 904 | Loss: 0.15759457086582787\n",
            "Epoch: 49 | Batch: 905 | Loss: 0.1983294511024242\n",
            "Epoch: 49 | Batch: 906 | Loss: 0.13570716378282663\n",
            "Epoch: 49 | Batch: 907 | Loss: 0.15710605313729095\n",
            "Epoch: 49 | Batch: 908 | Loss: 0.16096255847707971\n",
            "Epoch: 49 | Batch: 909 | Loss: 0.2098067579631494\n",
            "Epoch: 49 | Batch: 910 | Loss: 0.16886010973315752\n",
            "Epoch: 49 | Batch: 911 | Loss: 0.15018065686702095\n",
            "Epoch: 49 | Batch: 912 | Loss: 0.1629442546686884\n",
            "Epoch: 49 | Batch: 913 | Loss: 0.17532403566447255\n",
            "Epoch: 49 | Batch: 914 | Loss: 0.17605703053489707\n",
            "Epoch: 49 | Batch: 915 | Loss: 0.15204524164227196\n",
            "Epoch: 49 | Batch: 916 | Loss: 0.1519605436502212\n",
            "Epoch: 49 | Batch: 917 | Loss: 0.18504731363111573\n",
            "Epoch: 49 | Batch: 918 | Loss: 0.2041009507401509\n",
            "Epoch: 49 | Batch: 919 | Loss: 0.1623831367138734\n",
            "Epoch: 49 | Batch: 920 | Loss: 0.16204252649259523\n",
            "Epoch: 49 | Batch: 921 | Loss: 0.1523550021390287\n",
            "Epoch: 49 | Batch: 922 | Loss: 0.15118327509512078\n",
            "Epoch: 49 | Batch: 923 | Loss: 0.15932228406416252\n",
            "Epoch: 49 | Batch: 924 | Loss: 0.17299922471015475\n",
            "Epoch: 49 | Batch: 925 | Loss: 0.1594053878998715\n",
            "Epoch: 49 | Batch: 926 | Loss: 0.16486312959230423\n",
            "Epoch: 49 | Batch: 927 | Loss: 0.24509041070248305\n",
            "Epoch: 49 | Batch: 928 | Loss: 0.23022295970030998\n",
            "Epoch: 49 | Batch: 929 | Loss: 0.21656142762326122\n",
            "Epoch: 49 | Batch: 930 | Loss: 0.17259741262000924\n",
            "Epoch: 49 | Batch: 931 | Loss: 0.2297503765669147\n",
            "Epoch: 49 | Batch: 932 | Loss: 0.16021147066280858\n",
            "Epoch: 49 | Batch: 933 | Loss: 0.183092838977036\n",
            "Epoch: 49 | Batch: 934 | Loss: 0.13752813051427962\n",
            "Epoch: 49 | Batch: 935 | Loss: 0.158342070229652\n",
            "Epoch: 49 | Batch: 936 | Loss: 0.1418848835869238\n",
            "Epoch: 49 | Batch: 937 | Loss: 0.14000455699002518\n",
            "Epoch: 49 | Batch: 938 | Loss: 0.1808963685439735\n",
            "Epoch: 49 | Batch: 939 | Loss: 0.14475606708110966\n",
            "Epoch: 49 | Batch: 940 | Loss: 0.15807128246218133\n",
            "Epoch: 49 | Batch: 941 | Loss: 0.14116997644334517\n",
            "Epoch: 49 | Batch: 942 | Loss: 0.16790245488767022\n",
            "Epoch: 49 | Batch: 943 | Loss: 0.20368727455448118\n",
            "Epoch: 49 | Batch: 944 | Loss: 0.186736425718715\n",
            "Epoch: 49 | Batch: 945 | Loss: 0.19363222137868613\n",
            "Epoch: 49 | Batch: 946 | Loss: 0.19346201834909804\n",
            "Epoch: 49 | Batch: 947 | Loss: 0.17782874246266134\n",
            "Epoch: 49 | Batch: 948 | Loss: 0.16846571930120602\n",
            "Epoch: 49 | Batch: 949 | Loss: 0.13479052686328535\n",
            "Epoch: 49 | Batch: 950 | Loss: 0.15500824824155915\n",
            "Epoch: 49 | Batch: 951 | Loss: 0.23491740165219788\n",
            "Epoch: 49 | Batch: 952 | Loss: 0.18013796042108754\n",
            "Epoch: 49 | Batch: 953 | Loss: 0.20414940748988034\n",
            "Epoch: 49 | Batch: 954 | Loss: 0.16292323828325075\n",
            "Epoch: 49 | Batch: 955 | Loss: 0.16256615745539757\n",
            "Epoch: 49 | Batch: 956 | Loss: 0.1567106137057985\n",
            "Epoch: 49 | Batch: 957 | Loss: 0.1745356090810808\n",
            "Epoch: 49 | Batch: 958 | Loss: 0.17040633268035968\n",
            "Epoch: 49 | Batch: 959 | Loss: 0.16070077777817043\n",
            "Epoch: 49 | Batch: 960 | Loss: 0.17485549791577665\n",
            "Epoch: 49 | Batch: 961 | Loss: 0.12133322760893936\n",
            "Epoch: 49 | Batch: 962 | Loss: 0.16375946964955124\n",
            "Epoch: 49 | Batch: 963 | Loss: 0.19122252593770322\n",
            "Epoch: 49 | Batch: 964 | Loss: 0.2213691128371\n",
            "Epoch: 49 | Batch: 965 | Loss: 0.14322535475201165\n",
            "Epoch: 49 | Batch: 966 | Loss: 0.19434310599852878\n",
            "Epoch: 49 | Batch: 967 | Loss: 0.12725993844028008\n",
            "Epoch: 49 | Batch: 968 | Loss: 0.16543848036029915\n",
            "Epoch: 49 | Batch: 969 | Loss: 0.17530382243556006\n",
            "Epoch: 49 | Batch: 970 | Loss: 0.13107512218230027\n",
            "Epoch: 49 | Batch: 971 | Loss: 0.1827043786920292\n",
            "Epoch: 49 | Batch: 972 | Loss: 0.17322343423273132\n",
            "Epoch: 49 | Batch: 973 | Loss: 0.17276662267795712\n",
            "Epoch: 49 | Batch: 974 | Loss: 0.14997427362666868\n",
            "Epoch: 49 | Batch: 975 | Loss: 0.16230765276951956\n",
            "Epoch: 49 | Batch: 976 | Loss: 0.15052522395656448\n",
            "Epoch: 49 | Batch: 977 | Loss: 0.15911453740218917\n",
            "Epoch: 49 | Batch: 978 | Loss: 0.17911544791664116\n",
            "Epoch: 49 | Batch: 979 | Loss: 0.11658556246396107\n",
            "Epoch: 49 | Batch: 980 | Loss: 0.12537530717263062\n",
            "Epoch: 49 | Batch: 981 | Loss: 0.24691212057551512\n",
            "Epoch: 49 | Batch: 982 | Loss: 0.1463268634476379\n",
            "Epoch: 49 | Batch: 983 | Loss: 0.15241846846251056\n",
            "Epoch: 49 | Batch: 984 | Loss: 0.16968773427844525\n",
            "Epoch: 49 | Batch: 985 | Loss: 0.16052271944116583\n",
            "Epoch: 49 | Batch: 986 | Loss: 0.17361007477716695\n",
            "Epoch: 49 | Batch: 987 | Loss: 0.16077658934179423\n",
            "Epoch: 49 | Batch: 988 | Loss: 0.1611182908348519\n",
            "Epoch: 49 | Batch: 989 | Loss: 0.16294771902093674\n",
            "Epoch: 49 | Batch: 990 | Loss: 0.16191147663286587\n",
            "Epoch: 49 | Batch: 991 | Loss: 0.19723469816131214\n",
            "Epoch: 49 | Batch: 992 | Loss: 0.15170347593938227\n",
            "Epoch: 49 | Batch: 993 | Loss: 0.15758414303243942\n",
            "Epoch: 49 | Batch: 994 | Loss: 0.17232219710605207\n",
            "Epoch: 49 | Batch: 995 | Loss: 0.14684492558562817\n",
            "Epoch: 49 | Batch: 996 | Loss: 0.19736497777986783\n",
            "Epoch: 49 | Batch: 997 | Loss: 0.1857941044132978\n",
            "Epoch: 49 | Batch: 998 | Loss: 0.23603532312548575\n",
            "Epoch: 49 | Batch: 999 | Loss: 0.15850092301143323\n",
            "Epoch: 49 | Batch: 1000 | Loss: 0.2228964706978242\n",
            "Epoch: 49 | Batch: 1001 | Loss: 0.1770836585052624\n",
            "Epoch: 49 | Batch: 1002 | Loss: 0.24069693252521063\n",
            "Epoch: 49 | Batch: 1003 | Loss: 0.21526142117142674\n",
            "Epoch: 49 | Batch: 1004 | Loss: 0.21411110221756405\n",
            "Epoch: 49 | Batch: 1005 | Loss: 0.164980441414537\n",
            "Epoch: 49 | Batch: 1006 | Loss: 0.15201416886488917\n",
            "Epoch: 49 | Batch: 1007 | Loss: 0.1743598294584388\n",
            "Epoch: 49 | Batch: 1008 | Loss: 0.19964262235236868\n",
            "Epoch: 49 | Batch: 1009 | Loss: 0.13504483827151725\n",
            "Epoch: 49 | Batch: 1010 | Loss: 0.16931959090450552\n",
            "Epoch: 49 | Batch: 1011 | Loss: 0.2020859732231084\n",
            "Epoch: 49 | Batch: 1012 | Loss: 0.17151952129121495\n",
            "Epoch: 49 | Batch: 1013 | Loss: 0.15475367502822035\n",
            "Epoch: 49 | Batch: 1014 | Loss: 0.10644610955954076\n",
            "Epoch: 49 | Batch: 1015 | Loss: 0.1978852453987157\n",
            "Epoch: 49 | Batch: 1016 | Loss: 0.12972335051678416\n",
            "Epoch: 49 | Batch: 1017 | Loss: 0.16219712453313934\n",
            "Epoch: 49 | Batch: 1018 | Loss: 0.15055588749139848\n",
            "Epoch: 49 | Batch: 1019 | Loss: 0.16709233175694727\n",
            "Epoch: 49 | Batch: 1020 | Loss: 0.22360496669261576\n",
            "Epoch: 49 | Batch: 1021 | Loss: 0.12852535714514662\n",
            "Epoch: 49 | Batch: 1022 | Loss: 0.13225357527679968\n",
            "Epoch: 49 | Batch: 1023 | Loss: 0.11591407862404772\n",
            "Epoch: 49 | Batch: 1024 | Loss: 0.17213786496689779\n",
            "Epoch: 49 | Batch: 1025 | Loss: 0.1327661550606739\n",
            "Epoch: 49 | Batch: 1026 | Loss: 0.15001507778392312\n",
            "Epoch: 49 | Batch: 1027 | Loss: 0.20693078122659614\n",
            "Epoch: 49 | Batch: 1028 | Loss: 0.16163616415833665\n",
            "Epoch: 49 | Batch: 1029 | Loss: 0.19529307316376976\n",
            "Epoch: 49 | Batch: 1030 | Loss: 0.19422814307887656\n",
            "Epoch: 49 | Batch: 1031 | Loss: 0.14866125931329852\n",
            "Epoch: 49 | Batch: 1032 | Loss: 0.1717660836337949\n",
            "Epoch: 49 | Batch: 1033 | Loss: 0.16775063500138002\n",
            "Epoch: 49 | Batch: 1034 | Loss: 0.16117812978211604\n",
            "Epoch: 49 | Batch: 1035 | Loss: 0.14846179298800027\n",
            "Epoch: 49 | Batch: 1036 | Loss: 0.16217491883442808\n",
            "Epoch: 49 | Batch: 1037 | Loss: 0.20035336075535226\n",
            "Epoch: 49 | Batch: 1038 | Loss: 0.1711232488680619\n",
            "Epoch: 49 | Batch: 1039 | Loss: 0.1451070711859236\n",
            "Epoch: 49 | Batch: 1040 | Loss: 0.1429121392071842\n",
            "Epoch: 49 | Batch: 1041 | Loss: 0.14211361647586263\n",
            "Epoch: 49 | Batch: 1042 | Loss: 0.2055512964269529\n",
            "Epoch: 49 | Batch: 1043 | Loss: 0.17561166256660035\n",
            "Epoch: 49 | Batch: 1044 | Loss: 0.1331900228214203\n",
            "Epoch: 49 | Batch: 1045 | Loss: 0.12218394013035028\n",
            "Epoch: 49 | Batch: 1046 | Loss: 0.14699748014245945\n",
            "Epoch: 49 | Batch: 1047 | Loss: 0.15029449303773043\n",
            "Epoch: 49 | Batch: 1048 | Loss: 0.17775057684136367\n",
            "Epoch: 49 | Batch: 1049 | Loss: 0.1648531224658932\n",
            "Epoch: 49 | Batch: 1050 | Loss: 0.1633023399787126\n",
            "Epoch: 49 | Batch: 1051 | Loss: 0.19684583650573015\n",
            "Epoch: 49 | Batch: 1052 | Loss: 0.1880189690737369\n",
            "Epoch: 49 | Batch: 1053 | Loss: 0.14543093172329036\n",
            "Epoch: 49 | Batch: 1054 | Loss: 0.17719189358992915\n",
            "Epoch: 49 | Batch: 1055 | Loss: 0.21206847024355568\n",
            "Epoch: 49 | Batch: 1056 | Loss: 0.16279783004311538\n",
            "Epoch: 49 | Batch: 1057 | Loss: 0.15548614201065347\n",
            "Epoch: 49 | Batch: 1058 | Loss: 0.14474843871054843\n",
            "Epoch: 49 | Batch: 1059 | Loss: 0.13400875733520407\n",
            "Epoch: 49 | Batch: 1060 | Loss: 0.18283534137710733\n",
            "Epoch: 49 | Batch: 1061 | Loss: 0.12532651632012642\n",
            "Epoch: 49 | Batch: 1062 | Loss: 0.17440659413060927\n",
            "Epoch: 49 | Batch: 1063 | Loss: 0.17890008344407513\n",
            "Epoch: 49 | Batch: 1064 | Loss: 0.1843463822670814\n",
            "Epoch: 49 | Batch: 1065 | Loss: 0.12758133526089832\n",
            "Epoch: 49 | Batch: 1066 | Loss: 0.15733073328779792\n",
            "Epoch: 49 | Batch: 1067 | Loss: 0.15768622256899828\n",
            "Epoch: 49 | Batch: 1068 | Loss: 0.17945508483125328\n",
            "Epoch: 49 | Batch: 1069 | Loss: 0.18372123432768334\n",
            "Epoch: 49 | Batch: 1070 | Loss: 0.20063262943037846\n",
            "Epoch: 49 | Batch: 1071 | Loss: 0.2051301538244785\n",
            "Epoch: 49 | Batch: 1072 | Loss: 0.14683892038789118\n",
            "Epoch: 49 | Batch: 1073 | Loss: 0.16798243486124784\n",
            "Epoch: 49 | Batch: 1074 | Loss: 0.1409544676311418\n",
            "Epoch: 49 | Batch: 1075 | Loss: 0.15201338887063554\n",
            "Epoch: 49 | Batch: 1076 | Loss: 0.14737099615329688\n",
            "Epoch: 49 | Batch: 1077 | Loss: 0.21138724681854035\n",
            "Epoch: 49 | Batch: 1078 | Loss: 0.1584272134697934\n",
            "Epoch: 49 | Batch: 1079 | Loss: 0.18637111345584145\n",
            "Epoch: 49 | Batch: 1080 | Loss: 0.1289025055073288\n",
            "Epoch: 49 | Batch: 1081 | Loss: 0.15699307522669445\n",
            "Epoch: 49 | Batch: 1082 | Loss: 0.15319758267874997\n",
            "Epoch: 49 | Batch: 1083 | Loss: 0.14575988714652177\n",
            "Epoch: 49 | Batch: 1084 | Loss: 0.1226844693011144\n",
            "Epoch: 49 | Batch: 1085 | Loss: 0.15169389164969166\n",
            "Epoch: 49 | Batch: 1086 | Loss: 0.2104032803176371\n",
            "Epoch: 49 | Batch: 1087 | Loss: 0.1748912956963502\n",
            "Epoch: 49 | Batch: 1088 | Loss: 0.1608641685611502\n",
            "Epoch: 49 | Batch: 1089 | Loss: 0.13675909260675767\n",
            "Epoch: 49 | Batch: 1090 | Loss: 0.16746269383800522\n",
            "Epoch: 49 | Batch: 1091 | Loss: 0.18307719565564426\n",
            "Epoch: 49 | Batch: 1092 | Loss: 0.14193940744231348\n",
            "Epoch: 49 | Batch: 1093 | Loss: 0.1770327980779724\n",
            "Epoch: 49 | Batch: 1094 | Loss: 0.17225343637822993\n",
            "Epoch: 49 | Batch: 1095 | Loss: 0.14071680788300878\n",
            "Epoch: 49 | Batch: 1096 | Loss: 0.15999785728668353\n",
            "Epoch: 49 | Batch: 1097 | Loss: 0.13634505041707085\n",
            "Epoch: 49 | Batch: 1098 | Loss: 0.1593079162386866\n",
            "Epoch: 49 | Batch: 1099 | Loss: 0.18056627088189536\n",
            "Epoch: 49 | Batch: 1100 | Loss: 0.1633770761833129\n",
            "Epoch: 49 | Batch: 1101 | Loss: 0.17121286692969567\n",
            "Epoch: 49 | Batch: 1102 | Loss: 0.11728791174981458\n",
            "Epoch: 49 | Batch: 1103 | Loss: 0.14547901553991413\n",
            "Epoch: 49 | Batch: 1104 | Loss: 0.16136577498404836\n",
            "Epoch: 49 | Batch: 1105 | Loss: 0.1757957974741516\n",
            "Epoch: 49 | Batch: 1106 | Loss: 0.1498714698848577\n",
            "Epoch: 49 | Batch: 1107 | Loss: 0.14999602927966857\n",
            "Epoch: 49 | Batch: 1108 | Loss: 0.15281391273541134\n",
            "Epoch: 49 | Batch: 1109 | Loss: 0.18866949536589078\n",
            "Epoch: 49 | Batch: 1110 | Loss: 0.1563753493303956\n",
            "Epoch: 49 | Batch: 1111 | Loss: 0.18363325195754904\n",
            "Epoch: 49 | Batch: 1112 | Loss: 0.1420216150868418\n",
            "Epoch: 49 | Batch: 1113 | Loss: 0.15660119265072414\n",
            "Epoch: 49 | Batch: 1114 | Loss: 0.12856815884048134\n",
            "Epoch: 49 | Batch: 1115 | Loss: 0.1802235524304127\n",
            "Epoch: 49 | Batch: 1116 | Loss: 0.1522631819846324\n",
            "Epoch: 49 | Batch: 1117 | Loss: 0.11248215996098708\n",
            "Epoch: 49 | Batch: 1118 | Loss: 0.1896232633113406\n",
            "Epoch: 49 | Batch: 1119 | Loss: 0.18498541157884693\n",
            "Epoch: 49 | Batch: 1120 | Loss: 0.1689112453238451\n",
            "Epoch: 49 | Batch: 1121 | Loss: 0.15145124833401977\n",
            "Epoch: 49 | Batch: 1122 | Loss: 0.13969017028459463\n",
            "Epoch: 49 | Batch: 1123 | Loss: 0.15978864789927344\n",
            "Epoch: 49 | Batch: 1124 | Loss: 0.1304881694793469\n",
            "Epoch: 49 | Batch: 1125 | Loss: 0.16493587871591572\n",
            "Epoch: 49 | Batch: 1126 | Loss: 0.1538796631652267\n",
            "Epoch: 49 | Batch: 1127 | Loss: 0.19572167599422993\n",
            "Epoch: 49 | Batch: 1128 | Loss: 0.15954012057358186\n",
            "Epoch: 49 | Batch: 1129 | Loss: 0.1195935915747291\n",
            "Epoch: 49 | Batch: 1130 | Loss: 0.1381440342412702\n",
            "Epoch: 49 | Batch: 1131 | Loss: 0.12133312203910884\n",
            "Epoch: 49 | Batch: 1132 | Loss: 0.1483073591445958\n",
            "Epoch: 49 | Batch: 1133 | Loss: 0.1818072000332363\n",
            "Epoch: 49 | Batch: 1134 | Loss: 0.14069413902846656\n",
            "Epoch: 49 | Batch: 1135 | Loss: 0.16244524844470556\n",
            "Epoch: 49 | Batch: 1136 | Loss: 0.1418088777060488\n",
            "Epoch: 49 | Batch: 1137 | Loss: 0.13401556333693582\n",
            "Epoch: 49 | Batch: 1138 | Loss: 0.2300469294616688\n",
            "Epoch: 49 | Batch: 1139 | Loss: 0.19754052238494546\n",
            "Epoch: 49 | Batch: 1140 | Loss: 0.18095182812951704\n",
            "Epoch: 49 | Batch: 1141 | Loss: 0.17017452766023122\n",
            "Epoch: 49 | Batch: 1142 | Loss: 0.15391678168131623\n",
            "Epoch: 49 | Batch: 1143 | Loss: 0.1446690809492535\n",
            "Epoch: 49 | Batch: 1144 | Loss: 0.19093131394330815\n",
            "Epoch: 49 | Batch: 1145 | Loss: 0.15668698358321495\n",
            "Epoch: 49 | Batch: 1146 | Loss: 0.164529277781224\n",
            "Epoch: 49 | Batch: 1147 | Loss: 0.14360112521794088\n",
            "Epoch: 49 | Batch: 1148 | Loss: 0.12271370792149107\n",
            "Epoch: 49 | Batch: 1149 | Loss: 0.12013241286127793\n",
            "Epoch: 49 | Batch: 1150 | Loss: 0.13518248085749815\n",
            "Epoch: 49 | Batch: 1151 | Loss: 0.16554722554554313\n",
            "Epoch: 49 | Batch: 1152 | Loss: 0.16153478007422534\n",
            "Epoch: 49 | Batch: 1153 | Loss: 0.18851003334004718\n",
            "Epoch: 49 | Batch: 1154 | Loss: 0.13191898470660146\n",
            "Epoch: 49 | Batch: 1155 | Loss: 0.1778542954869751\n",
            "Epoch: 49 | Batch: 1156 | Loss: 0.1980217165441868\n",
            "Epoch: 49 | Batch: 1157 | Loss: 0.1131677969663446\n",
            "Epoch: 49 | Batch: 1158 | Loss: 0.1369983289198504\n",
            "Epoch: 49 | Batch: 1159 | Loss: 0.14245353499859634\n",
            "Epoch: 49 | Batch: 1160 | Loss: 0.17841540533351996\n",
            "Epoch: 49 | Batch: 1161 | Loss: 0.19915085108172018\n",
            "Epoch: 49 | Batch: 1162 | Loss: 0.12639519695096868\n",
            "Epoch: 49 | Batch: 1163 | Loss: 0.19469028147509193\n",
            "Epoch: 49 | Batch: 1164 | Loss: 0.20747514566857422\n",
            "Epoch: 49 | Batch: 1165 | Loss: 0.22473589053655454\n",
            "Epoch: 49 | Batch: 1166 | Loss: 0.17529504466253656\n",
            "Epoch: 49 | Batch: 1167 | Loss: 0.16595965552330116\n",
            "Epoch: 49 | Batch: 1168 | Loss: 0.13332807706441924\n",
            "Epoch: 49 | Batch: 1169 | Loss: 0.1691520685997567\n",
            "Epoch: 49 | Batch: 1170 | Loss: 0.18753752538516055\n",
            "Epoch: 49 | Batch: 1171 | Loss: 0.134011689496026\n",
            "Epoch: 49 | Batch: 1172 | Loss: 0.14914219609853463\n",
            "Epoch: 49 | Batch: 1173 | Loss: 0.14129741016131842\n",
            "Epoch: 49 | Batch: 1174 | Loss: 0.15378231599292252\n",
            "Epoch: 49 | Batch: 1175 | Loss: 0.16513401848317583\n",
            "Epoch: 49 | Batch: 1176 | Loss: 0.13644436070565694\n",
            "Epoch: 49 | Batch: 1177 | Loss: 0.15349575055470854\n",
            "Epoch: 49 | Batch: 1178 | Loss: 0.16370720778110628\n",
            "Epoch: 49 | Batch: 1179 | Loss: 0.19115852940740446\n",
            "Epoch: 49 | Batch: 1180 | Loss: 0.15987291513816604\n",
            "Epoch: 49 | Batch: 1181 | Loss: 0.15012660038792713\n",
            "Epoch: 49 | Batch: 1182 | Loss: 0.14970089855844607\n",
            "Epoch: 49 | Batch: 1183 | Loss: 0.12914032594851227\n",
            "Epoch: 49 | Batch: 1184 | Loss: 0.19522555319650173\n",
            "Epoch: 49 | Batch: 1185 | Loss: 0.21649853150155124\n",
            "Epoch: 49 | Batch: 1186 | Loss: 0.20197060909293363\n",
            "Epoch: 49 | Batch: 1187 | Loss: 0.13463264720210122\n",
            "Epoch: 49 | Batch: 1188 | Loss: 0.1443611572603459\n",
            "Epoch: 49 | Batch: 1189 | Loss: 0.18186405409575368\n",
            "Epoch: 49 | Batch: 1190 | Loss: 0.17397534279498095\n",
            "Epoch: 49 | Batch: 1191 | Loss: 0.17936727926018356\n",
            "Epoch: 49 | Batch: 1192 | Loss: 0.19567750267833725\n",
            "Epoch: 49 | Batch: 1193 | Loss: 0.18277228269746426\n",
            "Epoch: 49 | Batch: 1194 | Loss: 0.16858201841986942\n",
            "Epoch: 49 | Batch: 1195 | Loss: 0.1577411519855207\n",
            "Epoch: 49 | Batch: 1196 | Loss: 0.16409812945608254\n",
            "Epoch: 49 | Batch: 1197 | Loss: 0.14630780044386538\n",
            "Epoch: 49 | Batch: 1198 | Loss: 0.14653468420124674\n",
            "Epoch: 49 | Batch: 1199 | Loss: 0.16245414570544003\n",
            "Epoch: 49 | Batch: 1200 | Loss: 0.1653074695881006\n",
            "Epoch: 49 | Batch: 1201 | Loss: 0.1621702286787963\n",
            "Epoch: 49 | Batch: 1202 | Loss: 0.14715508296749824\n",
            "Epoch: 49 | Batch: 1203 | Loss: 0.15799905646478504\n",
            "Epoch: 49 | Batch: 1204 | Loss: 0.174635318325305\n",
            "Epoch: 49 | Batch: 1205 | Loss: 0.15146468309031752\n",
            "Epoch: 49 | Batch: 1206 | Loss: 0.139320555067736\n",
            "Epoch: 49 | Batch: 1207 | Loss: 0.19241924162599613\n",
            "Epoch: 49 | Batch: 1208 | Loss: 0.14651890774114773\n",
            "Epoch: 49 | Batch: 1209 | Loss: 0.15400913185051518\n",
            "Epoch: 49 | Batch: 1210 | Loss: 0.13594878326985385\n",
            "Epoch: 49 | Batch: 1211 | Loss: 0.16171469670613256\n",
            "Epoch: 49 | Batch: 1212 | Loss: 0.14834017913154984\n",
            "Epoch: 49 | Batch: 1213 | Loss: 0.2163442474547184\n",
            "Epoch: 49 | Batch: 1214 | Loss: 0.19924562433272008\n",
            "Epoch: 49 | Batch: 1215 | Loss: 0.14646483507561509\n",
            "Epoch: 49 | Batch: 1216 | Loss: 0.1572646495436713\n",
            "Epoch: 49 | Batch: 1217 | Loss: 0.1917903054310205\n",
            "Epoch: 49 | Batch: 1218 | Loss: 0.18968948170330505\n",
            "Epoch: 49 | Batch: 1219 | Loss: 0.1454461519918307\n",
            "Epoch: 49 | Batch: 1220 | Loss: 0.14431407005770455\n",
            "Epoch: 49 | Batch: 1221 | Loss: 0.12338358560851706\n",
            "Epoch: 49 | Batch: 1222 | Loss: 0.19189178570286716\n",
            "Epoch: 49 | Batch: 1223 | Loss: 0.13331707758171596\n",
            "Epoch: 49 | Batch: 1224 | Loss: 0.16533126860305103\n",
            "Epoch: 49 | Batch: 1225 | Loss: 0.18067376702678645\n",
            "Epoch: 49 | Batch: 1226 | Loss: 0.19062565061728068\n",
            "Epoch: 49 | Batch: 1227 | Loss: 0.1615591930707121\n",
            "Epoch: 49 | Batch: 1228 | Loss: 0.14400606641787064\n",
            "Epoch: 49 | Batch: 1229 | Loss: 0.18238408635052927\n",
            "Epoch: 49 | Batch: 1230 | Loss: 0.1508704211546724\n",
            "Epoch: 49 | Batch: 1231 | Loss: 0.14079174798336247\n",
            "Epoch: 49 | Batch: 1232 | Loss: 0.14790240422714246\n",
            "Epoch: 49 | Batch: 1233 | Loss: 0.18759298011111145\n",
            "Epoch: 49 | Batch: 1234 | Loss: 0.1786317742033948\n",
            "Epoch: 49 | Batch: 1235 | Loss: 0.1425840526219006\n",
            "Epoch: 49 | Batch: 1236 | Loss: 0.11617599323083605\n",
            "Epoch: 49 | Batch: 1237 | Loss: 0.18273057834139567\n",
            "Epoch: 49 | Batch: 1238 | Loss: 0.153219680245296\n",
            "Epoch: 49 | Batch: 1239 | Loss: 0.13178911929308382\n",
            "Epoch: 49 | Batch: 1240 | Loss: 0.18993244674483495\n",
            "Epoch: 49 | Batch: 1241 | Loss: 0.15934871547608442\n",
            "Epoch: 49 | Batch: 1242 | Loss: 0.15106323081929626\n",
            "Epoch: 49 | Batch: 1243 | Loss: 0.17657590952042307\n",
            "Epoch: 49 | Batch: 1244 | Loss: 0.17989768606940393\n",
            "Epoch: 49 | Batch: 1245 | Loss: 0.1391636617171168\n",
            "Epoch: 49 | Batch: 1246 | Loss: 0.1320796594839237\n",
            "Epoch: 49 | Batch: 1247 | Loss: 0.15959067180473813\n",
            "Epoch: 49 | Batch: 1248 | Loss: 0.16429532420641713\n",
            "Epoch: 49 | Batch: 1249 | Loss: 0.1555915073298476\n",
            "Epoch: 49 | Batch: 1250 | Loss: 0.18840785747668906\n",
            "Epoch: 49 | Batch: 1251 | Loss: 0.16842790996662815\n",
            "Epoch: 49 | Batch: 1252 | Loss: 0.15282446293860194\n",
            "Epoch: 49 | Batch: 1253 | Loss: 0.17775845285711073\n",
            "Epoch: 49 | Batch: 1254 | Loss: 0.24769859803797883\n",
            "Epoch: 49 | Batch: 1255 | Loss: 0.17766286428179195\n",
            "Epoch: 49 | Batch: 1256 | Loss: 0.14252800816071412\n",
            "Epoch: 49 | Batch: 1257 | Loss: 0.12986414522106207\n",
            "Epoch: 49 | Batch: 1258 | Loss: 0.14438383530821197\n",
            "Epoch: 49 | Batch: 1259 | Loss: 0.14074057490217728\n",
            "Epoch: 49 | Batch: 1260 | Loss: 0.2016384738670864\n",
            "Epoch: 49 | Batch: 1261 | Loss: 0.1857801595866521\n",
            "Epoch: 49 | Batch: 1262 | Loss: 0.1399116871787592\n",
            "Epoch: 49 | Batch: 1263 | Loss: 0.17833526747541473\n",
            "Epoch: 49 | Batch: 1264 | Loss: 0.12961520403165946\n",
            "Epoch: 49 | Batch: 1265 | Loss: 0.17120863258285945\n",
            "Epoch: 49 | Batch: 1266 | Loss: 0.14375946059563763\n",
            "Epoch: 49 | Batch: 1267 | Loss: 0.1487130544204205\n",
            "Epoch: 49 | Batch: 1268 | Loss: 0.18595930312136544\n",
            "Epoch: 49 | Batch: 1269 | Loss: 0.17955321085270104\n",
            "Epoch: 49 | Batch: 1270 | Loss: 0.17213669408654603\n",
            "Epoch: 49 | Batch: 1271 | Loss: 0.17614931085770014\n",
            "Epoch: 49 | Batch: 1272 | Loss: 0.10697596812489832\n",
            "Epoch: 49 | Batch: 1273 | Loss: 0.1298405781333796\n",
            "Epoch: 49 | Batch: 1274 | Loss: 0.11676348395971209\n",
            "Epoch: 49 | Batch: 1275 | Loss: 0.1772366518020511\n",
            "Epoch: 49 | Batch: 1276 | Loss: 0.15849007387395062\n",
            "Epoch: 49 | Batch: 1277 | Loss: 0.17052370097696884\n",
            "Epoch: 49 | Batch: 1278 | Loss: 0.12554005011046626\n",
            "Epoch: 49 | Batch: 1279 | Loss: 0.16382539914062666\n",
            "Epoch: 49 | Batch: 1280 | Loss: 0.15507226378095537\n",
            "Epoch: 49 | Batch: 1281 | Loss: 0.16412761683797486\n",
            "Epoch: 49 | Batch: 1282 | Loss: 0.19211582363998367\n",
            "Epoch: 49 | Batch: 1283 | Loss: 0.1650340922819409\n",
            "Epoch: 49 | Batch: 1284 | Loss: 0.20296466609638908\n",
            "Epoch: 49 | Batch: 1285 | Loss: 0.1492985952648057\n",
            "Epoch: 49 | Batch: 1286 | Loss: 0.17758670759905376\n",
            "Epoch: 49 | Batch: 1287 | Loss: 0.15207438680579438\n",
            "Epoch: 49 | Batch: 1288 | Loss: 0.16064646160615664\n",
            "Epoch: 49 | Batch: 1289 | Loss: 0.17976066956587988\n",
            "Epoch: 49 | Batch: 1290 | Loss: 0.14183471480368318\n",
            "Epoch: 49 | Batch: 1291 | Loss: 0.2410862473211112\n",
            "Epoch: 49 | Batch: 1292 | Loss: 0.13337796980973238\n",
            "Epoch: 49 | Batch: 1293 | Loss: 0.15771960507252616\n",
            "Epoch: 49 | Batch: 1294 | Loss: 0.1600671256042317\n",
            "Epoch: 49 | Batch: 1295 | Loss: 0.11268378561635373\n",
            "Epoch: 49 | Batch: 1296 | Loss: 0.152503425267172\n",
            "Epoch: 49 | Batch: 1297 | Loss: 0.16788034560201312\n",
            "Epoch: 49 | Batch: 1298 | Loss: 0.16717161432986435\n",
            "Epoch: 49 | Batch: 1299 | Loss: 0.15448906522191488\n",
            "Epoch: 49 | Batch: 1300 | Loss: 0.13929385369238728\n",
            "Epoch: 49 | Batch: 1301 | Loss: 0.16184183114761239\n",
            "Epoch: 49 | Batch: 1302 | Loss: 0.17610079630674458\n",
            "Epoch: 49 | Batch: 1303 | Loss: 0.20415759466666403\n",
            "Epoch: 49 | Batch: 1304 | Loss: 0.12817689628563864\n",
            "Epoch: 49 | Batch: 1305 | Loss: 0.19648656559293254\n",
            "Epoch: 49 | Batch: 1306 | Loss: 0.21753319055214868\n",
            "Epoch: 49 | Batch: 1307 | Loss: 0.15159680124568659\n",
            "Epoch: 49 | Batch: 1308 | Loss: 0.1760649036792398\n",
            "Epoch: 49 | Batch: 1309 | Loss: 0.15026743233859102\n",
            "Epoch: 49 | Batch: 1310 | Loss: 0.1649593708073305\n",
            "Epoch: 49 | Batch: 1311 | Loss: 0.16154550321652997\n",
            "Epoch: 49 | Batch: 1312 | Loss: 0.2146727060794303\n",
            "Epoch: 49 | Batch: 1313 | Loss: 0.1592333340438644\n",
            "Epoch: 49 | Batch: 1314 | Loss: 0.17271536002764196\n",
            "Epoch: 49 | Batch: 1315 | Loss: 0.16277806196970468\n",
            "Epoch: 49 | Batch: 1316 | Loss: 0.19464765827326028\n",
            "Epoch: 49 | Batch: 1317 | Loss: 0.19038115002594605\n",
            "Epoch: 49 | Batch: 1318 | Loss: 0.14904498677494316\n",
            "Epoch: 49 | Batch: 1319 | Loss: 0.18952659023573556\n",
            "Epoch: 49 | Batch: 1320 | Loss: 0.12514153642264747\n",
            "Epoch: 49 | Batch: 1321 | Loss: 0.14862677970474114\n",
            "Epoch: 49 | Batch: 1322 | Loss: 0.12441824470077317\n",
            "Epoch: 49 | Batch: 1323 | Loss: 0.14246441886163907\n",
            "Epoch: 49 | Batch: 1324 | Loss: 0.1715463698134093\n",
            "Epoch: 49 | Batch: 1325 | Loss: 0.1459704990212506\n",
            "Epoch: 49 | Batch: 1326 | Loss: 0.1204285797603569\n",
            "Epoch: 49 | Batch: 1327 | Loss: 0.12486096900100943\n",
            "Epoch: 49 | Batch: 1328 | Loss: 0.1360443465134839\n",
            "Epoch: 49 | Batch: 1329 | Loss: 0.14402383973380867\n",
            "Epoch: 49 | Batch: 1330 | Loss: 0.144505647842878\n",
            "Epoch: 49 | Batch: 1331 | Loss: 0.15755279501095784\n",
            "Epoch: 49 | Batch: 1332 | Loss: 0.17010346720115307\n",
            "Epoch: 49 | Batch: 1333 | Loss: 0.14903022832899612\n",
            "Epoch: 49 | Batch: 1334 | Loss: 0.1697262440261597\n",
            "Epoch: 49 | Batch: 1335 | Loss: 0.1488300987184359\n",
            "Epoch: 49 | Batch: 1336 | Loss: 0.20490635829734552\n",
            "Epoch: 49 | Batch: 1337 | Loss: 0.20470544160729653\n",
            "Epoch: 49 | Batch: 1338 | Loss: 0.161726998226133\n",
            "Epoch: 49 | Batch: 1339 | Loss: 0.1339550923312619\n",
            "Epoch: 49 | Batch: 1340 | Loss: 0.14556662550819488\n",
            "Epoch: 49 | Batch: 1341 | Loss: 0.16806478124655444\n",
            "Epoch: 49 | Batch: 1342 | Loss: 0.1814654864253052\n",
            "Epoch: 49 | Batch: 1343 | Loss: 0.18249106463033699\n",
            "Epoch: 49 | Batch: 1344 | Loss: 0.19926905099707357\n",
            "Epoch: 49 | Batch: 1345 | Loss: 0.15179503504966693\n",
            "Epoch: 49 | Batch: 1346 | Loss: 0.1407950484496846\n",
            "Epoch: 49 | Batch: 1347 | Loss: 0.15222597810066688\n",
            "Epoch: 49 | Batch: 1348 | Loss: 0.17792078684749907\n",
            "Epoch: 49 | Batch: 1349 | Loss: 0.17596473449321323\n",
            "Epoch: 49 | Batch: 1350 | Loss: 0.1610022717707562\n",
            "Epoch: 49 | Batch: 1351 | Loss: 0.1500521532967885\n",
            "Epoch: 49 | Batch: 1352 | Loss: 0.197647362987881\n",
            "Epoch: 49 | Batch: 1353 | Loss: 0.17387537209642176\n",
            "Epoch: 49 | Batch: 1354 | Loss: 0.11219501559530579\n",
            "Epoch: 49 | Batch: 1355 | Loss: 0.12346430473078064\n",
            "Epoch: 49 | Batch: 1356 | Loss: 0.13006890432420512\n",
            "Epoch: 49 | Batch: 1357 | Loss: 0.16983140643750871\n",
            "Epoch: 49 | Batch: 1358 | Loss: 0.17178149223969702\n",
            "Epoch: 49 | Batch: 1359 | Loss: 0.17580467475520997\n",
            "Epoch: 49 | Batch: 1360 | Loss: 0.21240735267707897\n",
            "Epoch: 49 | Batch: 1361 | Loss: 0.2275100464189713\n",
            "Epoch: 49 | Batch: 1362 | Loss: 0.19537000108669417\n",
            "Epoch: 49 | Batch: 1363 | Loss: 0.13321536764234443\n",
            "Epoch: 49 | Batch: 1364 | Loss: 0.20606836480562463\n",
            "Epoch: 49 | Batch: 1365 | Loss: 0.18833465391815687\n",
            "Epoch: 49 | Batch: 1366 | Loss: 0.13388052162321754\n",
            "Epoch: 49 | Batch: 1367 | Loss: 0.19421381086136758\n",
            "Epoch: 49 | Batch: 1368 | Loss: 0.18739230760814624\n",
            "Epoch: 49 | Batch: 1369 | Loss: 0.17257871766961624\n",
            "Epoch: 49 | Batch: 1370 | Loss: 0.13373716021728974\n",
            "Epoch: 49 | Batch: 1371 | Loss: 0.11146138038300207\n",
            "Epoch: 49 | Batch: 1372 | Loss: 0.1633790829015598\n",
            "Epoch: 49 | Batch: 1373 | Loss: 0.1639993991003238\n",
            "Epoch: 49 | Batch: 1374 | Loss: 0.18783858714639362\n",
            "Epoch: 49 | Batch: 1375 | Loss: 0.18619194850922177\n",
            "Epoch: 49 | Batch: 1376 | Loss: 0.12400354461798935\n",
            "Epoch: 49 | Batch: 1377 | Loss: 0.17456033877020177\n",
            "Epoch: 49 | Batch: 1378 | Loss: 0.13982826165702672\n",
            "Epoch: 49 | Batch: 1379 | Loss: 0.1472373530525514\n",
            "Epoch: 49 | Batch: 1380 | Loss: 0.2044195962706632\n",
            "Epoch: 49 | Batch: 1381 | Loss: 0.14603301432872323\n",
            "Epoch: 49 | Batch: 1382 | Loss: 0.1727385604354152\n",
            "Epoch: 49 | Batch: 1383 | Loss: 0.20845085023433318\n",
            "Epoch: 49 | Batch: 1384 | Loss: 0.2182466495667684\n",
            "Epoch: 49 | Batch: 1385 | Loss: 0.14458380957312977\n",
            "Epoch: 49 | Batch: 1386 | Loss: 0.1504464917801867\n",
            "Epoch: 49 | Batch: 1387 | Loss: 0.19214048981876442\n",
            "Epoch: 49 | Batch: 1388 | Loss: 0.16408057621693636\n",
            "Epoch: 49 | Batch: 1389 | Loss: 0.20789525562951744\n",
            "Epoch: 49 | Batch: 1390 | Loss: 0.17976443682710286\n",
            "Epoch: 49 | Batch: 1391 | Loss: 0.1914487890265959\n",
            "Epoch: 49 | Batch: 1392 | Loss: 0.15054575794362965\n",
            "Epoch: 49 | Batch: 1393 | Loss: 0.1335444754861791\n",
            "Epoch: 49 | Batch: 1394 | Loss: 0.1423154798797543\n",
            "Epoch: 49 | Batch: 1395 | Loss: 0.1635972220819607\n",
            "Epoch: 49 | Batch: 1396 | Loss: 0.18215561886435128\n",
            "Epoch: 49 | Batch: 1397 | Loss: 0.153295718859996\n",
            "Epoch: 49 | Batch: 1398 | Loss: 0.13868347649833723\n",
            "Epoch: 49 | Batch: 1399 | Loss: 0.14907046687361952\n",
            "Epoch: 49 | Batch: 1400 | Loss: 0.14057976901064465\n",
            "Epoch: 49 | Batch: 1401 | Loss: 0.16578623889582128\n",
            "Epoch: 49 | Batch: 1402 | Loss: 0.16972384342290936\n",
            "Epoch: 49 | Batch: 1403 | Loss: 0.16452398989718076\n",
            "Epoch: 49 | Batch: 1404 | Loss: 0.14397332635728868\n",
            "Epoch: 49 | Batch: 1405 | Loss: 0.14426290660010316\n",
            "Epoch: 49 | Batch: 1406 | Loss: 0.13284826158085594\n",
            "Epoch: 49 | Batch: 1407 | Loss: 0.1214630897768465\n",
            "Epoch: 49 | Batch: 1408 | Loss: 0.15868554662869125\n",
            "Epoch: 49 | Batch: 1409 | Loss: 0.1690852029608929\n",
            "Epoch: 49 | Batch: 1410 | Loss: 0.16047878335682106\n",
            "Epoch: 49 | Batch: 1411 | Loss: 0.14036900647809747\n",
            "Epoch: 49 | Batch: 1412 | Loss: 0.14792262666574624\n",
            "Epoch: 49 | Batch: 1413 | Loss: 0.13318106900474547\n",
            "Epoch: 49 | Batch: 1414 | Loss: 0.15350485654992557\n",
            "Epoch: 49 | Batch: 1415 | Loss: 0.19985307791285395\n",
            "Epoch: 49 | Batch: 1416 | Loss: 0.1643907645800731\n",
            "Epoch: 49 | Batch: 1417 | Loss: 0.1477008225556187\n",
            "Epoch: 49 | Batch: 1418 | Loss: 0.17212727568118172\n",
            "Epoch: 49 | Batch: 1419 | Loss: 0.14765939378813175\n",
            "Epoch: 49 | Batch: 1420 | Loss: 0.14096716803835624\n",
            "Epoch: 49 | Batch: 1421 | Loss: 0.17987082015618105\n",
            "Epoch: 49 | Batch: 1422 | Loss: 0.14344597904550888\n",
            "Epoch: 49 | Batch: 1423 | Loss: 0.15454654614309024\n",
            "Epoch: 49 | Batch: 1424 | Loss: 0.17371961004448208\n",
            "Epoch: 49 | Batch: 1425 | Loss: 0.12380878076985415\n",
            "Epoch: 49 | Batch: 1426 | Loss: 0.171041465018749\n",
            "Epoch: 49 | Batch: 1427 | Loss: 0.13629770368306082\n",
            "Epoch: 49 | Batch: 1428 | Loss: 0.18869294288369834\n",
            "Epoch: 49 | Batch: 1429 | Loss: 0.151275541323044\n",
            "Epoch: 49 | Batch: 1430 | Loss: 0.16706828217375777\n",
            "Epoch: 49 | Batch: 1431 | Loss: 0.19554694470418446\n",
            "Epoch: 49 | Batch: 1432 | Loss: 0.15640760839871484\n",
            "Epoch: 49 | Batch: 1433 | Loss: 0.17727983194181596\n",
            "Epoch: 49 | Batch: 1434 | Loss: 0.14113462753804884\n",
            "Epoch: 49 | Batch: 1435 | Loss: 0.18373077049371886\n",
            "Epoch: 49 | Batch: 1436 | Loss: 0.17173460810116964\n",
            "Epoch: 49 | Batch: 1437 | Loss: 0.13890479742931242\n",
            "Epoch: 49 | Batch: 1438 | Loss: 0.1921776947799231\n",
            "Epoch: 49 | Batch: 1439 | Loss: 0.19785921721368124\n",
            "Epoch: 49 | Batch: 1440 | Loss: 0.16887098058085362\n",
            "Epoch: 49 | Batch: 1441 | Loss: 0.19990390974314556\n",
            "Epoch: 49 | Batch: 1442 | Loss: 0.20384782605094282\n",
            "Epoch: 49 | Batch: 1443 | Loss: 0.17744061923822949\n",
            "Epoch: 49 | Batch: 1444 | Loss: 0.17268328683410725\n",
            "Epoch: 49 | Batch: 1445 | Loss: 0.18247498683980365\n",
            "Epoch: 49 | Batch: 1446 | Loss: 0.170424114031515\n",
            "Epoch: 49 | Batch: 1447 | Loss: 0.17586189705120303\n",
            "Epoch: 49 | Batch: 1448 | Loss: 0.18005750373119445\n",
            "Epoch: 49 | Batch: 1449 | Loss: 0.17538089651570432\n",
            "Epoch: 49 | Batch: 1450 | Loss: 0.1723924719574929\n",
            "Epoch: 49 | Batch: 1451 | Loss: 0.16619211604278894\n",
            "Epoch: 49 | Batch: 1452 | Loss: 0.17444826814707892\n",
            "Epoch: 49 | Batch: 1453 | Loss: 0.16778009858425214\n",
            "Epoch: 49 | Batch: 1454 | Loss: 0.15757996278056752\n",
            "Epoch: 49 | Batch: 1455 | Loss: 0.17502950075484336\n",
            "Epoch: 49 | Batch: 1456 | Loss: 0.1563216692538611\n",
            "Epoch: 49 | Batch: 1457 | Loss: 0.16832735546990518\n",
            "Epoch: 49 | Batch: 1458 | Loss: 0.1926515112970413\n",
            "Epoch: 49 | Batch: 1459 | Loss: 0.13882047119116167\n",
            "Epoch: 49 | Batch: 1460 | Loss: 0.15902182568630208\n",
            "Epoch: 49 | Batch: 1461 | Loss: 0.1631300657307192\n",
            "Epoch: 49 | Batch: 1462 | Loss: 0.1257048890283207\n",
            "Epoch: 49 | Batch: 1463 | Loss: 0.17722542552386847\n",
            "Epoch: 49 | Batch: 1464 | Loss: 0.1626619828256496\n",
            "Epoch: 49 | Batch: 1465 | Loss: 0.19636503986604728\n",
            "Epoch: 49 | Batch: 1466 | Loss: 0.12841040535650172\n",
            "Epoch: 49 | Batch: 1467 | Loss: 0.1503047863625518\n",
            "Epoch: 49 | Batch: 1468 | Loss: 0.2035773445659248\n",
            "Epoch: 49 | Batch: 1469 | Loss: 0.16896091342769246\n",
            "Epoch: 49 | Batch: 1470 | Loss: 0.1609810880748756\n",
            "Epoch: 49 | Batch: 1471 | Loss: 0.15652427744607972\n",
            "Epoch: 49 | Batch: 1472 | Loss: 0.14256677121283112\n",
            "Epoch: 49 | Batch: 1473 | Loss: 0.1741938516450255\n",
            "Epoch: 49 | Batch: 1474 | Loss: 0.16417563556190995\n",
            "Epoch: 49 | Batch: 1475 | Loss: 0.1430655199584853\n",
            "Epoch: 49 | Batch: 1476 | Loss: 0.2192248389738913\n",
            "Epoch: 49 | Batch: 1477 | Loss: 0.1864099447735433\n",
            "Epoch: 49 | Batch: 1478 | Loss: 0.16683333120511573\n",
            "Epoch: 49 | Batch: 1479 | Loss: 0.21682860228375955\n",
            "Epoch: 49 | Batch: 1480 | Loss: 0.11512455492043921\n",
            "Epoch: 49 | Batch: 1481 | Loss: 0.18001772875603833\n",
            "Epoch: 49 | Batch: 1482 | Loss: 0.14791860806292456\n",
            "Epoch: 49 | Batch: 1483 | Loss: 0.2238123745511752\n",
            "Epoch: 49 | Batch: 1484 | Loss: 0.16116294321465585\n",
            "Epoch: 49 | Batch: 1485 | Loss: 0.2011783767555408\n",
            "Epoch: 49 | Batch: 1486 | Loss: 0.2100682729621924\n",
            "Epoch: 49 | Batch: 1487 | Loss: 0.1591968904092164\n",
            "Epoch: 49 | Batch: 1488 | Loss: 0.17306665159501886\n",
            "Epoch: 49 | Batch: 1489 | Loss: 0.18691506833688012\n",
            "Epoch: 49 | Batch: 1490 | Loss: 0.17775914962084416\n",
            "Epoch: 49 | Batch: 1491 | Loss: 0.1716511854878464\n",
            "Epoch: 49 | Batch: 1492 | Loss: 0.18084048297186184\n",
            "Epoch: 49 | Batch: 1493 | Loss: 0.12228556303580887\n",
            "Epoch: 49 | Batch: 1494 | Loss: 0.20272452096099947\n",
            "Epoch: 49 | Batch: 1495 | Loss: 0.16267229752682233\n",
            "Epoch: 49 | Batch: 1496 | Loss: 0.16342711745086166\n",
            "Epoch: 49 | Batch: 1497 | Loss: 0.13987550351466244\n",
            "Epoch: 49 | Batch: 1498 | Loss: 0.2309320626895906\n",
            "Epoch: 49 | Batch: 1499 | Loss: 0.16625270590747498\n",
            "Epoch: 49 | Batch: 1500 | Loss: 0.1698680811080659\n",
            "Epoch: 49 | Batch: 1501 | Loss: 0.15657306592183187\n",
            "Epoch: 49 | Batch: 1502 | Loss: 0.1390557973421404\n",
            "Epoch: 49 | Batch: 1503 | Loss: 0.14986486276715752\n",
            "Epoch: 49 | Batch: 1504 | Loss: 0.1794295079985388\n",
            "Epoch: 49 | Batch: 1505 | Loss: 0.14473058039128495\n",
            "Epoch: 49 | Batch: 1506 | Loss: 0.14827289496665008\n",
            "Epoch: 49 | Batch: 1507 | Loss: 0.1922567106515291\n",
            "Epoch: 49 | Batch: 1508 | Loss: 0.17456234027722442\n",
            "Epoch: 49 | Batch: 1509 | Loss: 0.14885717467392942\n",
            "Epoch: 49 | Batch: 1510 | Loss: 0.14693614068730823\n",
            "Epoch: 49 | Batch: 1511 | Loss: 0.16936427030141077\n",
            "Epoch: 49 | Batch: 1512 | Loss: 0.17652475785718894\n",
            "Epoch: 49 | Batch: 1513 | Loss: 0.20809338002943317\n",
            "Epoch: 49 | Batch: 1514 | Loss: 0.16456344921588933\n",
            "Epoch: 49 | Batch: 1515 | Loss: 0.13175332783374685\n",
            "Epoch: 49 | Batch: 1516 | Loss: 0.15023566530122787\n",
            "Epoch: 49 | Batch: 1517 | Loss: 0.16805573785262215\n",
            "Epoch: 49 | Batch: 1518 | Loss: 0.16564465370536693\n",
            "Epoch: 49 | Batch: 1519 | Loss: 0.1512787018365873\n",
            "Epoch: 49 | Batch: 1520 | Loss: 0.15417065202761515\n",
            "Epoch: 49 | Batch: 1521 | Loss: 0.15947607910046413\n",
            "Epoch: 49 | Batch: 1522 | Loss: 0.2437126438428932\n",
            "Epoch: 49 | Batch: 1523 | Loss: 0.11759095762850486\n",
            "Epoch: 49 | Batch: 1524 | Loss: 0.1526624279676298\n",
            "Epoch: 49 | Batch: 1525 | Loss: 0.1415180347866199\n",
            "Epoch: 49 | Batch: 1526 | Loss: 0.14223360466347837\n",
            "Epoch: 49 | Batch: 1527 | Loss: 0.15233513732789547\n",
            "Epoch: 49 | Batch: 1528 | Loss: 0.11923049350755219\n",
            "Epoch: 49 | Batch: 1529 | Loss: 0.1801303548797818\n",
            "Epoch: 49 | Batch: 1530 | Loss: 0.1962897394911385\n",
            "Epoch: 49 | Batch: 1531 | Loss: 0.20769804209813436\n",
            "Epoch: 49 | Batch: 1532 | Loss: 0.17347787438768728\n",
            "Epoch: 49 | Batch: 1533 | Loss: 0.2701956936913178\n",
            "Epoch: 49 | Batch: 1534 | Loss: 0.18490786370120543\n",
            "Epoch: 49 | Batch: 1535 | Loss: 0.15733806994437738\n",
            "Epoch: 49 | Batch: 1536 | Loss: 0.15880834324510856\n",
            "Epoch: 49 | Batch: 1537 | Loss: 0.19594925368994445\n",
            "Epoch: 49 | Batch: 1538 | Loss: 0.2057977982610245\n",
            "Epoch: 49 | Batch: 1539 | Loss: 0.16598548512004246\n",
            "Epoch: 49 | Batch: 1540 | Loss: 0.1701981841396322\n",
            "Epoch: 49 | Batch: 1541 | Loss: 0.17741043499322187\n",
            "Epoch: 49 | Batch: 1542 | Loss: 0.13859622468591257\n",
            "Epoch: 49 | Batch: 1543 | Loss: 0.15381617743920578\n",
            "Epoch: 49 | Batch: 1544 | Loss: 0.11878818352036027\n",
            "Epoch: 49 | Batch: 1545 | Loss: 0.12319445318938999\n",
            "Epoch: 49 | Batch: 1546 | Loss: 0.17957793967451574\n",
            "Epoch: 49 | Batch: 1547 | Loss: 0.19214864537579174\n",
            "Epoch: 49 | Batch: 1548 | Loss: 0.15744440443792795\n",
            "Epoch: 49 | Batch: 1549 | Loss: 0.14842669908242354\n",
            "Epoch: 49 | Batch: 1550 | Loss: 0.14909245150365874\n",
            "Epoch: 49 | Batch: 1551 | Loss: 0.22896608497633011\n",
            "Epoch: 49 | Batch: 1552 | Loss: 0.20534192603446919\n",
            "Epoch: 49 | Batch: 1553 | Loss: 0.1817208401016649\n",
            "Epoch: 49 | Batch: 1554 | Loss: 0.18659201629605096\n",
            "Epoch: 49 | Batch: 1555 | Loss: 0.17037142665195365\n",
            "Epoch: 49 | Batch: 1556 | Loss: 0.1635651095255153\n",
            "Epoch: 49 | Batch: 1557 | Loss: 0.20291758890009842\n",
            "Epoch: 49 | Batch: 1558 | Loss: 0.16147821867371062\n",
            "Epoch: 49 | Batch: 1559 | Loss: 0.19255869808740014\n",
            "Epoch: 49 | Batch: 1560 | Loss: 0.17983241383576593\n",
            "Epoch: 49 | Batch: 1561 | Loss: 0.18511091439699068\n",
            "Epoch: 49 | Batch: 1562 | Loss: 0.20933137015382844\n",
            "Epoch: 49 | Batch: 1563 | Loss: 0.17423376931585455\n",
            "Epoch: 49 | Batch: 1564 | Loss: 0.14737508298050736\n",
            "Epoch: 49 | Batch: 1565 | Loss: 0.15258399447749427\n",
            "Epoch: 49 | Batch: 1566 | Loss: 0.16218814613610258\n",
            "Epoch: 49 | Batch: 1567 | Loss: 0.17368484430368972\n",
            "Epoch: 49 | Batch: 1568 | Loss: 0.16964999045322948\n",
            "Epoch: 49 | Batch: 1569 | Loss: 0.15662278272521069\n",
            "Epoch: 49 | Batch: 1570 | Loss: 0.1219571098601148\n",
            "Epoch: 49 | Batch: 1571 | Loss: 0.15038207047431554\n",
            "Epoch: 49 | Batch: 1572 | Loss: 0.19526534398220005\n",
            "Epoch: 49 | Batch: 1573 | Loss: 0.16723805504806355\n",
            "Epoch: 49 | Batch: 1574 | Loss: 0.14280058324507994\n",
            "Epoch: 49 | Batch: 1575 | Loss: 0.1791814839116876\n",
            "Epoch: 49 | Batch: 1576 | Loss: 0.1631830820706245\n",
            "Epoch: 49 | Batch: 1577 | Loss: 0.1638668255112728\n",
            "Epoch: 49 | Batch: 1578 | Loss: 0.16073686763839745\n",
            "Epoch: 49 | Batch: 1579 | Loss: 0.19210125295662117\n",
            "Epoch: 49 | Batch: 1580 | Loss: 0.15666773523395935\n",
            "Epoch: 49 | Batch: 1581 | Loss: 0.1926940878384284\n",
            "Epoch: 49 | Batch: 1582 | Loss: 0.15484092852839526\n",
            "Epoch: 49 | Batch: 1583 | Loss: 0.18095484731625797\n",
            "Epoch: 49 | Batch: 1584 | Loss: 0.16845826214722057\n",
            "Epoch: 49 | Batch: 1585 | Loss: 0.18175278443466622\n",
            "Epoch: 49 | Batch: 1586 | Loss: 0.20444850157456793\n",
            "Epoch: 49 | Batch: 1587 | Loss: 0.132629829413345\n",
            "Epoch: 49 | Batch: 1588 | Loss: 0.13915254720104173\n",
            "Epoch: 49 | Batch: 1589 | Loss: 0.2043982476407113\n",
            "Epoch: 49 | Batch: 1590 | Loss: 0.17007978365186932\n",
            "Epoch: 49 | Batch: 1591 | Loss: 0.19974698465422683\n",
            "Epoch: 49 | Batch: 1592 | Loss: 0.17192415772994282\n",
            "Epoch: 49 | Batch: 1593 | Loss: 0.1490552321042267\n",
            "Epoch: 49 | Batch: 1594 | Loss: 0.2452806230922479\n",
            "Epoch: 49 | Batch: 1595 | Loss: 0.16701006418140618\n",
            "Epoch: 49 | Batch: 1596 | Loss: 0.15330810039835718\n",
            "Epoch: 49 | Batch: 1597 | Loss: 0.18228113704273535\n",
            "Epoch: 49 | Batch: 1598 | Loss: 0.17502374882700364\n",
            "Epoch: 49 | Batch: 1599 | Loss: 0.143656223040407\n",
            "Epoch: 49 | Batch: 1600 | Loss: 0.19486059241276557\n",
            "Epoch: 49 | Batch: 1601 | Loss: 0.13334904666854103\n",
            "Epoch: 49 | Batch: 1602 | Loss: 0.14491262344587919\n",
            "Epoch: 49 | Batch: 1603 | Loss: 0.14315008341872704\n",
            "Epoch: 49 | Batch: 1604 | Loss: 0.17968479343118526\n",
            "Epoch: 49 | Batch: 1605 | Loss: 0.11926984419758903\n",
            "Epoch: 49 | Batch: 1606 | Loss: 0.19816325740491078\n",
            "Epoch: 49 | Batch: 1607 | Loss: 0.14265865240971717\n",
            "Epoch: 49 | Batch: 1608 | Loss: 0.22614399489037848\n",
            "Epoch: 49 | Batch: 1609 | Loss: 0.16651333121815193\n",
            "Epoch: 49 | Batch: 1610 | Loss: 0.14983655374876187\n",
            "Epoch: 49 | Batch: 1611 | Loss: 0.11618979925252482\n",
            "Epoch: 49 | Batch: 1612 | Loss: 0.14964319091916378\n",
            "Epoch: 49 | Batch: 1613 | Loss: 0.1476623285331787\n",
            "Epoch: 49 | Batch: 1614 | Loss: 0.17457267768399087\n",
            "Epoch: 49 | Batch: 1615 | Loss: 0.13825600434049581\n",
            "Epoch: 49 | Batch: 1616 | Loss: 0.15599642001425212\n",
            "Epoch: 49 | Batch: 1617 | Loss: 0.18533014725352143\n",
            "Epoch: 49 | Batch: 1618 | Loss: 0.1865387604406765\n",
            "Epoch: 49 | Batch: 1619 | Loss: 0.14280636562504098\n",
            "Epoch: 49 | Batch: 1620 | Loss: 0.14555219697239463\n",
            "Epoch: 49 | Batch: 1621 | Loss: 0.18026085539409553\n",
            "Epoch: 49 | Batch: 1622 | Loss: 0.1569755158857605\n",
            "Epoch: 49 | Batch: 1623 | Loss: 0.1831415426585248\n",
            "Epoch: 49 | Batch: 1624 | Loss: 0.18116371358200709\n",
            "Epoch: 49 | Batch: 1625 | Loss: 0.15996877059271952\n",
            "Epoch: 49 | Batch: 1626 | Loss: 0.12878642071869553\n",
            "Epoch: 49 | Batch: 1627 | Loss: 0.18286981830419477\n",
            "Epoch: 49 | Batch: 1628 | Loss: 0.1806097422269722\n",
            "Epoch: 49 | Batch: 1629 | Loss: 0.1847574916780704\n",
            "Epoch: 49 | Batch: 1630 | Loss: 0.16225532949233562\n",
            "Epoch: 49 | Batch: 1631 | Loss: 0.16982212846159042\n",
            "Epoch: 49 | Batch: 1632 | Loss: 0.14310250860270354\n",
            "Epoch: 49 | Batch: 1633 | Loss: 0.2117090471849419\n",
            "Epoch: 49 | Batch: 1634 | Loss: 0.14785445155373228\n",
            "Epoch: 49 | Batch: 1635 | Loss: 0.11759288865665639\n",
            "Epoch: 49 | Batch: 1636 | Loss: 0.16081147129823922\n",
            "Epoch: 49 | Batch: 1637 | Loss: 0.17829294116168357\n",
            "Epoch: 49 | Batch: 1638 | Loss: 0.18751485835654\n",
            "Epoch: 49 | Batch: 1639 | Loss: 0.17164998140973126\n",
            "Epoch: 49 | Batch: 1640 | Loss: 0.140603164598103\n",
            "Epoch: 49 | Batch: 1641 | Loss: 0.1705750244642213\n",
            "Epoch: 49 | Batch: 1642 | Loss: 0.17012672234246384\n",
            "Epoch: 49 | Batch: 1643 | Loss: 0.1737839325554917\n",
            "Epoch: 49 | Batch: 1644 | Loss: 0.16602084942561496\n",
            "Epoch: 49 | Batch: 1645 | Loss: 0.15506731191896697\n",
            "Epoch: 49 | Batch: 1646 | Loss: 0.1888137409655771\n",
            "Epoch: 49 | Batch: 1647 | Loss: 0.16937182061189476\n",
            "Epoch: 49 | Batch: 1648 | Loss: 0.15607015060244567\n",
            "Epoch: 49 | Batch: 1649 | Loss: 0.16426595785968615\n",
            "Epoch: 49 | Batch: 1650 | Loss: 0.17276006820095705\n",
            "Epoch: 49 | Batch: 1651 | Loss: 0.18400440900156198\n",
            "Epoch: 49 | Batch: 1652 | Loss: 0.17054733983724124\n",
            "Epoch: 49 | Batch: 1653 | Loss: 0.1961529656395477\n",
            "Epoch: 49 | Batch: 1654 | Loss: 0.10742528606472063\n",
            "Epoch: 49 | Batch: 1655 | Loss: 0.1493477086626337\n",
            "Epoch: 49 | Batch: 1656 | Loss: 0.14319133532342912\n",
            "Epoch: 49 | Batch: 1657 | Loss: 0.2030798761103274\n",
            "Epoch: 49 | Batch: 1658 | Loss: 0.16498709612380474\n",
            "Epoch: 49 | Batch: 1659 | Loss: 0.14468321703398945\n",
            "Epoch: 49 | Batch: 1660 | Loss: 0.158097623064544\n",
            "Epoch: 49 | Batch: 1661 | Loss: 0.15362489005787888\n",
            "Epoch: 49 | Batch: 1662 | Loss: 0.14327749171102064\n",
            "Epoch: 49 | Batch: 1663 | Loss: 0.18672310427412384\n",
            "Epoch: 49 | Batch: 1664 | Loss: 0.17768945571751943\n",
            "Epoch: 49 | Batch: 1665 | Loss: 0.16108370360469249\n",
            "Epoch: 49 | Batch: 1666 | Loss: 0.14758924393628892\n",
            "Epoch: 49 | Batch: 1667 | Loss: 0.14355045432855537\n",
            "Epoch: 49 | Batch: 1668 | Loss: 0.1320181103440844\n",
            "Epoch: 49 | Batch: 1669 | Loss: 0.1569494614825829\n",
            "Epoch: 49 | Batch: 1670 | Loss: 0.15374036578648928\n",
            "Epoch: 49 | Batch: 1671 | Loss: 0.12745724018048016\n",
            "Epoch: 49 | Batch: 1672 | Loss: 0.13814080847015137\n",
            "Epoch: 49 | Batch: 1673 | Loss: 0.19909350765265527\n",
            "Epoch: 49 | Batch: 1674 | Loss: 0.213967373319503\n",
            "Epoch: 49 | Batch: 1675 | Loss: 0.13617601360386752\n",
            "Epoch: 49 | Batch: 1676 | Loss: 0.1835881030087898\n",
            "Epoch: 49 | Batch: 1677 | Loss: 0.17353614870084336\n",
            "Epoch: 49 | Batch: 1678 | Loss: 0.14656444678742095\n",
            "Epoch: 49 | Batch: 1679 | Loss: 0.20966291446946453\n",
            "Epoch: 49 | Batch: 1680 | Loss: 0.19328806807393242\n",
            "Epoch: 49 | Batch: 1681 | Loss: 0.14579902288138974\n",
            "Epoch: 49 | Batch: 1682 | Loss: 0.13158007975625713\n",
            "Epoch: 49 | Batch: 1683 | Loss: 0.15562050365785213\n",
            "Epoch: 49 | Batch: 1684 | Loss: 0.1625507214274775\n",
            "Epoch: 49 | Batch: 1685 | Loss: 0.22224913301142557\n",
            "Epoch: 49 | Batch: 1686 | Loss: 0.16859535378438975\n",
            "Epoch: 49 | Batch: 1687 | Loss: 0.16619321116214147\n",
            "Epoch: 49 | Batch: 1688 | Loss: 0.17005045851106296\n",
            "Epoch: 49 | Batch: 1689 | Loss: 0.16900274980411914\n",
            "Epoch: 49 | Batch: 1690 | Loss: 0.20022632763799486\n",
            "Epoch: 49 | Batch: 1691 | Loss: 0.15373911067416862\n",
            "Epoch: 49 | Batch: 1692 | Loss: 0.15827148199717944\n",
            "Epoch: 49 | Batch: 1693 | Loss: 0.17009145888519175\n",
            "Epoch: 49 | Batch: 1694 | Loss: 0.1634300115133665\n",
            "Epoch: 49 | Batch: 1695 | Loss: 0.1553645155504425\n",
            "Epoch: 49 | Batch: 1696 | Loss: 0.18236352452045435\n",
            "Epoch: 49 | Batch: 1697 | Loss: 0.12966778764204318\n",
            "Epoch: 49 | Batch: 1698 | Loss: 0.1827462530030038\n",
            "Epoch: 49 | Batch: 1699 | Loss: 0.17105818203655357\n",
            "Epoch: 49 | Batch: 1700 | Loss: 0.16166354923030507\n",
            "Epoch: 49 | Batch: 1701 | Loss: 0.17469314186710594\n",
            "Epoch: 49 | Batch: 1702 | Loss: 0.147727386726247\n",
            "Epoch: 49 | Batch: 1703 | Loss: 0.1529664366718697\n",
            "Epoch: 49 | Batch: 1704 | Loss: 0.14658994185282326\n",
            "Epoch: 49 | Batch: 1705 | Loss: 0.1681133032972771\n",
            "Epoch: 49 | Batch: 1706 | Loss: 0.16608463777826826\n",
            "Epoch: 49 | Batch: 1707 | Loss: 0.2080169897341198\n",
            "Epoch: 49 | Batch: 1708 | Loss: 0.20939863173470005\n",
            "Epoch: 49 | Batch: 1709 | Loss: 0.1635218888259587\n",
            "Epoch: 49 | Batch: 1710 | Loss: 0.17727806041592553\n",
            "Epoch: 49 | Batch: 1711 | Loss: 0.17966267798593635\n",
            "Epoch: 49 | Batch: 1712 | Loss: 0.14248735980258198\n",
            "Epoch: 49 | Batch: 1713 | Loss: 0.13908239319662252\n",
            "Epoch: 49 | Batch: 1714 | Loss: 0.17480834837582537\n",
            "Epoch: 49 | Batch: 1715 | Loss: 0.19466431376543902\n",
            "Epoch: 49 | Batch: 1716 | Loss: 0.1640404828075514\n",
            "Epoch: 49 | Batch: 1717 | Loss: 0.14407483498954798\n",
            "Epoch: 49 | Batch: 1718 | Loss: 0.17287605227835037\n",
            "Epoch: 49 | Batch: 1719 | Loss: 0.16846984789376093\n",
            "Epoch: 49 | Batch: 1720 | Loss: 0.24100537918034065\n",
            "Epoch: 49 | Batch: 1721 | Loss: 0.161709317760852\n",
            "Epoch: 49 | Batch: 1722 | Loss: 0.16272887371578004\n",
            "Epoch: 49 | Batch: 1723 | Loss: 0.15958327385980772\n",
            "Epoch: 49 | Batch: 1724 | Loss: 0.11729034267512066\n",
            "Epoch: 49 | Batch: 1725 | Loss: 0.1401108338845883\n",
            "Epoch: 49 | Batch: 1726 | Loss: 0.19282209902275965\n",
            "Epoch: 49 | Batch: 1727 | Loss: 0.17691002971176573\n",
            "Epoch: 49 | Batch: 1728 | Loss: 0.18113943685263878\n",
            "Epoch: 49 | Batch: 1729 | Loss: 0.15461584462955416\n",
            "Epoch: 49 | Batch: 1730 | Loss: 0.16530601977771608\n",
            "Epoch: 49 | Batch: 1731 | Loss: 0.1728798258027861\n",
            "Epoch: 49 | Batch: 1732 | Loss: 0.13864759061676799\n",
            "Epoch: 49 | Batch: 1733 | Loss: 0.14012405385583523\n",
            "Epoch: 49 | Batch: 1734 | Loss: 0.14817791584639323\n",
            "Epoch: 49 | Batch: 1735 | Loss: 0.1656861853156971\n",
            "Epoch: 49 | Batch: 1736 | Loss: 0.22003419811602354\n",
            "Epoch: 49 | Batch: 1737 | Loss: 0.14889875863370222\n",
            "Epoch: 49 | Batch: 1738 | Loss: 0.24587494584731853\n",
            "Epoch: 49 | Batch: 1739 | Loss: 0.13808577372577238\n",
            "Epoch: 49 | Batch: 1740 | Loss: 0.17483340740433037\n",
            "Epoch: 49 | Batch: 1741 | Loss: 0.16591766611629832\n",
            "Epoch: 49 | Batch: 1742 | Loss: 0.1573380303154392\n",
            "Epoch: 49 | Batch: 1743 | Loss: 0.1762537479209768\n",
            "Epoch: 49 | Batch: 1744 | Loss: 0.19023697164120654\n",
            "Epoch: 49 | Batch: 1745 | Loss: 0.16404345192236736\n",
            "Epoch: 49 | Batch: 1746 | Loss: 0.18830789389752634\n",
            "Epoch: 49 | Batch: 1747 | Loss: 0.19298603900125363\n",
            "Epoch: 49 | Batch: 1748 | Loss: 0.20894844934147339\n",
            "Epoch: 49 | Batch: 1749 | Loss: 0.1949588409385057\n",
            "Epoch: 49 | Batch: 1750 | Loss: 0.12092920909737552\n",
            "Epoch: 49 | Batch: 1751 | Loss: 0.20396091343856812\n",
            "Epoch: 49 | Batch: 1752 | Loss: 0.15687962349070103\n",
            "Epoch: 49 | Batch: 1753 | Loss: 0.1521617615914988\n",
            "Epoch: 49 | Batch: 1754 | Loss: 0.22700888995356122\n",
            "Epoch: 49 | Batch: 1755 | Loss: 0.13432207718528943\n",
            "Epoch: 49 | Batch: 1756 | Loss: 0.18848845644889378\n",
            "Epoch: 49 | Batch: 1757 | Loss: 0.1585132179344835\n",
            "Epoch: 49 | Batch: 1758 | Loss: 0.13992457904748973\n",
            "Epoch: 49 | Batch: 1759 | Loss: 0.16669419652463652\n",
            "Epoch: 49 | Batch: 1760 | Loss: 0.17881825510674448\n",
            "Epoch: 49 | Batch: 1761 | Loss: 0.209875318297851\n",
            "Epoch: 49 | Batch: 1762 | Loss: 0.16744641755656267\n",
            "Epoch: 49 | Batch: 1763 | Loss: 0.2042451403702391\n",
            "Epoch: 49 | Batch: 1764 | Loss: 0.1885113261530585\n",
            "Epoch: 49 | Batch: 1765 | Loss: 0.1274773794985549\n",
            "Epoch: 49 | Batch: 1766 | Loss: 0.12888321338959188\n",
            "Epoch: 49 | Batch: 1767 | Loss: 0.1721930013340332\n",
            "Epoch: 49 | Batch: 1768 | Loss: 0.16358863862949657\n",
            "Epoch: 49 | Batch: 1769 | Loss: 0.1593007652654077\n",
            "Epoch: 49 | Batch: 1770 | Loss: 0.15353051450048788\n",
            "Epoch: 49 | Batch: 1771 | Loss: 0.197103502038721\n",
            "Epoch: 49 | Batch: 1772 | Loss: 0.16793337375749315\n",
            "Epoch: 49 | Batch: 1773 | Loss: 0.1773561376517614\n",
            "Epoch: 49 | Batch: 1774 | Loss: 0.14644604946277626\n",
            "Epoch: 49 | Batch: 1775 | Loss: 0.15392599109626381\n",
            "Epoch: 49 | Batch: 1776 | Loss: 0.21850853984011262\n",
            "Epoch: 49 | Batch: 1777 | Loss: 0.15156917799424519\n",
            "Epoch: 49 | Batch: 1778 | Loss: 0.18184052038877188\n",
            "Epoch: 49 | Batch: 1779 | Loss: 0.1734046433167904\n",
            "Epoch: 49 | Batch: 1780 | Loss: 0.12282752513263374\n",
            "Epoch: 49 | Batch: 1781 | Loss: 0.156469569943625\n",
            "Epoch: 49 | Batch: 1782 | Loss: 0.16108094525258848\n",
            "Epoch: 49 | Batch: 1783 | Loss: 0.12137130914745252\n",
            "Epoch: 49 | Batch: 1784 | Loss: 0.14248505325201494\n",
            "Epoch: 49 | Batch: 1785 | Loss: 0.1642186395445511\n",
            "Epoch: 49 | Batch: 1786 | Loss: 0.14706886367958547\n",
            "Epoch: 49 | Batch: 1787 | Loss: 0.18291717421598844\n",
            "Epoch: 49 | Batch: 1788 | Loss: 0.13527177257498205\n",
            "Epoch: 49 | Batch: 1789 | Loss: 0.17495821827253047\n",
            "Epoch: 49 | Batch: 1790 | Loss: 0.1822685747604871\n",
            "Epoch: 49 | Batch: 1791 | Loss: 0.2601886549362945\n",
            "Epoch: 49 | Batch: 1792 | Loss: 0.15143785042334723\n",
            "Epoch: 49 | Batch: 1793 | Loss: 0.1873483338949188\n",
            "Epoch: 49 | Batch: 1794 | Loss: 0.17822073551412537\n",
            "Epoch: 49 | Batch: 1795 | Loss: 0.13550114507524394\n",
            "Epoch: 49 | Batch: 1796 | Loss: 0.12792245177006187\n",
            "Epoch: 49 | Batch: 1797 | Loss: 0.14676182718989247\n",
            "Epoch: 49 | Batch: 1798 | Loss: 0.1551403914281196\n",
            "Epoch: 49 | Batch: 1799 | Loss: 0.1252569701112364\n",
            "Epoch: 49 | Batch: 1800 | Loss: 0.19237168859926132\n",
            "Epoch: 49 | Batch: 1801 | Loss: 0.18775891808081818\n",
            "Epoch: 49 | Batch: 1802 | Loss: 0.14257202460724933\n",
            "Epoch: 49 | Batch: 1803 | Loss: 0.1633572140773379\n",
            "Epoch: 49 | Batch: 1804 | Loss: 0.12397337267524926\n",
            "Epoch: 49 | Batch: 1805 | Loss: 0.16016099956202554\n",
            "Epoch: 49 | Batch: 1806 | Loss: 0.14222882024727457\n",
            "Epoch: 49 | Batch: 1807 | Loss: 0.14850588218246663\n",
            "Epoch: 49 | Batch: 1808 | Loss: 0.152049863223104\n",
            "Epoch: 49 | Batch: 1809 | Loss: 0.17095055752420218\n",
            "Epoch: 49 | Batch: 1810 | Loss: 0.16933110436515045\n",
            "Epoch: 49 | Batch: 1811 | Loss: 0.22685946928970074\n",
            "Epoch: 49 | Batch: 1812 | Loss: 0.16199293564028255\n",
            "Epoch: 49 | Batch: 1813 | Loss: 0.144617854388362\n",
            "Epoch: 49 | Batch: 1814 | Loss: 0.14880522467133253\n",
            "Epoch: 49 | Batch: 1815 | Loss: 0.16145305399488674\n",
            "Epoch: 49 | Batch: 1816 | Loss: 0.1581667652541116\n",
            "Epoch: 49 | Batch: 1817 | Loss: 0.20300124137590725\n",
            "Epoch: 49 | Batch: 1818 | Loss: 0.23382503914601177\n",
            "Epoch: 49 | Batch: 1819 | Loss: 0.15727413734116993\n",
            "Epoch: 49 | Batch: 1820 | Loss: 0.16831595701206015\n",
            "Epoch: 49 | Batch: 1821 | Loss: 0.1586884822617302\n",
            "Epoch: 49 | Batch: 1822 | Loss: 0.1496309007532958\n",
            "Epoch: 49 | Batch: 1823 | Loss: 0.16913935196445154\n",
            "Epoch: 49 | Batch: 1824 | Loss: 0.14936504111201004\n",
            "Epoch: 49 | Batch: 1825 | Loss: 0.13918027528279772\n",
            "Epoch: 49 | Batch: 1826 | Loss: 0.2413577115742302\n",
            "Epoch: 49 | Batch: 1827 | Loss: 0.13965506340853365\n",
            "Epoch: 49 | Batch: 1828 | Loss: 0.17838726677933328\n",
            "Epoch: 49 | Batch: 1829 | Loss: 0.13567014088007373\n",
            "Epoch: 49 | Batch: 1830 | Loss: 0.16369175721902196\n",
            "Epoch: 49 | Batch: 1831 | Loss: 0.1652853635309874\n",
            "Epoch: 49 | Batch: 1832 | Loss: 0.13403111763192851\n",
            "Epoch: 49 | Batch: 1833 | Loss: 0.19241687315407974\n",
            "Epoch: 49 | Batch: 1834 | Loss: 0.1564975669549732\n",
            "Epoch: 49 | Batch: 1835 | Loss: 0.19951990367749886\n",
            "Epoch: 49 | Batch: 1836 | Loss: 0.11985750428726755\n",
            "Epoch: 49 | Batch: 1837 | Loss: 0.12640217004490287\n",
            "Epoch: 49 | Batch: 1838 | Loss: 0.18875312679886394\n",
            "Epoch: 49 | Batch: 1839 | Loss: 0.1452450844423196\n",
            "Epoch: 49 | Batch: 1840 | Loss: 0.1567432493588725\n",
            "Epoch: 49 | Batch: 1841 | Loss: 0.1674382842564192\n",
            "Epoch: 49 | Batch: 1842 | Loss: 0.15256923673685707\n",
            "Epoch: 49 | Batch: 1843 | Loss: 0.15920480549633947\n",
            "Epoch: 49 | Batch: 1844 | Loss: 0.20820612127676086\n",
            "Epoch: 49 | Batch: 1845 | Loss: 0.13508205190191475\n",
            "Epoch: 49 | Batch: 1846 | Loss: 0.15899949787648457\n",
            "Epoch: 49 | Batch: 1847 | Loss: 0.16964807540609958\n",
            "Epoch: 49 | Batch: 1848 | Loss: 0.19273965011969932\n",
            "Epoch: 49 | Batch: 1849 | Loss: 0.15302406463819468\n",
            "Epoch: 49 | Batch: 1850 | Loss: 0.16263100012184822\n",
            "Epoch: 49 | Batch: 1851 | Loss: 0.2073857047769435\n",
            "Epoch: 49 | Batch: 1852 | Loss: 0.15389800503200335\n",
            "Epoch: 49 | Batch: 1853 | Loss: 0.1655461936396993\n",
            "Epoch: 49 | Batch: 1854 | Loss: 0.14031620990298382\n",
            "Epoch: 49 | Batch: 1855 | Loss: 0.1373434074406721\n",
            "Epoch: 49 | Batch: 1856 | Loss: 0.1359047831436348\n",
            "Epoch: 49 | Batch: 1857 | Loss: 0.13915177046946903\n",
            "Epoch: 49 | Batch: 1858 | Loss: 0.11811120976896332\n",
            "Epoch: 49 | Batch: 1859 | Loss: 0.1556815587215567\n",
            "Epoch: 49 | Batch: 1860 | Loss: 0.15422668544539\n",
            "Epoch: 49 | Batch: 1861 | Loss: 0.1885348598911688\n",
            "Epoch: 49 | Batch: 1862 | Loss: 0.1670681553625993\n",
            "Epoch: 49 | Batch: 1863 | Loss: 0.20466141603442287\n",
            "Epoch: 49 | Batch: 1864 | Loss: 0.13594037213916324\n",
            "Epoch: 49 | Batch: 1865 | Loss: 0.18033323096600704\n",
            "Epoch: 49 | Batch: 1866 | Loss: 0.17252114367461746\n",
            "Epoch: 49 | Batch: 1867 | Loss: 0.14764668062947867\n",
            "Epoch: 49 | Batch: 1868 | Loss: 0.18661225418298696\n",
            "Epoch: 49 | Batch: 1869 | Loss: 0.15945907594664308\n",
            "Epoch: 49 | Batch: 1870 | Loss: 0.15087004797750694\n",
            "Epoch: 49 | Batch: 1871 | Loss: 0.15877399354207608\n",
            "Epoch: 49 | Batch: 1872 | Loss: 0.16700749957482705\n",
            "Epoch: 49 | Batch: 1873 | Loss: 0.1890485596116536\n",
            "Epoch: 49 | Batch: 1874 | Loss: 0.10779332667833634\n",
            "Epoch: 49 | Batch: 1875 | Loss: 0.23470376810388943\n",
            "Epoch: 49 | Batch: 1876 | Loss: 0.19819708164403044\n",
            "Epoch: 49 | Batch: 1877 | Loss: 0.1494801174377954\n",
            "Epoch: 49 | Batch: 1878 | Loss: 0.19141868270170742\n",
            "Epoch: 49 | Batch: 1879 | Loss: 0.14853836308222437\n",
            "Epoch: 49 | Batch: 1880 | Loss: 0.13897770669175447\n",
            "Epoch: 49 | Batch: 1881 | Loss: 0.20951780025549274\n",
            "Epoch: 49 | Batch: 1882 | Loss: 0.15058507431070994\n",
            "Epoch: 49 | Batch: 1883 | Loss: 0.2029187941892208\n",
            "Epoch: 49 | Batch: 1884 | Loss: 0.17007740561079254\n",
            "Epoch: 49 | Batch: 1885 | Loss: 0.18508492658180392\n",
            "Epoch: 49 | Batch: 1886 | Loss: 0.15813691211052464\n",
            "Epoch: 49 | Batch: 1887 | Loss: 0.17991218124882377\n",
            "Epoch: 49 | Batch: 1888 | Loss: 0.1597923530656274\n",
            "Epoch: 49 | Batch: 1889 | Loss: 0.23207809425941844\n",
            "Epoch: 49 | Batch: 1890 | Loss: 0.17376132057380417\n",
            "Epoch: 49 | Batch: 1891 | Loss: 0.2012381499136232\n",
            "Epoch: 49 | Batch: 1892 | Loss: 0.15030104315538925\n",
            "Epoch: 49 | Batch: 1893 | Loss: 0.16183898058686047\n",
            "Epoch: 49 | Batch: 1894 | Loss: 0.20410979801416237\n",
            "Epoch: 49 | Batch: 1895 | Loss: 0.0869923532607828\n",
            "Epoch: 49 | Batch: 1896 | Loss: 0.17391907784712182\n",
            "Epoch: 49 | Batch: 1897 | Loss: 0.15401735069024072\n",
            "Epoch: 49 | Batch: 1898 | Loss: 0.16579579596932661\n",
            "Epoch: 49 | Batch: 1899 | Loss: 0.16398204792797952\n",
            "Epoch: 49 | Batch: 1900 | Loss: 0.10786733563219311\n",
            "Epoch: 49 | Batch: 1901 | Loss: 0.14195044594049752\n",
            "Epoch: 49 | Batch: 1902 | Loss: 0.1876881040018711\n",
            "Epoch: 49 | Batch: 1903 | Loss: 0.139082835420166\n",
            "Epoch: 49 | Batch: 1904 | Loss: 0.18069934692755824\n",
            "Epoch: 49 | Batch: 1905 | Loss: 0.22980687784934015\n",
            "Epoch: 49 | Batch: 1906 | Loss: 0.18298861023491947\n",
            "Epoch: 49 | Batch: 1907 | Loss: 0.16670787945543522\n",
            "Epoch: 49 | Batch: 1908 | Loss: 0.16060877829701414\n",
            "Epoch: 49 | Batch: 1909 | Loss: 0.12990960564706605\n",
            "Epoch: 49 | Batch: 1910 | Loss: 0.1457051106962143\n",
            "Epoch: 49 | Batch: 1911 | Loss: 0.17868975709029025\n",
            "Epoch: 49 | Batch: 1912 | Loss: 0.12047969623548457\n",
            "Epoch: 49 | Batch: 1913 | Loss: 0.11820300166666278\n",
            "Epoch: 49 | Batch: 1914 | Loss: 0.21061037266887433\n",
            "Epoch: 49 | Batch: 1915 | Loss: 0.16223584725910878\n",
            "Epoch: 49 | Batch: 1916 | Loss: 0.11395131780317647\n",
            "Epoch: 49 | Batch: 1917 | Loss: 0.16021119058707886\n",
            "Epoch: 49 | Batch: 1918 | Loss: 0.21823102210443157\n",
            "Epoch: 49 | Batch: 1919 | Loss: 0.12083989578545391\n",
            "Epoch: 49 | Batch: 1920 | Loss: 0.17642483703071543\n",
            "Epoch: 49 | Batch: 1921 | Loss: 0.2320346016818843\n",
            "Epoch: 49 | Batch: 1922 | Loss: 0.1604075804449523\n",
            "Epoch: 49 | Batch: 1923 | Loss: 0.17465487760078544\n",
            "Epoch: 49 | Batch: 1924 | Loss: 0.20242116947228375\n",
            "Epoch: 49 | Batch: 1925 | Loss: 0.14038638764073133\n",
            "Epoch: 49 | Batch: 1926 | Loss: 0.15843951477606527\n",
            "Epoch: 49 | Batch: 1927 | Loss: 0.23609828989378837\n",
            "Epoch: 49 | Batch: 1928 | Loss: 0.17688332767240442\n",
            "Epoch: 49 | Batch: 1929 | Loss: 0.13413515166872086\n",
            "Epoch: 49 | Batch: 1930 | Loss: 0.1251441403488542\n",
            "Epoch: 49 | Batch: 1931 | Loss: 0.1615375537031769\n",
            "Epoch: 49 | Batch: 1932 | Loss: 0.181259434880013\n",
            "Epoch: 49 | Batch: 1933 | Loss: 0.12480164634593478\n",
            "Epoch: 49 | Batch: 1934 | Loss: 0.16994753542891625\n",
            "Epoch: 49 | Batch: 1935 | Loss: 0.14840934074754847\n",
            "Epoch: 49 | Batch: 1936 | Loss: 0.15424060475290394\n",
            "Epoch: 49 | Batch: 1937 | Loss: 0.16942343299201879\n",
            "Epoch: 49 | Batch: 1938 | Loss: 0.19531691051131791\n",
            "Epoch: 49 | Batch: 1939 | Loss: 0.15481068674633913\n",
            "Epoch: 49 | Batch: 1940 | Loss: 0.1840040367468178\n",
            "Epoch: 49 | Batch: 1941 | Loss: 0.16160697796072188\n",
            "Epoch: 49 | Batch: 1942 | Loss: 0.12785353710740335\n",
            "Epoch: 49 | Batch: 1943 | Loss: 0.20238966985989804\n",
            "Epoch: 49 | Batch: 1944 | Loss: 0.15471011523060196\n",
            "Epoch: 49 | Batch: 1945 | Loss: 0.13916466778660014\n",
            "Epoch: 49 | Batch: 1946 | Loss: 0.20748549996546228\n",
            "Epoch: 49 | Batch: 1947 | Loss: 0.13928225882895023\n",
            "Epoch: 49 | Batch: 1948 | Loss: 0.13189793627247998\n",
            "Epoch: 49 | Batch: 1949 | Loss: 0.1839873485579565\n",
            "Epoch: 49 | Batch: 1950 | Loss: 0.1449145563791338\n",
            "Epoch: 49 | Batch: 1951 | Loss: 0.18488810387588783\n",
            "Epoch: 49 | Batch: 1952 | Loss: 0.1478480326519595\n",
            "Epoch: 49 | Batch: 1953 | Loss: 0.1448661923435182\n",
            "Epoch: 49 | Batch: 1954 | Loss: 0.19494846986881978\n",
            "Epoch: 49 | Batch: 1955 | Loss: 0.17739550806406523\n",
            "Epoch: 49 | Batch: 1956 | Loss: 0.15563929289034806\n",
            "Epoch: 49 | Batch: 1957 | Loss: 0.11416665272471287\n",
            "Epoch: 49 | Batch: 1958 | Loss: 0.18341639206768134\n",
            "Epoch: 49 | Batch: 1959 | Loss: 0.1510377814232694\n",
            "Epoch: 49 | Batch: 1960 | Loss: 0.16252443540878678\n",
            "Epoch: 49 | Batch: 1961 | Loss: 0.20067724208144\n",
            "Epoch: 49 | Batch: 1962 | Loss: 0.19391738547055037\n",
            "Epoch: 49 | Batch: 1963 | Loss: 0.14470466803621018\n",
            "Epoch: 49 | Batch: 1964 | Loss: 0.17708243698096626\n",
            "Epoch: 49 | Batch: 1965 | Loss: 0.16363404755850455\n",
            "Epoch: 49 | Batch: 1966 | Loss: 0.18048990664255066\n",
            "Epoch: 49 | Batch: 1967 | Loss: 0.16616889948047248\n",
            "Epoch: 49 | Batch: 1968 | Loss: 0.17714935068196666\n",
            "Epoch: 49 | Batch: 1969 | Loss: 0.14510773443340497\n",
            "Epoch: 49 | Batch: 1970 | Loss: 0.13535688826936287\n",
            "Epoch: 49 | Batch: 1971 | Loss: 0.13365735951321112\n",
            "Epoch: 49 | Batch: 1972 | Loss: 0.17365654093653565\n",
            "Epoch: 49 | Batch: 1973 | Loss: 0.19685815604307325\n",
            "Epoch: 49 | Batch: 1974 | Loss: 0.1704147301629495\n",
            "Epoch: 49 | Batch: 1975 | Loss: 0.12201773480771058\n",
            "Epoch: 49 | Batch: 1976 | Loss: 0.180280958915304\n",
            "Epoch: 49 | Batch: 1977 | Loss: 0.17714594035980985\n",
            "Epoch: 49 | Batch: 1978 | Loss: 0.18037420145671013\n",
            "Epoch: 49 | Batch: 1979 | Loss: 0.1682823985246821\n",
            "Epoch: 49 | Batch: 1980 | Loss: 0.21869273895936886\n",
            "Epoch: 49 | Batch: 1981 | Loss: 0.1433884395046438\n",
            "Epoch: 49 | Batch: 1982 | Loss: 0.16528365702006867\n",
            "Epoch: 49 | Batch: 1983 | Loss: 0.1619653989620172\n",
            "Epoch: 49 | Batch: 1984 | Loss: 0.20509691443264047\n",
            "Epoch: 49 | Batch: 1985 | Loss: 0.18468808015222704\n",
            "Epoch: 49 | Batch: 1986 | Loss: 0.17281958756223295\n",
            "Epoch: 49 | Batch: 1987 | Loss: 0.15779880651329437\n",
            "Epoch: 49 | Batch: 1988 | Loss: 0.16493238104011512\n",
            "Epoch: 49 | Batch: 1989 | Loss: 0.1709794548619776\n",
            "Epoch: 49 | Batch: 1990 | Loss: 0.17022400674230323\n",
            "Epoch: 49 | Batch: 1991 | Loss: 0.20073232934732727\n",
            "Epoch: 49 | Batch: 1992 | Loss: 0.18165405347903232\n",
            "Epoch: 49 | Batch: 1993 | Loss: 0.18924731354147592\n",
            "Epoch: 49 | Batch: 1994 | Loss: 0.19460071679653348\n",
            "Epoch: 49 | Batch: 1995 | Loss: 0.16528250260236457\n",
            "Epoch: 49 | Batch: 1996 | Loss: 0.16042732070095786\n",
            "Epoch: 49 | Batch: 1997 | Loss: 0.1682202256817361\n",
            "Epoch: 49 | Batch: 1998 | Loss: 0.19501327814095226\n",
            "Epoch: 49 | Batch: 1999 | Loss: 0.18860563045417433\n",
            "Epoch: 49 | Batch: 2000 | Loss: 0.16312937450371454\n",
            "Epoch: 49 | Batch: 2001 | Loss: 0.16669426002376497\n",
            "Epoch: 49 | Batch: 2002 | Loss: 0.15676850651729948\n",
            "Epoch: 49 | Batch: 2003 | Loss: 0.1743629970566508\n",
            "Epoch: 49 | Batch: 2004 | Loss: 0.15690683710294756\n",
            "Epoch: 49 | Batch: 2005 | Loss: 0.15133905333111292\n",
            "Epoch: 49 | Batch: 2006 | Loss: 0.1296249335019733\n",
            "Epoch: 49 | Batch: 2007 | Loss: 0.13772109075230998\n",
            "Epoch: 49 | Batch: 2008 | Loss: 0.19481266874016603\n",
            "Epoch: 49 | Batch: 2009 | Loss: 0.2007739323736514\n",
            "Epoch: 49 | Batch: 2010 | Loss: 0.16790256765374884\n",
            "Epoch: 49 | Batch: 2011 | Loss: 0.1410679752872935\n",
            "Epoch: 49 | Batch: 2012 | Loss: 0.13932928937902425\n",
            "Epoch: 49 | Batch: 2013 | Loss: 0.17404940475570738\n",
            "Epoch: 49 | Batch: 2014 | Loss: 0.16169814188552104\n",
            "Epoch: 49 | Batch: 2015 | Loss: 0.20039764720072886\n",
            "Epoch: 49 | Batch: 2016 | Loss: 0.13886014197298494\n",
            "Epoch: 49 | Batch: 2017 | Loss: 0.10584048338780856\n",
            "Epoch: 49 | Batch: 2018 | Loss: 0.10833177841162311\n",
            "Epoch: 49 | Batch: 2019 | Loss: 0.1701400013282724\n",
            "Epoch: 49 | Batch: 2020 | Loss: 0.16788706417575872\n",
            "Epoch: 49 | Batch: 2021 | Loss: 0.1485868525641111\n",
            "Epoch: 49 | Batch: 2022 | Loss: 0.19825338313293622\n",
            "Epoch: 49 | Batch: 2023 | Loss: 0.1531343619864524\n",
            "Epoch: 49 | Batch: 2024 | Loss: 0.15425345889142195\n",
            "Epoch: 49 | Batch: 2025 | Loss: 0.16552730857277814\n",
            "Epoch: 49 | Batch: 2026 | Loss: 0.19506274044463717\n",
            "Epoch: 49 | Batch: 2027 | Loss: 0.20070535552402552\n",
            "Epoch: 49 | Batch: 2028 | Loss: 0.17550256959098523\n",
            "Epoch: 49 | Batch: 2029 | Loss: 0.16770796796765178\n",
            "Epoch: 49 | Batch: 2030 | Loss: 0.15362833758141264\n",
            "Epoch: 49 | Batch: 2031 | Loss: 0.15734281301951736\n",
            "Epoch: 49 | Batch: 2032 | Loss: 0.12632754416439468\n",
            "Epoch: 49 | Batch: 2033 | Loss: 0.13754467244804466\n",
            "Epoch: 49 | Batch: 2034 | Loss: 0.12114786045588176\n",
            "Epoch: 49 | Batch: 2035 | Loss: 0.15438697884534477\n",
            "Epoch: 49 | Batch: 2036 | Loss: 0.16859993575022508\n",
            "Epoch: 49 | Batch: 2037 | Loss: 0.1841836113530381\n",
            "Epoch: 49 | Batch: 2038 | Loss: 0.11201405780045198\n",
            "Epoch: 49 | Batch: 2039 | Loss: 0.15652993261539924\n",
            "Epoch: 49 | Batch: 2040 | Loss: 0.1972845477348548\n",
            "Epoch: 49 | Batch: 2041 | Loss: 0.19212849869181026\n",
            "Epoch: 49 | Batch: 2042 | Loss: 0.1398494597330328\n",
            "Epoch: 49 | Batch: 2043 | Loss: 0.14039822006653663\n",
            "Epoch: 49 | Batch: 2044 | Loss: 0.1593047063352948\n",
            "Epoch: 49 | Batch: 2045 | Loss: 0.17278135780556447\n",
            "Epoch: 49 | Batch: 2046 | Loss: 0.1445440969407033\n",
            "Epoch: 49 | Batch: 2047 | Loss: 0.1679024205721482\n",
            "Epoch: 49 | Batch: 2048 | Loss: 0.17160885985687235\n",
            "Epoch: 49 | Batch: 2049 | Loss: 0.187613544757853\n",
            "Epoch: 49 | Batch: 2050 | Loss: 0.11439663678501164\n",
            "Epoch: 49 | Batch: 2051 | Loss: 0.1363064544084352\n",
            "Epoch: 49 | Batch: 2052 | Loss: 0.1846187209828376\n",
            "Epoch: 49 | Batch: 2053 | Loss: 0.16516803223413556\n",
            "Epoch: 49 | Batch: 2054 | Loss: 0.1515186397649085\n",
            "Epoch: 49 | Batch: 2055 | Loss: 0.1553264771314351\n",
            "Epoch: 49 | Batch: 2056 | Loss: 0.16727853559891062\n",
            "Epoch: 49 | Batch: 2057 | Loss: 0.183091140298312\n",
            "Epoch: 49 | Batch: 2058 | Loss: 0.15932703491767305\n",
            "Epoch: 49 | Batch: 2059 | Loss: 0.18973716243953337\n",
            "Epoch: 49 | Batch: 2060 | Loss: 0.21616225280934562\n",
            "Epoch: 49 | Batch: 2061 | Loss: 0.10836169857690281\n",
            "Epoch: 49 | Batch: 2062 | Loss: 0.20935972147403156\n",
            "Epoch: 49 | Batch: 2063 | Loss: 0.17480816577623842\n",
            "Epoch: 49 | Batch: 2064 | Loss: 0.20666886832559395\n",
            "Epoch: 49 | Batch: 2065 | Loss: 0.19939199968582288\n",
            "Epoch: 49 | Batch: 2066 | Loss: 0.17157427822189886\n",
            "Epoch: 49 | Batch: 2067 | Loss: 0.23147585634860487\n",
            "Epoch: 49 | Batch: 2068 | Loss: 0.1486206848117728\n",
            "Epoch: 49 | Batch: 2069 | Loss: 0.13693299077910814\n",
            "Epoch: 49 | Batch: 2070 | Loss: 0.19595240292225702\n",
            "Epoch: 49 | Batch: 2071 | Loss: 0.14873294009671378\n",
            "Epoch: 49 | Batch: 2072 | Loss: 0.17452246842729888\n",
            "Epoch: 49 | Batch: 2073 | Loss: 0.18349739200996443\n",
            "Epoch: 49 | Batch: 2074 | Loss: 0.13249227743095845\n",
            "Epoch: 49 | Batch: 2075 | Loss: 0.19414701556059136\n",
            "Epoch: 49 | Batch: 2076 | Loss: 0.11717712226057449\n",
            "Epoch: 49 | Batch: 2077 | Loss: 0.11200646140693979\n",
            "Epoch: 49 | Batch: 2078 | Loss: 0.22555484105520707\n",
            "Epoch: 49 | Batch: 2079 | Loss: 0.17495477734808915\n",
            "Epoch: 49 | Batch: 2080 | Loss: 0.17801134950352965\n",
            "Epoch: 49 | Batch: 2081 | Loss: 0.1524950595141303\n",
            "Epoch: 49 | Batch: 2082 | Loss: 0.15514001616565345\n",
            "Epoch: 49 | Batch: 2083 | Loss: 0.141491714229265\n",
            "Epoch: 49 | Batch: 2084 | Loss: 0.18431515745842975\n",
            "Epoch: 49 | Batch: 2085 | Loss: 0.15523641391489904\n",
            "Epoch: 49 | Batch: 2086 | Loss: 0.15172090404085428\n",
            "Epoch: 49 | Batch: 2087 | Loss: 0.1638414146254094\n",
            "Epoch: 49 | Batch: 2088 | Loss: 0.1165742785008036\n",
            "Epoch: 49 | Batch: 2089 | Loss: 0.1591924773440918\n",
            "Epoch: 49 | Batch: 2090 | Loss: 0.1453800139495966\n",
            "Epoch: 49 | Batch: 2091 | Loss: 0.15438668712808237\n",
            "Epoch: 49 | Batch: 2092 | Loss: 0.2189814647085131\n",
            "Epoch: 49 | Batch: 2093 | Loss: 0.18403823181115586\n",
            "Epoch: 49 | Batch: 2094 | Loss: 0.14367805433285885\n",
            "Epoch: 49 | Batch: 2095 | Loss: 0.17374383868061788\n",
            "Epoch: 49 | Batch: 2096 | Loss: 0.233182452708335\n",
            "Epoch: 49 | Batch: 2097 | Loss: 0.14259737664798594\n",
            "Epoch: 49 | Batch: 2098 | Loss: 0.13160161479636745\n",
            "Epoch: 49 | Batch: 2099 | Loss: 0.15324637977028943\n",
            "Epoch: 49 | Batch: 2100 | Loss: 0.11424110134956279\n",
            "Epoch: 49 | Batch: 2101 | Loss: 0.18427259499359158\n",
            "Epoch: 49 | Batch: 2102 | Loss: 0.23305755657855448\n",
            "Epoch: 49 | Batch: 2103 | Loss: 0.15033208693810654\n",
            "Epoch: 49 | Batch: 2104 | Loss: 0.16836294763982296\n",
            "Epoch: 49 | Batch: 2105 | Loss: 0.1784968418543003\n",
            "Epoch: 49 | Batch: 2106 | Loss: 0.17056813331601753\n",
            "Epoch: 49 | Batch: 2107 | Loss: 0.2262037572253372\n",
            "Epoch: 49 | Batch: 2108 | Loss: 0.20107591829830165\n",
            "Epoch: 49 | Batch: 2109 | Loss: 0.15893739923930036\n",
            "Epoch: 49 | Batch: 2110 | Loss: 0.13500674005952473\n",
            "Epoch: 49 | Batch: 2111 | Loss: 0.15957514222329347\n",
            "Epoch: 49 | Batch: 2112 | Loss: 0.19426462559952812\n",
            "Epoch: 49 | Batch: 2113 | Loss: 0.18659018653452625\n",
            "Epoch: 49 | Batch: 2114 | Loss: 0.18216599684469562\n",
            "Epoch: 49 | Batch: 2115 | Loss: 0.11200325161360808\n",
            "Epoch: 49 | Batch: 2116 | Loss: 0.12009614258767931\n",
            "Epoch: 49 | Batch: 2117 | Loss: 0.15028644334519492\n",
            "Epoch: 49 | Batch: 2118 | Loss: 0.1612835807763024\n",
            "Epoch: 49 | Batch: 2119 | Loss: 0.15993504752949037\n",
            "Epoch: 49 | Batch: 2120 | Loss: 0.16465167419739019\n",
            "Epoch: 49 | Batch: 2121 | Loss: 0.18174364560135925\n",
            "Epoch: 49 | Batch: 2122 | Loss: 0.13323127942133478\n",
            "Epoch: 49 | Batch: 2123 | Loss: 0.15022605471198883\n",
            "Epoch: 49 | Batch: 2124 | Loss: 0.145901109055224\n",
            "Epoch: 49 | Batch: 2125 | Loss: 0.1443443645934554\n",
            "Epoch: 49 | Batch: 2126 | Loss: 0.13890285641481842\n",
            "Epoch: 49 | Batch: 2127 | Loss: 0.13775888340112058\n",
            "Epoch: 49 | Batch: 2128 | Loss: 0.15086923190882148\n",
            "Epoch: 49 | Batch: 2129 | Loss: 0.12911377962298518\n",
            "Epoch: 49 | Batch: 2130 | Loss: 0.16460938007751327\n",
            "Epoch: 49 | Batch: 2131 | Loss: 0.12902797384679382\n",
            "Epoch: 49 | Batch: 2132 | Loss: 0.23595920329288445\n",
            "Epoch: 49 | Batch: 2133 | Loss: 0.20462176410261818\n",
            "Epoch: 49 | Batch: 2134 | Loss: 0.15458259738112176\n",
            "Epoch: 49 | Batch: 2135 | Loss: 0.16240170650801075\n",
            "Epoch: 49 | Batch: 2136 | Loss: 0.13665482117109748\n",
            "Epoch: 49 | Batch: 2137 | Loss: 0.17661617864162785\n",
            "Epoch: 49 | Batch: 2138 | Loss: 0.15362024283062578\n",
            "Epoch: 49 | Batch: 2139 | Loss: 0.21812332592510209\n",
            "Epoch: 49 | Batch: 2140 | Loss: 0.19009793573244407\n",
            "Epoch: 49 | Batch: 2141 | Loss: 0.17696212989927712\n",
            "Epoch: 49 | Batch: 2142 | Loss: 0.14265242441416026\n",
            "Epoch: 49 | Batch: 2143 | Loss: 0.14620346526515074\n",
            "Epoch: 49 | Batch: 2144 | Loss: 0.17032988717515202\n",
            "Epoch: 49 | Batch: 2145 | Loss: 0.1632579946698564\n",
            "Epoch: 49 | Batch: 2146 | Loss: 0.12092184239028209\n",
            "Epoch: 49 | Batch: 2147 | Loss: 0.17234767548282037\n",
            "Epoch: 49 | Batch: 2148 | Loss: 0.12578301156009325\n",
            "Epoch: 49 | Batch: 2149 | Loss: 0.1650357313129759\n",
            "Epoch: 49 | Batch: 2150 | Loss: 0.1559161427244784\n",
            "Epoch: 49 | Batch: 2151 | Loss: 0.14282474858288574\n",
            "Epoch: 49 | Batch: 2152 | Loss: 0.1969586657068879\n",
            "Epoch: 49 | Batch: 2153 | Loss: 0.15011080390003517\n",
            "Epoch: 49 | Batch: 2154 | Loss: 0.14192353695353332\n",
            "Epoch: 49 | Batch: 2155 | Loss: 0.13162738427727944\n",
            "Epoch: 49 | Batch: 2156 | Loss: 0.1464701618019779\n",
            "Epoch: 49 | Batch: 2157 | Loss: 0.16935495981917828\n",
            "Epoch: 49 | Batch: 2158 | Loss: 0.19398288039825132\n",
            "Epoch: 49 | Batch: 2159 | Loss: 0.2194238804948621\n",
            "Epoch: 49 | Batch: 2160 | Loss: 0.16226139672930695\n",
            "Epoch: 49 | Batch: 2161 | Loss: 0.15277307566176418\n",
            "Epoch: 49 | Batch: 2162 | Loss: 0.16477822364241637\n",
            "Epoch: 49 | Batch: 2163 | Loss: 0.18081175361378177\n",
            "Epoch: 49 | Batch: 2164 | Loss: 0.18663887182041997\n",
            "Epoch: 49 | Batch: 2165 | Loss: 0.17613627404706345\n",
            "Epoch: 49 | Batch: 2166 | Loss: 0.16686045497369326\n",
            "Epoch: 49 | Batch: 2167 | Loss: 0.1320807436452315\n",
            "Epoch: 49 | Batch: 2168 | Loss: 0.175922239825823\n",
            "Epoch: 49 | Batch: 2169 | Loss: 0.151347141233899\n",
            "Epoch: 49 | Batch: 2170 | Loss: 0.2145436707258807\n",
            "Epoch: 49 | Batch: 2171 | Loss: 0.15537573336193705\n",
            "Epoch: 49 | Batch: 2172 | Loss: 0.15223821130760948\n",
            "Epoch: 49 | Batch: 2173 | Loss: 0.1618037855620987\n",
            "Epoch: 49 | Batch: 2174 | Loss: 0.1778169495638433\n",
            "Epoch: 49 | Batch: 2175 | Loss: 0.19029748384727396\n",
            "Epoch: 49 | Batch: 2176 | Loss: 0.1424761530891379\n",
            "Epoch: 49 | Batch: 2177 | Loss: 0.11795425498423065\n",
            "Epoch: 49 | Batch: 2178 | Loss: 0.16845011676607238\n",
            "Epoch: 49 | Batch: 2179 | Loss: 0.18343247261681248\n",
            "Epoch: 49 | Batch: 2180 | Loss: 0.1324373679735744\n",
            "Epoch: 49 | Batch: 2181 | Loss: 0.12883261164002127\n",
            "Epoch: 49 | Batch: 2182 | Loss: 0.17680128165210446\n",
            "Epoch: 49 | Batch: 2183 | Loss: 0.22136798430933108\n",
            "Epoch: 49 | Batch: 2184 | Loss: 0.1555775330633431\n",
            "Epoch: 49 | Batch: 2185 | Loss: 0.18615643358270245\n",
            "Epoch: 49 | Batch: 2186 | Loss: 0.19341526613941235\n",
            "Epoch: 49 | Batch: 2187 | Loss: 0.1871795667090754\n",
            "Epoch: 49 | Batch: 2188 | Loss: 0.18250913187421505\n",
            "Epoch: 49 | Batch: 2189 | Loss: 0.15960358489966953\n",
            "Epoch: 49 | Batch: 2190 | Loss: 0.21453639330811264\n",
            "Epoch: 49 | Batch: 2191 | Loss: 0.19352273825778513\n",
            "Epoch: 50 | Batch: 1 | Loss: 0.21965520673083078\n",
            "Epoch: 50 | Batch: 2 | Loss: 0.21778093978244556\n",
            "Epoch: 50 | Batch: 3 | Loss: 0.16134897871195064\n",
            "Epoch: 50 | Batch: 4 | Loss: 0.18836539921595458\n",
            "Epoch: 50 | Batch: 5 | Loss: 0.20512556550639963\n",
            "Epoch: 50 | Batch: 6 | Loss: 0.17108887586460372\n",
            "Epoch: 50 | Batch: 7 | Loss: 0.15127971819091438\n",
            "Epoch: 50 | Batch: 8 | Loss: 0.19906976242532742\n",
            "Epoch: 50 | Batch: 9 | Loss: 0.1471270476695766\n",
            "Epoch: 50 | Batch: 10 | Loss: 0.18860812006314154\n",
            "Epoch: 50 | Batch: 11 | Loss: 0.1532897258409223\n",
            "Epoch: 50 | Batch: 12 | Loss: 0.1849579670079784\n",
            "Epoch: 50 | Batch: 13 | Loss: 0.18852184948086387\n",
            "Epoch: 50 | Batch: 14 | Loss: 0.1641095674296557\n",
            "Epoch: 50 | Batch: 15 | Loss: 0.14778172283386376\n",
            "Epoch: 50 | Batch: 16 | Loss: 0.14102299262265341\n",
            "Epoch: 50 | Batch: 17 | Loss: 0.17705549330226605\n",
            "Epoch: 50 | Batch: 18 | Loss: 0.2015484177189903\n",
            "Epoch: 50 | Batch: 19 | Loss: 0.21783937910928466\n",
            "Epoch: 50 | Batch: 20 | Loss: 0.23647376738953585\n",
            "Epoch: 50 | Batch: 21 | Loss: 0.14886151495047498\n",
            "Epoch: 50 | Batch: 22 | Loss: 0.19431637083636982\n",
            "Epoch: 50 | Batch: 23 | Loss: 0.18955733544286743\n",
            "Epoch: 50 | Batch: 24 | Loss: 0.1349099042472289\n",
            "Epoch: 50 | Batch: 25 | Loss: 0.17143660936993588\n",
            "Epoch: 50 | Batch: 26 | Loss: 0.1583270767347158\n",
            "Epoch: 50 | Batch: 27 | Loss: 0.164624449547024\n",
            "Epoch: 50 | Batch: 28 | Loss: 0.16394400813922574\n",
            "Epoch: 50 | Batch: 29 | Loss: 0.19501328913314092\n",
            "Epoch: 50 | Batch: 30 | Loss: 0.11526239571570537\n",
            "Epoch: 50 | Batch: 31 | Loss: 0.17064216628694195\n",
            "Epoch: 50 | Batch: 32 | Loss: 0.19794948047894195\n",
            "Epoch: 50 | Batch: 33 | Loss: 0.1546346326780802\n",
            "Epoch: 50 | Batch: 34 | Loss: 0.19242245275118036\n",
            "Epoch: 50 | Batch: 35 | Loss: 0.153430541657886\n",
            "Epoch: 50 | Batch: 36 | Loss: 0.18598597924607807\n",
            "Epoch: 50 | Batch: 37 | Loss: 0.14373397494318427\n",
            "Epoch: 50 | Batch: 38 | Loss: 0.15223079161541236\n",
            "Epoch: 50 | Batch: 39 | Loss: 0.16146327208476377\n",
            "Epoch: 50 | Batch: 40 | Loss: 0.15262051461106438\n",
            "Epoch: 50 | Batch: 41 | Loss: 0.12854947788517648\n",
            "Epoch: 50 | Batch: 42 | Loss: 0.1663245125671813\n",
            "Epoch: 50 | Batch: 43 | Loss: 0.1724721261534158\n",
            "Epoch: 50 | Batch: 44 | Loss: 0.15732478852650805\n",
            "Epoch: 50 | Batch: 45 | Loss: 0.2467647707622973\n",
            "Epoch: 50 | Batch: 46 | Loss: 0.18586232039754108\n",
            "Epoch: 50 | Batch: 47 | Loss: 0.1356575533295654\n",
            "Epoch: 50 | Batch: 48 | Loss: 0.16006747138869915\n",
            "Epoch: 50 | Batch: 49 | Loss: 0.19488586445049802\n",
            "Epoch: 50 | Batch: 50 | Loss: 0.14473722715238838\n",
            "Epoch: 50 | Batch: 51 | Loss: 0.20107574448875043\n",
            "Epoch: 50 | Batch: 52 | Loss: 0.16857542636172584\n",
            "Epoch: 50 | Batch: 53 | Loss: 0.1545984191629622\n",
            "Epoch: 50 | Batch: 54 | Loss: 0.1487760554697806\n",
            "Epoch: 50 | Batch: 55 | Loss: 0.16492685553294775\n",
            "Epoch: 50 | Batch: 56 | Loss: 0.1911242603200699\n",
            "Epoch: 50 | Batch: 57 | Loss: 0.20238111174258264\n",
            "Epoch: 50 | Batch: 58 | Loss: 0.15923127997828912\n",
            "Epoch: 50 | Batch: 59 | Loss: 0.19346814493564565\n",
            "Epoch: 50 | Batch: 60 | Loss: 0.12398483854769045\n",
            "Epoch: 50 | Batch: 61 | Loss: 0.15104929453073698\n",
            "Epoch: 50 | Batch: 62 | Loss: 0.13620471965536046\n",
            "Epoch: 50 | Batch: 63 | Loss: 0.14932046020723652\n",
            "Epoch: 50 | Batch: 64 | Loss: 0.19808416714686572\n",
            "Epoch: 50 | Batch: 65 | Loss: 0.15689141349578584\n",
            "Epoch: 50 | Batch: 66 | Loss: 0.15421560252068028\n",
            "Epoch: 50 | Batch: 67 | Loss: 0.12571232003057883\n",
            "Epoch: 50 | Batch: 68 | Loss: 0.1444287142858448\n",
            "Epoch: 50 | Batch: 69 | Loss: 0.14166960159475298\n",
            "Epoch: 50 | Batch: 70 | Loss: 0.149822136864261\n",
            "Epoch: 50 | Batch: 71 | Loss: 0.15280505590796448\n",
            "Epoch: 50 | Batch: 72 | Loss: 0.1483725482614628\n",
            "Epoch: 50 | Batch: 73 | Loss: 0.13933418911186563\n",
            "Epoch: 50 | Batch: 74 | Loss: 0.17200150608737508\n",
            "Epoch: 50 | Batch: 75 | Loss: 0.14307911603598839\n",
            "Epoch: 50 | Batch: 76 | Loss: 0.1670246926165483\n",
            "Epoch: 50 | Batch: 77 | Loss: 0.1769396495765467\n",
            "Epoch: 50 | Batch: 78 | Loss: 0.1713708414463948\n",
            "Epoch: 50 | Batch: 79 | Loss: 0.17414893207467444\n",
            "Epoch: 50 | Batch: 80 | Loss: 0.12459961296278645\n",
            "Epoch: 50 | Batch: 81 | Loss: 0.1457725102522795\n",
            "Epoch: 50 | Batch: 82 | Loss: 0.188075374995033\n",
            "Epoch: 50 | Batch: 83 | Loss: 0.13725123036725168\n",
            "Epoch: 50 | Batch: 84 | Loss: 0.12445607225856128\n",
            "Epoch: 50 | Batch: 85 | Loss: 0.19445291346235824\n",
            "Epoch: 50 | Batch: 86 | Loss: 0.18421053054458433\n",
            "Epoch: 50 | Batch: 87 | Loss: 0.17711736464858832\n",
            "Epoch: 50 | Batch: 88 | Loss: 0.2388624590028157\n",
            "Epoch: 50 | Batch: 89 | Loss: 0.19215817251680606\n",
            "Epoch: 50 | Batch: 90 | Loss: 0.1497482593171375\n",
            "Epoch: 50 | Batch: 91 | Loss: 0.12236046807041025\n",
            "Epoch: 50 | Batch: 92 | Loss: 0.14955368246685008\n",
            "Epoch: 50 | Batch: 93 | Loss: 0.1204293961164343\n",
            "Epoch: 50 | Batch: 94 | Loss: 0.18258088400413555\n",
            "Epoch: 50 | Batch: 95 | Loss: 0.18394871530710616\n",
            "Epoch: 50 | Batch: 96 | Loss: 0.1500808603209235\n",
            "Epoch: 50 | Batch: 97 | Loss: 0.2019739213448322\n",
            "Epoch: 50 | Batch: 98 | Loss: 0.17516969310494773\n",
            "Epoch: 50 | Batch: 99 | Loss: 0.17416535687146917\n",
            "Epoch: 50 | Batch: 100 | Loss: 0.16935557065621465\n",
            "Epoch: 50 | Batch: 101 | Loss: 0.11346074337355694\n",
            "Epoch: 50 | Batch: 102 | Loss: 0.1178933199604607\n",
            "Epoch: 50 | Batch: 103 | Loss: 0.16901847300763426\n",
            "Epoch: 50 | Batch: 104 | Loss: 0.12068937169750832\n",
            "Epoch: 50 | Batch: 105 | Loss: 0.17229402533768629\n",
            "Epoch: 50 | Batch: 106 | Loss: 0.11580200841445924\n",
            "Epoch: 50 | Batch: 107 | Loss: 0.16966514886027675\n",
            "Epoch: 50 | Batch: 108 | Loss: 0.21252986196969262\n",
            "Epoch: 50 | Batch: 109 | Loss: 0.20960492536725034\n",
            "Epoch: 50 | Batch: 110 | Loss: 0.1808396568891043\n",
            "Epoch: 50 | Batch: 111 | Loss: 0.18243637388917422\n",
            "Epoch: 50 | Batch: 112 | Loss: 0.16881301307570284\n",
            "Epoch: 50 | Batch: 113 | Loss: 0.1548245783860341\n",
            "Epoch: 50 | Batch: 114 | Loss: 0.142671912987544\n",
            "Epoch: 50 | Batch: 115 | Loss: 0.1444073518863025\n",
            "Epoch: 50 | Batch: 116 | Loss: 0.128104104314191\n",
            "Epoch: 50 | Batch: 117 | Loss: 0.1863504558789237\n",
            "Epoch: 50 | Batch: 118 | Loss: 0.20483793283554108\n",
            "Epoch: 50 | Batch: 119 | Loss: 0.16287591789132672\n",
            "Epoch: 50 | Batch: 120 | Loss: 0.1757665500166651\n",
            "Epoch: 50 | Batch: 121 | Loss: 0.13867593677890508\n",
            "Epoch: 50 | Batch: 122 | Loss: 0.11591130931524671\n",
            "Epoch: 50 | Batch: 123 | Loss: 0.18176227649576424\n",
            "Epoch: 50 | Batch: 124 | Loss: 0.10979511847348827\n",
            "Epoch: 50 | Batch: 125 | Loss: 0.15050287908451845\n",
            "Epoch: 50 | Batch: 126 | Loss: 0.16263379822114482\n",
            "Epoch: 50 | Batch: 127 | Loss: 0.1593155661790962\n",
            "Epoch: 50 | Batch: 128 | Loss: 0.15834205955590863\n",
            "Epoch: 50 | Batch: 129 | Loss: 0.1509625904185313\n",
            "Epoch: 50 | Batch: 130 | Loss: 0.16523411851829214\n",
            "Epoch: 50 | Batch: 131 | Loss: 0.124877351524306\n",
            "Epoch: 50 | Batch: 132 | Loss: 0.17761755568430332\n",
            "Epoch: 50 | Batch: 133 | Loss: 0.16830496151449525\n",
            "Epoch: 50 | Batch: 134 | Loss: 0.18671227925650102\n",
            "Epoch: 50 | Batch: 135 | Loss: 0.15807108304756376\n",
            "Epoch: 50 | Batch: 136 | Loss: 0.12407709671129535\n",
            "Epoch: 50 | Batch: 137 | Loss: 0.12722478607190088\n",
            "Epoch: 50 | Batch: 138 | Loss: 0.15395705049874933\n",
            "Epoch: 50 | Batch: 139 | Loss: 0.16156251287092246\n",
            "Epoch: 50 | Batch: 140 | Loss: 0.16338145009318572\n",
            "Epoch: 50 | Batch: 141 | Loss: 0.15841976070661323\n",
            "Epoch: 50 | Batch: 142 | Loss: 0.18740700422229367\n",
            "Epoch: 50 | Batch: 143 | Loss: 0.1473111067182758\n",
            "Epoch: 50 | Batch: 144 | Loss: 0.15556576543889136\n",
            "Epoch: 50 | Batch: 145 | Loss: 0.1257988936408624\n",
            "Epoch: 50 | Batch: 146 | Loss: 0.15406587034007896\n",
            "Epoch: 50 | Batch: 147 | Loss: 0.18472233865884904\n",
            "Epoch: 50 | Batch: 148 | Loss: 0.20305567901374236\n",
            "Epoch: 50 | Batch: 149 | Loss: 0.1493844138978787\n",
            "Epoch: 50 | Batch: 150 | Loss: 0.14254018015750852\n",
            "Epoch: 50 | Batch: 151 | Loss: 0.1260544408473283\n",
            "Epoch: 50 | Batch: 152 | Loss: 0.15072509925356656\n",
            "Epoch: 50 | Batch: 153 | Loss: 0.1910771654694954\n",
            "Epoch: 50 | Batch: 154 | Loss: 0.1391030879978987\n",
            "Epoch: 50 | Batch: 155 | Loss: 0.14332654795795724\n",
            "Epoch: 50 | Batch: 156 | Loss: 0.1284940197593973\n",
            "Epoch: 50 | Batch: 157 | Loss: 0.21127963560056373\n",
            "Epoch: 50 | Batch: 158 | Loss: 0.22968398449751204\n",
            "Epoch: 50 | Batch: 159 | Loss: 0.18313961508178025\n",
            "Epoch: 50 | Batch: 160 | Loss: 0.14822217426969417\n",
            "Epoch: 50 | Batch: 161 | Loss: 0.14916817037087912\n",
            "Epoch: 50 | Batch: 162 | Loss: 0.1948819195247185\n",
            "Epoch: 50 | Batch: 163 | Loss: 0.20272841095983246\n",
            "Epoch: 50 | Batch: 164 | Loss: 0.1610829046424912\n",
            "Epoch: 50 | Batch: 165 | Loss: 0.17609826667923537\n",
            "Epoch: 50 | Batch: 166 | Loss: 0.16777176837975033\n",
            "Epoch: 50 | Batch: 167 | Loss: 0.15197632785215462\n",
            "Epoch: 50 | Batch: 168 | Loss: 0.16852078777223964\n",
            "Epoch: 50 | Batch: 169 | Loss: 0.2089275697519396\n",
            "Epoch: 50 | Batch: 170 | Loss: 0.1542568260938067\n",
            "Epoch: 50 | Batch: 171 | Loss: 0.11803590239821256\n",
            "Epoch: 50 | Batch: 172 | Loss: 0.1739632175351012\n",
            "Epoch: 50 | Batch: 173 | Loss: 0.17417839424459186\n",
            "Epoch: 50 | Batch: 174 | Loss: 0.19166026730858868\n",
            "Epoch: 50 | Batch: 175 | Loss: 0.1971305032333058\n",
            "Epoch: 50 | Batch: 176 | Loss: 0.17955106731836337\n",
            "Epoch: 50 | Batch: 177 | Loss: 0.16641855612356166\n",
            "Epoch: 50 | Batch: 178 | Loss: 0.14899649194474524\n",
            "Epoch: 50 | Batch: 179 | Loss: 0.1704519967418152\n",
            "Epoch: 50 | Batch: 180 | Loss: 0.1746964500422261\n",
            "Epoch: 50 | Batch: 181 | Loss: 0.20979121370511705\n",
            "Epoch: 50 | Batch: 182 | Loss: 0.17223788842797227\n",
            "Epoch: 50 | Batch: 183 | Loss: 0.1844671119331845\n",
            "Epoch: 50 | Batch: 184 | Loss: 0.1657483774988451\n",
            "Epoch: 50 | Batch: 185 | Loss: 0.17438016916686508\n",
            "Epoch: 50 | Batch: 186 | Loss: 0.1971411356304388\n",
            "Epoch: 50 | Batch: 187 | Loss: 0.16289283095982376\n",
            "Epoch: 50 | Batch: 188 | Loss: 0.19979985899817893\n",
            "Epoch: 50 | Batch: 189 | Loss: 0.1358821260602612\n",
            "Epoch: 50 | Batch: 190 | Loss: 0.15152526372981429\n",
            "Epoch: 50 | Batch: 191 | Loss: 0.1859494064800753\n",
            "Epoch: 50 | Batch: 192 | Loss: 0.15628222224339028\n",
            "Epoch: 50 | Batch: 193 | Loss: 0.17290898767926563\n",
            "Epoch: 50 | Batch: 194 | Loss: 0.14014165891375624\n",
            "Epoch: 50 | Batch: 195 | Loss: 0.14734367468258486\n",
            "Epoch: 50 | Batch: 196 | Loss: 0.1492037089373453\n",
            "Epoch: 50 | Batch: 197 | Loss: 0.1826791999043602\n",
            "Epoch: 50 | Batch: 198 | Loss: 0.18275985599207312\n",
            "Epoch: 50 | Batch: 199 | Loss: 0.11135272235955908\n",
            "Epoch: 50 | Batch: 200 | Loss: 0.1536899136759796\n",
            "Epoch: 50 | Batch: 201 | Loss: 0.18398793537028016\n",
            "Epoch: 50 | Batch: 202 | Loss: 0.19634636101521014\n",
            "Epoch: 50 | Batch: 203 | Loss: 0.18782029284506838\n",
            "Epoch: 50 | Batch: 204 | Loss: 0.23069839639038459\n",
            "Epoch: 50 | Batch: 205 | Loss: 0.15919460045668218\n",
            "Epoch: 50 | Batch: 206 | Loss: 0.12633159831679108\n",
            "Epoch: 50 | Batch: 207 | Loss: 0.11586417786330641\n",
            "Epoch: 50 | Batch: 208 | Loss: 0.1860618041783588\n",
            "Epoch: 50 | Batch: 209 | Loss: 0.1723230684964203\n",
            "Epoch: 50 | Batch: 210 | Loss: 0.1551803136422744\n",
            "Epoch: 50 | Batch: 211 | Loss: 0.16076135321749602\n",
            "Epoch: 50 | Batch: 212 | Loss: 0.16142446971672791\n",
            "Epoch: 50 | Batch: 213 | Loss: 0.2595605914154619\n",
            "Epoch: 50 | Batch: 214 | Loss: 0.19953572987307336\n",
            "Epoch: 50 | Batch: 215 | Loss: 0.1883767753718041\n",
            "Epoch: 50 | Batch: 216 | Loss: 0.134699483391767\n",
            "Epoch: 50 | Batch: 217 | Loss: 0.15537177649141973\n",
            "Epoch: 50 | Batch: 218 | Loss: 0.153074351307756\n",
            "Epoch: 50 | Batch: 219 | Loss: 0.15988358789199392\n",
            "Epoch: 50 | Batch: 220 | Loss: 0.17352343434237805\n",
            "Epoch: 50 | Batch: 221 | Loss: 0.12635788809482318\n",
            "Epoch: 50 | Batch: 222 | Loss: 0.18477566168899057\n",
            "Epoch: 50 | Batch: 223 | Loss: 0.19168766536778925\n",
            "Epoch: 50 | Batch: 224 | Loss: 0.11458065591029559\n",
            "Epoch: 50 | Batch: 225 | Loss: 0.14932344362156152\n",
            "Epoch: 50 | Batch: 226 | Loss: 0.13662018171337353\n",
            "Epoch: 50 | Batch: 227 | Loss: 0.17908297707243515\n",
            "Epoch: 50 | Batch: 228 | Loss: 0.16560903273216573\n",
            "Epoch: 50 | Batch: 229 | Loss: 0.12025662177383414\n",
            "Epoch: 50 | Batch: 230 | Loss: 0.14790511865584458\n",
            "Epoch: 50 | Batch: 231 | Loss: 0.15612037851611485\n",
            "Epoch: 50 | Batch: 232 | Loss: 0.19086828038671388\n",
            "Epoch: 50 | Batch: 233 | Loss: 0.19222313839233546\n",
            "Epoch: 50 | Batch: 234 | Loss: 0.210647714260021\n",
            "Epoch: 50 | Batch: 235 | Loss: 0.16894888589638796\n",
            "Epoch: 50 | Batch: 236 | Loss: 0.23522189031355717\n",
            "Epoch: 50 | Batch: 237 | Loss: 0.15178847177286162\n",
            "Epoch: 50 | Batch: 238 | Loss: 0.1840095048971663\n",
            "Epoch: 50 | Batch: 239 | Loss: 0.17833936043759444\n",
            "Epoch: 50 | Batch: 240 | Loss: 0.2426995917883342\n",
            "Epoch: 50 | Batch: 241 | Loss: 0.1413011452504885\n",
            "Epoch: 50 | Batch: 242 | Loss: 0.15907292802448658\n",
            "Epoch: 50 | Batch: 243 | Loss: 0.19309657117438705\n",
            "Epoch: 50 | Batch: 244 | Loss: 0.14559837517614324\n",
            "Epoch: 50 | Batch: 245 | Loss: 0.22108499446405538\n",
            "Epoch: 50 | Batch: 246 | Loss: 0.1557616537530688\n",
            "Epoch: 50 | Batch: 247 | Loss: 0.1769896955378506\n",
            "Epoch: 50 | Batch: 248 | Loss: 0.15989199095208875\n",
            "Epoch: 50 | Batch: 249 | Loss: 0.17044283984151265\n",
            "Epoch: 50 | Batch: 250 | Loss: 0.15040038994004526\n",
            "Epoch: 50 | Batch: 251 | Loss: 0.15494123911201718\n",
            "Epoch: 50 | Batch: 252 | Loss: 0.14656002775249516\n",
            "Epoch: 50 | Batch: 253 | Loss: 0.18064262976558784\n",
            "Epoch: 50 | Batch: 254 | Loss: 0.12647766340011102\n",
            "Epoch: 50 | Batch: 255 | Loss: 0.1398411308721692\n",
            "Epoch: 50 | Batch: 256 | Loss: 0.17257463466400183\n",
            "Epoch: 50 | Batch: 257 | Loss: 0.19480175171648062\n",
            "Epoch: 50 | Batch: 258 | Loss: 0.18678332539188228\n",
            "Epoch: 50 | Batch: 259 | Loss: 0.12758117804409302\n",
            "Epoch: 50 | Batch: 260 | Loss: 0.18754003657347199\n",
            "Epoch: 50 | Batch: 261 | Loss: 0.21172960945080518\n",
            "Epoch: 50 | Batch: 262 | Loss: 0.18126465710505504\n",
            "Epoch: 50 | Batch: 263 | Loss: 0.1929981544624192\n",
            "Epoch: 50 | Batch: 264 | Loss: 0.18849991437092828\n",
            "Epoch: 50 | Batch: 265 | Loss: 0.1797349312955557\n",
            "Epoch: 50 | Batch: 266 | Loss: 0.1551290418973146\n",
            "Epoch: 50 | Batch: 267 | Loss: 0.14410961374706183\n",
            "Epoch: 50 | Batch: 268 | Loss: 0.15769592133373111\n",
            "Epoch: 50 | Batch: 269 | Loss: 0.13784586952255193\n",
            "Epoch: 50 | Batch: 270 | Loss: 0.12582280372825047\n",
            "Epoch: 50 | Batch: 271 | Loss: 0.1920177580796326\n",
            "Epoch: 50 | Batch: 272 | Loss: 0.22383382579408814\n",
            "Epoch: 50 | Batch: 273 | Loss: 0.1378268228798175\n",
            "Epoch: 50 | Batch: 274 | Loss: 0.21615819647835266\n",
            "Epoch: 50 | Batch: 275 | Loss: 0.16326486459348502\n",
            "Epoch: 50 | Batch: 276 | Loss: 0.16245611452044106\n",
            "Epoch: 50 | Batch: 277 | Loss: 0.14918027382562854\n",
            "Epoch: 50 | Batch: 278 | Loss: 0.1430131298572034\n",
            "Epoch: 50 | Batch: 279 | Loss: 0.1444718758515956\n",
            "Epoch: 50 | Batch: 280 | Loss: 0.16226129187694413\n",
            "Epoch: 50 | Batch: 281 | Loss: 0.14297846421338462\n",
            "Epoch: 50 | Batch: 282 | Loss: 0.15550916839694703\n",
            "Epoch: 50 | Batch: 283 | Loss: 0.1741977914555344\n",
            "Epoch: 50 | Batch: 284 | Loss: 0.15029380094897482\n",
            "Epoch: 50 | Batch: 285 | Loss: 0.16468278712432652\n",
            "Epoch: 50 | Batch: 286 | Loss: 0.16273989674949643\n",
            "Epoch: 50 | Batch: 287 | Loss: 0.1428330318890292\n",
            "Epoch: 50 | Batch: 288 | Loss: 0.12709335639584066\n",
            "Epoch: 50 | Batch: 289 | Loss: 0.18564304823163222\n",
            "Epoch: 50 | Batch: 290 | Loss: 0.16344706451597707\n",
            "Epoch: 50 | Batch: 291 | Loss: 0.1413336945110606\n",
            "Epoch: 50 | Batch: 292 | Loss: 0.19532233888911163\n",
            "Epoch: 50 | Batch: 293 | Loss: 0.18221043055624273\n",
            "Epoch: 50 | Batch: 294 | Loss: 0.18991167033666062\n",
            "Epoch: 50 | Batch: 295 | Loss: 0.13015554431174042\n",
            "Epoch: 50 | Batch: 296 | Loss: 0.13591190410667672\n",
            "Epoch: 50 | Batch: 297 | Loss: 0.14505772913856813\n",
            "Epoch: 50 | Batch: 298 | Loss: 0.1520319597192437\n",
            "Epoch: 50 | Batch: 299 | Loss: 0.1795326020364253\n",
            "Epoch: 50 | Batch: 300 | Loss: 0.14889033452919023\n",
            "Epoch: 50 | Batch: 301 | Loss: 0.16319895677970891\n",
            "Epoch: 50 | Batch: 302 | Loss: 0.1294929519365893\n",
            "Epoch: 50 | Batch: 303 | Loss: 0.18069817005121208\n",
            "Epoch: 50 | Batch: 304 | Loss: 0.1485165932593776\n",
            "Epoch: 50 | Batch: 305 | Loss: 0.1956570990643046\n",
            "Epoch: 50 | Batch: 306 | Loss: 0.12745575585806967\n",
            "Epoch: 50 | Batch: 307 | Loss: 0.1692047448188726\n",
            "Epoch: 50 | Batch: 308 | Loss: 0.17849922382528427\n",
            "Epoch: 50 | Batch: 309 | Loss: 0.12159804698342493\n",
            "Epoch: 50 | Batch: 310 | Loss: 0.15012045539801247\n",
            "Epoch: 50 | Batch: 311 | Loss: 0.14851828454565355\n",
            "Epoch: 50 | Batch: 312 | Loss: 0.19991295223306432\n",
            "Epoch: 50 | Batch: 313 | Loss: 0.19806036821363543\n",
            "Epoch: 50 | Batch: 314 | Loss: 0.1685895120408737\n",
            "Epoch: 50 | Batch: 315 | Loss: 0.1317222959294287\n",
            "Epoch: 50 | Batch: 316 | Loss: 0.15037141398735737\n",
            "Epoch: 50 | Batch: 317 | Loss: 0.12296755082942182\n",
            "Epoch: 50 | Batch: 318 | Loss: 0.17180960131675307\n",
            "Epoch: 50 | Batch: 319 | Loss: 0.1676818077283769\n",
            "Epoch: 50 | Batch: 320 | Loss: 0.1944581327607297\n",
            "Epoch: 50 | Batch: 321 | Loss: 0.18696339534586254\n",
            "Epoch: 50 | Batch: 322 | Loss: 0.14222394495782942\n",
            "Epoch: 50 | Batch: 323 | Loss: 0.13342872067846295\n",
            "Epoch: 50 | Batch: 324 | Loss: 0.1279653500678295\n",
            "Epoch: 50 | Batch: 325 | Loss: 0.19701731246684642\n",
            "Epoch: 50 | Batch: 326 | Loss: 0.12761864836216283\n",
            "Epoch: 50 | Batch: 327 | Loss: 0.18603704921036307\n",
            "Epoch: 50 | Batch: 328 | Loss: 0.16546750036667027\n",
            "Epoch: 50 | Batch: 329 | Loss: 0.16969718569876271\n",
            "Epoch: 50 | Batch: 330 | Loss: 0.1585130834251499\n",
            "Epoch: 50 | Batch: 331 | Loss: 0.1743737439672087\n",
            "Epoch: 50 | Batch: 332 | Loss: 0.18158585258554985\n",
            "Epoch: 50 | Batch: 333 | Loss: 0.22111106134090724\n",
            "Epoch: 50 | Batch: 334 | Loss: 0.18220381958399884\n",
            "Epoch: 50 | Batch: 335 | Loss: 0.16925208987494436\n",
            "Epoch: 50 | Batch: 336 | Loss: 0.20347088829571094\n",
            "Epoch: 50 | Batch: 337 | Loss: 0.13553671894573877\n",
            "Epoch: 50 | Batch: 338 | Loss: 0.2351030925904933\n",
            "Epoch: 50 | Batch: 339 | Loss: 0.14224175576650452\n",
            "Epoch: 50 | Batch: 340 | Loss: 0.18507163305151034\n",
            "Epoch: 50 | Batch: 341 | Loss: 0.16246360003138258\n",
            "Epoch: 50 | Batch: 342 | Loss: 0.20045005171177407\n",
            "Epoch: 50 | Batch: 343 | Loss: 0.16958334860979205\n",
            "Epoch: 50 | Batch: 344 | Loss: 0.17307390030935538\n",
            "Epoch: 50 | Batch: 345 | Loss: 0.19738809122238699\n",
            "Epoch: 50 | Batch: 346 | Loss: 0.1587834289385227\n",
            "Epoch: 50 | Batch: 347 | Loss: 0.17535864207852062\n",
            "Epoch: 50 | Batch: 348 | Loss: 0.18636828002862224\n",
            "Epoch: 50 | Batch: 349 | Loss: 0.21936975432674216\n",
            "Epoch: 50 | Batch: 350 | Loss: 0.13961002008943443\n",
            "Epoch: 50 | Batch: 351 | Loss: 0.15037045635606908\n",
            "Epoch: 50 | Batch: 352 | Loss: 0.18288158163817175\n",
            "Epoch: 50 | Batch: 353 | Loss: 0.18103968846025395\n",
            "Epoch: 50 | Batch: 354 | Loss: 0.19323866258804698\n",
            "Epoch: 50 | Batch: 355 | Loss: 0.18968191468520498\n",
            "Epoch: 50 | Batch: 356 | Loss: 0.1579970324526257\n",
            "Epoch: 50 | Batch: 357 | Loss: 0.16350454388728372\n",
            "Epoch: 50 | Batch: 358 | Loss: 0.15519337786382056\n",
            "Epoch: 50 | Batch: 359 | Loss: 0.14557722372388596\n",
            "Epoch: 50 | Batch: 360 | Loss: 0.1667408735145426\n",
            "Epoch: 50 | Batch: 361 | Loss: 0.12790165505003112\n",
            "Epoch: 50 | Batch: 362 | Loss: 0.13696544511251985\n",
            "Epoch: 50 | Batch: 363 | Loss: 0.14026282398505682\n",
            "Epoch: 50 | Batch: 364 | Loss: 0.16153575417981303\n",
            "Epoch: 50 | Batch: 365 | Loss: 0.1886952877336085\n",
            "Epoch: 50 | Batch: 366 | Loss: 0.2104718818076474\n",
            "Epoch: 50 | Batch: 367 | Loss: 0.1833974061284905\n",
            "Epoch: 50 | Batch: 368 | Loss: 0.21291320062872343\n",
            "Epoch: 50 | Batch: 369 | Loss: 0.12673188178153266\n",
            "Epoch: 50 | Batch: 370 | Loss: 0.15112582373134223\n",
            "Epoch: 50 | Batch: 371 | Loss: 0.1756592857989497\n",
            "Epoch: 50 | Batch: 372 | Loss: 0.17404339881387917\n",
            "Epoch: 50 | Batch: 373 | Loss: 0.14709661259460127\n",
            "Epoch: 50 | Batch: 374 | Loss: 0.13383544540619108\n",
            "Epoch: 50 | Batch: 375 | Loss: 0.12899880747414844\n",
            "Epoch: 50 | Batch: 376 | Loss: 0.13407696043826167\n",
            "Epoch: 50 | Batch: 377 | Loss: 0.1424670482338218\n",
            "Epoch: 50 | Batch: 378 | Loss: 0.14635489402779867\n",
            "Epoch: 50 | Batch: 379 | Loss: 0.17404791173216844\n",
            "Epoch: 50 | Batch: 380 | Loss: 0.20419220266452326\n",
            "Epoch: 50 | Batch: 381 | Loss: 0.12404580839769172\n",
            "Epoch: 50 | Batch: 382 | Loss: 0.151838260649665\n",
            "Epoch: 50 | Batch: 383 | Loss: 0.15317371243851813\n",
            "Epoch: 50 | Batch: 384 | Loss: 0.13174534917517272\n",
            "Epoch: 50 | Batch: 385 | Loss: 0.17203579582144585\n",
            "Epoch: 50 | Batch: 386 | Loss: 0.13397864336661655\n",
            "Epoch: 50 | Batch: 387 | Loss: 0.20210900723991804\n",
            "Epoch: 50 | Batch: 388 | Loss: 0.20572654314255967\n",
            "Epoch: 50 | Batch: 389 | Loss: 0.2135291009160491\n",
            "Epoch: 50 | Batch: 390 | Loss: 0.14201349938720442\n",
            "Epoch: 50 | Batch: 391 | Loss: 0.13267072891545453\n",
            "Epoch: 50 | Batch: 392 | Loss: 0.21495885092750572\n",
            "Epoch: 50 | Batch: 393 | Loss: 0.189855767317472\n",
            "Epoch: 50 | Batch: 394 | Loss: 0.15223740036306024\n",
            "Epoch: 50 | Batch: 395 | Loss: 0.23403036276770567\n",
            "Epoch: 50 | Batch: 396 | Loss: 0.1725384710548039\n",
            "Epoch: 50 | Batch: 397 | Loss: 0.1693477764156794\n",
            "Epoch: 50 | Batch: 398 | Loss: 0.14546949596964148\n",
            "Epoch: 50 | Batch: 399 | Loss: 0.13617911440570274\n",
            "Epoch: 50 | Batch: 400 | Loss: 0.13428143898794792\n",
            "Epoch: 50 | Batch: 401 | Loss: 0.15457693638960066\n",
            "Epoch: 50 | Batch: 402 | Loss: 0.16330595898655553\n",
            "Epoch: 50 | Batch: 403 | Loss: 0.11684542031303638\n",
            "Epoch: 50 | Batch: 404 | Loss: 0.15305525004148238\n",
            "Epoch: 50 | Batch: 405 | Loss: 0.176275469769687\n",
            "Epoch: 50 | Batch: 406 | Loss: 0.15056494004592952\n",
            "Epoch: 50 | Batch: 407 | Loss: 0.16412327340014865\n",
            "Epoch: 50 | Batch: 408 | Loss: 0.10215782992075925\n",
            "Epoch: 50 | Batch: 409 | Loss: 0.1706109605680986\n",
            "Epoch: 50 | Batch: 410 | Loss: 0.18897152303031375\n",
            "Epoch: 50 | Batch: 411 | Loss: 0.1545149692497176\n",
            "Epoch: 50 | Batch: 412 | Loss: 0.1468986553497392\n",
            "Epoch: 50 | Batch: 413 | Loss: 0.1882205445030767\n",
            "Epoch: 50 | Batch: 414 | Loss: 0.1535095283138363\n",
            "Epoch: 50 | Batch: 415 | Loss: 0.14028718000586954\n",
            "Epoch: 50 | Batch: 416 | Loss: 0.15190892238423825\n",
            "Epoch: 50 | Batch: 417 | Loss: 0.1332025822127746\n",
            "Epoch: 50 | Batch: 418 | Loss: 0.1495670816354643\n",
            "Epoch: 50 | Batch: 419 | Loss: 0.15659045551703163\n",
            "Epoch: 50 | Batch: 420 | Loss: 0.18229010569055817\n",
            "Epoch: 50 | Batch: 421 | Loss: 0.14665559350987828\n",
            "Epoch: 50 | Batch: 422 | Loss: 0.17680119657240212\n",
            "Epoch: 50 | Batch: 423 | Loss: 0.17918788652549725\n",
            "Epoch: 50 | Batch: 424 | Loss: 0.14191453833914028\n",
            "Epoch: 50 | Batch: 425 | Loss: 0.15472541996794298\n",
            "Epoch: 50 | Batch: 426 | Loss: 0.17057711945970458\n",
            "Epoch: 50 | Batch: 427 | Loss: 0.13798917502702926\n",
            "Epoch: 50 | Batch: 428 | Loss: 0.15840053792783276\n",
            "Epoch: 50 | Batch: 429 | Loss: 0.127529380468702\n",
            "Epoch: 50 | Batch: 430 | Loss: 0.16440623766625653\n",
            "Epoch: 50 | Batch: 431 | Loss: 0.10977270532431796\n",
            "Epoch: 50 | Batch: 432 | Loss: 0.14030963916496592\n",
            "Epoch: 50 | Batch: 433 | Loss: 0.1752072246128973\n",
            "Epoch: 50 | Batch: 434 | Loss: 0.16509349928291842\n",
            "Epoch: 50 | Batch: 435 | Loss: 0.13913238666842917\n",
            "Epoch: 50 | Batch: 436 | Loss: 0.18302124771113162\n",
            "Epoch: 50 | Batch: 437 | Loss: 0.2266936199894429\n",
            "Epoch: 50 | Batch: 438 | Loss: 0.1551655606390366\n",
            "Epoch: 50 | Batch: 439 | Loss: 0.14035067091340694\n",
            "Epoch: 50 | Batch: 440 | Loss: 0.17881316560924407\n",
            "Epoch: 50 | Batch: 441 | Loss: 0.16861391801046388\n",
            "Epoch: 50 | Batch: 442 | Loss: 0.19569589282906016\n",
            "Epoch: 50 | Batch: 443 | Loss: 0.16130510022419328\n",
            "Epoch: 50 | Batch: 444 | Loss: 0.1633389371969552\n",
            "Epoch: 50 | Batch: 445 | Loss: 0.16198780999348883\n",
            "Epoch: 50 | Batch: 446 | Loss: 0.18708125769088332\n",
            "Epoch: 50 | Batch: 447 | Loss: 0.1903966973307141\n",
            "Epoch: 50 | Batch: 448 | Loss: 0.13159651973245254\n",
            "Epoch: 50 | Batch: 449 | Loss: 0.15860343146120942\n",
            "Epoch: 50 | Batch: 450 | Loss: 0.188743612799004\n",
            "Epoch: 50 | Batch: 451 | Loss: 0.1558262872660831\n",
            "Epoch: 50 | Batch: 452 | Loss: 0.16433731212682062\n",
            "Epoch: 50 | Batch: 453 | Loss: 0.13825776484008945\n",
            "Epoch: 50 | Batch: 454 | Loss: 0.16775704160627494\n",
            "Epoch: 50 | Batch: 455 | Loss: 0.13192004994632464\n",
            "Epoch: 50 | Batch: 456 | Loss: 0.17795003615638794\n",
            "Epoch: 50 | Batch: 457 | Loss: 0.13171578093902486\n",
            "Epoch: 50 | Batch: 458 | Loss: 0.15709744752832802\n",
            "Epoch: 50 | Batch: 459 | Loss: 0.1831474930450365\n",
            "Epoch: 50 | Batch: 460 | Loss: 0.14043405590750516\n",
            "Epoch: 50 | Batch: 461 | Loss: 0.10697046862600698\n",
            "Epoch: 50 | Batch: 462 | Loss: 0.14903851680061073\n",
            "Epoch: 50 | Batch: 463 | Loss: 0.16901977326660755\n",
            "Epoch: 50 | Batch: 464 | Loss: 0.20122000509956983\n",
            "Epoch: 50 | Batch: 465 | Loss: 0.14863185204398388\n",
            "Epoch: 50 | Batch: 466 | Loss: 0.15092921327926684\n",
            "Epoch: 50 | Batch: 467 | Loss: 0.17246339356479495\n",
            "Epoch: 50 | Batch: 468 | Loss: 0.14663943905728788\n",
            "Epoch: 50 | Batch: 469 | Loss: 0.2089976834573925\n",
            "Epoch: 50 | Batch: 470 | Loss: 0.1931899678652913\n",
            "Epoch: 50 | Batch: 471 | Loss: 0.1537953422343793\n",
            "Epoch: 50 | Batch: 472 | Loss: 0.15943073082532577\n",
            "Epoch: 50 | Batch: 473 | Loss: 0.1795680994317725\n",
            "Epoch: 50 | Batch: 474 | Loss: 0.14679135504680674\n",
            "Epoch: 50 | Batch: 475 | Loss: 0.1187219177121574\n",
            "Epoch: 50 | Batch: 476 | Loss: 0.17260258230561773\n",
            "Epoch: 50 | Batch: 477 | Loss: 0.12350719670703855\n",
            "Epoch: 50 | Batch: 478 | Loss: 0.15709614899957336\n",
            "Epoch: 50 | Batch: 479 | Loss: 0.20449988323662283\n",
            "Epoch: 50 | Batch: 480 | Loss: 0.20815850528186391\n",
            "Epoch: 50 | Batch: 481 | Loss: 0.20333798025644884\n",
            "Epoch: 50 | Batch: 482 | Loss: 0.148029944759993\n",
            "Epoch: 50 | Batch: 483 | Loss: 0.17336356878252776\n",
            "Epoch: 50 | Batch: 484 | Loss: 0.19922434735933656\n",
            "Epoch: 50 | Batch: 485 | Loss: 0.14136367507985514\n",
            "Epoch: 50 | Batch: 486 | Loss: 0.16110333741656085\n",
            "Epoch: 50 | Batch: 487 | Loss: 0.15249526325333734\n",
            "Epoch: 50 | Batch: 488 | Loss: 0.16764589597316804\n",
            "Epoch: 50 | Batch: 489 | Loss: 0.15442717289629915\n",
            "Epoch: 50 | Batch: 490 | Loss: 0.13409846197708464\n",
            "Epoch: 50 | Batch: 491 | Loss: 0.1992690209304731\n",
            "Epoch: 50 | Batch: 492 | Loss: 0.1389823274695671\n",
            "Epoch: 50 | Batch: 493 | Loss: 0.20999779461586512\n",
            "Epoch: 50 | Batch: 494 | Loss: 0.1439146354267072\n",
            "Epoch: 50 | Batch: 495 | Loss: 0.15369612663654558\n",
            "Epoch: 50 | Batch: 496 | Loss: 0.18085674321495848\n",
            "Epoch: 50 | Batch: 497 | Loss: 0.14284964565312638\n",
            "Epoch: 50 | Batch: 498 | Loss: 0.20879532324988734\n",
            "Epoch: 50 | Batch: 499 | Loss: 0.19993192065479465\n",
            "Epoch: 50 | Batch: 500 | Loss: 0.1475597502044212\n",
            "Epoch: 50 | Batch: 501 | Loss: 0.1620073285098329\n",
            "Epoch: 50 | Batch: 502 | Loss: 0.171075907629547\n",
            "Epoch: 50 | Batch: 503 | Loss: 0.21401911643236493\n",
            "Epoch: 50 | Batch: 504 | Loss: 0.17463996802124948\n",
            "Epoch: 50 | Batch: 505 | Loss: 0.17983197525669783\n",
            "Epoch: 50 | Batch: 506 | Loss: 0.15544117582816042\n",
            "Epoch: 50 | Batch: 507 | Loss: 0.1882649752055009\n",
            "Epoch: 50 | Batch: 508 | Loss: 0.1846088190960738\n",
            "Epoch: 50 | Batch: 509 | Loss: 0.1587837534866194\n",
            "Epoch: 50 | Batch: 510 | Loss: 0.18558181563567722\n",
            "Epoch: 50 | Batch: 511 | Loss: 0.14263506740022594\n",
            "Epoch: 50 | Batch: 512 | Loss: 0.18130615794659802\n",
            "Epoch: 50 | Batch: 513 | Loss: 0.16761087974957747\n",
            "Epoch: 50 | Batch: 514 | Loss: 0.17005763520895795\n",
            "Epoch: 50 | Batch: 515 | Loss: 0.16483735901782157\n",
            "Epoch: 50 | Batch: 516 | Loss: 0.15539571906120142\n",
            "Epoch: 50 | Batch: 517 | Loss: 0.16268695048484028\n",
            "Epoch: 50 | Batch: 518 | Loss: 0.19854729259971488\n",
            "Epoch: 50 | Batch: 519 | Loss: 0.19400724507941078\n",
            "Epoch: 50 | Batch: 520 | Loss: 0.1763725238611257\n",
            "Epoch: 50 | Batch: 521 | Loss: 0.18223329403588392\n",
            "Epoch: 50 | Batch: 522 | Loss: 0.15771724088853695\n",
            "Epoch: 50 | Batch: 523 | Loss: 0.1843778253187579\n",
            "Epoch: 50 | Batch: 524 | Loss: 0.15080416395611934\n",
            "Epoch: 50 | Batch: 525 | Loss: 0.17931401361173846\n",
            "Epoch: 50 | Batch: 526 | Loss: 0.14224578761616075\n",
            "Epoch: 50 | Batch: 527 | Loss: 0.15756439501589328\n",
            "Epoch: 50 | Batch: 528 | Loss: 0.17373776434446417\n",
            "Epoch: 50 | Batch: 529 | Loss: 0.15343451191129717\n",
            "Epoch: 50 | Batch: 530 | Loss: 0.14043508573939537\n",
            "Epoch: 50 | Batch: 531 | Loss: 0.17827805406465044\n",
            "Epoch: 50 | Batch: 532 | Loss: 0.1621405532788595\n",
            "Epoch: 50 | Batch: 533 | Loss: 0.16022420273059984\n",
            "Epoch: 50 | Batch: 534 | Loss: 0.11454118301676117\n",
            "Epoch: 50 | Batch: 535 | Loss: 0.17137739303470545\n",
            "Epoch: 50 | Batch: 536 | Loss: 0.12467923648696665\n",
            "Epoch: 50 | Batch: 537 | Loss: 0.15795078214411287\n",
            "Epoch: 50 | Batch: 538 | Loss: 0.16525398541055986\n",
            "Epoch: 50 | Batch: 539 | Loss: 0.1796095015192031\n",
            "Epoch: 50 | Batch: 540 | Loss: 0.14690412376139442\n",
            "Epoch: 50 | Batch: 541 | Loss: 0.17873394660960273\n",
            "Epoch: 50 | Batch: 542 | Loss: 0.13682390687745588\n",
            "Epoch: 50 | Batch: 543 | Loss: 0.1392541595839836\n",
            "Epoch: 50 | Batch: 544 | Loss: 0.13256046469505642\n",
            "Epoch: 50 | Batch: 545 | Loss: 0.1400262843602869\n",
            "Epoch: 50 | Batch: 546 | Loss: 0.16148485524029677\n",
            "Epoch: 50 | Batch: 547 | Loss: 0.12842004471679588\n",
            "Epoch: 50 | Batch: 548 | Loss: 0.19982902724935744\n",
            "Epoch: 50 | Batch: 549 | Loss: 0.1821465475507446\n",
            "Epoch: 50 | Batch: 550 | Loss: 0.1641904057308296\n",
            "Epoch: 50 | Batch: 551 | Loss: 0.14807430387913262\n",
            "Epoch: 50 | Batch: 552 | Loss: 0.1896257393824094\n",
            "Epoch: 50 | Batch: 553 | Loss: 0.1797490097600591\n",
            "Epoch: 50 | Batch: 554 | Loss: 0.1377932810571928\n",
            "Epoch: 50 | Batch: 555 | Loss: 0.19120356762193058\n",
            "Epoch: 50 | Batch: 556 | Loss: 0.17492262843973985\n",
            "Epoch: 50 | Batch: 557 | Loss: 0.15815801215073402\n",
            "Epoch: 50 | Batch: 558 | Loss: 0.16464066429545288\n",
            "Epoch: 50 | Batch: 559 | Loss: 0.1489017517308003\n",
            "Epoch: 50 | Batch: 560 | Loss: 0.12515880446762587\n",
            "Epoch: 50 | Batch: 561 | Loss: 0.20199904511449912\n",
            "Epoch: 50 | Batch: 562 | Loss: 0.2017110794434121\n",
            "Epoch: 50 | Batch: 563 | Loss: 0.20561099254413437\n",
            "Epoch: 50 | Batch: 564 | Loss: 0.1586301931978593\n",
            "Epoch: 50 | Batch: 565 | Loss: 0.16912271190955472\n",
            "Epoch: 50 | Batch: 566 | Loss: 0.13034268062692367\n",
            "Epoch: 50 | Batch: 567 | Loss: 0.20448369040029504\n",
            "Epoch: 50 | Batch: 568 | Loss: 0.15360877272021778\n",
            "Epoch: 50 | Batch: 569 | Loss: 0.19505129624916462\n",
            "Epoch: 50 | Batch: 570 | Loss: 0.11574475518100925\n",
            "Epoch: 50 | Batch: 571 | Loss: 0.17721203437846256\n",
            "Epoch: 50 | Batch: 572 | Loss: 0.19581334754944224\n",
            "Epoch: 50 | Batch: 573 | Loss: 0.1544040924991963\n",
            "Epoch: 50 | Batch: 574 | Loss: 0.18226962055123483\n",
            "Epoch: 50 | Batch: 575 | Loss: 0.1956999457843509\n",
            "Epoch: 50 | Batch: 576 | Loss: 0.12445518564626468\n",
            "Epoch: 50 | Batch: 577 | Loss: 0.17271896070383225\n",
            "Epoch: 50 | Batch: 578 | Loss: 0.13699103201347768\n",
            "Epoch: 50 | Batch: 579 | Loss: 0.19450632579680724\n",
            "Epoch: 50 | Batch: 580 | Loss: 0.15975256259014944\n",
            "Epoch: 50 | Batch: 581 | Loss: 0.1355315263749967\n",
            "Epoch: 50 | Batch: 582 | Loss: 0.1380641190151951\n",
            "Epoch: 50 | Batch: 583 | Loss: 0.14367994878900273\n",
            "Epoch: 50 | Batch: 584 | Loss: 0.20321635054125212\n",
            "Epoch: 50 | Batch: 585 | Loss: 0.15046008078906012\n",
            "Epoch: 50 | Batch: 586 | Loss: 0.16856499402736608\n",
            "Epoch: 50 | Batch: 587 | Loss: 0.1846516310731163\n",
            "Epoch: 50 | Batch: 588 | Loss: 0.1382943777903241\n",
            "Epoch: 50 | Batch: 589 | Loss: 0.17740329322558718\n",
            "Epoch: 50 | Batch: 590 | Loss: 0.22306272072129577\n",
            "Epoch: 50 | Batch: 591 | Loss: 0.21868955988505132\n",
            "Epoch: 50 | Batch: 592 | Loss: 0.14721253563902204\n",
            "Epoch: 50 | Batch: 593 | Loss: 0.16423497934148706\n",
            "Epoch: 50 | Batch: 594 | Loss: 0.15451305377201374\n",
            "Epoch: 50 | Batch: 595 | Loss: 0.2160015881271178\n",
            "Epoch: 50 | Batch: 596 | Loss: 0.16798278765524788\n",
            "Epoch: 50 | Batch: 597 | Loss: 0.13013466456888978\n",
            "Epoch: 50 | Batch: 598 | Loss: 0.187365958919614\n",
            "Epoch: 50 | Batch: 599 | Loss: 0.1785835332463269\n",
            "Epoch: 50 | Batch: 600 | Loss: 0.1708712593342403\n",
            "Epoch: 50 | Batch: 601 | Loss: 0.1745368942262337\n",
            "Epoch: 50 | Batch: 602 | Loss: 0.14291172722062104\n",
            "Epoch: 50 | Batch: 603 | Loss: 0.1702605481971065\n",
            "Epoch: 50 | Batch: 604 | Loss: 0.19023184061628787\n",
            "Epoch: 50 | Batch: 605 | Loss: 0.13350191349596502\n",
            "Epoch: 50 | Batch: 606 | Loss: 0.16421122220215884\n",
            "Epoch: 50 | Batch: 607 | Loss: 0.20230163797428005\n",
            "Epoch: 50 | Batch: 608 | Loss: 0.15316636479337803\n",
            "Epoch: 50 | Batch: 609 | Loss: 0.14473445498186693\n",
            "Epoch: 50 | Batch: 610 | Loss: 0.19985747824983235\n",
            "Epoch: 50 | Batch: 611 | Loss: 0.14872775209817085\n",
            "Epoch: 50 | Batch: 612 | Loss: 0.17861762884906682\n",
            "Epoch: 50 | Batch: 613 | Loss: 0.17184775040216171\n",
            "Epoch: 50 | Batch: 614 | Loss: 0.16736761970283456\n",
            "Epoch: 50 | Batch: 615 | Loss: 0.15441177843525417\n",
            "Epoch: 50 | Batch: 616 | Loss: 0.14877236338565084\n",
            "Epoch: 50 | Batch: 617 | Loss: 0.14949222860610534\n",
            "Epoch: 50 | Batch: 618 | Loss: 0.19174811746442572\n",
            "Epoch: 50 | Batch: 619 | Loss: 0.158106360971302\n",
            "Epoch: 50 | Batch: 620 | Loss: 0.19747186975331407\n",
            "Epoch: 50 | Batch: 621 | Loss: 0.16298148088326883\n",
            "Epoch: 50 | Batch: 622 | Loss: 0.14675168038454864\n",
            "Epoch: 50 | Batch: 623 | Loss: 0.1799917437410025\n",
            "Epoch: 50 | Batch: 624 | Loss: 0.14621107579064715\n",
            "Epoch: 50 | Batch: 625 | Loss: 0.1863638934437456\n",
            "Epoch: 50 | Batch: 626 | Loss: 0.15454898866433653\n",
            "Epoch: 50 | Batch: 627 | Loss: 0.15526142368783613\n",
            "Epoch: 50 | Batch: 628 | Loss: 0.18860090116250514\n",
            "Epoch: 50 | Batch: 629 | Loss: 0.1421277769477645\n",
            "Epoch: 50 | Batch: 630 | Loss: 0.1316446976705115\n",
            "Epoch: 50 | Batch: 631 | Loss: 0.1824571886503002\n",
            "Epoch: 50 | Batch: 632 | Loss: 0.16720829622931357\n",
            "Epoch: 50 | Batch: 633 | Loss: 0.17032168598156394\n",
            "Epoch: 50 | Batch: 634 | Loss: 0.1902226918619115\n",
            "Epoch: 50 | Batch: 635 | Loss: 0.16809929128801987\n",
            "Epoch: 50 | Batch: 636 | Loss: 0.14994111979946212\n",
            "Epoch: 50 | Batch: 637 | Loss: 0.16041792380394476\n",
            "Epoch: 50 | Batch: 638 | Loss: 0.18016152116088036\n",
            "Epoch: 50 | Batch: 639 | Loss: 0.16049549328086224\n",
            "Epoch: 50 | Batch: 640 | Loss: 0.14294767134768646\n",
            "Epoch: 50 | Batch: 641 | Loss: 0.16618075085051548\n",
            "Epoch: 50 | Batch: 642 | Loss: 0.1716827858964291\n",
            "Epoch: 50 | Batch: 643 | Loss: 0.2029890829315384\n",
            "Epoch: 50 | Batch: 644 | Loss: 0.135300302301188\n",
            "Epoch: 50 | Batch: 645 | Loss: 0.16454608456054598\n",
            "Epoch: 50 | Batch: 646 | Loss: 0.2088416092499546\n",
            "Epoch: 50 | Batch: 647 | Loss: 0.1396779314465292\n",
            "Epoch: 50 | Batch: 648 | Loss: 0.1613940886149971\n",
            "Epoch: 50 | Batch: 649 | Loss: 0.15693282048439727\n",
            "Epoch: 50 | Batch: 650 | Loss: 0.13861645556390403\n",
            "Epoch: 50 | Batch: 651 | Loss: 0.17096223012985678\n",
            "Epoch: 50 | Batch: 652 | Loss: 0.1904257649388432\n",
            "Epoch: 50 | Batch: 653 | Loss: 0.16446773414999016\n",
            "Epoch: 50 | Batch: 654 | Loss: 0.11109413174854962\n",
            "Epoch: 50 | Batch: 655 | Loss: 0.1930657083539336\n",
            "Epoch: 50 | Batch: 656 | Loss: 0.15379986481857236\n",
            "Epoch: 50 | Batch: 657 | Loss: 0.14453270107899796\n",
            "Epoch: 50 | Batch: 658 | Loss: 0.1958036284899826\n",
            "Epoch: 50 | Batch: 659 | Loss: 0.1608470831473197\n",
            "Epoch: 50 | Batch: 660 | Loss: 0.1899241631953527\n",
            "Epoch: 50 | Batch: 661 | Loss: 0.16721237220139765\n",
            "Epoch: 50 | Batch: 662 | Loss: 0.20057373693233055\n",
            "Epoch: 50 | Batch: 663 | Loss: 0.15158632110207373\n",
            "Epoch: 50 | Batch: 664 | Loss: 0.12827652927591743\n",
            "Epoch: 50 | Batch: 665 | Loss: 0.21721128167755202\n",
            "Epoch: 50 | Batch: 666 | Loss: 0.1478787228272702\n",
            "Epoch: 50 | Batch: 667 | Loss: 0.1582106695087804\n",
            "Epoch: 50 | Batch: 668 | Loss: 0.19070095740518986\n",
            "Epoch: 50 | Batch: 669 | Loss: 0.16697008047038867\n",
            "Epoch: 50 | Batch: 670 | Loss: 0.14373136588124064\n",
            "Epoch: 50 | Batch: 671 | Loss: 0.14753907220143542\n",
            "Epoch: 50 | Batch: 672 | Loss: 0.19926215692064791\n",
            "Epoch: 50 | Batch: 673 | Loss: 0.15113442656546933\n",
            "Epoch: 50 | Batch: 674 | Loss: 0.17528022516189368\n",
            "Epoch: 50 | Batch: 675 | Loss: 0.14177562014275333\n",
            "Epoch: 50 | Batch: 676 | Loss: 0.1304166003619479\n",
            "Epoch: 50 | Batch: 677 | Loss: 0.16725900575091954\n",
            "Epoch: 50 | Batch: 678 | Loss: 0.17233307801710926\n",
            "Epoch: 50 | Batch: 679 | Loss: 0.172861405383052\n",
            "Epoch: 50 | Batch: 680 | Loss: 0.1724884799676074\n",
            "Epoch: 50 | Batch: 681 | Loss: 0.16769601186893038\n",
            "Epoch: 50 | Batch: 682 | Loss: 0.14902406365296628\n",
            "Epoch: 50 | Batch: 683 | Loss: 0.20399960866145847\n",
            "Epoch: 50 | Batch: 684 | Loss: 0.11139179760245282\n",
            "Epoch: 50 | Batch: 685 | Loss: 0.14644190465119356\n",
            "Epoch: 50 | Batch: 686 | Loss: 0.1633919621003781\n",
            "Epoch: 50 | Batch: 687 | Loss: 0.16073376193639802\n",
            "Epoch: 50 | Batch: 688 | Loss: 0.15449925237927492\n",
            "Epoch: 50 | Batch: 689 | Loss: 0.2104037468936404\n",
            "Epoch: 50 | Batch: 690 | Loss: 0.23828546339420398\n",
            "Epoch: 50 | Batch: 691 | Loss: 0.22035830409506113\n",
            "Epoch: 50 | Batch: 692 | Loss: 0.16426014324420224\n",
            "Epoch: 50 | Batch: 693 | Loss: 0.13699792247039483\n",
            "Epoch: 50 | Batch: 694 | Loss: 0.16448831040346645\n",
            "Epoch: 50 | Batch: 695 | Loss: 0.2086166421893189\n",
            "Epoch: 50 | Batch: 696 | Loss: 0.17962791494479274\n",
            "Epoch: 50 | Batch: 697 | Loss: 0.19593608784518754\n",
            "Epoch: 50 | Batch: 698 | Loss: 0.16928452405707484\n",
            "Epoch: 50 | Batch: 699 | Loss: 0.1494624968437561\n",
            "Epoch: 50 | Batch: 700 | Loss: 0.15948993749824547\n",
            "Epoch: 50 | Batch: 701 | Loss: 0.16870759343817732\n",
            "Epoch: 50 | Batch: 702 | Loss: 0.17605947404150546\n",
            "Epoch: 50 | Batch: 703 | Loss: 0.15520775876196996\n",
            "Epoch: 50 | Batch: 704 | Loss: 0.17177932921770583\n",
            "Epoch: 50 | Batch: 705 | Loss: 0.17863690490717402\n",
            "Epoch: 50 | Batch: 706 | Loss: 0.15437708159735608\n",
            "Epoch: 50 | Batch: 707 | Loss: 0.15421246915257564\n",
            "Epoch: 50 | Batch: 708 | Loss: 0.1588314765146523\n",
            "Epoch: 50 | Batch: 709 | Loss: 0.21431222254474072\n",
            "Epoch: 50 | Batch: 710 | Loss: 0.15251388827389117\n",
            "Epoch: 50 | Batch: 711 | Loss: 0.15223149009182066\n",
            "Epoch: 50 | Batch: 712 | Loss: 0.17200854247020392\n",
            "Epoch: 50 | Batch: 713 | Loss: 0.1434678337079853\n",
            "Epoch: 50 | Batch: 714 | Loss: 0.17091906988646227\n",
            "Epoch: 50 | Batch: 715 | Loss: 0.14537114055599434\n",
            "Epoch: 50 | Batch: 716 | Loss: 0.1615326769274817\n",
            "Epoch: 50 | Batch: 717 | Loss: 0.12141649027433452\n",
            "Epoch: 50 | Batch: 718 | Loss: 0.14631281363284726\n",
            "Epoch: 50 | Batch: 719 | Loss: 0.1508218121491843\n",
            "Epoch: 50 | Batch: 720 | Loss: 0.16611942843292932\n",
            "Epoch: 50 | Batch: 721 | Loss: 0.1600472122883172\n",
            "Epoch: 50 | Batch: 722 | Loss: 0.19835399886587735\n",
            "Epoch: 50 | Batch: 723 | Loss: 0.1654152524973005\n",
            "Epoch: 50 | Batch: 724 | Loss: 0.14514539228607784\n",
            "Epoch: 50 | Batch: 725 | Loss: 0.16046005364530427\n",
            "Epoch: 50 | Batch: 726 | Loss: 0.17749143385301847\n",
            "Epoch: 50 | Batch: 727 | Loss: 0.14566297617711937\n",
            "Epoch: 50 | Batch: 728 | Loss: 0.2026627240586907\n",
            "Epoch: 50 | Batch: 729 | Loss: 0.14968649263989084\n",
            "Epoch: 50 | Batch: 730 | Loss: 0.18734905283415904\n",
            "Epoch: 50 | Batch: 731 | Loss: 0.16898082708291598\n",
            "Epoch: 50 | Batch: 732 | Loss: 0.17437456455636224\n",
            "Epoch: 50 | Batch: 733 | Loss: 0.16819676442016593\n",
            "Epoch: 50 | Batch: 734 | Loss: 0.21191465913512816\n",
            "Epoch: 50 | Batch: 735 | Loss: 0.14362519825823358\n",
            "Epoch: 50 | Batch: 736 | Loss: 0.20608082429432512\n",
            "Epoch: 50 | Batch: 737 | Loss: 0.20165632895305663\n",
            "Epoch: 50 | Batch: 738 | Loss: 0.15360011871040172\n",
            "Epoch: 50 | Batch: 739 | Loss: 0.20953499144096954\n",
            "Epoch: 50 | Batch: 740 | Loss: 0.12137323593981927\n",
            "Epoch: 50 | Batch: 741 | Loss: 0.1463048214732499\n",
            "Epoch: 50 | Batch: 742 | Loss: 0.20882471183021234\n",
            "Epoch: 50 | Batch: 743 | Loss: 0.15508180628416618\n",
            "Epoch: 50 | Batch: 744 | Loss: 0.17467022608683397\n",
            "Epoch: 50 | Batch: 745 | Loss: 0.16595293306174283\n",
            "Epoch: 50 | Batch: 746 | Loss: 0.1514408278508344\n",
            "Epoch: 50 | Batch: 747 | Loss: 0.15813638465453783\n",
            "Epoch: 50 | Batch: 748 | Loss: 0.1413153437600465\n",
            "Epoch: 50 | Batch: 749 | Loss: 0.15729297535765335\n",
            "Epoch: 50 | Batch: 750 | Loss: 0.18165706199934675\n",
            "Epoch: 50 | Batch: 751 | Loss: 0.19192637574203558\n",
            "Epoch: 50 | Batch: 752 | Loss: 0.17606049840093801\n",
            "Epoch: 50 | Batch: 753 | Loss: 0.1737593493821571\n",
            "Epoch: 50 | Batch: 754 | Loss: 0.17415238767337446\n",
            "Epoch: 50 | Batch: 755 | Loss: 0.17390860721754725\n",
            "Epoch: 50 | Batch: 756 | Loss: 0.14204252030647668\n",
            "Epoch: 50 | Batch: 757 | Loss: 0.14127217694378602\n",
            "Epoch: 50 | Batch: 758 | Loss: 0.17714827024230387\n",
            "Epoch: 50 | Batch: 759 | Loss: 0.13799814276889805\n",
            "Epoch: 50 | Batch: 760 | Loss: 0.16041685371163045\n",
            "Epoch: 50 | Batch: 761 | Loss: 0.15310451522284488\n",
            "Epoch: 50 | Batch: 762 | Loss: 0.18547347911790033\n",
            "Epoch: 50 | Batch: 763 | Loss: 0.24059385071430378\n",
            "Epoch: 50 | Batch: 764 | Loss: 0.20282715638092674\n",
            "Epoch: 50 | Batch: 765 | Loss: 0.18994722579792775\n",
            "Epoch: 50 | Batch: 766 | Loss: 0.1768720149332977\n",
            "Epoch: 50 | Batch: 767 | Loss: 0.1848045654183052\n",
            "Epoch: 50 | Batch: 768 | Loss: 0.22685549373333358\n",
            "Epoch: 50 | Batch: 769 | Loss: 0.14485142945621815\n",
            "Epoch: 50 | Batch: 770 | Loss: 0.14207089631021302\n",
            "Epoch: 50 | Batch: 771 | Loss: 0.1614777103579483\n",
            "Epoch: 50 | Batch: 772 | Loss: 0.2147340113556797\n",
            "Epoch: 50 | Batch: 773 | Loss: 0.15783809885398814\n",
            "Epoch: 50 | Batch: 774 | Loss: 0.15337345636943128\n",
            "Epoch: 50 | Batch: 775 | Loss: 0.1486239681624548\n",
            "Epoch: 50 | Batch: 776 | Loss: 0.1712854147028205\n",
            "Epoch: 50 | Batch: 777 | Loss: 0.16307068467709154\n",
            "Epoch: 50 | Batch: 778 | Loss: 0.15334500905217952\n",
            "Epoch: 50 | Batch: 779 | Loss: 0.17263933790574684\n",
            "Epoch: 50 | Batch: 780 | Loss: 0.15558611887717377\n",
            "Epoch: 50 | Batch: 781 | Loss: 0.13693326600773453\n",
            "Epoch: 50 | Batch: 782 | Loss: 0.1601618714423051\n",
            "Epoch: 50 | Batch: 783 | Loss: 0.17294680077896898\n",
            "Epoch: 50 | Batch: 784 | Loss: 0.12657645873110648\n",
            "Epoch: 50 | Batch: 785 | Loss: 0.1761337956273451\n",
            "Epoch: 50 | Batch: 786 | Loss: 0.1766035081859283\n",
            "Epoch: 50 | Batch: 787 | Loss: 0.1918693505326989\n",
            "Epoch: 50 | Batch: 788 | Loss: 0.17151660515835643\n",
            "Epoch: 50 | Batch: 789 | Loss: 0.1781893069822201\n",
            "Epoch: 50 | Batch: 790 | Loss: 0.17283971079024413\n",
            "Epoch: 50 | Batch: 791 | Loss: 0.168417221024103\n",
            "Epoch: 50 | Batch: 792 | Loss: 0.19398942976549077\n",
            "Epoch: 50 | Batch: 793 | Loss: 0.17351916250274846\n",
            "Epoch: 50 | Batch: 794 | Loss: 0.20370841302737547\n",
            "Epoch: 50 | Batch: 795 | Loss: 0.17290171842660318\n",
            "Epoch: 50 | Batch: 796 | Loss: 0.17246619559904608\n",
            "Epoch: 50 | Batch: 797 | Loss: 0.16088569071297193\n",
            "Epoch: 50 | Batch: 798 | Loss: 0.15803850867840444\n",
            "Epoch: 50 | Batch: 799 | Loss: 0.19493942574642653\n",
            "Epoch: 50 | Batch: 800 | Loss: 0.20846501244626597\n",
            "Epoch: 50 | Batch: 801 | Loss: 0.15826853727456563\n",
            "Epoch: 50 | Batch: 802 | Loss: 0.13255691161149058\n",
            "Epoch: 50 | Batch: 803 | Loss: 0.20889774630876043\n",
            "Epoch: 50 | Batch: 804 | Loss: 0.1654413393699694\n",
            "Epoch: 50 | Batch: 805 | Loss: 0.20006364100232707\n",
            "Epoch: 50 | Batch: 806 | Loss: 0.2132875359027473\n",
            "Epoch: 50 | Batch: 807 | Loss: 0.16833323305689277\n",
            "Epoch: 50 | Batch: 808 | Loss: 0.14140673837428652\n",
            "Epoch: 50 | Batch: 809 | Loss: 0.15017110063890748\n",
            "Epoch: 50 | Batch: 810 | Loss: 0.15946656030145193\n",
            "Epoch: 50 | Batch: 811 | Loss: 0.15090621355274092\n",
            "Epoch: 50 | Batch: 812 | Loss: 0.1311653838222573\n",
            "Epoch: 50 | Batch: 813 | Loss: 0.15364373582082566\n",
            "Epoch: 50 | Batch: 814 | Loss: 0.15877137667011426\n",
            "Epoch: 50 | Batch: 815 | Loss: 0.17028916427861474\n",
            "Epoch: 50 | Batch: 816 | Loss: 0.14044398653223852\n",
            "Epoch: 50 | Batch: 817 | Loss: 0.16872752370098346\n",
            "Epoch: 50 | Batch: 818 | Loss: 0.12592483822162576\n",
            "Epoch: 50 | Batch: 819 | Loss: 0.15293550501650277\n",
            "Epoch: 50 | Batch: 820 | Loss: 0.18175792272012875\n",
            "Epoch: 50 | Batch: 821 | Loss: 0.18745116528872802\n",
            "Epoch: 50 | Batch: 822 | Loss: 0.14579833426343855\n",
            "Epoch: 50 | Batch: 823 | Loss: 0.19121156074057571\n",
            "Epoch: 50 | Batch: 824 | Loss: 0.19252118502229149\n",
            "Epoch: 50 | Batch: 825 | Loss: 0.11482632894394929\n",
            "Epoch: 50 | Batch: 826 | Loss: 0.16813023134681435\n",
            "Epoch: 50 | Batch: 827 | Loss: 0.16964175097856254\n",
            "Epoch: 50 | Batch: 828 | Loss: 0.16817068859073686\n",
            "Epoch: 50 | Batch: 829 | Loss: 0.14756078430508662\n",
            "Epoch: 50 | Batch: 830 | Loss: 0.173259959528643\n",
            "Epoch: 50 | Batch: 831 | Loss: 0.16760448047138152\n",
            "Epoch: 50 | Batch: 832 | Loss: 0.15471772923919444\n",
            "Epoch: 50 | Batch: 833 | Loss: 0.17338125087749615\n",
            "Epoch: 50 | Batch: 834 | Loss: 0.1693718511089897\n",
            "Epoch: 50 | Batch: 835 | Loss: 0.152059736485197\n",
            "Epoch: 50 | Batch: 836 | Loss: 0.17133900125952592\n",
            "Epoch: 50 | Batch: 837 | Loss: 0.1762934684660508\n",
            "Epoch: 50 | Batch: 838 | Loss: 0.16386913438716505\n",
            "Epoch: 50 | Batch: 839 | Loss: 0.17262093273521692\n",
            "Epoch: 50 | Batch: 840 | Loss: 0.17967590270777\n",
            "Epoch: 50 | Batch: 841 | Loss: 0.18249550564152062\n",
            "Epoch: 50 | Batch: 842 | Loss: 0.18992405304291912\n",
            "Epoch: 50 | Batch: 843 | Loss: 0.19260065716694508\n",
            "Epoch: 50 | Batch: 844 | Loss: 0.17381077793815014\n",
            "Epoch: 50 | Batch: 845 | Loss: 0.16095240450256926\n",
            "Epoch: 50 | Batch: 846 | Loss: 0.16977054309296874\n",
            "Epoch: 50 | Batch: 847 | Loss: 0.15366112278054583\n",
            "Epoch: 50 | Batch: 848 | Loss: 0.1680966172952888\n",
            "Epoch: 50 | Batch: 849 | Loss: 0.21584715733406235\n",
            "Epoch: 50 | Batch: 850 | Loss: 0.16153315171839927\n",
            "Epoch: 50 | Batch: 851 | Loss: 0.16957001538988087\n",
            "Epoch: 50 | Batch: 852 | Loss: 0.13303298583747553\n",
            "Epoch: 50 | Batch: 853 | Loss: 0.17328705839757133\n",
            "Epoch: 50 | Batch: 854 | Loss: 0.15792301022071414\n",
            "Epoch: 50 | Batch: 855 | Loss: 0.20585636589921755\n",
            "Epoch: 50 | Batch: 856 | Loss: 0.16021907587505613\n",
            "Epoch: 50 | Batch: 857 | Loss: 0.18782095904541884\n",
            "Epoch: 50 | Batch: 858 | Loss: 0.19593631162137398\n",
            "Epoch: 50 | Batch: 859 | Loss: 0.16522548961672684\n",
            "Epoch: 50 | Batch: 860 | Loss: 0.11740543896481842\n",
            "Epoch: 50 | Batch: 861 | Loss: 0.1585708949795386\n",
            "Epoch: 50 | Batch: 862 | Loss: 0.17697713929390763\n",
            "Epoch: 50 | Batch: 863 | Loss: 0.14847235389338312\n",
            "Epoch: 50 | Batch: 864 | Loss: 0.14713242192547432\n",
            "Epoch: 50 | Batch: 865 | Loss: 0.12251970397621642\n",
            "Epoch: 50 | Batch: 866 | Loss: 0.1582090615950902\n",
            "Epoch: 50 | Batch: 867 | Loss: 0.1787114020746567\n",
            "Epoch: 50 | Batch: 868 | Loss: 0.1423385470677115\n",
            "Epoch: 50 | Batch: 869 | Loss: 0.13696397167613764\n",
            "Epoch: 50 | Batch: 870 | Loss: 0.17493436559701314\n",
            "Epoch: 50 | Batch: 871 | Loss: 0.18484924047705747\n",
            "Epoch: 50 | Batch: 872 | Loss: 0.18662845955930377\n",
            "Epoch: 50 | Batch: 873 | Loss: 0.15753914530671986\n",
            "Epoch: 50 | Batch: 874 | Loss: 0.13297744862538274\n",
            "Epoch: 50 | Batch: 875 | Loss: 0.16873274918061665\n",
            "Epoch: 50 | Batch: 876 | Loss: 0.15006599045026311\n",
            "Epoch: 50 | Batch: 877 | Loss: 0.1807177952546934\n",
            "Epoch: 50 | Batch: 878 | Loss: 0.15239786893965188\n",
            "Epoch: 50 | Batch: 879 | Loss: 0.1731158996883665\n",
            "Epoch: 50 | Batch: 880 | Loss: 0.13340824826542738\n",
            "Epoch: 50 | Batch: 881 | Loss: 0.14191664672966214\n",
            "Epoch: 50 | Batch: 882 | Loss: 0.15732481434970733\n",
            "Epoch: 50 | Batch: 883 | Loss: 0.16913127782704573\n",
            "Epoch: 50 | Batch: 884 | Loss: 0.2141949631226885\n",
            "Epoch: 50 | Batch: 885 | Loss: 0.1505477344580059\n",
            "Epoch: 50 | Batch: 886 | Loss: 0.19257866156055947\n",
            "Epoch: 50 | Batch: 887 | Loss: 0.15960467162025757\n",
            "Epoch: 50 | Batch: 888 | Loss: 0.1697788915472062\n",
            "Epoch: 50 | Batch: 889 | Loss: 0.15013854432027712\n",
            "Epoch: 50 | Batch: 890 | Loss: 0.13861460182082078\n",
            "Epoch: 50 | Batch: 891 | Loss: 0.13709033502435242\n",
            "Epoch: 50 | Batch: 892 | Loss: 0.15804508003404635\n",
            "Epoch: 50 | Batch: 893 | Loss: 0.1919091388930601\n",
            "Epoch: 50 | Batch: 894 | Loss: 0.1596504096054305\n",
            "Epoch: 50 | Batch: 895 | Loss: 0.13920061189782318\n",
            "Epoch: 50 | Batch: 896 | Loss: 0.16346639394826218\n",
            "Epoch: 50 | Batch: 897 | Loss: 0.19218542091811408\n",
            "Epoch: 50 | Batch: 898 | Loss: 0.20022157564311252\n",
            "Epoch: 50 | Batch: 899 | Loss: 0.13686169156234312\n",
            "Epoch: 50 | Batch: 900 | Loss: 0.11369242334293321\n",
            "Epoch: 50 | Batch: 901 | Loss: 0.1666925955382515\n",
            "Epoch: 50 | Batch: 902 | Loss: 0.1545358843726793\n",
            "Epoch: 50 | Batch: 903 | Loss: 0.17662761555811637\n",
            "Epoch: 50 | Batch: 904 | Loss: 0.24455656215938915\n",
            "Epoch: 50 | Batch: 905 | Loss: 0.1610457770072075\n",
            "Epoch: 50 | Batch: 906 | Loss: 0.15025143082562514\n",
            "Epoch: 50 | Batch: 907 | Loss: 0.1199204469605692\n",
            "Epoch: 50 | Batch: 908 | Loss: 0.17327015422251818\n",
            "Epoch: 50 | Batch: 909 | Loss: 0.21162878734361049\n",
            "Epoch: 50 | Batch: 910 | Loss: 0.20697183351027373\n",
            "Epoch: 50 | Batch: 911 | Loss: 0.21020918270772748\n",
            "Epoch: 50 | Batch: 912 | Loss: 0.12588858284799298\n",
            "Epoch: 50 | Batch: 913 | Loss: 0.151697406182686\n",
            "Epoch: 50 | Batch: 914 | Loss: 0.18406323081087828\n",
            "Epoch: 50 | Batch: 915 | Loss: 0.17529287469392263\n",
            "Epoch: 50 | Batch: 916 | Loss: 0.16148311757994582\n",
            "Epoch: 50 | Batch: 917 | Loss: 0.17227427883334306\n",
            "Epoch: 50 | Batch: 918 | Loss: 0.1780980588045898\n",
            "Epoch: 50 | Batch: 919 | Loss: 0.1903284201286509\n",
            "Epoch: 50 | Batch: 920 | Loss: 0.21639723312822112\n",
            "Epoch: 50 | Batch: 921 | Loss: 0.21351159023212676\n",
            "Epoch: 50 | Batch: 922 | Loss: 0.17091318995853888\n",
            "Epoch: 50 | Batch: 923 | Loss: 0.18601623962671074\n",
            "Epoch: 50 | Batch: 924 | Loss: 0.13822201321297548\n",
            "Epoch: 50 | Batch: 925 | Loss: 0.16496129224163847\n",
            "Epoch: 50 | Batch: 926 | Loss: 0.14679345982536673\n",
            "Epoch: 50 | Batch: 927 | Loss: 0.19442643203019336\n",
            "Epoch: 50 | Batch: 928 | Loss: 0.16708774858514683\n",
            "Epoch: 50 | Batch: 929 | Loss: 0.17844240823236876\n",
            "Epoch: 50 | Batch: 930 | Loss: 0.12694379796889252\n",
            "Epoch: 50 | Batch: 931 | Loss: 0.16964048114438282\n",
            "Epoch: 50 | Batch: 932 | Loss: 0.2068480205321228\n",
            "Epoch: 50 | Batch: 933 | Loss: 0.14996936187532708\n",
            "Epoch: 50 | Batch: 934 | Loss: 0.17085465300653907\n",
            "Epoch: 50 | Batch: 935 | Loss: 0.2057321500348087\n",
            "Epoch: 50 | Batch: 936 | Loss: 0.25403692752682705\n",
            "Epoch: 50 | Batch: 937 | Loss: 0.17376230634282014\n",
            "Epoch: 50 | Batch: 938 | Loss: 0.1850757209092255\n",
            "Epoch: 50 | Batch: 939 | Loss: 0.1300639806462247\n",
            "Epoch: 50 | Batch: 940 | Loss: 0.16516574993818112\n",
            "Epoch: 50 | Batch: 941 | Loss: 0.17761567081012586\n",
            "Epoch: 50 | Batch: 942 | Loss: 0.18896229569884798\n",
            "Epoch: 50 | Batch: 943 | Loss: 0.15875388832469203\n",
            "Epoch: 50 | Batch: 944 | Loss: 0.18484189204593532\n",
            "Epoch: 50 | Batch: 945 | Loss: 0.14055630327263555\n",
            "Epoch: 50 | Batch: 946 | Loss: 0.17252654971774045\n",
            "Epoch: 50 | Batch: 947 | Loss: 0.19283162816666852\n",
            "Epoch: 50 | Batch: 948 | Loss: 0.1591974457797751\n",
            "Epoch: 50 | Batch: 949 | Loss: 0.15259965127802727\n",
            "Epoch: 50 | Batch: 950 | Loss: 0.2098033829935905\n",
            "Epoch: 50 | Batch: 951 | Loss: 0.18975696761880587\n",
            "Epoch: 50 | Batch: 952 | Loss: 0.1915835956735441\n",
            "Epoch: 50 | Batch: 953 | Loss: 0.15198031581480742\n",
            "Epoch: 50 | Batch: 954 | Loss: 0.19941021744389104\n",
            "Epoch: 50 | Batch: 955 | Loss: 0.17031168684861936\n",
            "Epoch: 50 | Batch: 956 | Loss: 0.13135566134361085\n",
            "Epoch: 50 | Batch: 957 | Loss: 0.14645704592292721\n",
            "Epoch: 50 | Batch: 958 | Loss: 0.16198032199740595\n",
            "Epoch: 50 | Batch: 959 | Loss: 0.15152961636603068\n",
            "Epoch: 50 | Batch: 960 | Loss: 0.19283796599928948\n",
            "Epoch: 50 | Batch: 961 | Loss: 0.18045952673424254\n",
            "Epoch: 50 | Batch: 962 | Loss: 0.16105360422170245\n",
            "Epoch: 50 | Batch: 963 | Loss: 0.17968956942780964\n",
            "Epoch: 50 | Batch: 964 | Loss: 0.16656843418014064\n",
            "Epoch: 50 | Batch: 965 | Loss: 0.1279881121473427\n",
            "Epoch: 50 | Batch: 966 | Loss: 0.14109202532261242\n",
            "Epoch: 50 | Batch: 967 | Loss: 0.12404223071524943\n",
            "Epoch: 50 | Batch: 968 | Loss: 0.17472765036483487\n",
            "Epoch: 50 | Batch: 969 | Loss: 0.16686436895087992\n",
            "Epoch: 50 | Batch: 970 | Loss: 0.15974431731713196\n",
            "Epoch: 50 | Batch: 971 | Loss: 0.1947244241175339\n",
            "Epoch: 50 | Batch: 972 | Loss: 0.21277648921538667\n",
            "Epoch: 50 | Batch: 973 | Loss: 0.15080337637371416\n",
            "Epoch: 50 | Batch: 974 | Loss: 0.16997610678060787\n",
            "Epoch: 50 | Batch: 975 | Loss: 0.18487915092378437\n",
            "Epoch: 50 | Batch: 976 | Loss: 0.13647212372521542\n",
            "Epoch: 50 | Batch: 977 | Loss: 0.22005199983103518\n",
            "Epoch: 50 | Batch: 978 | Loss: 0.16931329150492325\n",
            "Epoch: 50 | Batch: 979 | Loss: 0.1531276356864352\n",
            "Epoch: 50 | Batch: 980 | Loss: 0.13264182989584627\n",
            "Epoch: 50 | Batch: 981 | Loss: 0.1604574352264988\n",
            "Epoch: 50 | Batch: 982 | Loss: 0.16735510263144482\n",
            "Epoch: 50 | Batch: 983 | Loss: 0.24215150036038632\n",
            "Epoch: 50 | Batch: 984 | Loss: 0.13404652104894163\n",
            "Epoch: 50 | Batch: 985 | Loss: 0.17471408001427907\n",
            "Epoch: 50 | Batch: 986 | Loss: 0.15778250262065685\n",
            "Epoch: 50 | Batch: 987 | Loss: 0.1742934950745244\n",
            "Epoch: 50 | Batch: 988 | Loss: 0.11571717802635616\n",
            "Epoch: 50 | Batch: 989 | Loss: 0.16376072867722524\n",
            "Epoch: 50 | Batch: 990 | Loss: 0.1725664115025745\n",
            "Epoch: 50 | Batch: 991 | Loss: 0.144833546280201\n",
            "Epoch: 50 | Batch: 992 | Loss: 0.14956865760248547\n",
            "Epoch: 50 | Batch: 993 | Loss: 0.17603988685327188\n",
            "Epoch: 50 | Batch: 994 | Loss: 0.16348783948055773\n",
            "Epoch: 50 | Batch: 995 | Loss: 0.1497509753232197\n",
            "Epoch: 50 | Batch: 996 | Loss: 0.1850387760142297\n",
            "Epoch: 50 | Batch: 997 | Loss: 0.1621308048997582\n",
            "Epoch: 50 | Batch: 998 | Loss: 0.23661406771288912\n",
            "Epoch: 50 | Batch: 999 | Loss: 0.17333691334972165\n",
            "Epoch: 50 | Batch: 1000 | Loss: 0.17518261761733347\n",
            "Epoch: 50 | Batch: 1001 | Loss: 0.13575886521966996\n",
            "Epoch: 50 | Batch: 1002 | Loss: 0.1523987357417565\n",
            "Epoch: 50 | Batch: 1003 | Loss: 0.13616131045939117\n",
            "Epoch: 50 | Batch: 1004 | Loss: 0.13137857518655774\n",
            "Epoch: 50 | Batch: 1005 | Loss: 0.16771307130480373\n",
            "Epoch: 50 | Batch: 1006 | Loss: 0.18572972519479372\n",
            "Epoch: 50 | Batch: 1007 | Loss: 0.20773597369389873\n",
            "Epoch: 50 | Batch: 1008 | Loss: 0.14551587131253138\n",
            "Epoch: 50 | Batch: 1009 | Loss: 0.14455326018783352\n",
            "Epoch: 50 | Batch: 1010 | Loss: 0.16656360407760967\n",
            "Epoch: 50 | Batch: 1011 | Loss: 0.2202959918196587\n",
            "Epoch: 50 | Batch: 1012 | Loss: 0.19697484833111278\n",
            "Epoch: 50 | Batch: 1013 | Loss: 0.1204277625174556\n",
            "Epoch: 50 | Batch: 1014 | Loss: 0.1756665158987047\n",
            "Epoch: 50 | Batch: 1015 | Loss: 0.18478242408322595\n",
            "Epoch: 50 | Batch: 1016 | Loss: 0.12292852693041087\n",
            "Epoch: 50 | Batch: 1017 | Loss: 0.13357481389266757\n",
            "Epoch: 50 | Batch: 1018 | Loss: 0.14416391495272113\n",
            "Epoch: 50 | Batch: 1019 | Loss: 0.244909507343321\n",
            "Epoch: 50 | Batch: 1020 | Loss: 0.14262964626811425\n",
            "Epoch: 50 | Batch: 1021 | Loss: 0.12868574976456004\n",
            "Epoch: 50 | Batch: 1022 | Loss: 0.17850679404202394\n",
            "Epoch: 50 | Batch: 1023 | Loss: 0.1609960260884493\n",
            "Epoch: 50 | Batch: 1024 | Loss: 0.24527151940294928\n",
            "Epoch: 50 | Batch: 1025 | Loss: 0.1294726658279545\n",
            "Epoch: 50 | Batch: 1026 | Loss: 0.1762594290291032\n",
            "Epoch: 50 | Batch: 1027 | Loss: 0.12527333601879395\n",
            "Epoch: 50 | Batch: 1028 | Loss: 0.14738943521170852\n",
            "Epoch: 50 | Batch: 1029 | Loss: 0.21956083870484838\n",
            "Epoch: 50 | Batch: 1030 | Loss: 0.1428586606835033\n",
            "Epoch: 50 | Batch: 1031 | Loss: 0.18174474566261797\n",
            "Epoch: 50 | Batch: 1032 | Loss: 0.1393425657853391\n",
            "Epoch: 50 | Batch: 1033 | Loss: 0.13246944241781813\n",
            "Epoch: 50 | Batch: 1034 | Loss: 0.13474284338093323\n",
            "Epoch: 50 | Batch: 1035 | Loss: 0.20941737251949002\n",
            "Epoch: 50 | Batch: 1036 | Loss: 0.18520858691964753\n",
            "Epoch: 50 | Batch: 1037 | Loss: 0.20498586091393728\n",
            "Epoch: 50 | Batch: 1038 | Loss: 0.15547096441058764\n",
            "Epoch: 50 | Batch: 1039 | Loss: 0.2127491232047419\n",
            "Epoch: 50 | Batch: 1040 | Loss: 0.14527086935652173\n",
            "Epoch: 50 | Batch: 1041 | Loss: 0.1998349465645363\n",
            "Epoch: 50 | Batch: 1042 | Loss: 0.12449746841076492\n",
            "Epoch: 50 | Batch: 1043 | Loss: 0.14961796602806005\n",
            "Epoch: 50 | Batch: 1044 | Loss: 0.13697496343114024\n",
            "Epoch: 50 | Batch: 1045 | Loss: 0.1668130721724754\n",
            "Epoch: 50 | Batch: 1046 | Loss: 0.2341818008458914\n",
            "Epoch: 50 | Batch: 1047 | Loss: 0.1497342235689844\n",
            "Epoch: 50 | Batch: 1048 | Loss: 0.17288409778803568\n",
            "Epoch: 50 | Batch: 1049 | Loss: 0.15480641610304957\n",
            "Epoch: 50 | Batch: 1050 | Loss: 0.20781433750167766\n",
            "Epoch: 50 | Batch: 1051 | Loss: 0.1349527881806178\n",
            "Epoch: 50 | Batch: 1052 | Loss: 0.16787802946589672\n",
            "Epoch: 50 | Batch: 1053 | Loss: 0.13954874796865407\n",
            "Epoch: 50 | Batch: 1054 | Loss: 0.15484008681462194\n",
            "Epoch: 50 | Batch: 1055 | Loss: 0.17667884498693076\n",
            "Epoch: 50 | Batch: 1056 | Loss: 0.1960856935166168\n",
            "Epoch: 50 | Batch: 1057 | Loss: 0.17384602123265389\n",
            "Epoch: 50 | Batch: 1058 | Loss: 0.19098631950890357\n",
            "Epoch: 50 | Batch: 1059 | Loss: 0.1377191124327652\n",
            "Epoch: 50 | Batch: 1060 | Loss: 0.17971444328594616\n",
            "Epoch: 50 | Batch: 1061 | Loss: 0.20704564920670718\n",
            "Epoch: 50 | Batch: 1062 | Loss: 0.1782810186112392\n",
            "Epoch: 50 | Batch: 1063 | Loss: 0.19576057898565194\n",
            "Epoch: 50 | Batch: 1064 | Loss: 0.14638077862839302\n",
            "Epoch: 50 | Batch: 1065 | Loss: 0.16307528396517906\n",
            "Epoch: 50 | Batch: 1066 | Loss: 0.13201361941501166\n",
            "Epoch: 50 | Batch: 1067 | Loss: 0.16079261610423815\n",
            "Epoch: 50 | Batch: 1068 | Loss: 0.17915656045503742\n",
            "Epoch: 50 | Batch: 1069 | Loss: 0.17117800901096286\n",
            "Epoch: 50 | Batch: 1070 | Loss: 0.17609151096329925\n",
            "Epoch: 50 | Batch: 1071 | Loss: 0.16807351819377495\n",
            "Epoch: 50 | Batch: 1072 | Loss: 0.15738074087711842\n",
            "Epoch: 50 | Batch: 1073 | Loss: 0.19847481223639366\n",
            "Epoch: 50 | Batch: 1074 | Loss: 0.14212865351096649\n",
            "Epoch: 50 | Batch: 1075 | Loss: 0.1519739513004785\n",
            "Epoch: 50 | Batch: 1076 | Loss: 0.19676479628206336\n",
            "Epoch: 50 | Batch: 1077 | Loss: 0.16196244905055907\n",
            "Epoch: 50 | Batch: 1078 | Loss: 0.16230428765687574\n",
            "Epoch: 50 | Batch: 1079 | Loss: 0.20352920057991952\n",
            "Epoch: 50 | Batch: 1080 | Loss: 0.14879798227169605\n",
            "Epoch: 50 | Batch: 1081 | Loss: 0.15881519336216043\n",
            "Epoch: 50 | Batch: 1082 | Loss: 0.1461043993291398\n",
            "Epoch: 50 | Batch: 1083 | Loss: 0.14452360147512627\n",
            "Epoch: 50 | Batch: 1084 | Loss: 0.15689000679672538\n",
            "Epoch: 50 | Batch: 1085 | Loss: 0.197292238871221\n",
            "Epoch: 50 | Batch: 1086 | Loss: 0.16629696979414346\n",
            "Epoch: 50 | Batch: 1087 | Loss: 0.18352215536107425\n",
            "Epoch: 50 | Batch: 1088 | Loss: 0.20364114586029633\n",
            "Epoch: 50 | Batch: 1089 | Loss: 0.16187530719416887\n",
            "Epoch: 50 | Batch: 1090 | Loss: 0.1674559735908942\n",
            "Epoch: 50 | Batch: 1091 | Loss: 0.14349617418668115\n",
            "Epoch: 50 | Batch: 1092 | Loss: 0.15220596724520463\n",
            "Epoch: 50 | Batch: 1093 | Loss: 0.14801373340396742\n",
            "Epoch: 50 | Batch: 1094 | Loss: 0.14617738431593577\n",
            "Epoch: 50 | Batch: 1095 | Loss: 0.19012693016951004\n",
            "Epoch: 50 | Batch: 1096 | Loss: 0.173478847308116\n",
            "Epoch: 50 | Batch: 1097 | Loss: 0.17198670128420704\n",
            "Epoch: 50 | Batch: 1098 | Loss: 0.17411644792231484\n",
            "Epoch: 50 | Batch: 1099 | Loss: 0.1685308303271557\n",
            "Epoch: 50 | Batch: 1100 | Loss: 0.1663833510645324\n",
            "Epoch: 50 | Batch: 1101 | Loss: 0.1802915354079725\n",
            "Epoch: 50 | Batch: 1102 | Loss: 0.16705184428387124\n",
            "Epoch: 50 | Batch: 1103 | Loss: 0.18629809991723734\n",
            "Epoch: 50 | Batch: 1104 | Loss: 0.15252195833963214\n",
            "Epoch: 50 | Batch: 1105 | Loss: 0.1598448939198316\n",
            "Epoch: 50 | Batch: 1106 | Loss: 0.2079837215678995\n",
            "Epoch: 50 | Batch: 1107 | Loss: 0.15488738218159545\n",
            "Epoch: 50 | Batch: 1108 | Loss: 0.16283105945523124\n",
            "Epoch: 50 | Batch: 1109 | Loss: 0.14456976158053095\n",
            "Epoch: 50 | Batch: 1110 | Loss: 0.13823031298315847\n",
            "Epoch: 50 | Batch: 1111 | Loss: 0.15509095301763143\n",
            "Epoch: 50 | Batch: 1112 | Loss: 0.21373565758742225\n",
            "Epoch: 50 | Batch: 1113 | Loss: 0.16742203017045215\n",
            "Epoch: 50 | Batch: 1114 | Loss: 0.15597138837557628\n",
            "Epoch: 50 | Batch: 1115 | Loss: 0.11638297453340857\n",
            "Epoch: 50 | Batch: 1116 | Loss: 0.15531787562101318\n",
            "Epoch: 50 | Batch: 1117 | Loss: 0.1939825618001737\n",
            "Epoch: 50 | Batch: 1118 | Loss: 0.1845553178244077\n",
            "Epoch: 50 | Batch: 1119 | Loss: 0.18563220251985763\n",
            "Epoch: 50 | Batch: 1120 | Loss: 0.15941868927346123\n",
            "Epoch: 50 | Batch: 1121 | Loss: 0.17470283080488247\n",
            "Epoch: 50 | Batch: 1122 | Loss: 0.20147099912186597\n",
            "Epoch: 50 | Batch: 1123 | Loss: 0.11876493091696286\n",
            "Epoch: 50 | Batch: 1124 | Loss: 0.16325564368473378\n",
            "Epoch: 50 | Batch: 1125 | Loss: 0.14574296716415294\n",
            "Epoch: 50 | Batch: 1126 | Loss: 0.15945029327121052\n",
            "Epoch: 50 | Batch: 1127 | Loss: 0.16987888460886494\n",
            "Epoch: 50 | Batch: 1128 | Loss: 0.14317175207073196\n",
            "Epoch: 50 | Batch: 1129 | Loss: 0.13606652253338283\n",
            "Epoch: 50 | Batch: 1130 | Loss: 0.16977999293828344\n",
            "Epoch: 50 | Batch: 1131 | Loss: 0.1802517045121287\n",
            "Epoch: 50 | Batch: 1132 | Loss: 0.21031240576744933\n",
            "Epoch: 50 | Batch: 1133 | Loss: 0.13914112145362734\n",
            "Epoch: 50 | Batch: 1134 | Loss: 0.18682472143095882\n",
            "Epoch: 50 | Batch: 1135 | Loss: 0.16231930051331261\n",
            "Epoch: 50 | Batch: 1136 | Loss: 0.16238418781556807\n",
            "Epoch: 50 | Batch: 1137 | Loss: 0.1946828911524625\n",
            "Epoch: 50 | Batch: 1138 | Loss: 0.18932516142885314\n",
            "Epoch: 50 | Batch: 1139 | Loss: 0.18526396163961306\n",
            "Epoch: 50 | Batch: 1140 | Loss: 0.17009668115314303\n",
            "Epoch: 50 | Batch: 1141 | Loss: 0.164697333525038\n",
            "Epoch: 50 | Batch: 1142 | Loss: 0.14003176893181687\n",
            "Epoch: 50 | Batch: 1143 | Loss: 0.19714173930010168\n",
            "Epoch: 50 | Batch: 1144 | Loss: 0.17820451937309512\n",
            "Epoch: 50 | Batch: 1145 | Loss: 0.2505726381106973\n",
            "Epoch: 50 | Batch: 1146 | Loss: 0.14016103908410962\n",
            "Epoch: 50 | Batch: 1147 | Loss: 0.22065433605041224\n",
            "Epoch: 50 | Batch: 1148 | Loss: 0.14770014726453692\n",
            "Epoch: 50 | Batch: 1149 | Loss: 0.1458933932836116\n",
            "Epoch: 50 | Batch: 1150 | Loss: 0.1390507275018077\n",
            "Epoch: 50 | Batch: 1151 | Loss: 0.19367397314904328\n",
            "Epoch: 50 | Batch: 1152 | Loss: 0.17577243598915876\n",
            "Epoch: 50 | Batch: 1153 | Loss: 0.2223954432176816\n",
            "Epoch: 50 | Batch: 1154 | Loss: 0.18806786467191583\n",
            "Epoch: 50 | Batch: 1155 | Loss: 0.18499851599122918\n",
            "Epoch: 50 | Batch: 1156 | Loss: 0.1823824348574326\n",
            "Epoch: 50 | Batch: 1157 | Loss: 0.16319721871594609\n",
            "Epoch: 50 | Batch: 1158 | Loss: 0.2405028941481297\n",
            "Epoch: 50 | Batch: 1159 | Loss: 0.13872342300428311\n",
            "Epoch: 50 | Batch: 1160 | Loss: 0.15959464232740717\n",
            "Epoch: 50 | Batch: 1161 | Loss: 0.1542162546590252\n",
            "Epoch: 50 | Batch: 1162 | Loss: 0.1878681381646032\n",
            "Epoch: 50 | Batch: 1163 | Loss: 0.18714658587965666\n",
            "Epoch: 50 | Batch: 1164 | Loss: 0.20355756553137178\n",
            "Epoch: 50 | Batch: 1165 | Loss: 0.18264034498830262\n",
            "Epoch: 50 | Batch: 1166 | Loss: 0.18162110568104506\n",
            "Epoch: 50 | Batch: 1167 | Loss: 0.16792681735780074\n",
            "Epoch: 50 | Batch: 1168 | Loss: 0.19995153668675997\n",
            "Epoch: 50 | Batch: 1169 | Loss: 0.14828162780717333\n",
            "Epoch: 50 | Batch: 1170 | Loss: 0.1857797146615054\n",
            "Epoch: 50 | Batch: 1171 | Loss: 0.20848101735277524\n",
            "Epoch: 50 | Batch: 1172 | Loss: 0.19754991737810956\n",
            "Epoch: 50 | Batch: 1173 | Loss: 0.17780230836943123\n",
            "Epoch: 50 | Batch: 1174 | Loss: 0.15534800771383833\n",
            "Epoch: 50 | Batch: 1175 | Loss: 0.1574631488973312\n",
            "Epoch: 50 | Batch: 1176 | Loss: 0.17412549185983697\n",
            "Epoch: 50 | Batch: 1177 | Loss: 0.13813056316958097\n",
            "Epoch: 50 | Batch: 1178 | Loss: 0.15530896867191404\n",
            "Epoch: 50 | Batch: 1179 | Loss: 0.14656915902545165\n",
            "Epoch: 50 | Batch: 1180 | Loss: 0.1686545095421975\n",
            "Epoch: 50 | Batch: 1181 | Loss: 0.1348884192728568\n",
            "Epoch: 50 | Batch: 1182 | Loss: 0.17126702921536882\n",
            "Epoch: 50 | Batch: 1183 | Loss: 0.1492405419322061\n",
            "Epoch: 50 | Batch: 1184 | Loss: 0.1583646033783345\n",
            "Epoch: 50 | Batch: 1185 | Loss: 0.16498972489944608\n",
            "Epoch: 50 | Batch: 1186 | Loss: 0.18083176698720005\n",
            "Epoch: 50 | Batch: 1187 | Loss: 0.18901394414173267\n",
            "Epoch: 50 | Batch: 1188 | Loss: 0.15285199756041404\n",
            "Epoch: 50 | Batch: 1189 | Loss: 0.19896361071554497\n",
            "Epoch: 50 | Batch: 1190 | Loss: 0.18437177197511811\n",
            "Epoch: 50 | Batch: 1191 | Loss: 0.1728028733726734\n",
            "Epoch: 50 | Batch: 1192 | Loss: 0.21279464737710013\n",
            "Epoch: 50 | Batch: 1193 | Loss: 0.16461653904079057\n",
            "Epoch: 50 | Batch: 1194 | Loss: 0.2347404320977391\n",
            "Epoch: 50 | Batch: 1195 | Loss: 0.19191395973822384\n",
            "Epoch: 50 | Batch: 1196 | Loss: 0.14172177777903597\n",
            "Epoch: 50 | Batch: 1197 | Loss: 0.14783354136619575\n",
            "Epoch: 50 | Batch: 1198 | Loss: 0.147350446046928\n",
            "Epoch: 50 | Batch: 1199 | Loss: 0.14395711922519772\n",
            "Epoch: 50 | Batch: 1200 | Loss: 0.16515824247816913\n",
            "Epoch: 50 | Batch: 1201 | Loss: 0.1808692957173221\n",
            "Epoch: 50 | Batch: 1202 | Loss: 0.17596987589343585\n",
            "Epoch: 50 | Batch: 1203 | Loss: 0.17003000968584034\n",
            "Epoch: 50 | Batch: 1204 | Loss: 0.17690412951300902\n",
            "Epoch: 50 | Batch: 1205 | Loss: 0.16703890571171634\n",
            "Epoch: 50 | Batch: 1206 | Loss: 0.16024507688557557\n",
            "Epoch: 50 | Batch: 1207 | Loss: 0.14689075596193849\n",
            "Epoch: 50 | Batch: 1208 | Loss: 0.16923593730518294\n",
            "Epoch: 50 | Batch: 1209 | Loss: 0.13777738536279482\n",
            "Epoch: 50 | Batch: 1210 | Loss: 0.16945291110704983\n",
            "Epoch: 50 | Batch: 1211 | Loss: 0.1812843910331124\n",
            "Epoch: 50 | Batch: 1212 | Loss: 0.11376465342694615\n",
            "Epoch: 50 | Batch: 1213 | Loss: 0.21359858931601516\n",
            "Epoch: 50 | Batch: 1214 | Loss: 0.14088115565820172\n",
            "Epoch: 50 | Batch: 1215 | Loss: 0.1238582807519405\n",
            "Epoch: 50 | Batch: 1216 | Loss: 0.11751032247816857\n",
            "Epoch: 50 | Batch: 1217 | Loss: 0.13661755008056445\n",
            "Epoch: 50 | Batch: 1218 | Loss: 0.21244577712172863\n",
            "Epoch: 50 | Batch: 1219 | Loss: 0.18892707163713057\n",
            "Epoch: 50 | Batch: 1220 | Loss: 0.15440541479694395\n",
            "Epoch: 50 | Batch: 1221 | Loss: 0.14185364054533203\n",
            "Epoch: 50 | Batch: 1222 | Loss: 0.10589192271737902\n",
            "Epoch: 50 | Batch: 1223 | Loss: 0.13337567886272866\n",
            "Epoch: 50 | Batch: 1224 | Loss: 0.1854509072795063\n",
            "Epoch: 50 | Batch: 1225 | Loss: 0.14971172164511504\n",
            "Epoch: 50 | Batch: 1226 | Loss: 0.17879239128072524\n",
            "Epoch: 50 | Batch: 1227 | Loss: 0.164286878724054\n",
            "Epoch: 50 | Batch: 1228 | Loss: 0.16214047222799693\n",
            "Epoch: 50 | Batch: 1229 | Loss: 0.19769341706598487\n",
            "Epoch: 50 | Batch: 1230 | Loss: 0.18998102823490898\n",
            "Epoch: 50 | Batch: 1231 | Loss: 0.19946297048402978\n",
            "Epoch: 50 | Batch: 1232 | Loss: 0.1704390934817348\n",
            "Epoch: 50 | Batch: 1233 | Loss: 0.15624052020691614\n",
            "Epoch: 50 | Batch: 1234 | Loss: 0.17494849673902294\n",
            "Epoch: 50 | Batch: 1235 | Loss: 0.1584024493074146\n",
            "Epoch: 50 | Batch: 1236 | Loss: 0.17146599939529816\n",
            "Epoch: 50 | Batch: 1237 | Loss: 0.14966799096093572\n",
            "Epoch: 50 | Batch: 1238 | Loss: 0.1755562560836043\n",
            "Epoch: 50 | Batch: 1239 | Loss: 0.1598082137933693\n",
            "Epoch: 50 | Batch: 1240 | Loss: 0.18648532767057122\n",
            "Epoch: 50 | Batch: 1241 | Loss: 0.18236136662441754\n",
            "Epoch: 50 | Batch: 1242 | Loss: 0.20933518708967183\n",
            "Epoch: 50 | Batch: 1243 | Loss: 0.14946452307620464\n",
            "Epoch: 50 | Batch: 1244 | Loss: 0.14658750079024924\n",
            "Epoch: 50 | Batch: 1245 | Loss: 0.14486855766294793\n",
            "Epoch: 50 | Batch: 1246 | Loss: 0.14221989257510653\n",
            "Epoch: 50 | Batch: 1247 | Loss: 0.18397648049583198\n",
            "Epoch: 50 | Batch: 1248 | Loss: 0.1621939596426994\n",
            "Epoch: 50 | Batch: 1249 | Loss: 0.16397003523981687\n",
            "Epoch: 50 | Batch: 1250 | Loss: 0.17398452539689915\n",
            "Epoch: 50 | Batch: 1251 | Loss: 0.15458546406729587\n",
            "Epoch: 50 | Batch: 1252 | Loss: 0.23796324003304847\n",
            "Epoch: 50 | Batch: 1253 | Loss: 0.15512101115383922\n",
            "Epoch: 50 | Batch: 1254 | Loss: 0.1489931719194681\n",
            "Epoch: 50 | Batch: 1255 | Loss: 0.14830658642909345\n",
            "Epoch: 50 | Batch: 1256 | Loss: 0.14272394001497202\n",
            "Epoch: 50 | Batch: 1257 | Loss: 0.1657818594738483\n",
            "Epoch: 50 | Batch: 1258 | Loss: 0.18767464530512168\n",
            "Epoch: 50 | Batch: 1259 | Loss: 0.1601465059304224\n",
            "Epoch: 50 | Batch: 1260 | Loss: 0.14320260916648866\n",
            "Epoch: 50 | Batch: 1261 | Loss: 0.14592095691627016\n",
            "Epoch: 50 | Batch: 1262 | Loss: 0.1992282021361036\n",
            "Epoch: 50 | Batch: 1263 | Loss: 0.15511854951504295\n",
            "Epoch: 50 | Batch: 1264 | Loss: 0.14183889401130306\n",
            "Epoch: 50 | Batch: 1265 | Loss: 0.17522469780510155\n",
            "Epoch: 50 | Batch: 1266 | Loss: 0.1480332146842557\n",
            "Epoch: 50 | Batch: 1267 | Loss: 0.17586007891311792\n",
            "Epoch: 50 | Batch: 1268 | Loss: 0.17278042626527135\n",
            "Epoch: 50 | Batch: 1269 | Loss: 0.19179225021635585\n",
            "Epoch: 50 | Batch: 1270 | Loss: 0.18453415824090913\n",
            "Epoch: 50 | Batch: 1271 | Loss: 0.2022669930610677\n",
            "Epoch: 50 | Batch: 1272 | Loss: 0.1399588272383963\n",
            "Epoch: 50 | Batch: 1273 | Loss: 0.17959958846727744\n",
            "Epoch: 50 | Batch: 1274 | Loss: 0.20344290962923944\n",
            "Epoch: 50 | Batch: 1275 | Loss: 0.15969222432238567\n",
            "Epoch: 50 | Batch: 1276 | Loss: 0.17147486817104907\n",
            "Epoch: 50 | Batch: 1277 | Loss: 0.2274179715014975\n",
            "Epoch: 50 | Batch: 1278 | Loss: 0.1961506236499061\n",
            "Epoch: 50 | Batch: 1279 | Loss: 0.13160081336168683\n",
            "Epoch: 50 | Batch: 1280 | Loss: 0.18590500163776524\n",
            "Epoch: 50 | Batch: 1281 | Loss: 0.15436635497372267\n",
            "Epoch: 50 | Batch: 1282 | Loss: 0.12907353066969232\n",
            "Epoch: 50 | Batch: 1283 | Loss: 0.1715851759580088\n",
            "Epoch: 50 | Batch: 1284 | Loss: 0.1639802826935985\n",
            "Epoch: 50 | Batch: 1285 | Loss: 0.1998565004809338\n",
            "Epoch: 50 | Batch: 1286 | Loss: 0.13098248550940272\n",
            "Epoch: 50 | Batch: 1287 | Loss: 0.18373821365117785\n",
            "Epoch: 50 | Batch: 1288 | Loss: 0.1601817389042532\n",
            "Epoch: 50 | Batch: 1289 | Loss: 0.14875303244940713\n",
            "Epoch: 50 | Batch: 1290 | Loss: 0.15200224851716637\n",
            "Epoch: 50 | Batch: 1291 | Loss: 0.14952624840852202\n",
            "Epoch: 50 | Batch: 1292 | Loss: 0.14945440300112106\n",
            "Epoch: 50 | Batch: 1293 | Loss: 0.19296499120853916\n",
            "Epoch: 50 | Batch: 1294 | Loss: 0.19425969657875355\n",
            "Epoch: 50 | Batch: 1295 | Loss: 0.15691032528794596\n",
            "Epoch: 50 | Batch: 1296 | Loss: 0.1732144917684324\n",
            "Epoch: 50 | Batch: 1297 | Loss: 0.1749778285941606\n",
            "Epoch: 50 | Batch: 1298 | Loss: 0.17431965052637022\n",
            "Epoch: 50 | Batch: 1299 | Loss: 0.1529694456836599\n",
            "Epoch: 50 | Batch: 1300 | Loss: 0.14926845331088381\n",
            "Epoch: 50 | Batch: 1301 | Loss: 0.1884231915508769\n",
            "Epoch: 50 | Batch: 1302 | Loss: 0.13642556762284308\n",
            "Epoch: 50 | Batch: 1303 | Loss: 0.17298429309347574\n",
            "Epoch: 50 | Batch: 1304 | Loss: 0.15234213038104003\n",
            "Epoch: 50 | Batch: 1305 | Loss: 0.11058068778678884\n",
            "Epoch: 50 | Batch: 1306 | Loss: 0.13660569065435268\n",
            "Epoch: 50 | Batch: 1307 | Loss: 0.16555045073062888\n",
            "Epoch: 50 | Batch: 1308 | Loss: 0.1937906134298908\n",
            "Epoch: 50 | Batch: 1309 | Loss: 0.16000685846946427\n",
            "Epoch: 50 | Batch: 1310 | Loss: 0.162462486078136\n",
            "Epoch: 50 | Batch: 1311 | Loss: 0.1756123875109456\n",
            "Epoch: 50 | Batch: 1312 | Loss: 0.14109536029127465\n",
            "Epoch: 50 | Batch: 1313 | Loss: 0.15032957740262626\n",
            "Epoch: 50 | Batch: 1314 | Loss: 0.15610025530115706\n",
            "Epoch: 50 | Batch: 1315 | Loss: 0.1335936182813105\n",
            "Epoch: 50 | Batch: 1316 | Loss: 0.1981720707200671\n",
            "Epoch: 50 | Batch: 1317 | Loss: 0.16804003930815986\n",
            "Epoch: 50 | Batch: 1318 | Loss: 0.15189437454152\n",
            "Epoch: 50 | Batch: 1319 | Loss: 0.16750688373121042\n",
            "Epoch: 50 | Batch: 1320 | Loss: 0.17531766454979483\n",
            "Epoch: 50 | Batch: 1321 | Loss: 0.15396647457405674\n",
            "Epoch: 50 | Batch: 1322 | Loss: 0.2005139298244276\n",
            "Epoch: 50 | Batch: 1323 | Loss: 0.1585141268781805\n",
            "Epoch: 50 | Batch: 1324 | Loss: 0.1487811186252046\n",
            "Epoch: 50 | Batch: 1325 | Loss: 0.1391211546904106\n",
            "Epoch: 50 | Batch: 1326 | Loss: 0.187084367340463\n",
            "Epoch: 50 | Batch: 1327 | Loss: 0.1960663247833936\n",
            "Epoch: 50 | Batch: 1328 | Loss: 0.19413174685073448\n",
            "Epoch: 50 | Batch: 1329 | Loss: 0.1651600794176753\n",
            "Epoch: 50 | Batch: 1330 | Loss: 0.19512088353610602\n",
            "Epoch: 50 | Batch: 1331 | Loss: 0.15196770641365423\n",
            "Epoch: 50 | Batch: 1332 | Loss: 0.12651874354198733\n",
            "Epoch: 50 | Batch: 1333 | Loss: 0.1916453979239542\n",
            "Epoch: 50 | Batch: 1334 | Loss: 0.14092919738912\n",
            "Epoch: 50 | Batch: 1335 | Loss: 0.14816913147764565\n",
            "Epoch: 50 | Batch: 1336 | Loss: 0.15129629985585208\n",
            "Epoch: 50 | Batch: 1337 | Loss: 0.1826044890149216\n",
            "Epoch: 50 | Batch: 1338 | Loss: 0.18167503872964483\n",
            "Epoch: 50 | Batch: 1339 | Loss: 0.17612718359555357\n",
            "Epoch: 50 | Batch: 1340 | Loss: 0.15111624918585329\n",
            "Epoch: 50 | Batch: 1341 | Loss: 0.13668677605816634\n",
            "Epoch: 50 | Batch: 1342 | Loss: 0.13594439694933955\n",
            "Epoch: 50 | Batch: 1343 | Loss: 0.14065451283627925\n",
            "Epoch: 50 | Batch: 1344 | Loss: 0.10821639583786144\n",
            "Epoch: 50 | Batch: 1345 | Loss: 0.1464403377614726\n",
            "Epoch: 50 | Batch: 1346 | Loss: 0.14780538178967528\n",
            "Epoch: 50 | Batch: 1347 | Loss: 0.16943386679520353\n",
            "Epoch: 50 | Batch: 1348 | Loss: 0.15626361016478224\n",
            "Epoch: 50 | Batch: 1349 | Loss: 0.15785121428219867\n",
            "Epoch: 50 | Batch: 1350 | Loss: 0.17493314059337348\n",
            "Epoch: 50 | Batch: 1351 | Loss: 0.13673303182899382\n",
            "Epoch: 50 | Batch: 1352 | Loss: 0.13628390838800064\n",
            "Epoch: 50 | Batch: 1353 | Loss: 0.19623368163219218\n",
            "Epoch: 50 | Batch: 1354 | Loss: 0.1473743543488097\n",
            "Epoch: 50 | Batch: 1355 | Loss: 0.23025736065655455\n",
            "Epoch: 50 | Batch: 1356 | Loss: 0.1937649188697124\n",
            "Epoch: 50 | Batch: 1357 | Loss: 0.1251606204606447\n",
            "Epoch: 50 | Batch: 1358 | Loss: 0.14057376572182484\n",
            "Epoch: 50 | Batch: 1359 | Loss: 0.16017074774244142\n",
            "Epoch: 50 | Batch: 1360 | Loss: 0.1460733512487998\n",
            "Epoch: 50 | Batch: 1361 | Loss: 0.18719038205692928\n",
            "Epoch: 50 | Batch: 1362 | Loss: 0.17000430825203172\n",
            "Epoch: 50 | Batch: 1363 | Loss: 0.15641487704274823\n",
            "Epoch: 50 | Batch: 1364 | Loss: 0.17631524304303084\n",
            "Epoch: 50 | Batch: 1365 | Loss: 0.16171942086427368\n",
            "Epoch: 50 | Batch: 1366 | Loss: 0.16199788533922366\n",
            "Epoch: 50 | Batch: 1367 | Loss: 0.19074218099471107\n",
            "Epoch: 50 | Batch: 1368 | Loss: 0.15385981590823616\n",
            "Epoch: 50 | Batch: 1369 | Loss: 0.1805226166375178\n",
            "Epoch: 50 | Batch: 1370 | Loss: 0.1460331966240971\n",
            "Epoch: 50 | Batch: 1371 | Loss: 0.1436416885016848\n",
            "Epoch: 50 | Batch: 1372 | Loss: 0.16278954220232134\n",
            "Epoch: 50 | Batch: 1373 | Loss: 0.14894822576681574\n",
            "Epoch: 50 | Batch: 1374 | Loss: 0.14407445069071356\n",
            "Epoch: 50 | Batch: 1375 | Loss: 0.11399714100243603\n",
            "Epoch: 50 | Batch: 1376 | Loss: 0.2203065989492844\n",
            "Epoch: 50 | Batch: 1377 | Loss: 0.17846785506475085\n",
            "Epoch: 50 | Batch: 1378 | Loss: 0.22700264125505384\n",
            "Epoch: 50 | Batch: 1379 | Loss: 0.12818053950461727\n",
            "Epoch: 50 | Batch: 1380 | Loss: 0.2187805521370128\n",
            "Epoch: 50 | Batch: 1381 | Loss: 0.20075362795781648\n",
            "Epoch: 50 | Batch: 1382 | Loss: 0.18142828237051598\n",
            "Epoch: 50 | Batch: 1383 | Loss: 0.20683217621295058\n",
            "Epoch: 50 | Batch: 1384 | Loss: 0.1904916817597294\n",
            "Epoch: 50 | Batch: 1385 | Loss: 0.17702514988404522\n",
            "Epoch: 50 | Batch: 1386 | Loss: 0.13659979197748667\n",
            "Epoch: 50 | Batch: 1387 | Loss: 0.17909569964454392\n",
            "Epoch: 50 | Batch: 1388 | Loss: 0.18108041708335437\n",
            "Epoch: 50 | Batch: 1389 | Loss: 0.20745588728039363\n",
            "Epoch: 50 | Batch: 1390 | Loss: 0.175009337749066\n",
            "Epoch: 50 | Batch: 1391 | Loss: 0.1611659822365556\n",
            "Epoch: 50 | Batch: 1392 | Loss: 0.14869796605075175\n",
            "Epoch: 50 | Batch: 1393 | Loss: 0.16963591494601574\n",
            "Epoch: 50 | Batch: 1394 | Loss: 0.1572943516087732\n",
            "Epoch: 50 | Batch: 1395 | Loss: 0.18094420232734748\n",
            "Epoch: 50 | Batch: 1396 | Loss: 0.14424858418731498\n",
            "Epoch: 50 | Batch: 1397 | Loss: 0.18739620405937993\n",
            "Epoch: 50 | Batch: 1398 | Loss: 0.1764539383921976\n",
            "Epoch: 50 | Batch: 1399 | Loss: 0.19881343535943652\n",
            "Epoch: 50 | Batch: 1400 | Loss: 0.10671180067981641\n",
            "Epoch: 50 | Batch: 1401 | Loss: 0.19543006399962143\n",
            "Epoch: 50 | Batch: 1402 | Loss: 0.1694420267452158\n",
            "Epoch: 50 | Batch: 1403 | Loss: 0.1585638621017169\n",
            "Epoch: 50 | Batch: 1404 | Loss: 0.15195209805045734\n",
            "Epoch: 50 | Batch: 1405 | Loss: 0.2353748667410186\n",
            "Epoch: 50 | Batch: 1406 | Loss: 0.17417846928119834\n",
            "Epoch: 50 | Batch: 1407 | Loss: 0.13174685690182908\n",
            "Epoch: 50 | Batch: 1408 | Loss: 0.15367544085588558\n",
            "Epoch: 50 | Batch: 1409 | Loss: 0.1822304989166555\n",
            "Epoch: 50 | Batch: 1410 | Loss: 0.13315049679700053\n",
            "Epoch: 50 | Batch: 1411 | Loss: 0.1659301696598748\n",
            "Epoch: 50 | Batch: 1412 | Loss: 0.20067778152018917\n",
            "Epoch: 50 | Batch: 1413 | Loss: 0.17857165730849706\n",
            "Epoch: 50 | Batch: 1414 | Loss: 0.15862859063383647\n",
            "Epoch: 50 | Batch: 1415 | Loss: 0.12161265123523902\n",
            "Epoch: 50 | Batch: 1416 | Loss: 0.1771414485692853\n",
            "Epoch: 50 | Batch: 1417 | Loss: 0.18945082165040933\n",
            "Epoch: 50 | Batch: 1418 | Loss: 0.2026537735758414\n",
            "Epoch: 50 | Batch: 1419 | Loss: 0.13971181054643675\n",
            "Epoch: 50 | Batch: 1420 | Loss: 0.15886282531892404\n",
            "Epoch: 50 | Batch: 1421 | Loss: 0.1446012251108134\n",
            "Epoch: 50 | Batch: 1422 | Loss: 0.17132403509410052\n",
            "Epoch: 50 | Batch: 1423 | Loss: 0.20289917170691787\n",
            "Epoch: 50 | Batch: 1424 | Loss: 0.1458052397133617\n",
            "Epoch: 50 | Batch: 1425 | Loss: 0.1698905469027196\n",
            "Epoch: 50 | Batch: 1426 | Loss: 0.14791015785668915\n",
            "Epoch: 50 | Batch: 1427 | Loss: 0.15799151934540612\n",
            "Epoch: 50 | Batch: 1428 | Loss: 0.2130624201829411\n",
            "Epoch: 50 | Batch: 1429 | Loss: 0.21672678121836925\n",
            "Epoch: 50 | Batch: 1430 | Loss: 0.1679029776615308\n",
            "Epoch: 50 | Batch: 1431 | Loss: 0.14123403553614328\n",
            "Epoch: 50 | Batch: 1432 | Loss: 0.1702611872253768\n",
            "Epoch: 50 | Batch: 1433 | Loss: 0.12980478254504557\n",
            "Epoch: 50 | Batch: 1434 | Loss: 0.15176315909935317\n",
            "Epoch: 50 | Batch: 1435 | Loss: 0.16496742315675358\n",
            "Epoch: 50 | Batch: 1436 | Loss: 0.15109009189984782\n",
            "Epoch: 50 | Batch: 1437 | Loss: 0.18863400321554943\n",
            "Epoch: 50 | Batch: 1438 | Loss: 0.16796878712012464\n",
            "Epoch: 50 | Batch: 1439 | Loss: 0.21776538720711858\n",
            "Epoch: 50 | Batch: 1440 | Loss: 0.16189647393167397\n",
            "Epoch: 50 | Batch: 1441 | Loss: 0.1763508857466631\n",
            "Epoch: 50 | Batch: 1442 | Loss: 0.1877893586329532\n",
            "Epoch: 50 | Batch: 1443 | Loss: 0.13918770050816975\n",
            "Epoch: 50 | Batch: 1444 | Loss: 0.15544174302006475\n",
            "Epoch: 50 | Batch: 1445 | Loss: 0.13606296495797723\n",
            "Epoch: 50 | Batch: 1446 | Loss: 0.1323914461161406\n",
            "Epoch: 50 | Batch: 1447 | Loss: 0.1537922928719875\n",
            "Epoch: 50 | Batch: 1448 | Loss: 0.16497369950029803\n",
            "Epoch: 50 | Batch: 1449 | Loss: 0.14149737276297739\n",
            "Epoch: 50 | Batch: 1450 | Loss: 0.23137370726199746\n",
            "Epoch: 50 | Batch: 1451 | Loss: 0.1511303667421241\n",
            "Epoch: 50 | Batch: 1452 | Loss: 0.14416913735263\n",
            "Epoch: 50 | Batch: 1453 | Loss: 0.1529736170938573\n",
            "Epoch: 50 | Batch: 1454 | Loss: 0.1974360371892339\n",
            "Epoch: 50 | Batch: 1455 | Loss: 0.1908143611773024\n",
            "Epoch: 50 | Batch: 1456 | Loss: 0.15418886789917502\n",
            "Epoch: 50 | Batch: 1457 | Loss: 0.15037924910272732\n",
            "Epoch: 50 | Batch: 1458 | Loss: 0.12828830536594843\n",
            "Epoch: 50 | Batch: 1459 | Loss: 0.17959376336394878\n",
            "Epoch: 50 | Batch: 1460 | Loss: 0.17321205788043578\n",
            "Epoch: 50 | Batch: 1461 | Loss: 0.16590582335764903\n",
            "Epoch: 50 | Batch: 1462 | Loss: 0.16014151028801787\n",
            "Epoch: 50 | Batch: 1463 | Loss: 0.1670005393780453\n",
            "Epoch: 50 | Batch: 1464 | Loss: 0.15032047891391176\n",
            "Epoch: 50 | Batch: 1465 | Loss: 0.16056823683351187\n",
            "Epoch: 50 | Batch: 1466 | Loss: 0.17247380916753097\n",
            "Epoch: 50 | Batch: 1467 | Loss: 0.18294583377887458\n",
            "Epoch: 50 | Batch: 1468 | Loss: 0.16953588995552227\n",
            "Epoch: 50 | Batch: 1469 | Loss: 0.16479484241363598\n",
            "Epoch: 50 | Batch: 1470 | Loss: 0.19628444867321654\n",
            "Epoch: 50 | Batch: 1471 | Loss: 0.19944863983360528\n",
            "Epoch: 50 | Batch: 1472 | Loss: 0.1341734340373005\n",
            "Epoch: 50 | Batch: 1473 | Loss: 0.1581536001332818\n",
            "Epoch: 50 | Batch: 1474 | Loss: 0.1783323185960336\n",
            "Epoch: 50 | Batch: 1475 | Loss: 0.17214377187456692\n",
            "Epoch: 50 | Batch: 1476 | Loss: 0.1818016046919656\n",
            "Epoch: 50 | Batch: 1477 | Loss: 0.1493267845520683\n",
            "Epoch: 50 | Batch: 1478 | Loss: 0.14317923314343717\n",
            "Epoch: 50 | Batch: 1479 | Loss: 0.1703552787284369\n",
            "Epoch: 50 | Batch: 1480 | Loss: 0.1634286313501311\n",
            "Epoch: 50 | Batch: 1481 | Loss: 0.1321814809906167\n",
            "Epoch: 50 | Batch: 1482 | Loss: 0.1635059719871536\n",
            "Epoch: 50 | Batch: 1483 | Loss: 0.18236045289941097\n",
            "Epoch: 50 | Batch: 1484 | Loss: 0.16178756393297647\n",
            "Epoch: 50 | Batch: 1485 | Loss: 0.22999107672492045\n",
            "Epoch: 50 | Batch: 1486 | Loss: 0.14905316743153962\n",
            "Epoch: 50 | Batch: 1487 | Loss: 0.15029635882764653\n",
            "Epoch: 50 | Batch: 1488 | Loss: 0.1452453642879677\n",
            "Epoch: 50 | Batch: 1489 | Loss: 0.18130416909615044\n",
            "Epoch: 50 | Batch: 1490 | Loss: 0.16430202928397347\n",
            "Epoch: 50 | Batch: 1491 | Loss: 0.14884259023591254\n",
            "Epoch: 50 | Batch: 1492 | Loss: 0.15571684822929296\n",
            "Epoch: 50 | Batch: 1493 | Loss: 0.1346772225898611\n",
            "Epoch: 50 | Batch: 1494 | Loss: 0.18559237701177927\n",
            "Epoch: 50 | Batch: 1495 | Loss: 0.15851927824344972\n",
            "Epoch: 50 | Batch: 1496 | Loss: 0.1421462248406515\n",
            "Epoch: 50 | Batch: 1497 | Loss: 0.1621294052637918\n",
            "Epoch: 50 | Batch: 1498 | Loss: 0.15456579344187169\n",
            "Epoch: 50 | Batch: 1499 | Loss: 0.15548284267004855\n",
            "Epoch: 50 | Batch: 1500 | Loss: 0.15599222633116316\n",
            "Epoch: 50 | Batch: 1501 | Loss: 0.13555232123216363\n",
            "Epoch: 50 | Batch: 1502 | Loss: 0.17460976464824077\n",
            "Epoch: 50 | Batch: 1503 | Loss: 0.16289543051354982\n",
            "Epoch: 50 | Batch: 1504 | Loss: 0.16178389694835624\n",
            "Epoch: 50 | Batch: 1505 | Loss: 0.1501885575394129\n",
            "Epoch: 50 | Batch: 1506 | Loss: 0.14479782215319123\n",
            "Epoch: 50 | Batch: 1507 | Loss: 0.16786067527297813\n",
            "Epoch: 50 | Batch: 1508 | Loss: 0.10008782005383847\n",
            "Epoch: 50 | Batch: 1509 | Loss: 0.1619768509351045\n",
            "Epoch: 50 | Batch: 1510 | Loss: 0.1312564042562085\n",
            "Epoch: 50 | Batch: 1511 | Loss: 0.15921039823487854\n",
            "Epoch: 50 | Batch: 1512 | Loss: 0.14071747746489469\n",
            "Epoch: 50 | Batch: 1513 | Loss: 0.16401851043630644\n",
            "Epoch: 50 | Batch: 1514 | Loss: 0.1516291039211592\n",
            "Epoch: 50 | Batch: 1515 | Loss: 0.18589070884067374\n",
            "Epoch: 50 | Batch: 1516 | Loss: 0.1510091030201324\n",
            "Epoch: 50 | Batch: 1517 | Loss: 0.13167298552563994\n",
            "Epoch: 50 | Batch: 1518 | Loss: 0.159373452226583\n",
            "Epoch: 50 | Batch: 1519 | Loss: 0.1553388321817073\n",
            "Epoch: 50 | Batch: 1520 | Loss: 0.15033353135719119\n",
            "Epoch: 50 | Batch: 1521 | Loss: 0.2037389400457385\n",
            "Epoch: 50 | Batch: 1522 | Loss: 0.16959928374959116\n",
            "Epoch: 50 | Batch: 1523 | Loss: 0.15866045441609128\n",
            "Epoch: 50 | Batch: 1524 | Loss: 0.1552905238177548\n",
            "Epoch: 50 | Batch: 1525 | Loss: 0.2473669472787778\n",
            "Epoch: 50 | Batch: 1526 | Loss: 0.1751562197519743\n",
            "Epoch: 50 | Batch: 1527 | Loss: 0.17255735367514177\n",
            "Epoch: 50 | Batch: 1528 | Loss: 0.1608057757361327\n",
            "Epoch: 50 | Batch: 1529 | Loss: 0.15894600100179795\n",
            "Epoch: 50 | Batch: 1530 | Loss: 0.16085489520367813\n",
            "Epoch: 50 | Batch: 1531 | Loss: 0.14014083267764899\n",
            "Epoch: 50 | Batch: 1532 | Loss: 0.15803966076845558\n",
            "Epoch: 50 | Batch: 1533 | Loss: 0.16332722084112286\n",
            "Epoch: 50 | Batch: 1534 | Loss: 0.16160764135528588\n",
            "Epoch: 50 | Batch: 1535 | Loss: 0.1657903594745392\n",
            "Epoch: 50 | Batch: 1536 | Loss: 0.13261521873373838\n",
            "Epoch: 50 | Batch: 1537 | Loss: 0.1673564093566728\n",
            "Epoch: 50 | Batch: 1538 | Loss: 0.18705939665063642\n",
            "Epoch: 50 | Batch: 1539 | Loss: 0.2142545377300979\n",
            "Epoch: 50 | Batch: 1540 | Loss: 0.1586970766352731\n",
            "Epoch: 50 | Batch: 1541 | Loss: 0.18260496849532062\n",
            "Epoch: 50 | Batch: 1542 | Loss: 0.1598499359369162\n",
            "Epoch: 50 | Batch: 1543 | Loss: 0.17008446922846215\n",
            "Epoch: 50 | Batch: 1544 | Loss: 0.14617619673759574\n",
            "Epoch: 50 | Batch: 1545 | Loss: 0.13365550917853175\n",
            "Epoch: 50 | Batch: 1546 | Loss: 0.1520165540268224\n",
            "Epoch: 50 | Batch: 1547 | Loss: 0.15420866457930563\n",
            "Epoch: 50 | Batch: 1548 | Loss: 0.18028299313064186\n",
            "Epoch: 50 | Batch: 1549 | Loss: 0.15639874675560583\n",
            "Epoch: 50 | Batch: 1550 | Loss: 0.15195639619244733\n",
            "Epoch: 50 | Batch: 1551 | Loss: 0.174066692208103\n",
            "Epoch: 50 | Batch: 1552 | Loss: 0.15128815294894393\n",
            "Epoch: 50 | Batch: 1553 | Loss: 0.1570731475892475\n",
            "Epoch: 50 | Batch: 1554 | Loss: 0.16681322644059277\n",
            "Epoch: 50 | Batch: 1555 | Loss: 0.1172784190684982\n",
            "Epoch: 50 | Batch: 1556 | Loss: 0.16828920734467975\n",
            "Epoch: 50 | Batch: 1557 | Loss: 0.18452600303853872\n",
            "Epoch: 50 | Batch: 1558 | Loss: 0.143288686638375\n",
            "Epoch: 50 | Batch: 1559 | Loss: 0.19156225314984543\n",
            "Epoch: 50 | Batch: 1560 | Loss: 0.18587161685114673\n",
            "Epoch: 50 | Batch: 1561 | Loss: 0.1593172757766776\n",
            "Epoch: 50 | Batch: 1562 | Loss: 0.16046537947334044\n",
            "Epoch: 50 | Batch: 1563 | Loss: 0.14472121653208037\n",
            "Epoch: 50 | Batch: 1564 | Loss: 0.14714624945670415\n",
            "Epoch: 50 | Batch: 1565 | Loss: 0.14297583362909325\n",
            "Epoch: 50 | Batch: 1566 | Loss: 0.12089755115198961\n",
            "Epoch: 50 | Batch: 1567 | Loss: 0.13025256243054734\n",
            "Epoch: 50 | Batch: 1568 | Loss: 0.1727065979701955\n",
            "Epoch: 50 | Batch: 1569 | Loss: 0.22566370276042494\n",
            "Epoch: 50 | Batch: 1570 | Loss: 0.2153328247356936\n",
            "Epoch: 50 | Batch: 1571 | Loss: 0.14412194985669835\n",
            "Epoch: 50 | Batch: 1572 | Loss: 0.18812962367559893\n",
            "Epoch: 50 | Batch: 1573 | Loss: 0.163320615414683\n",
            "Epoch: 50 | Batch: 1574 | Loss: 0.1499289906504007\n",
            "Epoch: 50 | Batch: 1575 | Loss: 0.2127749983102394\n",
            "Epoch: 50 | Batch: 1576 | Loss: 0.19475170872475064\n",
            "Epoch: 50 | Batch: 1577 | Loss: 0.13615079917087705\n",
            "Epoch: 50 | Batch: 1578 | Loss: 0.1616689928754635\n",
            "Epoch: 50 | Batch: 1579 | Loss: 0.18140367733958196\n",
            "Epoch: 50 | Batch: 1580 | Loss: 0.1627222662429625\n",
            "Epoch: 50 | Batch: 1581 | Loss: 0.1718052892763195\n",
            "Epoch: 50 | Batch: 1582 | Loss: 0.14846474233533608\n",
            "Epoch: 50 | Batch: 1583 | Loss: 0.12943396809802227\n",
            "Epoch: 50 | Batch: 1584 | Loss: 0.1542666072570274\n",
            "Epoch: 50 | Batch: 1585 | Loss: 0.14698032205364958\n",
            "Epoch: 50 | Batch: 1586 | Loss: 0.12219489613562845\n",
            "Epoch: 50 | Batch: 1587 | Loss: 0.14723116636875339\n",
            "Epoch: 50 | Batch: 1588 | Loss: 0.16241317629249077\n",
            "Epoch: 50 | Batch: 1589 | Loss: 0.14410907893974334\n",
            "Epoch: 50 | Batch: 1590 | Loss: 0.13026660902875165\n",
            "Epoch: 50 | Batch: 1591 | Loss: 0.19160559551327\n",
            "Epoch: 50 | Batch: 1592 | Loss: 0.15471698472585843\n",
            "Epoch: 50 | Batch: 1593 | Loss: 0.1553132988409799\n",
            "Epoch: 50 | Batch: 1594 | Loss: 0.15988883625763967\n",
            "Epoch: 50 | Batch: 1595 | Loss: 0.15706981345110319\n",
            "Epoch: 50 | Batch: 1596 | Loss: 0.11608503961857156\n",
            "Epoch: 50 | Batch: 1597 | Loss: 0.1668117075034325\n",
            "Epoch: 50 | Batch: 1598 | Loss: 0.1589167727582576\n",
            "Epoch: 50 | Batch: 1599 | Loss: 0.15183642619368595\n",
            "Epoch: 50 | Batch: 1600 | Loss: 0.1506384877477233\n",
            "Epoch: 50 | Batch: 1601 | Loss: 0.21071819997761987\n",
            "Epoch: 50 | Batch: 1602 | Loss: 0.13741300199840834\n",
            "Epoch: 50 | Batch: 1603 | Loss: 0.21160349615873286\n",
            "Epoch: 50 | Batch: 1604 | Loss: 0.20078331572350508\n",
            "Epoch: 50 | Batch: 1605 | Loss: 0.14797298216610982\n",
            "Epoch: 50 | Batch: 1606 | Loss: 0.19602599350646016\n",
            "Epoch: 50 | Batch: 1607 | Loss: 0.14661021665248095\n",
            "Epoch: 50 | Batch: 1608 | Loss: 0.14568557549785296\n",
            "Epoch: 50 | Batch: 1609 | Loss: 0.18560615960955174\n",
            "Epoch: 50 | Batch: 1610 | Loss: 0.17985352914929056\n",
            "Epoch: 50 | Batch: 1611 | Loss: 0.20463243256447095\n",
            "Epoch: 50 | Batch: 1612 | Loss: 0.11083457204012886\n",
            "Epoch: 50 | Batch: 1613 | Loss: 0.17238463802937834\n",
            "Epoch: 50 | Batch: 1614 | Loss: 0.12005579195856685\n",
            "Epoch: 50 | Batch: 1615 | Loss: 0.17954441572771374\n",
            "Epoch: 50 | Batch: 1616 | Loss: 0.14565234996527074\n",
            "Epoch: 50 | Batch: 1617 | Loss: 0.1435705062930145\n",
            "Epoch: 50 | Batch: 1618 | Loss: 0.17751806226988642\n",
            "Epoch: 50 | Batch: 1619 | Loss: 0.18802853868221833\n",
            "Epoch: 50 | Batch: 1620 | Loss: 0.25483368734951095\n",
            "Epoch: 50 | Batch: 1621 | Loss: 0.16348591225929898\n",
            "Epoch: 50 | Batch: 1622 | Loss: 0.19008333913557882\n",
            "Epoch: 50 | Batch: 1623 | Loss: 0.18824501973608362\n",
            "Epoch: 50 | Batch: 1624 | Loss: 0.21777817504227653\n",
            "Epoch: 50 | Batch: 1625 | Loss: 0.17540402815947703\n",
            "Epoch: 50 | Batch: 1626 | Loss: 0.12922727612120805\n",
            "Epoch: 50 | Batch: 1627 | Loss: 0.1221974183761514\n",
            "Epoch: 50 | Batch: 1628 | Loss: 0.15324117341977972\n",
            "Epoch: 50 | Batch: 1629 | Loss: 0.18047890616636242\n",
            "Epoch: 50 | Batch: 1630 | Loss: 0.15626998409516785\n",
            "Epoch: 50 | Batch: 1631 | Loss: 0.19763669983591572\n",
            "Epoch: 50 | Batch: 1632 | Loss: 0.122711553888604\n",
            "Epoch: 50 | Batch: 1633 | Loss: 0.13585486582155773\n",
            "Epoch: 50 | Batch: 1634 | Loss: 0.1521255663951252\n",
            "Epoch: 50 | Batch: 1635 | Loss: 0.15598198051883538\n",
            "Epoch: 50 | Batch: 1636 | Loss: 0.1735207910685215\n",
            "Epoch: 50 | Batch: 1637 | Loss: 0.13661765147106628\n",
            "Epoch: 50 | Batch: 1638 | Loss: 0.14068225717329874\n",
            "Epoch: 50 | Batch: 1639 | Loss: 0.14506134687521796\n",
            "Epoch: 50 | Batch: 1640 | Loss: 0.17613020821142208\n",
            "Epoch: 50 | Batch: 1641 | Loss: 0.15421268011592038\n",
            "Epoch: 50 | Batch: 1642 | Loss: 0.17766955197223244\n",
            "Epoch: 50 | Batch: 1643 | Loss: 0.15305499799521666\n",
            "Epoch: 50 | Batch: 1644 | Loss: 0.16655855930335972\n",
            "Epoch: 50 | Batch: 1645 | Loss: 0.1997149255626287\n",
            "Epoch: 50 | Batch: 1646 | Loss: 0.14291333851593047\n",
            "Epoch: 50 | Batch: 1647 | Loss: 0.19444610197344053\n",
            "Epoch: 50 | Batch: 1648 | Loss: 0.1775513550949614\n",
            "Epoch: 50 | Batch: 1649 | Loss: 0.11212514526970097\n",
            "Epoch: 50 | Batch: 1650 | Loss: 0.13930870738210452\n",
            "Epoch: 50 | Batch: 1651 | Loss: 0.1777710747801881\n",
            "Epoch: 50 | Batch: 1652 | Loss: 0.16959822966860855\n",
            "Epoch: 50 | Batch: 1653 | Loss: 0.1674636855651888\n",
            "Epoch: 50 | Batch: 1654 | Loss: 0.22269826966900283\n",
            "Epoch: 50 | Batch: 1655 | Loss: 0.16799156191356424\n",
            "Epoch: 50 | Batch: 1656 | Loss: 0.15626475251908065\n",
            "Epoch: 50 | Batch: 1657 | Loss: 0.16805386202175843\n",
            "Epoch: 50 | Batch: 1658 | Loss: 0.1825509852626997\n",
            "Epoch: 50 | Batch: 1659 | Loss: 0.17613676765122857\n",
            "Epoch: 50 | Batch: 1660 | Loss: 0.18565739320495062\n",
            "Epoch: 50 | Batch: 1661 | Loss: 0.20662899717423586\n",
            "Epoch: 50 | Batch: 1662 | Loss: 0.1663140496096575\n",
            "Epoch: 50 | Batch: 1663 | Loss: 0.16937295915317477\n",
            "Epoch: 50 | Batch: 1664 | Loss: 0.1680904982184468\n",
            "Epoch: 50 | Batch: 1665 | Loss: 0.1328672869852122\n",
            "Epoch: 50 | Batch: 1666 | Loss: 0.16157902417137399\n",
            "Epoch: 50 | Batch: 1667 | Loss: 0.1646167203089213\n",
            "Epoch: 50 | Batch: 1668 | Loss: 0.140416628803894\n",
            "Epoch: 50 | Batch: 1669 | Loss: 0.14584342789400473\n",
            "Epoch: 50 | Batch: 1670 | Loss: 0.15651705037830754\n",
            "Epoch: 50 | Batch: 1671 | Loss: 0.1826935507403832\n",
            "Epoch: 50 | Batch: 1672 | Loss: 0.16780842107818997\n",
            "Epoch: 50 | Batch: 1673 | Loss: 0.15890614842498132\n",
            "Epoch: 50 | Batch: 1674 | Loss: 0.17299955878305065\n",
            "Epoch: 50 | Batch: 1675 | Loss: 0.16693604194486142\n",
            "Epoch: 50 | Batch: 1676 | Loss: 0.13188118184363037\n",
            "Epoch: 50 | Batch: 1677 | Loss: 0.18485765425383793\n",
            "Epoch: 50 | Batch: 1678 | Loss: 0.1658523430154462\n",
            "Epoch: 50 | Batch: 1679 | Loss: 0.15447030136687717\n",
            "Epoch: 50 | Batch: 1680 | Loss: 0.16474326632587624\n",
            "Epoch: 50 | Batch: 1681 | Loss: 0.13083015535565018\n",
            "Epoch: 50 | Batch: 1682 | Loss: 0.1463877729924279\n",
            "Epoch: 50 | Batch: 1683 | Loss: 0.1759233371629407\n",
            "Epoch: 50 | Batch: 1684 | Loss: 0.2123337580735943\n",
            "Epoch: 50 | Batch: 1685 | Loss: 0.14178856283471933\n",
            "Epoch: 50 | Batch: 1686 | Loss: 0.1505676477362129\n",
            "Epoch: 50 | Batch: 1687 | Loss: 0.16976422943776587\n",
            "Epoch: 50 | Batch: 1688 | Loss: 0.17805048192982934\n",
            "Epoch: 50 | Batch: 1689 | Loss: 0.14903039844048352\n",
            "Epoch: 50 | Batch: 1690 | Loss: 0.1476730991215887\n",
            "Epoch: 50 | Batch: 1691 | Loss: 0.16847069149529376\n",
            "Epoch: 50 | Batch: 1692 | Loss: 0.12160990812661493\n",
            "Epoch: 50 | Batch: 1693 | Loss: 0.15091826717232662\n",
            "Epoch: 50 | Batch: 1694 | Loss: 0.1776767546526914\n",
            "Epoch: 50 | Batch: 1695 | Loss: 0.15237379789384903\n",
            "Epoch: 50 | Batch: 1696 | Loss: 0.1535420991703395\n",
            "Epoch: 50 | Batch: 1697 | Loss: 0.1655813424801338\n",
            "Epoch: 50 | Batch: 1698 | Loss: 0.22838494763710307\n",
            "Epoch: 50 | Batch: 1699 | Loss: 0.18691826663390873\n",
            "Epoch: 50 | Batch: 1700 | Loss: 0.12890386085706468\n",
            "Epoch: 50 | Batch: 1701 | Loss: 0.20431999517538363\n",
            "Epoch: 50 | Batch: 1702 | Loss: 0.1876442709778546\n",
            "Epoch: 50 | Batch: 1703 | Loss: 0.15832979902953676\n",
            "Epoch: 50 | Batch: 1704 | Loss: 0.14678676608935906\n",
            "Epoch: 50 | Batch: 1705 | Loss: 0.16550407749502816\n",
            "Epoch: 50 | Batch: 1706 | Loss: 0.17292993234314727\n",
            "Epoch: 50 | Batch: 1707 | Loss: 0.19568952867511386\n",
            "Epoch: 50 | Batch: 1708 | Loss: 0.14530890877951344\n",
            "Epoch: 50 | Batch: 1709 | Loss: 0.1837493929293161\n",
            "Epoch: 50 | Batch: 1710 | Loss: 0.1426849881038515\n",
            "Epoch: 50 | Batch: 1711 | Loss: 0.21568645360383165\n",
            "Epoch: 50 | Batch: 1712 | Loss: 0.16076161150032112\n",
            "Epoch: 50 | Batch: 1713 | Loss: 0.1735251183830161\n",
            "Epoch: 50 | Batch: 1714 | Loss: 0.18261404321805988\n",
            "Epoch: 50 | Batch: 1715 | Loss: 0.17509598314692051\n",
            "Epoch: 50 | Batch: 1716 | Loss: 0.14516122501923975\n",
            "Epoch: 50 | Batch: 1717 | Loss: 0.18242262657466965\n",
            "Epoch: 50 | Batch: 1718 | Loss: 0.22246099850609102\n",
            "Epoch: 50 | Batch: 1719 | Loss: 0.13751606469729025\n",
            "Epoch: 50 | Batch: 1720 | Loss: 0.22692511349361894\n",
            "Epoch: 50 | Batch: 1721 | Loss: 0.15444904826661685\n",
            "Epoch: 50 | Batch: 1722 | Loss: 0.1701745777403369\n",
            "Epoch: 50 | Batch: 1723 | Loss: 0.1353688613517132\n",
            "Epoch: 50 | Batch: 1724 | Loss: 0.17524770442967952\n",
            "Epoch: 50 | Batch: 1725 | Loss: 0.16609985798061694\n",
            "Epoch: 50 | Batch: 1726 | Loss: 0.1505083313524496\n",
            "Epoch: 50 | Batch: 1727 | Loss: 0.15359832181356303\n",
            "Epoch: 50 | Batch: 1728 | Loss: 0.180111638207667\n",
            "Epoch: 50 | Batch: 1729 | Loss: 0.1488376165292818\n",
            "Epoch: 50 | Batch: 1730 | Loss: 0.15974824225021547\n",
            "Epoch: 50 | Batch: 1731 | Loss: 0.15379582225123686\n",
            "Epoch: 50 | Batch: 1732 | Loss: 0.14854011378258497\n",
            "Epoch: 50 | Batch: 1733 | Loss: 0.19514737929608122\n",
            "Epoch: 50 | Batch: 1734 | Loss: 0.19275888239229744\n",
            "Epoch: 50 | Batch: 1735 | Loss: 0.16885137829633332\n",
            "Epoch: 50 | Batch: 1736 | Loss: 0.14699445372731623\n",
            "Epoch: 50 | Batch: 1737 | Loss: 0.14982189054911718\n",
            "Epoch: 50 | Batch: 1738 | Loss: 0.18815798698189437\n",
            "Epoch: 50 | Batch: 1739 | Loss: 0.15968224223650454\n",
            "Epoch: 50 | Batch: 1740 | Loss: 0.13928089881355143\n",
            "Epoch: 50 | Batch: 1741 | Loss: 0.18168566030180466\n",
            "Epoch: 50 | Batch: 1742 | Loss: 0.1781134389173002\n",
            "Epoch: 50 | Batch: 1743 | Loss: 0.17423939822051326\n",
            "Epoch: 50 | Batch: 1744 | Loss: 0.14453720745250936\n",
            "Epoch: 50 | Batch: 1745 | Loss: 0.13668139330698284\n",
            "Epoch: 50 | Batch: 1746 | Loss: 0.1597270961261587\n",
            "Epoch: 50 | Batch: 1747 | Loss: 0.18119577261905448\n",
            "Epoch: 50 | Batch: 1748 | Loss: 0.19219929663143395\n",
            "Epoch: 50 | Batch: 1749 | Loss: 0.17039182137212774\n",
            "Epoch: 50 | Batch: 1750 | Loss: 0.14596545485737714\n",
            "Epoch: 50 | Batch: 1751 | Loss: 0.15996845386940653\n",
            "Epoch: 50 | Batch: 1752 | Loss: 0.14708821147799997\n",
            "Epoch: 50 | Batch: 1753 | Loss: 0.12913215403574957\n",
            "Epoch: 50 | Batch: 1754 | Loss: 0.15061650647363065\n",
            "Epoch: 50 | Batch: 1755 | Loss: 0.13283081673191482\n",
            "Epoch: 50 | Batch: 1756 | Loss: 0.1831329758802983\n",
            "Epoch: 50 | Batch: 1757 | Loss: 0.1926456525961493\n",
            "Epoch: 50 | Batch: 1758 | Loss: 0.16177966000632582\n",
            "Epoch: 50 | Batch: 1759 | Loss: 0.1547422985852258\n",
            "Epoch: 50 | Batch: 1760 | Loss: 0.16203389911574523\n",
            "Epoch: 50 | Batch: 1761 | Loss: 0.19125641283288553\n",
            "Epoch: 50 | Batch: 1762 | Loss: 0.19244505920340532\n",
            "Epoch: 50 | Batch: 1763 | Loss: 0.16061143242602421\n",
            "Epoch: 50 | Batch: 1764 | Loss: 0.20273537432053185\n",
            "Epoch: 50 | Batch: 1765 | Loss: 0.1855797662003721\n",
            "Epoch: 50 | Batch: 1766 | Loss: 0.16782738902630884\n",
            "Epoch: 50 | Batch: 1767 | Loss: 0.14542362032239184\n",
            "Epoch: 50 | Batch: 1768 | Loss: 0.19246991214118375\n",
            "Epoch: 50 | Batch: 1769 | Loss: 0.17860521476968538\n",
            "Epoch: 50 | Batch: 1770 | Loss: 0.203968782843493\n",
            "Epoch: 50 | Batch: 1771 | Loss: 0.17685420813732297\n",
            "Epoch: 50 | Batch: 1772 | Loss: 0.20296960984331078\n",
            "Epoch: 50 | Batch: 1773 | Loss: 0.22494949081817367\n",
            "Epoch: 50 | Batch: 1774 | Loss: 0.12762121795410616\n",
            "Epoch: 50 | Batch: 1775 | Loss: 0.1467250320250679\n",
            "Epoch: 50 | Batch: 1776 | Loss: 0.15397220348497206\n",
            "Epoch: 50 | Batch: 1777 | Loss: 0.1625551263520876\n",
            "Epoch: 50 | Batch: 1778 | Loss: 0.2104533648112206\n",
            "Epoch: 50 | Batch: 1779 | Loss: 0.157906110318273\n",
            "Epoch: 50 | Batch: 1780 | Loss: 0.18852588983940766\n",
            "Epoch: 50 | Batch: 1781 | Loss: 0.17077024879706415\n",
            "Epoch: 50 | Batch: 1782 | Loss: 0.1540721148194562\n",
            "Epoch: 50 | Batch: 1783 | Loss: 0.1620510206269448\n",
            "Epoch: 50 | Batch: 1784 | Loss: 0.12641426075920056\n",
            "Epoch: 50 | Batch: 1785 | Loss: 0.15958941132024876\n",
            "Epoch: 50 | Batch: 1786 | Loss: 0.19196690837562125\n",
            "Epoch: 50 | Batch: 1787 | Loss: 0.1714762868585242\n",
            "Epoch: 50 | Batch: 1788 | Loss: 0.19652473890374453\n",
            "Epoch: 50 | Batch: 1789 | Loss: 0.15064150919356561\n",
            "Epoch: 50 | Batch: 1790 | Loss: 0.17098986705831287\n",
            "Epoch: 50 | Batch: 1791 | Loss: 0.1642185596448349\n",
            "Epoch: 50 | Batch: 1792 | Loss: 0.17998397522183232\n",
            "Epoch: 50 | Batch: 1793 | Loss: 0.13481276931115416\n",
            "Epoch: 50 | Batch: 1794 | Loss: 0.1799213158180586\n",
            "Epoch: 50 | Batch: 1795 | Loss: 0.17071127303845693\n",
            "Epoch: 50 | Batch: 1796 | Loss: 0.14658030064268365\n",
            "Epoch: 50 | Batch: 1797 | Loss: 0.1995148936664596\n",
            "Epoch: 50 | Batch: 1798 | Loss: 0.2339690210423176\n",
            "Epoch: 50 | Batch: 1799 | Loss: 0.17783443841960656\n",
            "Epoch: 50 | Batch: 1800 | Loss: 0.15453823136901484\n",
            "Epoch: 50 | Batch: 1801 | Loss: 0.20569534186850455\n",
            "Epoch: 50 | Batch: 1802 | Loss: 0.16506729678035134\n",
            "Epoch: 50 | Batch: 1803 | Loss: 0.16371896981279666\n",
            "Epoch: 50 | Batch: 1804 | Loss: 0.12905160789251685\n",
            "Epoch: 50 | Batch: 1805 | Loss: 0.16375801035854262\n",
            "Epoch: 50 | Batch: 1806 | Loss: 0.1443185207686793\n",
            "Epoch: 50 | Batch: 1807 | Loss: 0.16581657518970522\n",
            "Epoch: 50 | Batch: 1808 | Loss: 0.16800156952796153\n",
            "Epoch: 50 | Batch: 1809 | Loss: 0.14798003534397058\n",
            "Epoch: 50 | Batch: 1810 | Loss: 0.15252652055221402\n",
            "Epoch: 50 | Batch: 1811 | Loss: 0.13524836962277614\n",
            "Epoch: 50 | Batch: 1812 | Loss: 0.159318136208003\n",
            "Epoch: 50 | Batch: 1813 | Loss: 0.16851033769575083\n",
            "Epoch: 50 | Batch: 1814 | Loss: 0.1503310349369332\n",
            "Epoch: 50 | Batch: 1815 | Loss: 0.12975116624713487\n",
            "Epoch: 50 | Batch: 1816 | Loss: 0.13877640212957862\n",
            "Epoch: 50 | Batch: 1817 | Loss: 0.13276707526720638\n",
            "Epoch: 50 | Batch: 1818 | Loss: 0.16237209807906106\n",
            "Epoch: 50 | Batch: 1819 | Loss: 0.10757719982803038\n",
            "Epoch: 50 | Batch: 1820 | Loss: 0.16053291356222335\n",
            "Epoch: 50 | Batch: 1821 | Loss: 0.19483024073233063\n",
            "Epoch: 50 | Batch: 1822 | Loss: 0.15109385394980146\n",
            "Epoch: 50 | Batch: 1823 | Loss: 0.15244704773090248\n",
            "Epoch: 50 | Batch: 1824 | Loss: 0.21202325571450456\n",
            "Epoch: 50 | Batch: 1825 | Loss: 0.1628920243788409\n",
            "Epoch: 50 | Batch: 1826 | Loss: 0.14286655788454822\n",
            "Epoch: 50 | Batch: 1827 | Loss: 0.20027236600403597\n",
            "Epoch: 50 | Batch: 1828 | Loss: 0.17876508553274334\n",
            "Epoch: 50 | Batch: 1829 | Loss: 0.1597609870828898\n",
            "Epoch: 50 | Batch: 1830 | Loss: 0.18582383326206686\n",
            "Epoch: 50 | Batch: 1831 | Loss: 0.1448665787294334\n",
            "Epoch: 50 | Batch: 1832 | Loss: 0.14828063486277723\n",
            "Epoch: 50 | Batch: 1833 | Loss: 0.1585086837896969\n",
            "Epoch: 50 | Batch: 1834 | Loss: 0.17057471641161154\n",
            "Epoch: 50 | Batch: 1835 | Loss: 0.19961432798320566\n",
            "Epoch: 50 | Batch: 1836 | Loss: 0.18497531037986933\n",
            "Epoch: 50 | Batch: 1837 | Loss: 0.1535062902773306\n",
            "Epoch: 50 | Batch: 1838 | Loss: 0.20043109063659112\n",
            "Epoch: 50 | Batch: 1839 | Loss: 0.2362192066612085\n",
            "Epoch: 50 | Batch: 1840 | Loss: 0.1716565078256238\n",
            "Epoch: 50 | Batch: 1841 | Loss: 0.1560950664212461\n",
            "Epoch: 50 | Batch: 1842 | Loss: 0.14191574939351265\n",
            "Epoch: 50 | Batch: 1843 | Loss: 0.16880396700329053\n",
            "Epoch: 50 | Batch: 1844 | Loss: 0.14196014974158927\n",
            "Epoch: 50 | Batch: 1845 | Loss: 0.1485611703344326\n",
            "Epoch: 50 | Batch: 1846 | Loss: 0.17716418220373087\n",
            "Epoch: 50 | Batch: 1847 | Loss: 0.18910762852458915\n",
            "Epoch: 50 | Batch: 1848 | Loss: 0.14345293661021602\n",
            "Epoch: 50 | Batch: 1849 | Loss: 0.16024298612350224\n",
            "Epoch: 50 | Batch: 1850 | Loss: 0.16560512980699696\n",
            "Epoch: 50 | Batch: 1851 | Loss: 0.1635522126951813\n",
            "Epoch: 50 | Batch: 1852 | Loss: 0.12379698564097319\n",
            "Epoch: 50 | Batch: 1853 | Loss: 0.1634122817247983\n",
            "Epoch: 50 | Batch: 1854 | Loss: 0.17075019041356831\n",
            "Epoch: 50 | Batch: 1855 | Loss: 0.18787921441027994\n",
            "Epoch: 50 | Batch: 1856 | Loss: 0.18867869668295023\n",
            "Epoch: 50 | Batch: 1857 | Loss: 0.1566913327000287\n",
            "Epoch: 50 | Batch: 1858 | Loss: 0.12271589288158469\n",
            "Epoch: 50 | Batch: 1859 | Loss: 0.16500376215155935\n",
            "Epoch: 50 | Batch: 1860 | Loss: 0.1184945964677721\n",
            "Epoch: 50 | Batch: 1861 | Loss: 0.1882326001239845\n",
            "Epoch: 50 | Batch: 1862 | Loss: 0.15696581780654112\n",
            "Epoch: 50 | Batch: 1863 | Loss: 0.21055888264454958\n",
            "Epoch: 50 | Batch: 1864 | Loss: 0.12602581682359756\n",
            "Epoch: 50 | Batch: 1865 | Loss: 0.1717983457333127\n",
            "Epoch: 50 | Batch: 1866 | Loss: 0.1567022681664759\n",
            "Epoch: 50 | Batch: 1867 | Loss: 0.1553319443879882\n",
            "Epoch: 50 | Batch: 1868 | Loss: 0.23431795332054614\n",
            "Epoch: 50 | Batch: 1869 | Loss: 0.18955092146488484\n",
            "Epoch: 50 | Batch: 1870 | Loss: 0.2135205560985658\n",
            "Epoch: 50 | Batch: 1871 | Loss: 0.14591306005438814\n",
            "Epoch: 50 | Batch: 1872 | Loss: 0.15398463444727767\n",
            "Epoch: 50 | Batch: 1873 | Loss: 0.1384260661060751\n",
            "Epoch: 50 | Batch: 1874 | Loss: 0.14552326909065272\n",
            "Epoch: 50 | Batch: 1875 | Loss: 0.20682095373960224\n",
            "Epoch: 50 | Batch: 1876 | Loss: 0.1421836466205129\n",
            "Epoch: 50 | Batch: 1877 | Loss: 0.16890088009474363\n",
            "Epoch: 50 | Batch: 1878 | Loss: 0.1319356427419958\n",
            "Epoch: 50 | Batch: 1879 | Loss: 0.1559834251275791\n",
            "Epoch: 50 | Batch: 1880 | Loss: 0.1276658939137467\n",
            "Epoch: 50 | Batch: 1881 | Loss: 0.15328207413278694\n",
            "Epoch: 50 | Batch: 1882 | Loss: 0.2038700471052133\n",
            "Epoch: 50 | Batch: 1883 | Loss: 0.1630644508886036\n",
            "Epoch: 50 | Batch: 1884 | Loss: 0.1433419221019039\n",
            "Epoch: 50 | Batch: 1885 | Loss: 0.2056590547225\n",
            "Epoch: 50 | Batch: 1886 | Loss: 0.15781666376266362\n",
            "Epoch: 50 | Batch: 1887 | Loss: 0.15849634761517511\n",
            "Epoch: 50 | Batch: 1888 | Loss: 0.16011943473127857\n",
            "Epoch: 50 | Batch: 1889 | Loss: 0.1723791137589939\n",
            "Epoch: 50 | Batch: 1890 | Loss: 0.16975634328904926\n",
            "Epoch: 50 | Batch: 1891 | Loss: 0.1251189410688506\n",
            "Epoch: 50 | Batch: 1892 | Loss: 0.1963032186272517\n",
            "Epoch: 50 | Batch: 1893 | Loss: 0.14528990393728575\n",
            "Epoch: 50 | Batch: 1894 | Loss: 0.13991487250116647\n",
            "Epoch: 50 | Batch: 1895 | Loss: 0.17190141687896676\n",
            "Epoch: 50 | Batch: 1896 | Loss: 0.16354301750199648\n",
            "Epoch: 50 | Batch: 1897 | Loss: 0.15981115607623017\n",
            "Epoch: 50 | Batch: 1898 | Loss: 0.13059086388995203\n",
            "Epoch: 50 | Batch: 1899 | Loss: 0.13114713849982146\n",
            "Epoch: 50 | Batch: 1900 | Loss: 0.1409007082049724\n",
            "Epoch: 50 | Batch: 1901 | Loss: 0.16113934529780943\n",
            "Epoch: 50 | Batch: 1902 | Loss: 0.12221429300806583\n",
            "Epoch: 50 | Batch: 1903 | Loss: 0.17854334575459413\n",
            "Epoch: 50 | Batch: 1904 | Loss: 0.11601709457677908\n",
            "Epoch: 50 | Batch: 1905 | Loss: 0.20331032123327394\n",
            "Epoch: 50 | Batch: 1906 | Loss: 0.16259235552303153\n",
            "Epoch: 50 | Batch: 1907 | Loss: 0.16044468263864092\n",
            "Epoch: 50 | Batch: 1908 | Loss: 0.20675437842918779\n",
            "Epoch: 50 | Batch: 1909 | Loss: 0.17006002958915448\n",
            "Epoch: 50 | Batch: 1910 | Loss: 0.11942241820472982\n",
            "Epoch: 50 | Batch: 1911 | Loss: 0.16205491798015517\n",
            "Epoch: 50 | Batch: 1912 | Loss: 0.18268587434086378\n",
            "Epoch: 50 | Batch: 1913 | Loss: 0.20681970540398836\n",
            "Epoch: 50 | Batch: 1914 | Loss: 0.18231113010112923\n",
            "Epoch: 50 | Batch: 1915 | Loss: 0.18873790952706113\n",
            "Epoch: 50 | Batch: 1916 | Loss: 0.18716451810568394\n",
            "Epoch: 50 | Batch: 1917 | Loss: 0.19501947357655156\n",
            "Epoch: 50 | Batch: 1918 | Loss: 0.20464978914605725\n",
            "Epoch: 50 | Batch: 1919 | Loss: 0.17311603829079575\n",
            "Epoch: 50 | Batch: 1920 | Loss: 0.16693556807172802\n",
            "Epoch: 50 | Batch: 1921 | Loss: 0.1670572323726988\n",
            "Epoch: 50 | Batch: 1922 | Loss: 0.188514943046462\n",
            "Epoch: 50 | Batch: 1923 | Loss: 0.14955537856424683\n",
            "Epoch: 50 | Batch: 1924 | Loss: 0.13443585478176154\n",
            "Epoch: 50 | Batch: 1925 | Loss: 0.21943050443524448\n",
            "Epoch: 50 | Batch: 1926 | Loss: 0.15866136384579124\n",
            "Epoch: 50 | Batch: 1927 | Loss: 0.16200074065453535\n",
            "Epoch: 50 | Batch: 1928 | Loss: 0.23215308060854134\n",
            "Epoch: 50 | Batch: 1929 | Loss: 0.15886862782656547\n",
            "Epoch: 50 | Batch: 1930 | Loss: 0.1626010500573557\n",
            "Epoch: 50 | Batch: 1931 | Loss: 0.16807811875489\n",
            "Epoch: 50 | Batch: 1932 | Loss: 0.18265403583246725\n",
            "Epoch: 50 | Batch: 1933 | Loss: 0.235811927968222\n",
            "Epoch: 50 | Batch: 1934 | Loss: 0.16336621076741653\n",
            "Epoch: 50 | Batch: 1935 | Loss: 0.18540817539409418\n",
            "Epoch: 50 | Batch: 1936 | Loss: 0.1708257450212993\n",
            "Epoch: 50 | Batch: 1937 | Loss: 0.1713372202509653\n",
            "Epoch: 50 | Batch: 1938 | Loss: 0.16344200090275707\n",
            "Epoch: 50 | Batch: 1939 | Loss: 0.13559124785864693\n",
            "Epoch: 50 | Batch: 1940 | Loss: 0.1268239460250077\n",
            "Epoch: 50 | Batch: 1941 | Loss: 0.18377046843219075\n",
            "Epoch: 50 | Batch: 1942 | Loss: 0.14788183138393926\n",
            "Epoch: 50 | Batch: 1943 | Loss: 0.14503737270442077\n",
            "Epoch: 50 | Batch: 1944 | Loss: 0.20543117282206952\n",
            "Epoch: 50 | Batch: 1945 | Loss: 0.18369046380950146\n",
            "Epoch: 50 | Batch: 1946 | Loss: 0.138541545159719\n",
            "Epoch: 50 | Batch: 1947 | Loss: 0.20848848278405968\n",
            "Epoch: 50 | Batch: 1948 | Loss: 0.1428656684521366\n",
            "Epoch: 50 | Batch: 1949 | Loss: 0.1584903678415024\n",
            "Epoch: 50 | Batch: 1950 | Loss: 0.1587000166638719\n",
            "Epoch: 50 | Batch: 1951 | Loss: 0.1828486920355191\n",
            "Epoch: 50 | Batch: 1952 | Loss: 0.15167352516466426\n",
            "Epoch: 50 | Batch: 1953 | Loss: 0.1779593350529089\n",
            "Epoch: 50 | Batch: 1954 | Loss: 0.1631332635597487\n",
            "Epoch: 50 | Batch: 1955 | Loss: 0.1828585981466644\n",
            "Epoch: 50 | Batch: 1956 | Loss: 0.14490217043409492\n",
            "Epoch: 50 | Batch: 1957 | Loss: 0.16672070289386876\n",
            "Epoch: 50 | Batch: 1958 | Loss: 0.16951467251968927\n",
            "Epoch: 50 | Batch: 1959 | Loss: 0.1956909494587422\n",
            "Epoch: 50 | Batch: 1960 | Loss: 0.18604873406460673\n",
            "Epoch: 50 | Batch: 1961 | Loss: 0.194652499018522\n",
            "Epoch: 50 | Batch: 1962 | Loss: 0.1646677551837705\n",
            "Epoch: 50 | Batch: 1963 | Loss: 0.16809223391738287\n",
            "Epoch: 50 | Batch: 1964 | Loss: 0.20504061850370586\n",
            "Epoch: 50 | Batch: 1965 | Loss: 0.20774240412568548\n",
            "Epoch: 50 | Batch: 1966 | Loss: 0.11930901329309392\n",
            "Epoch: 50 | Batch: 1967 | Loss: 0.1269606117877506\n",
            "Epoch: 50 | Batch: 1968 | Loss: 0.14159191517333525\n",
            "Epoch: 50 | Batch: 1969 | Loss: 0.18721507651638758\n",
            "Epoch: 50 | Batch: 1970 | Loss: 0.1624262091155324\n",
            "Epoch: 50 | Batch: 1971 | Loss: 0.16436599581006223\n",
            "Epoch: 50 | Batch: 1972 | Loss: 0.1846008483773246\n",
            "Epoch: 50 | Batch: 1973 | Loss: 0.19208418774363661\n",
            "Epoch: 50 | Batch: 1974 | Loss: 0.1608993991776213\n",
            "Epoch: 50 | Batch: 1975 | Loss: 0.20509958834980152\n",
            "Epoch: 50 | Batch: 1976 | Loss: 0.17052789545711322\n",
            "Epoch: 50 | Batch: 1977 | Loss: 0.13663553977349682\n",
            "Epoch: 50 | Batch: 1978 | Loss: 0.15761479295445838\n",
            "Epoch: 50 | Batch: 1979 | Loss: 0.20165671093305215\n",
            "Epoch: 50 | Batch: 1980 | Loss: 0.12504080410390384\n",
            "Epoch: 50 | Batch: 1981 | Loss: 0.1642182498283868\n",
            "Epoch: 50 | Batch: 1982 | Loss: 0.1613843941931455\n",
            "Epoch: 50 | Batch: 1983 | Loss: 0.16177486565906862\n",
            "Epoch: 50 | Batch: 1984 | Loss: 0.10920449765092537\n",
            "Epoch: 50 | Batch: 1985 | Loss: 0.15454334628474972\n",
            "Epoch: 50 | Batch: 1986 | Loss: 0.20246425905173435\n",
            "Epoch: 50 | Batch: 1987 | Loss: 0.2022961523376108\n",
            "Epoch: 50 | Batch: 1988 | Loss: 0.21267042724522106\n",
            "Epoch: 50 | Batch: 1989 | Loss: 0.19794172613287503\n",
            "Epoch: 50 | Batch: 1990 | Loss: 0.15999517606473446\n",
            "Epoch: 50 | Batch: 1991 | Loss: 0.12279376073738596\n",
            "Epoch: 50 | Batch: 1992 | Loss: 0.16861615078923378\n",
            "Epoch: 50 | Batch: 1993 | Loss: 0.1752229569011536\n",
            "Epoch: 50 | Batch: 1994 | Loss: 0.14790077142386687\n",
            "Epoch: 50 | Batch: 1995 | Loss: 0.17682820896305634\n",
            "Epoch: 50 | Batch: 1996 | Loss: 0.15926747011399758\n",
            "Epoch: 50 | Batch: 1997 | Loss: 0.17321426840446064\n",
            "Epoch: 50 | Batch: 1998 | Loss: 0.15138568760808183\n",
            "Epoch: 50 | Batch: 1999 | Loss: 0.15201621269070684\n",
            "Epoch: 50 | Batch: 2000 | Loss: 0.12324724234048712\n",
            "Epoch: 50 | Batch: 2001 | Loss: 0.15972785296756756\n",
            "Epoch: 50 | Batch: 2002 | Loss: 0.17886081470907794\n",
            "Epoch: 50 | Batch: 2003 | Loss: 0.18020843686532767\n",
            "Epoch: 50 | Batch: 2004 | Loss: 0.15392744743202044\n",
            "Epoch: 50 | Batch: 2005 | Loss: 0.14462636767155654\n",
            "Epoch: 50 | Batch: 2006 | Loss: 0.16935066089913883\n",
            "Epoch: 50 | Batch: 2007 | Loss: 0.13973406651511355\n",
            "Epoch: 50 | Batch: 2008 | Loss: 0.14744491551945146\n",
            "Epoch: 50 | Batch: 2009 | Loss: 0.13167652859611978\n",
            "Epoch: 50 | Batch: 2010 | Loss: 0.14860429210036624\n",
            "Epoch: 50 | Batch: 2011 | Loss: 0.17057773836139883\n",
            "Epoch: 50 | Batch: 2012 | Loss: 0.14826736558303946\n",
            "Epoch: 50 | Batch: 2013 | Loss: 0.1599251595541611\n",
            "Epoch: 50 | Batch: 2014 | Loss: 0.17582362536244717\n",
            "Epoch: 50 | Batch: 2015 | Loss: 0.22711744434388603\n",
            "Epoch: 50 | Batch: 2016 | Loss: 0.22105614321131203\n",
            "Epoch: 50 | Batch: 2017 | Loss: 0.1757202744188135\n",
            "Epoch: 50 | Batch: 2018 | Loss: 0.21157009535046462\n",
            "Epoch: 50 | Batch: 2019 | Loss: 0.17508682190296057\n",
            "Epoch: 50 | Batch: 2020 | Loss: 0.16280396005581035\n",
            "Epoch: 50 | Batch: 2021 | Loss: 0.15082324897555502\n",
            "Epoch: 50 | Batch: 2022 | Loss: 0.1530007044242271\n",
            "Epoch: 50 | Batch: 2023 | Loss: 0.17507699363029716\n",
            "Epoch: 50 | Batch: 2024 | Loss: 0.19039497620482487\n",
            "Epoch: 50 | Batch: 2025 | Loss: 0.19141411274335302\n",
            "Epoch: 50 | Batch: 2026 | Loss: 0.17991150158758554\n",
            "Epoch: 50 | Batch: 2027 | Loss: 0.16937269269148933\n",
            "Epoch: 50 | Batch: 2028 | Loss: 0.19306439767651737\n",
            "Epoch: 50 | Batch: 2029 | Loss: 0.1548390111447162\n",
            "Epoch: 50 | Batch: 2030 | Loss: 0.1424150116048903\n",
            "Epoch: 50 | Batch: 2031 | Loss: 0.2162217094305594\n",
            "Epoch: 50 | Batch: 2032 | Loss: 0.17159305903030359\n",
            "Epoch: 50 | Batch: 2033 | Loss: 0.13067073081735275\n",
            "Epoch: 50 | Batch: 2034 | Loss: 0.17458327483365343\n",
            "Epoch: 50 | Batch: 2035 | Loss: 0.17623026557725646\n",
            "Epoch: 50 | Batch: 2036 | Loss: 0.15560996860492338\n",
            "Epoch: 50 | Batch: 2037 | Loss: 0.16741246710180366\n",
            "Epoch: 50 | Batch: 2038 | Loss: 0.18801238372866647\n",
            "Epoch: 50 | Batch: 2039 | Loss: 0.21123750186937182\n",
            "Epoch: 50 | Batch: 2040 | Loss: 0.19734725563571148\n",
            "Epoch: 50 | Batch: 2041 | Loss: 0.17270514071534118\n",
            "Epoch: 50 | Batch: 2042 | Loss: 0.21480374953802406\n",
            "Epoch: 50 | Batch: 2043 | Loss: 0.16866709113570477\n",
            "Epoch: 50 | Batch: 2044 | Loss: 0.19203589750093156\n",
            "Epoch: 50 | Batch: 2045 | Loss: 0.1779476783530951\n",
            "Epoch: 50 | Batch: 2046 | Loss: 0.13394029936433935\n",
            "Epoch: 50 | Batch: 2047 | Loss: 0.16044232133841055\n",
            "Epoch: 50 | Batch: 2048 | Loss: 0.1638618204576008\n",
            "Epoch: 50 | Batch: 2049 | Loss: 0.16093243757383976\n",
            "Epoch: 50 | Batch: 2050 | Loss: 0.12467786085703805\n",
            "Epoch: 50 | Batch: 2051 | Loss: 0.12507107209952525\n",
            "Epoch: 50 | Batch: 2052 | Loss: 0.1828272246449448\n",
            "Epoch: 50 | Batch: 2053 | Loss: 0.14457030660252998\n",
            "Epoch: 50 | Batch: 2054 | Loss: 0.12615794709582398\n",
            "Epoch: 50 | Batch: 2055 | Loss: 0.14220799115434618\n",
            "Epoch: 50 | Batch: 2056 | Loss: 0.13658285291790193\n",
            "Epoch: 50 | Batch: 2057 | Loss: 0.16352971689832518\n",
            "Epoch: 50 | Batch: 2058 | Loss: 0.15950687465115923\n",
            "Epoch: 50 | Batch: 2059 | Loss: 0.1670905510001858\n",
            "Epoch: 50 | Batch: 2060 | Loss: 0.16611852511459815\n",
            "Epoch: 50 | Batch: 2061 | Loss: 0.19368950216713396\n",
            "Epoch: 50 | Batch: 2062 | Loss: 0.16125663343901708\n",
            "Epoch: 50 | Batch: 2063 | Loss: 0.14598663160286746\n",
            "Epoch: 50 | Batch: 2064 | Loss: 0.12818137895541665\n",
            "Epoch: 50 | Batch: 2065 | Loss: 0.14932086417214385\n",
            "Epoch: 50 | Batch: 2066 | Loss: 0.13492166540105152\n",
            "Epoch: 50 | Batch: 2067 | Loss: 0.15502838352375048\n",
            "Epoch: 50 | Batch: 2068 | Loss: 0.17129248669888494\n",
            "Epoch: 50 | Batch: 2069 | Loss: 0.19031208293048163\n",
            "Epoch: 50 | Batch: 2070 | Loss: 0.1579080468846164\n",
            "Epoch: 50 | Batch: 2071 | Loss: 0.17119411286955333\n",
            "Epoch: 50 | Batch: 2072 | Loss: 0.17257533264589411\n",
            "Epoch: 50 | Batch: 2073 | Loss: 0.18938519323468722\n",
            "Epoch: 50 | Batch: 2074 | Loss: 0.16288995413592525\n",
            "Epoch: 50 | Batch: 2075 | Loss: 0.18518288568496533\n",
            "Epoch: 50 | Batch: 2076 | Loss: 0.1787525279218203\n",
            "Epoch: 50 | Batch: 2077 | Loss: 0.19763092301894794\n",
            "Epoch: 50 | Batch: 2078 | Loss: 0.15647298150070402\n",
            "Epoch: 50 | Batch: 2079 | Loss: 0.1404113972260014\n",
            "Epoch: 50 | Batch: 2080 | Loss: 0.17151027805999508\n",
            "Epoch: 50 | Batch: 2081 | Loss: 0.13668723635116586\n",
            "Epoch: 50 | Batch: 2082 | Loss: 0.17140227675270048\n",
            "Epoch: 50 | Batch: 2083 | Loss: 0.17812135358102477\n",
            "Epoch: 50 | Batch: 2084 | Loss: 0.152966009679393\n",
            "Epoch: 50 | Batch: 2085 | Loss: 0.1431842862262393\n",
            "Epoch: 50 | Batch: 2086 | Loss: 0.1807433013584795\n",
            "Epoch: 50 | Batch: 2087 | Loss: 0.13664060700030542\n",
            "Epoch: 50 | Batch: 2088 | Loss: 0.19173790684265146\n",
            "Epoch: 50 | Batch: 2089 | Loss: 0.12503092278024852\n",
            "Epoch: 50 | Batch: 2090 | Loss: 0.1533604524686252\n",
            "Epoch: 50 | Batch: 2091 | Loss: 0.1793041181062564\n",
            "Epoch: 50 | Batch: 2092 | Loss: 0.18134108975785054\n",
            "Epoch: 50 | Batch: 2093 | Loss: 0.14533419828846628\n",
            "Epoch: 50 | Batch: 2094 | Loss: 0.12368880483637751\n",
            "Epoch: 50 | Batch: 2095 | Loss: 0.20213131286218528\n",
            "Epoch: 50 | Batch: 2096 | Loss: 0.1740800669606664\n",
            "Epoch: 50 | Batch: 2097 | Loss: 0.18803697807343894\n",
            "Epoch: 50 | Batch: 2098 | Loss: 0.178956128811431\n",
            "Epoch: 50 | Batch: 2099 | Loss: 0.14179156615963465\n",
            "Epoch: 50 | Batch: 2100 | Loss: 0.13834384245945608\n",
            "Epoch: 50 | Batch: 2101 | Loss: 0.15695526822325157\n",
            "Epoch: 50 | Batch: 2102 | Loss: 0.17457750558453344\n",
            "Epoch: 50 | Batch: 2103 | Loss: 0.1739941692206038\n",
            "Epoch: 50 | Batch: 2104 | Loss: 0.14150483686174692\n",
            "Epoch: 50 | Batch: 2105 | Loss: 0.12148090988553484\n",
            "Epoch: 50 | Batch: 2106 | Loss: 0.16867312767545442\n",
            "Epoch: 50 | Batch: 2107 | Loss: 0.17769083302055064\n",
            "Epoch: 50 | Batch: 2108 | Loss: 0.11450695337023203\n",
            "Epoch: 50 | Batch: 2109 | Loss: 0.16618444725104473\n",
            "Epoch: 50 | Batch: 2110 | Loss: 0.13137444446797264\n",
            "Epoch: 50 | Batch: 2111 | Loss: 0.1802784714624855\n",
            "Epoch: 50 | Batch: 2112 | Loss: 0.15205239752056113\n",
            "Epoch: 50 | Batch: 2113 | Loss: 0.17941094534889085\n",
            "Epoch: 50 | Batch: 2114 | Loss: 0.17280019060699345\n",
            "Epoch: 50 | Batch: 2115 | Loss: 0.15529223961464828\n",
            "Epoch: 50 | Batch: 2116 | Loss: 0.1943096457541783\n",
            "Epoch: 50 | Batch: 2117 | Loss: 0.19281120436058352\n",
            "Epoch: 50 | Batch: 2118 | Loss: 0.18339802819310125\n",
            "Epoch: 50 | Batch: 2119 | Loss: 0.18894362339093643\n",
            "Epoch: 50 | Batch: 2120 | Loss: 0.17272421899608606\n",
            "Epoch: 50 | Batch: 2121 | Loss: 0.14551109048315922\n",
            "Epoch: 50 | Batch: 2122 | Loss: 0.17658771624645014\n",
            "Epoch: 50 | Batch: 2123 | Loss: 0.17196341976357446\n",
            "Epoch: 50 | Batch: 2124 | Loss: 0.15000142390303098\n",
            "Epoch: 50 | Batch: 2125 | Loss: 0.15195586476031198\n",
            "Epoch: 50 | Batch: 2126 | Loss: 0.17121046226047798\n",
            "Epoch: 50 | Batch: 2127 | Loss: 0.15683682494995269\n",
            "Epoch: 50 | Batch: 2128 | Loss: 0.19808017477186157\n",
            "Epoch: 50 | Batch: 2129 | Loss: 0.11825506925643768\n",
            "Epoch: 50 | Batch: 2130 | Loss: 0.1880620727811219\n",
            "Epoch: 50 | Batch: 2131 | Loss: 0.17237292968770096\n",
            "Epoch: 50 | Batch: 2132 | Loss: 0.17766651888685167\n",
            "Epoch: 50 | Batch: 2133 | Loss: 0.14851671740152797\n",
            "Epoch: 50 | Batch: 2134 | Loss: 0.13520760281237398\n",
            "Epoch: 50 | Batch: 2135 | Loss: 0.14598249060196727\n",
            "Epoch: 50 | Batch: 2136 | Loss: 0.10763128294944649\n",
            "Epoch: 50 | Batch: 2137 | Loss: 0.14282529714927603\n",
            "Epoch: 50 | Batch: 2138 | Loss: 0.18054495802987658\n",
            "Epoch: 50 | Batch: 2139 | Loss: 0.1681613486752641\n",
            "Epoch: 50 | Batch: 2140 | Loss: 0.1823058721687793\n",
            "Epoch: 50 | Batch: 2141 | Loss: 0.1633906770867997\n",
            "Epoch: 50 | Batch: 2142 | Loss: 0.1759385064402338\n",
            "Epoch: 50 | Batch: 2143 | Loss: 0.19125317953126048\n",
            "Epoch: 50 | Batch: 2144 | Loss: 0.19037771179105198\n",
            "Epoch: 50 | Batch: 2145 | Loss: 0.2117311939343044\n",
            "Epoch: 50 | Batch: 2146 | Loss: 0.14727525104321973\n",
            "Epoch: 50 | Batch: 2147 | Loss: 0.19792095412622268\n",
            "Epoch: 50 | Batch: 2148 | Loss: 0.14919704774096934\n",
            "Epoch: 50 | Batch: 2149 | Loss: 0.16368398548830973\n",
            "Epoch: 50 | Batch: 2150 | Loss: 0.18429176599563693\n",
            "Epoch: 50 | Batch: 2151 | Loss: 0.13528370046859398\n",
            "Epoch: 50 | Batch: 2152 | Loss: 0.16624606534910813\n",
            "Epoch: 50 | Batch: 2153 | Loss: 0.17258810731807295\n",
            "Epoch: 50 | Batch: 2154 | Loss: 0.16878834425375125\n",
            "Epoch: 50 | Batch: 2155 | Loss: 0.1525021166794209\n",
            "Epoch: 50 | Batch: 2156 | Loss: 0.17943857534318589\n",
            "Epoch: 50 | Batch: 2157 | Loss: 0.19782766240498573\n",
            "Epoch: 50 | Batch: 2158 | Loss: 0.24592282456199938\n",
            "Epoch: 50 | Batch: 2159 | Loss: 0.23996343634566658\n",
            "Epoch: 50 | Batch: 2160 | Loss: 0.16904733024887666\n",
            "Epoch: 50 | Batch: 2161 | Loss: 0.1911126878612927\n",
            "Epoch: 50 | Batch: 2162 | Loss: 0.21744150010527086\n",
            "Epoch: 50 | Batch: 2163 | Loss: 0.14541365202985396\n",
            "Epoch: 50 | Batch: 2164 | Loss: 0.14529878257767553\n",
            "Epoch: 50 | Batch: 2165 | Loss: 0.1676502958481887\n",
            "Epoch: 50 | Batch: 2166 | Loss: 0.14393718179342735\n",
            "Epoch: 50 | Batch: 2167 | Loss: 0.1730042613862646\n",
            "Epoch: 50 | Batch: 2168 | Loss: 0.1457815265539907\n",
            "Epoch: 50 | Batch: 2169 | Loss: 0.14998764825870783\n",
            "Epoch: 50 | Batch: 2170 | Loss: 0.1315980274856663\n",
            "Epoch: 50 | Batch: 2171 | Loss: 0.15147988536824453\n",
            "Epoch: 50 | Batch: 2172 | Loss: 0.16997409713592945\n",
            "Epoch: 50 | Batch: 2173 | Loss: 0.15373302247941775\n",
            "Epoch: 50 | Batch: 2174 | Loss: 0.15042686059416513\n",
            "Epoch: 50 | Batch: 2175 | Loss: 0.16187885301134256\n",
            "Epoch: 50 | Batch: 2176 | Loss: 0.14235493522641904\n",
            "Epoch: 50 | Batch: 2177 | Loss: 0.13675762028780128\n",
            "Epoch: 50 | Batch: 2178 | Loss: 0.16106549283181468\n",
            "Epoch: 50 | Batch: 2179 | Loss: 0.18939296342907103\n",
            "Epoch: 50 | Batch: 2180 | Loss: 0.1501904770049623\n",
            "Epoch: 50 | Batch: 2181 | Loss: 0.15133464313495204\n",
            "Epoch: 50 | Batch: 2182 | Loss: 0.16400715071380512\n",
            "Epoch: 50 | Batch: 2183 | Loss: 0.16390999660447794\n",
            "Epoch: 50 | Batch: 2184 | Loss: 0.2072722493839591\n",
            "Epoch: 50 | Batch: 2185 | Loss: 0.11771307412675318\n",
            "Epoch: 50 | Batch: 2186 | Loss: 0.14425228950747265\n",
            "Epoch: 50 | Batch: 2187 | Loss: 0.1925135032561653\n",
            "Epoch: 50 | Batch: 2188 | Loss: 0.13521214369515738\n",
            "Epoch: 50 | Batch: 2189 | Loss: 0.10591540358125333\n",
            "Epoch: 50 | Batch: 2190 | Loss: 0.1674534330351555\n",
            "Epoch: 50 | Batch: 2191 | Loss: 0.1512040123739588\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(model,X_test,Y_test,data_df_combined_clean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "id": "dszGCVbW4uxW",
        "outputId": "17a2f5a5-95b9-4694-a17c-b8d80d8a41d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The mean square error is: 212.638398\n",
            "MAPE is: 2.425512\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HoXWn4XU4-QI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}