{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbDa28Z0yWvz",
        "outputId": "38b94bff-8d61-4425-f7be-a6e9b86b9903"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import newaxis\n",
        "\n",
        "def load_data(data_path,P,step):\n",
        "    num_logs = P+step\n",
        "    df = pd.read_csv(data_path)\n",
        "    \n",
        "\n",
        "    data_np = np.zeros((len(df),num_logs))\n",
        "    data_df_combined = pd.DataFrame(data_np)\n",
        "    data_df_combined.loc[:,0] = df['SYSLoad'].values\n",
        "\n",
        "    for i in range(1, num_logs):\n",
        "        data_df_combined.loc[:,i] = data_df_combined.shift(-i)\n",
        "\n",
        "    data_df_combined_clean = data_df_combined.dropna()\n",
        "    data_df_combined_clean = data_df_combined_clean.reset_index()\n",
        "    data_df_combined_clean.drop('index',axis=1,inplace=True)\n",
        "    data_combined_standardized = preprocessing.scale(data_df_combined_clean)\n",
        "\n",
        "    train_split = round(0.8 * data_combined_standardized.shape[0])\n",
        "    val_split = round(0.9 * data_combined_standardized.shape[0])\n",
        "    #print(\"all len\",data_combined_standardized.shape[0])\n",
        "    #print(\"train_split\",train_split)\n",
        "\n",
        "    X = data_combined_standardized[:,:P]\n",
        "    Y = data_combined_standardized[:,P:]\n",
        "\n",
        "    X_train = X[:train_split]\n",
        "    Y_train = Y[:train_split]\n",
        "    X_test = X[train_split:]\n",
        "    Y_test = Y[train_split:]\n",
        "\n",
        "    X_train = X_train.reshape((X_train.shape[0],X_train.shape[1],1))\n",
        "    Y_train = Y_train.reshape((Y_train.shape[0],Y_train.shape[1],1))\n",
        "    X_test = X_test.reshape((X_test.shape[0],X_test.shape[1],1))\n",
        "    Y_test = Y_test.reshape((Y_test.shape[0],Y_test.shape[1],1))\n",
        "\n",
        "    return X_train,Y_train,X_test,Y_test,data_df_combined_clean\n"
      ],
      "metadata": {
        "id": "spterHToycKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "class TorchDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.x[idx], self.y[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "class TorchDataLoader:\n",
        "    def __init__(self,batch_size,shuffle = True):\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "    \n",
        "    def torch_dataloader(self,train_data,target_data):\n",
        "        torch_dataset = TorchDataset(train_data,target_data)\n",
        "        torch_loader = DataLoader(dataset = torch_dataset,\n",
        "                                batch_size = self.batch_size, \n",
        "                                shuffle = self.shuffle)\n",
        "        return torch_loader\n",
        "\n",
        "def plot_results(predicted_data, true_data):\n",
        "    # use in train.py \n",
        "    # plot evaluate result\n",
        "    fig = plt.figure(facecolor='white', figsize=(12, 6))\n",
        "    ax = fig.add_subplot(111)\n",
        "    ax.plot(true_data[-200:], label='True Data')\n",
        "    plt.plot(predicted_data[-200:], label='Prediction')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def ToVariable(x):\n",
        "    # use in train.py \n",
        "    # change from numpy.array to torch.variable   \n",
        "    tmp = torch.DoubleTensor(x)\n",
        "    return Variable(tmp)\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "-mpjeLpOycm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "from torch.nn.parameter import Parameter\n",
        "import torch.nn.functional as F \n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "import numpy as np \n",
        "import h5py\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import pywt\n",
        "\n",
        "class Wavelet_LSTM(nn.Module):\n",
        "    def __init__(self, seq_len, hidden_size, output_size, num_rnn_levels):\n",
        "        super(Wavelet_LSTM, self).__init__()\n",
        "      \n",
        "        self.seq_len = seq_len\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.num_rnn_levels = num_rnn_levels\n",
        "\n",
        "        self.lstms = nn.ModuleList([nn.LSTM(1, hidden_size, batch_first=True) for _ in range(num_rnn_levels)])\n",
        "        self.mWDNs = nn.ModuleList([nn.Linear(int(seq_len / (2 ** i)), int(seq_len / (2 ** i))) for i in range(num_rnn_levels)])\n",
        "\n",
        "        self.a_to_x = nn.AvgPool1d(2)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.output = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "        wavelet = pywt.Wavelet('db4')\n",
        "        low = wavelet.dec_lo\n",
        "        high = wavelet.dec_hi\n",
        "        self.l_filter = low\n",
        "        self.h_filter = high\n",
        "\n",
        "        self.cmp_mWDNs_H = nn.ParameterList([nn.Parameter(torch.tensor(self.create_W(int(seq_len / (2 ** i)), False, is_comp=True)).double()) for i in range(num_rnn_levels)])\n",
        "        self.cmp_mWDNs_L = nn.ParameterList([nn.Parameter(torch.tensor(self.create_W(int(seq_len / (2 ** i)), True, is_comp=True)).double()) for i in range(num_rnn_levels)])\n",
        "\n",
        "\n",
        "        self.mWDNs_H = nn.ModuleList([nn.Linear(int(seq_len / (2 ** i)), int(seq_len / (2 ** i))) for i in range(num_rnn_levels)])\n",
        "        self.mWDNs_L = nn.ModuleList([nn.Linear(int(seq_len / (2 ** i)), int(seq_len / (2 ** i))) for i in range(num_rnn_levels)])\n",
        "\n",
        "        for i in range(num_rnn_levels):\n",
        "            self.mWDNs_H[i].weight = nn.Parameter(torch.tensor(self.create_W(int(seq_len / (2 ** i)), False)).double())\n",
        "            self.mWDNs_L[i].weight = nn.Parameter(torch.tensor(self.create_W(int(seq_len / (2 ** i)), True)).double())\n",
        "\n",
        "    def forward(self, input, hidden_states):\n",
        "        input = input.unsqueeze(-1)  # Reshape input tensor\n",
        "        hidden_states = [(hidden_states[i][0].to(input.device), hidden_states[i][1].to(input.device)) for i in range(self.num_rnn_levels)]\n",
        "        al = []\n",
        "        ah = []\n",
        "        xl =[]\n",
        "        xh =[]\n",
        "        # Wavelet decomposition layers\n",
        "        ah.append(self.sigmoid(self.mWDNs_H[0](input.view(input.size(0), -1))))  # Adjust weight matrix dimensions\n",
        "        al.append(self.sigmoid(self.mWDNs_L[0](input.view(input.size(0), -1))))  # Adjust weight matrix dimensions\n",
        "        xh.append(self.a_to_x(ah[0].view(ah[0].shape[0], 1, -1)))\n",
        "\n",
        "        xl.append(self.a_to_x(al[0].view(al[0].shape[0],1,-1)))\n",
        "        for i in range(1,self.num_rnn_levels):\n",
        "            ah.append(self.sigmoid(self.mWDNs_H[i](xl[i-1])))\n",
        "            al.append(self.sigmoid(self.mWDNs_L[i](xl[i-1])))\n",
        "            xh.append(self.a_to_x(ah[i]))\n",
        "            xl.append(self.a_to_x(al[i]))\n",
        "\n",
        "        # Transpose and apply LSTM layers\n",
        "        xh = [x.transpose(1, 2) for x in xh]\n",
        "        xl = [x.transpose(1, 2) for x in xl]\n",
        "        rnn_outputs = []\n",
        "        for i in range(self.num_rnn_levels):\n",
        "            rnn_output, hidden = self.lstms[i](xh[i], hidden_states[i])\n",
        "            rnn_outputs.append(rnn_output)\n",
        "\n",
        "        rnn_outputs = torch.cat(rnn_outputs, 1)\n",
        "\n",
        "        output = self.output(rnn_outputs)\n",
        "        return output, hidden\n",
        "\n",
        "    def init_state(self, batch_size):\n",
        "        hidden_states = [(Variable(torch.zeros(1, batch_size, self.hidden_size)).double(),\n",
        "                          Variable(torch.zeros(1, batch_size, self.hidden_size)).double())\n",
        "                         for _ in range(self.num_rnn_levels)]\n",
        "        return hidden_states\n",
        "\n",
        "    def create_W(self, P, is_l, is_comp=False):\n",
        "        if is_l:\n",
        "            filter_list = self.l_filter\n",
        "        else:\n",
        "            filter_list = self.h_filter\n",
        "\n",
        "        list_len = len(filter_list)\n",
        "\n",
        "        max_epsilon = np.min(np.abs(filter_list))\n",
        "        if is_comp:\n",
        "            weight_np = np.zeros((P, P))\n",
        "        else:\n",
        "            weight_np = np.random.randn(P, P) * 0.1 * max_epsilon\n",
        "\n",
        "        for i in range(0, P):\n",
        "            filter_index = 0\n",
        "            for j in range(i, P):\n",
        "                if filter_index < len(filter_list):\n",
        "                    weight_np[i][j] = filter_list[filter_index]\n",
        "                    filter_index += 1\n",
        "        return weight_np\n"
      ],
      "metadata": {
        "id": "szm8CjB_ye8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, x_train, y_train, epochs=10, batch_size=32, alpha=0.3, beta=0.3):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.008)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    torch_dataloader = TorchDataLoader(batch_size)\n",
        "    train_loader = torch_dataloader.torch_dataloader(x_train, y_train)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for batch, (X, Y) in enumerate(train_loader):\n",
        "            hidden_states = model.init_state(X.shape[0])\n",
        "            output, hidden_states = model(X, hidden_states)\n",
        "\n",
        "            loss = criterion(output[:, -1, :], Y[:, -1, :])\n",
        "\n",
        "            # Calculate wavelet loss\n",
        "            L_loss = 0\n",
        "            H_loss = 0\n",
        "            W_mWDNs_H = [getattr(model.mWDNs_H[i], 'weight') for i in range(model.num_rnn_levels)]\n",
        "            W_mWDNs_L = [getattr(model.mWDNs_L[i], 'weight') for i in range(model.num_rnn_levels)]\n",
        "            for i in range(model.num_rnn_levels):\n",
        "                L_loss += torch.norm((W_mWDNs_L[i] - model.cmp_mWDNs_L[i]), 2)\n",
        "                H_loss += torch.norm((W_mWDNs_H[i] - model.cmp_mWDNs_H[i]), 2)\n",
        "\n",
        "            loss += alpha * L_loss + beta * H_loss\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            print('Epoch:', epoch + 1, '| Batch:', batch + 1, '| Loss:', loss.item())\n",
        "\n",
        "    torch.save(model, '/content/drive/My Drive/thesis/preprocess/modelLSTM_C.pkl')\n",
        "\n",
        "\n",
        "def test(model, x_test, y_test, data_df_combined_clean):\n",
        "    model = torch.load('/content/drive/My Drive/thesis/preprocess/modelLSTM_C.pkl')\n",
        "    model.eval()\n",
        "    x_test = ToVariable(x_test).double() # Convert x_test to PyTorch tensor\n",
        "    hidden_states = model.init_state(x_test.shape[0])\n",
        "\n",
        "    pred_dat, hidden_states = model(x_test, hidden_states)\n",
        "\n",
        "    pred_dat = np.array(pred_dat.detach().numpy())\n",
        "\n",
        "    # De-standardize predictions\n",
        "    preds_unstd = pred_dat * data_df_combined_clean.iloc[:, -1].std() + data_df_combined_clean.iloc[:, -1].mean()\n",
        "    y_test_unstd = y_test * data_df_combined_clean.iloc[:, -1].std() + data_df_combined_clean.iloc[:, -1].mean()\n",
        "\n",
        "    mrse = np.sqrt(((preds_unstd[:, -1, :] - y_test_unstd[:, -1, :]) ** 2)).mean(axis=0)\n",
        "    print('The mean square error is: %f' % mrse)\n",
        "    mape = np.mean(np.abs((y_test_unstd[:, -1, :] - preds_unstd[:, -1, :]) / y_test_unstd[:, -1, :])) * 100\n",
        "    print('MAPE is: %f' % mape)\n",
        "\n",
        "    plot_results(preds_unstd[:, -1, :], y_test_unstd[:, -1, :])\n"
      ],
      "metadata": {
        "id": "BhHAvKdMzIlz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/drive/MyDrive/ausdata.csv'\n",
        "P = 24  # sequence length\n",
        "step = 6  # ahead predict steps\n",
        "\n",
        "X_train, Y_train, X_test, Y_test, data_df_combined_clean = load_data(data_path, P=P, step=step)\n",
        "\n",
        "#print(X_train.shape)\n",
        "#print(Y_train.shape)\n",
        "\n",
        "model = Wavelet_LSTM(P, 100, 1, num_rnn_levels=2)  # seq_len, hidden_size, output_size\n",
        "model = model.double()\n",
        "\n",
        "X_train = torch.from_numpy(X_train)\n",
        "Y_train = torch.from_numpy(Y_train)\n",
        "train(model, X_train, Y_train, epochs=50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyA9A3YxzUax",
        "outputId": "a4a7e75e-0f03-44bc-b663-3f7e433e6f8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch: 48 | Batch: 1574 | Loss: 0.0756008991992078\n",
            "Epoch: 48 | Batch: 1575 | Loss: 0.032640579881683826\n",
            "Epoch: 48 | Batch: 1576 | Loss: 0.06316741287639978\n",
            "Epoch: 48 | Batch: 1577 | Loss: 0.03479018251847141\n",
            "Epoch: 48 | Batch: 1578 | Loss: 0.06789347839667124\n",
            "Epoch: 48 | Batch: 1579 | Loss: 0.06441294214030686\n",
            "Epoch: 48 | Batch: 1580 | Loss: 0.05587170714646317\n",
            "Epoch: 48 | Batch: 1581 | Loss: 0.05282837489157269\n",
            "Epoch: 48 | Batch: 1582 | Loss: 0.05838230605968267\n",
            "Epoch: 48 | Batch: 1583 | Loss: 0.09510304948224299\n",
            "Epoch: 48 | Batch: 1584 | Loss: 0.04219250897308846\n",
            "Epoch: 48 | Batch: 1585 | Loss: 0.06072478158461875\n",
            "Epoch: 48 | Batch: 1586 | Loss: 0.04791820718764881\n",
            "Epoch: 48 | Batch: 1587 | Loss: 0.059417319313124786\n",
            "Epoch: 48 | Batch: 1588 | Loss: 0.03823676354311433\n",
            "Epoch: 48 | Batch: 1589 | Loss: 0.07416516654799968\n",
            "Epoch: 48 | Batch: 1590 | Loss: 0.05693206735059742\n",
            "Epoch: 48 | Batch: 1591 | Loss: 0.09639926749705695\n",
            "Epoch: 48 | Batch: 1592 | Loss: 0.07022596531501088\n",
            "Epoch: 48 | Batch: 1593 | Loss: 0.043462720068479996\n",
            "Epoch: 48 | Batch: 1594 | Loss: 0.04969979858078801\n",
            "Epoch: 48 | Batch: 1595 | Loss: 0.08885166328966694\n",
            "Epoch: 48 | Batch: 1596 | Loss: 0.09004969707901612\n",
            "Epoch: 48 | Batch: 1597 | Loss: 0.07248237230186388\n",
            "Epoch: 48 | Batch: 1598 | Loss: 0.04652214258630841\n",
            "Epoch: 48 | Batch: 1599 | Loss: 0.052366407588651936\n",
            "Epoch: 48 | Batch: 1600 | Loss: 0.046605679733735035\n",
            "Epoch: 48 | Batch: 1601 | Loss: 0.04186567915854089\n",
            "Epoch: 48 | Batch: 1602 | Loss: 0.052837193702013646\n",
            "Epoch: 48 | Batch: 1603 | Loss: 0.05890105000857217\n",
            "Epoch: 48 | Batch: 1604 | Loss: 0.10019020960470476\n",
            "Epoch: 48 | Batch: 1605 | Loss: 0.046766638118756046\n",
            "Epoch: 48 | Batch: 1606 | Loss: 0.04822945021007236\n",
            "Epoch: 48 | Batch: 1607 | Loss: 0.04989279120547454\n",
            "Epoch: 48 | Batch: 1608 | Loss: 0.043042567514891314\n",
            "Epoch: 48 | Batch: 1609 | Loss: 0.03459056959384548\n",
            "Epoch: 48 | Batch: 1610 | Loss: 0.06383610472484386\n",
            "Epoch: 48 | Batch: 1611 | Loss: 0.05793678687699633\n",
            "Epoch: 48 | Batch: 1612 | Loss: 0.05758434343851404\n",
            "Epoch: 48 | Batch: 1613 | Loss: 0.047998061045975274\n",
            "Epoch: 48 | Batch: 1614 | Loss: 0.054515630914625954\n",
            "Epoch: 48 | Batch: 1615 | Loss: 0.041205748361651404\n",
            "Epoch: 48 | Batch: 1616 | Loss: 0.058490060755674186\n",
            "Epoch: 48 | Batch: 1617 | Loss: 0.058671901685498774\n",
            "Epoch: 48 | Batch: 1618 | Loss: 0.055036125578491926\n",
            "Epoch: 48 | Batch: 1619 | Loss: 0.04374807780647841\n",
            "Epoch: 48 | Batch: 1620 | Loss: 0.06881093930820897\n",
            "Epoch: 48 | Batch: 1621 | Loss: 0.05030717287942394\n",
            "Epoch: 48 | Batch: 1622 | Loss: 0.04983639344829476\n",
            "Epoch: 48 | Batch: 1623 | Loss: 0.06522608765726431\n",
            "Epoch: 48 | Batch: 1624 | Loss: 0.049590740353948046\n",
            "Epoch: 48 | Batch: 1625 | Loss: 0.08165819401108793\n",
            "Epoch: 48 | Batch: 1626 | Loss: 0.04844160434628217\n",
            "Epoch: 48 | Batch: 1627 | Loss: 0.05515050330722735\n",
            "Epoch: 48 | Batch: 1628 | Loss: 0.04807256424624952\n",
            "Epoch: 48 | Batch: 1629 | Loss: 0.07372979731324278\n",
            "Epoch: 48 | Batch: 1630 | Loss: 0.04301797289055215\n",
            "Epoch: 48 | Batch: 1631 | Loss: 0.06263117397154049\n",
            "Epoch: 48 | Batch: 1632 | Loss: 0.06963557617534662\n",
            "Epoch: 48 | Batch: 1633 | Loss: 0.1184168348357165\n",
            "Epoch: 48 | Batch: 1634 | Loss: 0.06385581518156487\n",
            "Epoch: 48 | Batch: 1635 | Loss: 0.07260034805739883\n",
            "Epoch: 48 | Batch: 1636 | Loss: 0.04374398262824971\n",
            "Epoch: 48 | Batch: 1637 | Loss: 0.050766623103649794\n",
            "Epoch: 48 | Batch: 1638 | Loss: 0.043829266468043804\n",
            "Epoch: 48 | Batch: 1639 | Loss: 0.05436316114513701\n",
            "Epoch: 48 | Batch: 1640 | Loss: 0.03925747259378316\n",
            "Epoch: 48 | Batch: 1641 | Loss: 0.05834660304611829\n",
            "Epoch: 48 | Batch: 1642 | Loss: 0.07801492705620719\n",
            "Epoch: 48 | Batch: 1643 | Loss: 0.06363088456491961\n",
            "Epoch: 48 | Batch: 1644 | Loss: 0.05056941915435886\n",
            "Epoch: 48 | Batch: 1645 | Loss: 0.03853290206217558\n",
            "Epoch: 48 | Batch: 1646 | Loss: 0.04605863335589523\n",
            "Epoch: 48 | Batch: 1647 | Loss: 0.06141340842751049\n",
            "Epoch: 48 | Batch: 1648 | Loss: 0.04855961363035205\n",
            "Epoch: 48 | Batch: 1649 | Loss: 0.04653566060603363\n",
            "Epoch: 48 | Batch: 1650 | Loss: 0.06816972547942454\n",
            "Epoch: 48 | Batch: 1651 | Loss: 0.1580048408261115\n",
            "Epoch: 48 | Batch: 1652 | Loss: 0.05959534755302941\n",
            "Epoch: 48 | Batch: 1653 | Loss: 0.04340211557745753\n",
            "Epoch: 48 | Batch: 1654 | Loss: 0.06595974908058852\n",
            "Epoch: 48 | Batch: 1655 | Loss: 0.043607487409469445\n",
            "Epoch: 48 | Batch: 1656 | Loss: 0.05500496826574089\n",
            "Epoch: 48 | Batch: 1657 | Loss: 0.03905941126907009\n",
            "Epoch: 48 | Batch: 1658 | Loss: 0.04153892064474645\n",
            "Epoch: 48 | Batch: 1659 | Loss: 0.0708658621744627\n",
            "Epoch: 48 | Batch: 1660 | Loss: 0.06507030938380795\n",
            "Epoch: 48 | Batch: 1661 | Loss: 0.08983858498829926\n",
            "Epoch: 48 | Batch: 1662 | Loss: 0.05937782481723251\n",
            "Epoch: 48 | Batch: 1663 | Loss: 0.029524728368344504\n",
            "Epoch: 48 | Batch: 1664 | Loss: 0.041814037914374554\n",
            "Epoch: 48 | Batch: 1665 | Loss: 0.040933790811204636\n",
            "Epoch: 48 | Batch: 1666 | Loss: 0.04084420031877807\n",
            "Epoch: 48 | Batch: 1667 | Loss: 0.06523480265449251\n",
            "Epoch: 48 | Batch: 1668 | Loss: 0.06850342297221274\n",
            "Epoch: 48 | Batch: 1669 | Loss: 0.12217863321426194\n",
            "Epoch: 48 | Batch: 1670 | Loss: 0.045746868968583196\n",
            "Epoch: 48 | Batch: 1671 | Loss: 0.07970356303493116\n",
            "Epoch: 48 | Batch: 1672 | Loss: 0.07349553668087615\n",
            "Epoch: 48 | Batch: 1673 | Loss: 0.05544837514351737\n",
            "Epoch: 48 | Batch: 1674 | Loss: 0.05665536225676486\n",
            "Epoch: 48 | Batch: 1675 | Loss: 0.05866343692927283\n",
            "Epoch: 48 | Batch: 1676 | Loss: 0.07367157821877299\n",
            "Epoch: 48 | Batch: 1677 | Loss: 0.054035856207773916\n",
            "Epoch: 48 | Batch: 1678 | Loss: 0.04012720865044091\n",
            "Epoch: 48 | Batch: 1679 | Loss: 0.04952494471686379\n",
            "Epoch: 48 | Batch: 1680 | Loss: 0.057970940157876995\n",
            "Epoch: 48 | Batch: 1681 | Loss: 0.06777531487672132\n",
            "Epoch: 48 | Batch: 1682 | Loss: 0.05443342245978817\n",
            "Epoch: 48 | Batch: 1683 | Loss: 0.045712525457376973\n",
            "Epoch: 48 | Batch: 1684 | Loss: 0.05187029161413212\n",
            "Epoch: 48 | Batch: 1685 | Loss: 0.051197337389190536\n",
            "Epoch: 48 | Batch: 1686 | Loss: 0.07100211270455511\n",
            "Epoch: 48 | Batch: 1687 | Loss: 0.05859288857758647\n",
            "Epoch: 48 | Batch: 1688 | Loss: 0.10300091072871168\n",
            "Epoch: 48 | Batch: 1689 | Loss: 0.04722427818188377\n",
            "Epoch: 48 | Batch: 1690 | Loss: 0.053901689319541674\n",
            "Epoch: 48 | Batch: 1691 | Loss: 0.037984431447963575\n",
            "Epoch: 48 | Batch: 1692 | Loss: 0.07738314831810633\n",
            "Epoch: 48 | Batch: 1693 | Loss: 0.0804945386663942\n",
            "Epoch: 48 | Batch: 1694 | Loss: 0.04682866663333993\n",
            "Epoch: 48 | Batch: 1695 | Loss: 0.04985663326627904\n",
            "Epoch: 48 | Batch: 1696 | Loss: 0.055346251400807345\n",
            "Epoch: 48 | Batch: 1697 | Loss: 0.05540602211455331\n",
            "Epoch: 48 | Batch: 1698 | Loss: 0.039259252962488014\n",
            "Epoch: 48 | Batch: 1699 | Loss: 0.05630981978816185\n",
            "Epoch: 48 | Batch: 1700 | Loss: 0.037850172765716526\n",
            "Epoch: 48 | Batch: 1701 | Loss: 0.05218818869329285\n",
            "Epoch: 48 | Batch: 1702 | Loss: 0.04766043877655418\n",
            "Epoch: 48 | Batch: 1703 | Loss: 0.044173608631697295\n",
            "Epoch: 48 | Batch: 1704 | Loss: 0.06375641677252256\n",
            "Epoch: 48 | Batch: 1705 | Loss: 0.05857162478251478\n",
            "Epoch: 48 | Batch: 1706 | Loss: 0.056444861702682474\n",
            "Epoch: 48 | Batch: 1707 | Loss: 0.06375725119103397\n",
            "Epoch: 48 | Batch: 1708 | Loss: 0.05585326355877471\n",
            "Epoch: 48 | Batch: 1709 | Loss: 0.06943362379374793\n",
            "Epoch: 48 | Batch: 1710 | Loss: 0.05643336745584728\n",
            "Epoch: 48 | Batch: 1711 | Loss: 0.033927941599216\n",
            "Epoch: 48 | Batch: 1712 | Loss: 0.07478801041252821\n",
            "Epoch: 48 | Batch: 1713 | Loss: 0.0848465682123965\n",
            "Epoch: 48 | Batch: 1714 | Loss: 0.04976680712085623\n",
            "Epoch: 48 | Batch: 1715 | Loss: 0.07073551750078592\n",
            "Epoch: 48 | Batch: 1716 | Loss: 0.07378734064476145\n",
            "Epoch: 48 | Batch: 1717 | Loss: 0.03782851873634914\n",
            "Epoch: 48 | Batch: 1718 | Loss: 0.04141652761910916\n",
            "Epoch: 48 | Batch: 1719 | Loss: 0.04905625576026203\n",
            "Epoch: 48 | Batch: 1720 | Loss: 0.07215988675049674\n",
            "Epoch: 48 | Batch: 1721 | Loss: 0.06049587678474006\n",
            "Epoch: 48 | Batch: 1722 | Loss: 0.04817199526216602\n",
            "Epoch: 48 | Batch: 1723 | Loss: 0.07376219582342451\n",
            "Epoch: 48 | Batch: 1724 | Loss: 0.03296018398913618\n",
            "Epoch: 48 | Batch: 1725 | Loss: 0.058276910008695046\n",
            "Epoch: 48 | Batch: 1726 | Loss: 0.0865776753889131\n",
            "Epoch: 48 | Batch: 1727 | Loss: 0.06961842304321958\n",
            "Epoch: 48 | Batch: 1728 | Loss: 0.04078447620972688\n",
            "Epoch: 48 | Batch: 1729 | Loss: 0.03679280610670639\n",
            "Epoch: 48 | Batch: 1730 | Loss: 0.04965897116102359\n",
            "Epoch: 48 | Batch: 1731 | Loss: 0.10727137457975797\n",
            "Epoch: 48 | Batch: 1732 | Loss: 0.0683800020882644\n",
            "Epoch: 48 | Batch: 1733 | Loss: 0.04586206673121324\n",
            "Epoch: 48 | Batch: 1734 | Loss: 0.06593755971877409\n",
            "Epoch: 48 | Batch: 1735 | Loss: 0.10490132777072134\n",
            "Epoch: 48 | Batch: 1736 | Loss: 0.05435606967518035\n",
            "Epoch: 48 | Batch: 1737 | Loss: 0.04325520257875379\n",
            "Epoch: 48 | Batch: 1738 | Loss: 0.04647791370876202\n",
            "Epoch: 48 | Batch: 1739 | Loss: 0.04399205872175392\n",
            "Epoch: 48 | Batch: 1740 | Loss: 0.049969127316517495\n",
            "Epoch: 48 | Batch: 1741 | Loss: 0.03865284689896942\n",
            "Epoch: 48 | Batch: 1742 | Loss: 0.05347151586257361\n",
            "Epoch: 48 | Batch: 1743 | Loss: 0.08041303789347203\n",
            "Epoch: 48 | Batch: 1744 | Loss: 0.05489279337193997\n",
            "Epoch: 48 | Batch: 1745 | Loss: 0.05100493738222066\n",
            "Epoch: 48 | Batch: 1746 | Loss: 0.06210828329226997\n",
            "Epoch: 48 | Batch: 1747 | Loss: 0.03653173938422696\n",
            "Epoch: 48 | Batch: 1748 | Loss: 0.05884008072457682\n",
            "Epoch: 48 | Batch: 1749 | Loss: 0.07718535126983009\n",
            "Epoch: 48 | Batch: 1750 | Loss: 0.085982185201326\n",
            "Epoch: 48 | Batch: 1751 | Loss: 0.061106342834230096\n",
            "Epoch: 48 | Batch: 1752 | Loss: 0.07864243394767884\n",
            "Epoch: 48 | Batch: 1753 | Loss: 0.0601186210710982\n",
            "Epoch: 48 | Batch: 1754 | Loss: 0.03328248208444809\n",
            "Epoch: 48 | Batch: 1755 | Loss: 0.0780532909453675\n",
            "Epoch: 48 | Batch: 1756 | Loss: 0.03599376520344773\n",
            "Epoch: 48 | Batch: 1757 | Loss: 0.053822320236153465\n",
            "Epoch: 48 | Batch: 1758 | Loss: 0.06747650681299883\n",
            "Epoch: 48 | Batch: 1759 | Loss: 0.047869358558274754\n",
            "Epoch: 48 | Batch: 1760 | Loss: 0.04802068432905565\n",
            "Epoch: 48 | Batch: 1761 | Loss: 0.05148899725342179\n",
            "Epoch: 48 | Batch: 1762 | Loss: 0.036322786791121324\n",
            "Epoch: 48 | Batch: 1763 | Loss: 0.07695014825826939\n",
            "Epoch: 48 | Batch: 1764 | Loss: 0.05205798206418843\n",
            "Epoch: 48 | Batch: 1765 | Loss: 0.04321217681903462\n",
            "Epoch: 48 | Batch: 1766 | Loss: 0.06504376588867156\n",
            "Epoch: 48 | Batch: 1767 | Loss: 0.05978751238245922\n",
            "Epoch: 48 | Batch: 1768 | Loss: 0.05916232143260039\n",
            "Epoch: 48 | Batch: 1769 | Loss: 0.10102052434343697\n",
            "Epoch: 48 | Batch: 1770 | Loss: 0.04380328865291592\n",
            "Epoch: 48 | Batch: 1771 | Loss: 0.08443829751227641\n",
            "Epoch: 48 | Batch: 1772 | Loss: 0.06920668250036338\n",
            "Epoch: 48 | Batch: 1773 | Loss: 0.06637401251962034\n",
            "Epoch: 48 | Batch: 1774 | Loss: 0.09230198049894422\n",
            "Epoch: 48 | Batch: 1775 | Loss: 0.06961788807400321\n",
            "Epoch: 48 | Batch: 1776 | Loss: 0.1124068125719718\n",
            "Epoch: 48 | Batch: 1777 | Loss: 0.061217242773454264\n",
            "Epoch: 48 | Batch: 1778 | Loss: 0.06186012211733985\n",
            "Epoch: 48 | Batch: 1779 | Loss: 0.06488503037384591\n",
            "Epoch: 48 | Batch: 1780 | Loss: 0.06009009261015091\n",
            "Epoch: 48 | Batch: 1781 | Loss: 0.10460215589448552\n",
            "Epoch: 48 | Batch: 1782 | Loss: 0.06741766290878497\n",
            "Epoch: 48 | Batch: 1783 | Loss: 0.05587631246515463\n",
            "Epoch: 48 | Batch: 1784 | Loss: 0.051735057264989705\n",
            "Epoch: 48 | Batch: 1785 | Loss: 0.0755734658670208\n",
            "Epoch: 48 | Batch: 1786 | Loss: 0.0573168572996781\n",
            "Epoch: 48 | Batch: 1787 | Loss: 0.04225755384920406\n",
            "Epoch: 48 | Batch: 1788 | Loss: 0.09979239859036927\n",
            "Epoch: 48 | Batch: 1789 | Loss: 0.09870686629797311\n",
            "Epoch: 48 | Batch: 1790 | Loss: 0.059178908040302805\n",
            "Epoch: 48 | Batch: 1791 | Loss: 0.049759526796916045\n",
            "Epoch: 48 | Batch: 1792 | Loss: 0.06025508213330911\n",
            "Epoch: 48 | Batch: 1793 | Loss: 0.11089038331497908\n",
            "Epoch: 48 | Batch: 1794 | Loss: 0.07731116018360204\n",
            "Epoch: 48 | Batch: 1795 | Loss: 0.0803520115676031\n",
            "Epoch: 48 | Batch: 1796 | Loss: 0.03955561243785874\n",
            "Epoch: 48 | Batch: 1797 | Loss: 0.07644572589065136\n",
            "Epoch: 48 | Batch: 1798 | Loss: 0.07456576820021561\n",
            "Epoch: 48 | Batch: 1799 | Loss: 0.0694031531725076\n",
            "Epoch: 48 | Batch: 1800 | Loss: 0.10239051602791545\n",
            "Epoch: 48 | Batch: 1801 | Loss: 0.07117829236151853\n",
            "Epoch: 48 | Batch: 1802 | Loss: 0.06309550250072274\n",
            "Epoch: 48 | Batch: 1803 | Loss: 0.05380749274112515\n",
            "Epoch: 48 | Batch: 1804 | Loss: 0.06893399776201492\n",
            "Epoch: 48 | Batch: 1805 | Loss: 0.03431544796553749\n",
            "Epoch: 48 | Batch: 1806 | Loss: 0.06592460540693554\n",
            "Epoch: 48 | Batch: 1807 | Loss: 0.05601460356599686\n",
            "Epoch: 48 | Batch: 1808 | Loss: 0.08155334752578917\n",
            "Epoch: 48 | Batch: 1809 | Loss: 0.059054496169237206\n",
            "Epoch: 48 | Batch: 1810 | Loss: 0.05069225653019858\n",
            "Epoch: 48 | Batch: 1811 | Loss: 0.0521095126130247\n",
            "Epoch: 48 | Batch: 1812 | Loss: 0.06815351961129437\n",
            "Epoch: 48 | Batch: 1813 | Loss: 0.07294025105567928\n",
            "Epoch: 48 | Batch: 1814 | Loss: 0.05638807259083527\n",
            "Epoch: 48 | Batch: 1815 | Loss: 0.06431788132836476\n",
            "Epoch: 48 | Batch: 1816 | Loss: 0.0836468272525181\n",
            "Epoch: 48 | Batch: 1817 | Loss: 0.04243430561944242\n",
            "Epoch: 48 | Batch: 1818 | Loss: 0.06605737506859902\n",
            "Epoch: 48 | Batch: 1819 | Loss: 0.04858477762912287\n",
            "Epoch: 48 | Batch: 1820 | Loss: 0.08361617933208768\n",
            "Epoch: 48 | Batch: 1821 | Loss: 0.07006284084590016\n",
            "Epoch: 48 | Batch: 1822 | Loss: 0.06902563863965946\n",
            "Epoch: 48 | Batch: 1823 | Loss: 0.06686663312930592\n",
            "Epoch: 48 | Batch: 1824 | Loss: 0.05738046763659759\n",
            "Epoch: 48 | Batch: 1825 | Loss: 0.04641464555545152\n",
            "Epoch: 48 | Batch: 1826 | Loss: 0.03654406176255212\n",
            "Epoch: 48 | Batch: 1827 | Loss: 0.04829095871841248\n",
            "Epoch: 48 | Batch: 1828 | Loss: 0.0402392187931665\n",
            "Epoch: 48 | Batch: 1829 | Loss: 0.05430055430460434\n",
            "Epoch: 48 | Batch: 1830 | Loss: 0.05663305578527743\n",
            "Epoch: 48 | Batch: 1831 | Loss: 0.12388225995464287\n",
            "Epoch: 48 | Batch: 1832 | Loss: 0.05369047757604999\n",
            "Epoch: 48 | Batch: 1833 | Loss: 0.04847356026976971\n",
            "Epoch: 48 | Batch: 1834 | Loss: 0.05893552894977105\n",
            "Epoch: 48 | Batch: 1835 | Loss: 0.07357950515984227\n",
            "Epoch: 48 | Batch: 1836 | Loss: 0.06725932564216437\n",
            "Epoch: 48 | Batch: 1837 | Loss: 0.07943477840685113\n",
            "Epoch: 48 | Batch: 1838 | Loss: 0.04208007579320608\n",
            "Epoch: 48 | Batch: 1839 | Loss: 0.0560934601612221\n",
            "Epoch: 48 | Batch: 1840 | Loss: 0.04621798708549582\n",
            "Epoch: 48 | Batch: 1841 | Loss: 0.04946983388420079\n",
            "Epoch: 48 | Batch: 1842 | Loss: 0.04619952312466152\n",
            "Epoch: 48 | Batch: 1843 | Loss: 0.0604317798094029\n",
            "Epoch: 48 | Batch: 1844 | Loss: 0.06467086831065158\n",
            "Epoch: 48 | Batch: 1845 | Loss: 0.06122575439032578\n",
            "Epoch: 48 | Batch: 1846 | Loss: 0.08848382888821787\n",
            "Epoch: 48 | Batch: 1847 | Loss: 0.10047609365872776\n",
            "Epoch: 48 | Batch: 1848 | Loss: 0.046639975480568904\n",
            "Epoch: 48 | Batch: 1849 | Loss: 0.03502349028747745\n",
            "Epoch: 48 | Batch: 1850 | Loss: 0.06582793653220703\n",
            "Epoch: 48 | Batch: 1851 | Loss: 0.053223803343976354\n",
            "Epoch: 48 | Batch: 1852 | Loss: 0.055673442660650996\n",
            "Epoch: 48 | Batch: 1853 | Loss: 0.09043911276014678\n",
            "Epoch: 48 | Batch: 1854 | Loss: 0.05997221335663869\n",
            "Epoch: 48 | Batch: 1855 | Loss: 0.06005715091777082\n",
            "Epoch: 48 | Batch: 1856 | Loss: 0.06717511871969098\n",
            "Epoch: 48 | Batch: 1857 | Loss: 0.06570680019991876\n",
            "Epoch: 48 | Batch: 1858 | Loss: 0.07510517743780344\n",
            "Epoch: 48 | Batch: 1859 | Loss: 0.08350160523270503\n",
            "Epoch: 48 | Batch: 1860 | Loss: 0.05748727310272918\n",
            "Epoch: 48 | Batch: 1861 | Loss: 0.09178718567150938\n",
            "Epoch: 48 | Batch: 1862 | Loss: 0.03596774738188066\n",
            "Epoch: 48 | Batch: 1863 | Loss: 0.054719970623470615\n",
            "Epoch: 48 | Batch: 1864 | Loss: 0.06967865264128233\n",
            "Epoch: 48 | Batch: 1865 | Loss: 0.06817800453203483\n",
            "Epoch: 48 | Batch: 1866 | Loss: 0.06411304573086597\n",
            "Epoch: 48 | Batch: 1867 | Loss: 0.051942537313739705\n",
            "Epoch: 48 | Batch: 1868 | Loss: 0.0674401027203879\n",
            "Epoch: 48 | Batch: 1869 | Loss: 0.0800646112100186\n",
            "Epoch: 48 | Batch: 1870 | Loss: 0.06462354295165468\n",
            "Epoch: 48 | Batch: 1871 | Loss: 0.06799607637233343\n",
            "Epoch: 48 | Batch: 1872 | Loss: 0.05239893217509287\n",
            "Epoch: 48 | Batch: 1873 | Loss: 0.06578775622034796\n",
            "Epoch: 48 | Batch: 1874 | Loss: 0.053823378983506975\n",
            "Epoch: 48 | Batch: 1875 | Loss: 0.05499579184507052\n",
            "Epoch: 48 | Batch: 1876 | Loss: 0.05772848678856951\n",
            "Epoch: 48 | Batch: 1877 | Loss: 0.04554937658462649\n",
            "Epoch: 48 | Batch: 1878 | Loss: 0.0948402106891081\n",
            "Epoch: 48 | Batch: 1879 | Loss: 0.05306045838769292\n",
            "Epoch: 48 | Batch: 1880 | Loss: 0.04920416508672452\n",
            "Epoch: 48 | Batch: 1881 | Loss: 0.07098660933550521\n",
            "Epoch: 48 | Batch: 1882 | Loss: 0.03317374510642973\n",
            "Epoch: 48 | Batch: 1883 | Loss: 0.10359196688782481\n",
            "Epoch: 48 | Batch: 1884 | Loss: 0.049819595476667825\n",
            "Epoch: 48 | Batch: 1885 | Loss: 0.046810638127187984\n",
            "Epoch: 48 | Batch: 1886 | Loss: 0.060276373601037124\n",
            "Epoch: 48 | Batch: 1887 | Loss: 0.07581571948532367\n",
            "Epoch: 48 | Batch: 1888 | Loss: 0.05658295733550975\n",
            "Epoch: 48 | Batch: 1889 | Loss: 0.10502026699755877\n",
            "Epoch: 48 | Batch: 1890 | Loss: 0.0655750781876072\n",
            "Epoch: 48 | Batch: 1891 | Loss: 0.09650513382835306\n",
            "Epoch: 48 | Batch: 1892 | Loss: 0.05253612769854891\n",
            "Epoch: 48 | Batch: 1893 | Loss: 0.07707059397487348\n",
            "Epoch: 48 | Batch: 1894 | Loss: 0.05266228053406515\n",
            "Epoch: 48 | Batch: 1895 | Loss: 0.10822417221133326\n",
            "Epoch: 48 | Batch: 1896 | Loss: 0.05973893465416997\n",
            "Epoch: 48 | Batch: 1897 | Loss: 0.05609731895097361\n",
            "Epoch: 48 | Batch: 1898 | Loss: 0.08323989553060497\n",
            "Epoch: 48 | Batch: 1899 | Loss: 0.09343102574093852\n",
            "Epoch: 48 | Batch: 1900 | Loss: 0.07454793135842183\n",
            "Epoch: 48 | Batch: 1901 | Loss: 0.08534695266516625\n",
            "Epoch: 48 | Batch: 1902 | Loss: 0.07552187460175602\n",
            "Epoch: 48 | Batch: 1903 | Loss: 0.04358720928522862\n",
            "Epoch: 48 | Batch: 1904 | Loss: 0.043835390903752096\n",
            "Epoch: 48 | Batch: 1905 | Loss: 0.07648554506709852\n",
            "Epoch: 48 | Batch: 1906 | Loss: 0.07770116265310228\n",
            "Epoch: 48 | Batch: 1907 | Loss: 0.0958663283845843\n",
            "Epoch: 48 | Batch: 1908 | Loss: 0.08481036944525204\n",
            "Epoch: 48 | Batch: 1909 | Loss: 0.08961993051001796\n",
            "Epoch: 48 | Batch: 1910 | Loss: 0.05078874276933698\n",
            "Epoch: 48 | Batch: 1911 | Loss: 0.05649103467626966\n",
            "Epoch: 48 | Batch: 1912 | Loss: 0.05077892995796009\n",
            "Epoch: 48 | Batch: 1913 | Loss: 0.07556315554442813\n",
            "Epoch: 48 | Batch: 1914 | Loss: 0.07003197438425575\n",
            "Epoch: 48 | Batch: 1915 | Loss: 0.08893363729184783\n",
            "Epoch: 48 | Batch: 1916 | Loss: 0.0820903005858136\n",
            "Epoch: 48 | Batch: 1917 | Loss: 0.0571977863367705\n",
            "Epoch: 48 | Batch: 1918 | Loss: 0.06567757946900504\n",
            "Epoch: 48 | Batch: 1919 | Loss: 0.05296161348354208\n",
            "Epoch: 48 | Batch: 1920 | Loss: 0.07390505201043378\n",
            "Epoch: 48 | Batch: 1921 | Loss: 0.08193374733131636\n",
            "Epoch: 48 | Batch: 1922 | Loss: 0.0688306612568694\n",
            "Epoch: 48 | Batch: 1923 | Loss: 0.05464573812289833\n",
            "Epoch: 48 | Batch: 1924 | Loss: 0.059530041934865066\n",
            "Epoch: 48 | Batch: 1925 | Loss: 0.14198553284595203\n",
            "Epoch: 48 | Batch: 1926 | Loss: 0.08986148360479035\n",
            "Epoch: 48 | Batch: 1927 | Loss: 0.08859697805785058\n",
            "Epoch: 48 | Batch: 1928 | Loss: 0.07907357012444348\n",
            "Epoch: 48 | Batch: 1929 | Loss: 0.05655456361317645\n",
            "Epoch: 48 | Batch: 1930 | Loss: 0.05050526260324676\n",
            "Epoch: 48 | Batch: 1931 | Loss: 0.10191749041231343\n",
            "Epoch: 48 | Batch: 1932 | Loss: 0.07624975777283768\n",
            "Epoch: 48 | Batch: 1933 | Loss: 0.06799382668023032\n",
            "Epoch: 48 | Batch: 1934 | Loss: 0.07888850731062315\n",
            "Epoch: 48 | Batch: 1935 | Loss: 0.05593660882859374\n",
            "Epoch: 48 | Batch: 1936 | Loss: 0.05649211802380356\n",
            "Epoch: 48 | Batch: 1937 | Loss: 0.0588320716416868\n",
            "Epoch: 48 | Batch: 1938 | Loss: 0.0624705417029794\n",
            "Epoch: 48 | Batch: 1939 | Loss: 0.04803733396063969\n",
            "Epoch: 48 | Batch: 1940 | Loss: 0.06141393688726442\n",
            "Epoch: 48 | Batch: 1941 | Loss: 0.07091866917962542\n",
            "Epoch: 48 | Batch: 1942 | Loss: 0.05816995067985352\n",
            "Epoch: 48 | Batch: 1943 | Loss: 0.07537013612783168\n",
            "Epoch: 48 | Batch: 1944 | Loss: 0.06578934716505559\n",
            "Epoch: 48 | Batch: 1945 | Loss: 0.08947616872835627\n",
            "Epoch: 48 | Batch: 1946 | Loss: 0.03935004477524025\n",
            "Epoch: 48 | Batch: 1947 | Loss: 0.07636055345749378\n",
            "Epoch: 48 | Batch: 1948 | Loss: 0.09379740242783396\n",
            "Epoch: 48 | Batch: 1949 | Loss: 0.08246506148311869\n",
            "Epoch: 48 | Batch: 1950 | Loss: 0.047817993831114666\n",
            "Epoch: 48 | Batch: 1951 | Loss: 0.06361721515572419\n",
            "Epoch: 48 | Batch: 1952 | Loss: 0.057223439659106944\n",
            "Epoch: 48 | Batch: 1953 | Loss: 0.05846370399169214\n",
            "Epoch: 48 | Batch: 1954 | Loss: 0.06450070758097556\n",
            "Epoch: 48 | Batch: 1955 | Loss: 0.04447635191512783\n",
            "Epoch: 48 | Batch: 1956 | Loss: 0.05003842577529205\n",
            "Epoch: 48 | Batch: 1957 | Loss: 0.06727907322915201\n",
            "Epoch: 48 | Batch: 1958 | Loss: 0.059781528933505725\n",
            "Epoch: 48 | Batch: 1959 | Loss: 0.08456779046173886\n",
            "Epoch: 48 | Batch: 1960 | Loss: 0.06128634058290426\n",
            "Epoch: 48 | Batch: 1961 | Loss: 0.053793122218133926\n",
            "Epoch: 48 | Batch: 1962 | Loss: 0.051589901690866635\n",
            "Epoch: 48 | Batch: 1963 | Loss: 0.08049252568523096\n",
            "Epoch: 48 | Batch: 1964 | Loss: 0.04467750113914249\n",
            "Epoch: 48 | Batch: 1965 | Loss: 0.04070876353457561\n",
            "Epoch: 48 | Batch: 1966 | Loss: 0.043887642657838205\n",
            "Epoch: 48 | Batch: 1967 | Loss: 0.04865176605036427\n",
            "Epoch: 48 | Batch: 1968 | Loss: 0.05862174847228463\n",
            "Epoch: 48 | Batch: 1969 | Loss: 0.07165190901090579\n",
            "Epoch: 48 | Batch: 1970 | Loss: 0.0662686635014475\n",
            "Epoch: 48 | Batch: 1971 | Loss: 0.05104681484131558\n",
            "Epoch: 48 | Batch: 1972 | Loss: 0.04255624165804132\n",
            "Epoch: 48 | Batch: 1973 | Loss: 0.06391886645142078\n",
            "Epoch: 48 | Batch: 1974 | Loss: 0.06167141261585021\n",
            "Epoch: 48 | Batch: 1975 | Loss: 0.06071087185137083\n",
            "Epoch: 48 | Batch: 1976 | Loss: 0.07069787159069779\n",
            "Epoch: 48 | Batch: 1977 | Loss: 0.04083736689816074\n",
            "Epoch: 48 | Batch: 1978 | Loss: 0.04775697729252894\n",
            "Epoch: 48 | Batch: 1979 | Loss: 0.050601671316682084\n",
            "Epoch: 48 | Batch: 1980 | Loss: 0.061115994300100146\n",
            "Epoch: 48 | Batch: 1981 | Loss: 0.09777311007660673\n",
            "Epoch: 48 | Batch: 1982 | Loss: 0.042842300903071236\n",
            "Epoch: 48 | Batch: 1983 | Loss: 0.06486779440432533\n",
            "Epoch: 48 | Batch: 1984 | Loss: 0.05875359568849252\n",
            "Epoch: 48 | Batch: 1985 | Loss: 0.0754351183493553\n",
            "Epoch: 48 | Batch: 1986 | Loss: 0.04320550466418193\n",
            "Epoch: 48 | Batch: 1987 | Loss: 0.05286482112444348\n",
            "Epoch: 48 | Batch: 1988 | Loss: 0.05269358463018811\n",
            "Epoch: 48 | Batch: 1989 | Loss: 0.08539559756709247\n",
            "Epoch: 48 | Batch: 1990 | Loss: 0.06543090030678307\n",
            "Epoch: 48 | Batch: 1991 | Loss: 0.06801973601259036\n",
            "Epoch: 48 | Batch: 1992 | Loss: 0.05020560012461121\n",
            "Epoch: 48 | Batch: 1993 | Loss: 0.04313684054376955\n",
            "Epoch: 48 | Batch: 1994 | Loss: 0.06513199671680978\n",
            "Epoch: 48 | Batch: 1995 | Loss: 0.05544220716284631\n",
            "Epoch: 48 | Batch: 1996 | Loss: 0.05208969905494595\n",
            "Epoch: 48 | Batch: 1997 | Loss: 0.05475125655423881\n",
            "Epoch: 48 | Batch: 1998 | Loss: 0.0445555973933183\n",
            "Epoch: 48 | Batch: 1999 | Loss: 0.05719950327680233\n",
            "Epoch: 48 | Batch: 2000 | Loss: 0.054181820683118234\n",
            "Epoch: 48 | Batch: 2001 | Loss: 0.0439461914837584\n",
            "Epoch: 48 | Batch: 2002 | Loss: 0.036955624328228104\n",
            "Epoch: 48 | Batch: 2003 | Loss: 0.0454958240505206\n",
            "Epoch: 48 | Batch: 2004 | Loss: 0.04588037342965282\n",
            "Epoch: 48 | Batch: 2005 | Loss: 0.06811707764370765\n",
            "Epoch: 48 | Batch: 2006 | Loss: 0.05487216992293049\n",
            "Epoch: 48 | Batch: 2007 | Loss: 0.06766728678154914\n",
            "Epoch: 48 | Batch: 2008 | Loss: 0.03409378007785292\n",
            "Epoch: 48 | Batch: 2009 | Loss: 0.0717319764898525\n",
            "Epoch: 48 | Batch: 2010 | Loss: 0.03678702231904554\n",
            "Epoch: 48 | Batch: 2011 | Loss: 0.05036453389291294\n",
            "Epoch: 48 | Batch: 2012 | Loss: 0.06342804053147243\n",
            "Epoch: 48 | Batch: 2013 | Loss: 0.07633646193608574\n",
            "Epoch: 48 | Batch: 2014 | Loss: 0.08126746168261331\n",
            "Epoch: 48 | Batch: 2015 | Loss: 0.04446738620189067\n",
            "Epoch: 48 | Batch: 2016 | Loss: 0.07924929993038952\n",
            "Epoch: 48 | Batch: 2017 | Loss: 0.04181696471445773\n",
            "Epoch: 48 | Batch: 2018 | Loss: 0.051550353690669265\n",
            "Epoch: 48 | Batch: 2019 | Loss: 0.06351283993889724\n",
            "Epoch: 48 | Batch: 2020 | Loss: 0.03811281379427907\n",
            "Epoch: 48 | Batch: 2021 | Loss: 0.06211799998249568\n",
            "Epoch: 48 | Batch: 2022 | Loss: 0.041030916626055014\n",
            "Epoch: 48 | Batch: 2023 | Loss: 0.03435750561718982\n",
            "Epoch: 48 | Batch: 2024 | Loss: 0.08881462227549494\n",
            "Epoch: 48 | Batch: 2025 | Loss: 0.07932018186836261\n",
            "Epoch: 48 | Batch: 2026 | Loss: 0.06928000545688523\n",
            "Epoch: 48 | Batch: 2027 | Loss: 0.03625809334613719\n",
            "Epoch: 48 | Batch: 2028 | Loss: 0.05770361494652381\n",
            "Epoch: 48 | Batch: 2029 | Loss: 0.07805532877060596\n",
            "Epoch: 48 | Batch: 2030 | Loss: 0.04344137831908346\n",
            "Epoch: 48 | Batch: 2031 | Loss: 0.0627237058655496\n",
            "Epoch: 48 | Batch: 2032 | Loss: 0.05225967072166212\n",
            "Epoch: 48 | Batch: 2033 | Loss: 0.09751271211322342\n",
            "Epoch: 48 | Batch: 2034 | Loss: 0.04442716189947506\n",
            "Epoch: 48 | Batch: 2035 | Loss: 0.05029252863285025\n",
            "Epoch: 48 | Batch: 2036 | Loss: 0.04911914946528389\n",
            "Epoch: 48 | Batch: 2037 | Loss: 0.07292604001051349\n",
            "Epoch: 48 | Batch: 2038 | Loss: 0.07236227337374662\n",
            "Epoch: 48 | Batch: 2039 | Loss: 0.048906309709406987\n",
            "Epoch: 48 | Batch: 2040 | Loss: 0.039767693699706196\n",
            "Epoch: 48 | Batch: 2041 | Loss: 0.04078742272174337\n",
            "Epoch: 48 | Batch: 2042 | Loss: 0.05497818518587293\n",
            "Epoch: 48 | Batch: 2043 | Loss: 0.10649321215972096\n",
            "Epoch: 48 | Batch: 2044 | Loss: 0.08424300253714515\n",
            "Epoch: 48 | Batch: 2045 | Loss: 0.046233444023651135\n",
            "Epoch: 48 | Batch: 2046 | Loss: 0.05600102691334566\n",
            "Epoch: 48 | Batch: 2047 | Loss: 0.041192513477877266\n",
            "Epoch: 48 | Batch: 2048 | Loss: 0.05134683138812331\n",
            "Epoch: 48 | Batch: 2049 | Loss: 0.07258919701919805\n",
            "Epoch: 48 | Batch: 2050 | Loss: 0.04506640889318346\n",
            "Epoch: 48 | Batch: 2051 | Loss: 0.07325543711820207\n",
            "Epoch: 48 | Batch: 2052 | Loss: 0.03996590507615531\n",
            "Epoch: 48 | Batch: 2053 | Loss: 0.053776097931365306\n",
            "Epoch: 48 | Batch: 2054 | Loss: 0.05881525096530528\n",
            "Epoch: 48 | Batch: 2055 | Loss: 0.05802249756449924\n",
            "Epoch: 48 | Batch: 2056 | Loss: 0.0511761862529148\n",
            "Epoch: 48 | Batch: 2057 | Loss: 0.06722949242770031\n",
            "Epoch: 48 | Batch: 2058 | Loss: 0.0463884999388806\n",
            "Epoch: 48 | Batch: 2059 | Loss: 0.06513417620604496\n",
            "Epoch: 48 | Batch: 2060 | Loss: 0.06707145519271693\n",
            "Epoch: 48 | Batch: 2061 | Loss: 0.07129340932181162\n",
            "Epoch: 48 | Batch: 2062 | Loss: 0.06746501853861642\n",
            "Epoch: 48 | Batch: 2063 | Loss: 0.04999613266173588\n",
            "Epoch: 48 | Batch: 2064 | Loss: 0.04211252779186234\n",
            "Epoch: 48 | Batch: 2065 | Loss: 0.05272357396034072\n",
            "Epoch: 48 | Batch: 2066 | Loss: 0.07527539130843787\n",
            "Epoch: 48 | Batch: 2067 | Loss: 0.04295332608552968\n",
            "Epoch: 48 | Batch: 2068 | Loss: 0.06162398277120445\n",
            "Epoch: 48 | Batch: 2069 | Loss: 0.049802941197953754\n",
            "Epoch: 48 | Batch: 2070 | Loss: 0.07265320116264282\n",
            "Epoch: 48 | Batch: 2071 | Loss: 0.06719096240666596\n",
            "Epoch: 48 | Batch: 2072 | Loss: 0.05358505246856096\n",
            "Epoch: 48 | Batch: 2073 | Loss: 0.04840163625806617\n",
            "Epoch: 48 | Batch: 2074 | Loss: 0.046861071076097924\n",
            "Epoch: 48 | Batch: 2075 | Loss: 0.06551735909944666\n",
            "Epoch: 48 | Batch: 2076 | Loss: 0.05163835851122539\n",
            "Epoch: 48 | Batch: 2077 | Loss: 0.0755094873316488\n",
            "Epoch: 48 | Batch: 2078 | Loss: 0.0464845346757448\n",
            "Epoch: 48 | Batch: 2079 | Loss: 0.06653384094814663\n",
            "Epoch: 48 | Batch: 2080 | Loss: 0.0770740850159494\n",
            "Epoch: 48 | Batch: 2081 | Loss: 0.054152551880828306\n",
            "Epoch: 48 | Batch: 2082 | Loss: 0.06969171075885758\n",
            "Epoch: 48 | Batch: 2083 | Loss: 0.052076321861228306\n",
            "Epoch: 48 | Batch: 2084 | Loss: 0.0475261693464457\n",
            "Epoch: 48 | Batch: 2085 | Loss: 0.058527254105077475\n",
            "Epoch: 48 | Batch: 2086 | Loss: 0.042801755795455455\n",
            "Epoch: 48 | Batch: 2087 | Loss: 0.0530666901397642\n",
            "Epoch: 48 | Batch: 2088 | Loss: 0.07502144824423475\n",
            "Epoch: 48 | Batch: 2089 | Loss: 0.06642617681738446\n",
            "Epoch: 48 | Batch: 2090 | Loss: 0.05796686774450202\n",
            "Epoch: 48 | Batch: 2091 | Loss: 0.050459366639968944\n",
            "Epoch: 48 | Batch: 2092 | Loss: 0.06971105696384289\n",
            "Epoch: 48 | Batch: 2093 | Loss: 0.0345734298553664\n",
            "Epoch: 48 | Batch: 2094 | Loss: 0.05161414042341023\n",
            "Epoch: 48 | Batch: 2095 | Loss: 0.04805591814169547\n",
            "Epoch: 48 | Batch: 2096 | Loss: 0.054002123107304664\n",
            "Epoch: 48 | Batch: 2097 | Loss: 0.04790429486304673\n",
            "Epoch: 48 | Batch: 2098 | Loss: 0.05659806687892133\n",
            "Epoch: 48 | Batch: 2099 | Loss: 0.04128543723327512\n",
            "Epoch: 48 | Batch: 2100 | Loss: 0.04616693288497682\n",
            "Epoch: 48 | Batch: 2101 | Loss: 0.06267512758717497\n",
            "Epoch: 48 | Batch: 2102 | Loss: 0.0374889831326682\n",
            "Epoch: 48 | Batch: 2103 | Loss: 0.05328084993225564\n",
            "Epoch: 48 | Batch: 2104 | Loss: 0.0875668836651017\n",
            "Epoch: 48 | Batch: 2105 | Loss: 0.05680464565434975\n",
            "Epoch: 48 | Batch: 2106 | Loss: 0.05113810794800375\n",
            "Epoch: 48 | Batch: 2107 | Loss: 0.055676413405609644\n",
            "Epoch: 48 | Batch: 2108 | Loss: 0.0698316450502946\n",
            "Epoch: 48 | Batch: 2109 | Loss: 0.03879468688848542\n",
            "Epoch: 48 | Batch: 2110 | Loss: 0.044606724498667365\n",
            "Epoch: 48 | Batch: 2111 | Loss: 0.09280826113073258\n",
            "Epoch: 48 | Batch: 2112 | Loss: 0.0672624845483392\n",
            "Epoch: 48 | Batch: 2113 | Loss: 0.10098891232988252\n",
            "Epoch: 48 | Batch: 2114 | Loss: 0.053997408626306614\n",
            "Epoch: 48 | Batch: 2115 | Loss: 0.04208968636715315\n",
            "Epoch: 48 | Batch: 2116 | Loss: 0.08729471781900713\n",
            "Epoch: 48 | Batch: 2117 | Loss: 0.05616382043792938\n",
            "Epoch: 48 | Batch: 2118 | Loss: 0.0857081999247324\n",
            "Epoch: 48 | Batch: 2119 | Loss: 0.0676755293366211\n",
            "Epoch: 48 | Batch: 2120 | Loss: 0.058011705324066916\n",
            "Epoch: 48 | Batch: 2121 | Loss: 0.051550102172305046\n",
            "Epoch: 48 | Batch: 2122 | Loss: 0.08146512310086296\n",
            "Epoch: 48 | Batch: 2123 | Loss: 0.08051744472916633\n",
            "Epoch: 48 | Batch: 2124 | Loss: 0.05272485621585299\n",
            "Epoch: 48 | Batch: 2125 | Loss: 0.04354402451180628\n",
            "Epoch: 48 | Batch: 2126 | Loss: 0.06393224482378589\n",
            "Epoch: 48 | Batch: 2127 | Loss: 0.06145037885718595\n",
            "Epoch: 48 | Batch: 2128 | Loss: 0.07698970748361113\n",
            "Epoch: 48 | Batch: 2129 | Loss: 0.06576407928354679\n",
            "Epoch: 48 | Batch: 2130 | Loss: 0.09985637258431021\n",
            "Epoch: 48 | Batch: 2131 | Loss: 0.05712191264607609\n",
            "Epoch: 48 | Batch: 2132 | Loss: 0.07364559039834288\n",
            "Epoch: 48 | Batch: 2133 | Loss: 0.0664086974032437\n",
            "Epoch: 48 | Batch: 2134 | Loss: 0.06436434261006593\n",
            "Epoch: 48 | Batch: 2135 | Loss: 0.06845534306617013\n",
            "Epoch: 48 | Batch: 2136 | Loss: 0.05931840008184197\n",
            "Epoch: 48 | Batch: 2137 | Loss: 0.09939522204712573\n",
            "Epoch: 48 | Batch: 2138 | Loss: 0.04609900948885819\n",
            "Epoch: 48 | Batch: 2139 | Loss: 0.06075358425247766\n",
            "Epoch: 48 | Batch: 2140 | Loss: 0.05576838708687605\n",
            "Epoch: 48 | Batch: 2141 | Loss: 0.0828440525893629\n",
            "Epoch: 48 | Batch: 2142 | Loss: 0.09243950847466412\n",
            "Epoch: 48 | Batch: 2143 | Loss: 0.05937260137039307\n",
            "Epoch: 48 | Batch: 2144 | Loss: 0.051528826372227415\n",
            "Epoch: 48 | Batch: 2145 | Loss: 0.06321171722816733\n",
            "Epoch: 48 | Batch: 2146 | Loss: 0.052678616125884675\n",
            "Epoch: 48 | Batch: 2147 | Loss: 0.0622798129970286\n",
            "Epoch: 48 | Batch: 2148 | Loss: 0.05498268224018193\n",
            "Epoch: 48 | Batch: 2149 | Loss: 0.04575509660429468\n",
            "Epoch: 48 | Batch: 2150 | Loss: 0.030499616118900792\n",
            "Epoch: 48 | Batch: 2151 | Loss: 0.06626196621413\n",
            "Epoch: 48 | Batch: 2152 | Loss: 0.043003349797401565\n",
            "Epoch: 48 | Batch: 2153 | Loss: 0.05084309500835106\n",
            "Epoch: 48 | Batch: 2154 | Loss: 0.050218727060577846\n",
            "Epoch: 48 | Batch: 2155 | Loss: 0.050752684543413695\n",
            "Epoch: 48 | Batch: 2156 | Loss: 0.0585057054493926\n",
            "Epoch: 48 | Batch: 2157 | Loss: 0.06270675349869188\n",
            "Epoch: 48 | Batch: 2158 | Loss: 0.0636022637446413\n",
            "Epoch: 48 | Batch: 2159 | Loss: 0.04291082756090277\n",
            "Epoch: 48 | Batch: 2160 | Loss: 0.09792844736461026\n",
            "Epoch: 48 | Batch: 2161 | Loss: 0.1420222651325576\n",
            "Epoch: 48 | Batch: 2162 | Loss: 0.03921500519535731\n",
            "Epoch: 48 | Batch: 2163 | Loss: 0.06639317764922967\n",
            "Epoch: 48 | Batch: 2164 | Loss: 0.10737475191580362\n",
            "Epoch: 48 | Batch: 2165 | Loss: 0.06308698534798933\n",
            "Epoch: 48 | Batch: 2166 | Loss: 0.08111042524516622\n",
            "Epoch: 48 | Batch: 2167 | Loss: 0.039466656333760036\n",
            "Epoch: 48 | Batch: 2168 | Loss: 0.06557067752507746\n",
            "Epoch: 48 | Batch: 2169 | Loss: 0.05736645906332995\n",
            "Epoch: 48 | Batch: 2170 | Loss: 0.06654910594361345\n",
            "Epoch: 48 | Batch: 2171 | Loss: 0.06644309890568005\n",
            "Epoch: 48 | Batch: 2172 | Loss: 0.05272039487895819\n",
            "Epoch: 48 | Batch: 2173 | Loss: 0.046394887088392026\n",
            "Epoch: 48 | Batch: 2174 | Loss: 0.06360240500937897\n",
            "Epoch: 48 | Batch: 2175 | Loss: 0.04465617021084464\n",
            "Epoch: 48 | Batch: 2176 | Loss: 0.06362436757260484\n",
            "Epoch: 48 | Batch: 2177 | Loss: 0.11275781446729835\n",
            "Epoch: 48 | Batch: 2178 | Loss: 0.06831658108463737\n",
            "Epoch: 48 | Batch: 2179 | Loss: 0.06774801073274223\n",
            "Epoch: 48 | Batch: 2180 | Loss: 0.042408851300805114\n",
            "Epoch: 48 | Batch: 2181 | Loss: 0.05922814475897026\n",
            "Epoch: 48 | Batch: 2182 | Loss: 0.05621452644314922\n",
            "Epoch: 48 | Batch: 2183 | Loss: 0.03787491079451727\n",
            "Epoch: 48 | Batch: 2184 | Loss: 0.05864020216073894\n",
            "Epoch: 48 | Batch: 2185 | Loss: 0.050100464031681224\n",
            "Epoch: 48 | Batch: 2186 | Loss: 0.036179485430048064\n",
            "Epoch: 48 | Batch: 2187 | Loss: 0.07843065194443206\n",
            "Epoch: 48 | Batch: 2188 | Loss: 0.08911803013748568\n",
            "Epoch: 48 | Batch: 2189 | Loss: 0.06090658847641227\n",
            "Epoch: 48 | Batch: 2190 | Loss: 0.043824218052690656\n",
            "Epoch: 48 | Batch: 2191 | Loss: 0.13535583641876822\n",
            "Epoch: 49 | Batch: 1 | Loss: 0.06421785403201394\n",
            "Epoch: 49 | Batch: 2 | Loss: 0.04319244612353225\n",
            "Epoch: 49 | Batch: 3 | Loss: 0.0980194887865903\n",
            "Epoch: 49 | Batch: 4 | Loss: 0.06884251751577332\n",
            "Epoch: 49 | Batch: 5 | Loss: 0.09798852451373115\n",
            "Epoch: 49 | Batch: 6 | Loss: 0.10780664593349909\n",
            "Epoch: 49 | Batch: 7 | Loss: 0.07078076678211567\n",
            "Epoch: 49 | Batch: 8 | Loss: 0.09104246993120245\n",
            "Epoch: 49 | Batch: 9 | Loss: 0.06492348828918416\n",
            "Epoch: 49 | Batch: 10 | Loss: 0.03559668729374827\n",
            "Epoch: 49 | Batch: 11 | Loss: 0.042459475673390146\n",
            "Epoch: 49 | Batch: 12 | Loss: 0.06760209818907487\n",
            "Epoch: 49 | Batch: 13 | Loss: 0.07437380457033486\n",
            "Epoch: 49 | Batch: 14 | Loss: 0.036346995711435785\n",
            "Epoch: 49 | Batch: 15 | Loss: 0.06716693753883533\n",
            "Epoch: 49 | Batch: 16 | Loss: 0.05951350911948913\n",
            "Epoch: 49 | Batch: 17 | Loss: 0.051784643093268315\n",
            "Epoch: 49 | Batch: 18 | Loss: 0.07974094161781356\n",
            "Epoch: 49 | Batch: 19 | Loss: 0.06230112101787232\n",
            "Epoch: 49 | Batch: 20 | Loss: 0.049143626716164936\n",
            "Epoch: 49 | Batch: 21 | Loss: 0.05472470627702156\n",
            "Epoch: 49 | Batch: 22 | Loss: 0.049604381365241076\n",
            "Epoch: 49 | Batch: 23 | Loss: 0.07301899536559689\n",
            "Epoch: 49 | Batch: 24 | Loss: 0.040362218773021305\n",
            "Epoch: 49 | Batch: 25 | Loss: 0.074915338426039\n",
            "Epoch: 49 | Batch: 26 | Loss: 0.04465807985015202\n",
            "Epoch: 49 | Batch: 27 | Loss: 0.06672011232371486\n",
            "Epoch: 49 | Batch: 28 | Loss: 0.04695921410614368\n",
            "Epoch: 49 | Batch: 29 | Loss: 0.05794252152874449\n",
            "Epoch: 49 | Batch: 30 | Loss: 0.047364355706782844\n",
            "Epoch: 49 | Batch: 31 | Loss: 0.05944321373889465\n",
            "Epoch: 49 | Batch: 32 | Loss: 0.07016046450375532\n",
            "Epoch: 49 | Batch: 33 | Loss: 0.06798930662093712\n",
            "Epoch: 49 | Batch: 34 | Loss: 0.06323869527884132\n",
            "Epoch: 49 | Batch: 35 | Loss: 0.03987379265056414\n",
            "Epoch: 49 | Batch: 36 | Loss: 0.04574809774996674\n",
            "Epoch: 49 | Batch: 37 | Loss: 0.050000936407300856\n",
            "Epoch: 49 | Batch: 38 | Loss: 0.0570845558868455\n",
            "Epoch: 49 | Batch: 39 | Loss: 0.06037217057639965\n",
            "Epoch: 49 | Batch: 40 | Loss: 0.0769003552809876\n",
            "Epoch: 49 | Batch: 41 | Loss: 0.07989133692715991\n",
            "Epoch: 49 | Batch: 42 | Loss: 0.0473781272924135\n",
            "Epoch: 49 | Batch: 43 | Loss: 0.11937980020625874\n",
            "Epoch: 49 | Batch: 44 | Loss: 0.05102518518604986\n",
            "Epoch: 49 | Batch: 45 | Loss: 0.04461538458485327\n",
            "Epoch: 49 | Batch: 46 | Loss: 0.06459870625391124\n",
            "Epoch: 49 | Batch: 47 | Loss: 0.05565522490703041\n",
            "Epoch: 49 | Batch: 48 | Loss: 0.06334291031097851\n",
            "Epoch: 49 | Batch: 49 | Loss: 0.08836690702729551\n",
            "Epoch: 49 | Batch: 50 | Loss: 0.054447990782173175\n",
            "Epoch: 49 | Batch: 51 | Loss: 0.056406966618421185\n",
            "Epoch: 49 | Batch: 52 | Loss: 0.03965554610646532\n",
            "Epoch: 49 | Batch: 53 | Loss: 0.05457603977149444\n",
            "Epoch: 49 | Batch: 54 | Loss: 0.056420938316348083\n",
            "Epoch: 49 | Batch: 55 | Loss: 0.06433863144239955\n",
            "Epoch: 49 | Batch: 56 | Loss: 0.049259722645306994\n",
            "Epoch: 49 | Batch: 57 | Loss: 0.0716919139317717\n",
            "Epoch: 49 | Batch: 58 | Loss: 0.06008694410114247\n",
            "Epoch: 49 | Batch: 59 | Loss: 0.06389493478874657\n",
            "Epoch: 49 | Batch: 60 | Loss: 0.03152666376547218\n",
            "Epoch: 49 | Batch: 61 | Loss: 0.06218851989889955\n",
            "Epoch: 49 | Batch: 62 | Loss: 0.0392935037380991\n",
            "Epoch: 49 | Batch: 63 | Loss: 0.05745399030133955\n",
            "Epoch: 49 | Batch: 64 | Loss: 0.0386143524700351\n",
            "Epoch: 49 | Batch: 65 | Loss: 0.04245255735257146\n",
            "Epoch: 49 | Batch: 66 | Loss: 0.07928756895694979\n",
            "Epoch: 49 | Batch: 67 | Loss: 0.04849954875811194\n",
            "Epoch: 49 | Batch: 68 | Loss: 0.08037821222794259\n",
            "Epoch: 49 | Batch: 69 | Loss: 0.05704365424184963\n",
            "Epoch: 49 | Batch: 70 | Loss: 0.0580414865343604\n",
            "Epoch: 49 | Batch: 71 | Loss: 0.04291957972600842\n",
            "Epoch: 49 | Batch: 72 | Loss: 0.044309797080415186\n",
            "Epoch: 49 | Batch: 73 | Loss: 0.054009034899152465\n",
            "Epoch: 49 | Batch: 74 | Loss: 0.054828371497590116\n",
            "Epoch: 49 | Batch: 75 | Loss: 0.07377945352323005\n",
            "Epoch: 49 | Batch: 76 | Loss: 0.06664164959034595\n",
            "Epoch: 49 | Batch: 77 | Loss: 0.052794675595515796\n",
            "Epoch: 49 | Batch: 78 | Loss: 0.07511627966909992\n",
            "Epoch: 49 | Batch: 79 | Loss: 0.035089598377591416\n",
            "Epoch: 49 | Batch: 80 | Loss: 0.045328870128957977\n",
            "Epoch: 49 | Batch: 81 | Loss: 0.03391109607711258\n",
            "Epoch: 49 | Batch: 82 | Loss: 0.06364984723288997\n",
            "Epoch: 49 | Batch: 83 | Loss: 0.05307498419984965\n",
            "Epoch: 49 | Batch: 84 | Loss: 0.06999681688706\n",
            "Epoch: 49 | Batch: 85 | Loss: 0.08301875697559279\n",
            "Epoch: 49 | Batch: 86 | Loss: 0.04745043243606495\n",
            "Epoch: 49 | Batch: 87 | Loss: 0.051916861247398104\n",
            "Epoch: 49 | Batch: 88 | Loss: 0.039858466980142664\n",
            "Epoch: 49 | Batch: 89 | Loss: 0.045914973016703706\n",
            "Epoch: 49 | Batch: 90 | Loss: 0.06642350132883643\n",
            "Epoch: 49 | Batch: 91 | Loss: 0.06481668595022184\n",
            "Epoch: 49 | Batch: 92 | Loss: 0.0675071269995879\n",
            "Epoch: 49 | Batch: 93 | Loss: 0.04918001310055984\n",
            "Epoch: 49 | Batch: 94 | Loss: 0.04310075805129347\n",
            "Epoch: 49 | Batch: 95 | Loss: 0.0652541779869535\n",
            "Epoch: 49 | Batch: 96 | Loss: 0.04642599347935471\n",
            "Epoch: 49 | Batch: 97 | Loss: 0.03966981519283666\n",
            "Epoch: 49 | Batch: 98 | Loss: 0.06278965355515165\n",
            "Epoch: 49 | Batch: 99 | Loss: 0.07258587263938919\n",
            "Epoch: 49 | Batch: 100 | Loss: 0.0629276939103709\n",
            "Epoch: 49 | Batch: 101 | Loss: 0.05357953770193464\n",
            "Epoch: 49 | Batch: 102 | Loss: 0.07412677167316314\n",
            "Epoch: 49 | Batch: 103 | Loss: 0.061732292553409035\n",
            "Epoch: 49 | Batch: 104 | Loss: 0.044611787047468335\n",
            "Epoch: 49 | Batch: 105 | Loss: 0.07054001820889763\n",
            "Epoch: 49 | Batch: 106 | Loss: 0.0694470843086834\n",
            "Epoch: 49 | Batch: 107 | Loss: 0.04939808643333183\n",
            "Epoch: 49 | Batch: 108 | Loss: 0.06754993548415655\n",
            "Epoch: 49 | Batch: 109 | Loss: 0.04953195114013717\n",
            "Epoch: 49 | Batch: 110 | Loss: 0.04727035129731649\n",
            "Epoch: 49 | Batch: 111 | Loss: 0.06585031474991264\n",
            "Epoch: 49 | Batch: 112 | Loss: 0.0482470883064808\n",
            "Epoch: 49 | Batch: 113 | Loss: 0.04278995421456243\n",
            "Epoch: 49 | Batch: 114 | Loss: 0.05192868628286114\n",
            "Epoch: 49 | Batch: 115 | Loss: 0.07270539104875882\n",
            "Epoch: 49 | Batch: 116 | Loss: 0.048319356215342585\n",
            "Epoch: 49 | Batch: 117 | Loss: 0.08266465303307814\n",
            "Epoch: 49 | Batch: 118 | Loss: 0.04384448598257149\n",
            "Epoch: 49 | Batch: 119 | Loss: 0.04015489538260681\n",
            "Epoch: 49 | Batch: 120 | Loss: 0.07185224560991962\n",
            "Epoch: 49 | Batch: 121 | Loss: 0.061988403777760305\n",
            "Epoch: 49 | Batch: 122 | Loss: 0.043810819943115295\n",
            "Epoch: 49 | Batch: 123 | Loss: 0.0447828214678045\n",
            "Epoch: 49 | Batch: 124 | Loss: 0.05373358257529065\n",
            "Epoch: 49 | Batch: 125 | Loss: 0.050584082786769\n",
            "Epoch: 49 | Batch: 126 | Loss: 0.10275898795518851\n",
            "Epoch: 49 | Batch: 127 | Loss: 0.07101742645478556\n",
            "Epoch: 49 | Batch: 128 | Loss: 0.05545546182725\n",
            "Epoch: 49 | Batch: 129 | Loss: 0.04109894903890878\n",
            "Epoch: 49 | Batch: 130 | Loss: 0.05457093599917991\n",
            "Epoch: 49 | Batch: 131 | Loss: 0.11407882988873227\n",
            "Epoch: 49 | Batch: 132 | Loss: 0.069448178860579\n",
            "Epoch: 49 | Batch: 133 | Loss: 0.05556565355684981\n",
            "Epoch: 49 | Batch: 134 | Loss: 0.040772704349965286\n",
            "Epoch: 49 | Batch: 135 | Loss: 0.04684574142853935\n",
            "Epoch: 49 | Batch: 136 | Loss: 0.046240563591756365\n",
            "Epoch: 49 | Batch: 137 | Loss: 0.044280196178363915\n",
            "Epoch: 49 | Batch: 138 | Loss: 0.06496885480671634\n",
            "Epoch: 49 | Batch: 139 | Loss: 0.05443556030799942\n",
            "Epoch: 49 | Batch: 140 | Loss: 0.05160641452919735\n",
            "Epoch: 49 | Batch: 141 | Loss: 0.043130839987456926\n",
            "Epoch: 49 | Batch: 142 | Loss: 0.07704037572583804\n",
            "Epoch: 49 | Batch: 143 | Loss: 0.054081973199853\n",
            "Epoch: 49 | Batch: 144 | Loss: 0.04096611934536072\n",
            "Epoch: 49 | Batch: 145 | Loss: 0.0798740267008456\n",
            "Epoch: 49 | Batch: 146 | Loss: 0.04125737695587552\n",
            "Epoch: 49 | Batch: 147 | Loss: 0.06205186838889941\n",
            "Epoch: 49 | Batch: 148 | Loss: 0.09436166704181485\n",
            "Epoch: 49 | Batch: 149 | Loss: 0.05775740285401551\n",
            "Epoch: 49 | Batch: 150 | Loss: 0.051449746366194954\n",
            "Epoch: 49 | Batch: 151 | Loss: 0.05021352865538424\n",
            "Epoch: 49 | Batch: 152 | Loss: 0.050702608786862655\n",
            "Epoch: 49 | Batch: 153 | Loss: 0.04852978989332028\n",
            "Epoch: 49 | Batch: 154 | Loss: 0.05102317189401275\n",
            "Epoch: 49 | Batch: 155 | Loss: 0.07083281719471415\n",
            "Epoch: 49 | Batch: 156 | Loss: 0.07221491618349711\n",
            "Epoch: 49 | Batch: 157 | Loss: 0.07072138876002802\n",
            "Epoch: 49 | Batch: 158 | Loss: 0.06554021180840269\n",
            "Epoch: 49 | Batch: 159 | Loss: 0.05133698508210449\n",
            "Epoch: 49 | Batch: 160 | Loss: 0.07481732021490797\n",
            "Epoch: 49 | Batch: 161 | Loss: 0.07829656740565355\n",
            "Epoch: 49 | Batch: 162 | Loss: 0.08651601153190377\n",
            "Epoch: 49 | Batch: 163 | Loss: 0.06709837799020275\n",
            "Epoch: 49 | Batch: 164 | Loss: 0.05696789734920166\n",
            "Epoch: 49 | Batch: 165 | Loss: 0.07039969955895627\n",
            "Epoch: 49 | Batch: 166 | Loss: 0.04994142834494991\n",
            "Epoch: 49 | Batch: 167 | Loss: 0.05031885750830037\n",
            "Epoch: 49 | Batch: 168 | Loss: 0.04978055928856128\n",
            "Epoch: 49 | Batch: 169 | Loss: 0.05373875644604342\n",
            "Epoch: 49 | Batch: 170 | Loss: 0.058675887971910576\n",
            "Epoch: 49 | Batch: 171 | Loss: 0.07974387476462742\n",
            "Epoch: 49 | Batch: 172 | Loss: 0.06892490856427272\n",
            "Epoch: 49 | Batch: 173 | Loss: 0.0548106334942421\n",
            "Epoch: 49 | Batch: 174 | Loss: 0.054540311384614945\n",
            "Epoch: 49 | Batch: 175 | Loss: 0.1076159058137548\n",
            "Epoch: 49 | Batch: 176 | Loss: 0.04026305486965471\n",
            "Epoch: 49 | Batch: 177 | Loss: 0.04318148102684166\n",
            "Epoch: 49 | Batch: 178 | Loss: 0.0531062235888595\n",
            "Epoch: 49 | Batch: 179 | Loss: 0.06626061427465602\n",
            "Epoch: 49 | Batch: 180 | Loss: 0.04905765645466442\n",
            "Epoch: 49 | Batch: 181 | Loss: 0.060400582066547456\n",
            "Epoch: 49 | Batch: 182 | Loss: 0.07155636261548683\n",
            "Epoch: 49 | Batch: 183 | Loss: 0.04230454011515509\n",
            "Epoch: 49 | Batch: 184 | Loss: 0.04341448634845481\n",
            "Epoch: 49 | Batch: 185 | Loss: 0.06820913001974821\n",
            "Epoch: 49 | Batch: 186 | Loss: 0.08054874335812073\n",
            "Epoch: 49 | Batch: 187 | Loss: 0.11919607618381503\n",
            "Epoch: 49 | Batch: 188 | Loss: 0.07037272273184238\n",
            "Epoch: 49 | Batch: 189 | Loss: 0.05053153700170927\n",
            "Epoch: 49 | Batch: 190 | Loss: 0.05690656020665984\n",
            "Epoch: 49 | Batch: 191 | Loss: 0.05901872693112059\n",
            "Epoch: 49 | Batch: 192 | Loss: 0.04642125984190954\n",
            "Epoch: 49 | Batch: 193 | Loss: 0.0525474778795989\n",
            "Epoch: 49 | Batch: 194 | Loss: 0.045507804060680446\n",
            "Epoch: 49 | Batch: 195 | Loss: 0.07568635210172758\n",
            "Epoch: 49 | Batch: 196 | Loss: 0.05544445009143702\n",
            "Epoch: 49 | Batch: 197 | Loss: 0.04912229078218337\n",
            "Epoch: 49 | Batch: 198 | Loss: 0.0779341398657543\n",
            "Epoch: 49 | Batch: 199 | Loss: 0.08924833942937284\n",
            "Epoch: 49 | Batch: 200 | Loss: 0.12433148678255318\n",
            "Epoch: 49 | Batch: 201 | Loss: 0.05907131279379111\n",
            "Epoch: 49 | Batch: 202 | Loss: 0.047735969703635944\n",
            "Epoch: 49 | Batch: 203 | Loss: 0.06341471345978278\n",
            "Epoch: 49 | Batch: 204 | Loss: 0.04932610149903801\n",
            "Epoch: 49 | Batch: 205 | Loss: 0.0859746175701222\n",
            "Epoch: 49 | Batch: 206 | Loss: 0.044293120476704986\n",
            "Epoch: 49 | Batch: 207 | Loss: 0.057671563101315854\n",
            "Epoch: 49 | Batch: 208 | Loss: 0.07437999940852609\n",
            "Epoch: 49 | Batch: 209 | Loss: 0.09741320274565637\n",
            "Epoch: 49 | Batch: 210 | Loss: 0.08985431399233194\n",
            "Epoch: 49 | Batch: 211 | Loss: 0.07874745258771254\n",
            "Epoch: 49 | Batch: 212 | Loss: 0.08019414368689287\n",
            "Epoch: 49 | Batch: 213 | Loss: 0.052051179134883004\n",
            "Epoch: 49 | Batch: 214 | Loss: 0.05256900701722811\n",
            "Epoch: 49 | Batch: 215 | Loss: 0.08872985582952314\n",
            "Epoch: 49 | Batch: 216 | Loss: 0.051411634642620954\n",
            "Epoch: 49 | Batch: 217 | Loss: 0.039593462029895804\n",
            "Epoch: 49 | Batch: 218 | Loss: 0.0597869909399449\n",
            "Epoch: 49 | Batch: 219 | Loss: 0.07377169030054316\n",
            "Epoch: 49 | Batch: 220 | Loss: 0.036458982930529904\n",
            "Epoch: 49 | Batch: 221 | Loss: 0.054664151711806164\n",
            "Epoch: 49 | Batch: 222 | Loss: 0.07518614944132658\n",
            "Epoch: 49 | Batch: 223 | Loss: 0.04818919052969396\n",
            "Epoch: 49 | Batch: 224 | Loss: 0.08675316636376848\n",
            "Epoch: 49 | Batch: 225 | Loss: 0.03997047858360213\n",
            "Epoch: 49 | Batch: 226 | Loss: 0.049462300161767586\n",
            "Epoch: 49 | Batch: 227 | Loss: 0.037427379765232194\n",
            "Epoch: 49 | Batch: 228 | Loss: 0.03449500052903083\n",
            "Epoch: 49 | Batch: 229 | Loss: 0.04041646765463712\n",
            "Epoch: 49 | Batch: 230 | Loss: 0.03375036438746633\n",
            "Epoch: 49 | Batch: 231 | Loss: 0.06862678561023759\n",
            "Epoch: 49 | Batch: 232 | Loss: 0.0612032440254248\n",
            "Epoch: 49 | Batch: 233 | Loss: 0.03808320951478488\n",
            "Epoch: 49 | Batch: 234 | Loss: 0.0444110068699606\n",
            "Epoch: 49 | Batch: 235 | Loss: 0.08726992676707804\n",
            "Epoch: 49 | Batch: 236 | Loss: 0.03357176826901215\n",
            "Epoch: 49 | Batch: 237 | Loss: 0.04893549111316451\n",
            "Epoch: 49 | Batch: 238 | Loss: 0.04676953877109449\n",
            "Epoch: 49 | Batch: 239 | Loss: 0.06390914359881565\n",
            "Epoch: 49 | Batch: 240 | Loss: 0.07409177617652313\n",
            "Epoch: 49 | Batch: 241 | Loss: 0.054220106908832014\n",
            "Epoch: 49 | Batch: 242 | Loss: 0.04537506877901222\n",
            "Epoch: 49 | Batch: 243 | Loss: 0.08794343171999217\n",
            "Epoch: 49 | Batch: 244 | Loss: 0.06875454151676116\n",
            "Epoch: 49 | Batch: 245 | Loss: 0.054242691682029706\n",
            "Epoch: 49 | Batch: 246 | Loss: 0.052625259279304365\n",
            "Epoch: 49 | Batch: 247 | Loss: 0.04719615969609279\n",
            "Epoch: 49 | Batch: 248 | Loss: 0.06729188057246258\n",
            "Epoch: 49 | Batch: 249 | Loss: 0.05127541351260518\n",
            "Epoch: 49 | Batch: 250 | Loss: 0.08019236546553934\n",
            "Epoch: 49 | Batch: 251 | Loss: 0.07574173301096333\n",
            "Epoch: 49 | Batch: 252 | Loss: 0.054947407243527216\n",
            "Epoch: 49 | Batch: 253 | Loss: 0.06847898804406087\n",
            "Epoch: 49 | Batch: 254 | Loss: 0.0496904873963299\n",
            "Epoch: 49 | Batch: 255 | Loss: 0.07214082367688374\n",
            "Epoch: 49 | Batch: 256 | Loss: 0.051978046670141664\n",
            "Epoch: 49 | Batch: 257 | Loss: 0.07337351810831068\n",
            "Epoch: 49 | Batch: 258 | Loss: 0.07223299757738827\n",
            "Epoch: 49 | Batch: 259 | Loss: 0.04959419640687704\n",
            "Epoch: 49 | Batch: 260 | Loss: 0.03232615675498293\n",
            "Epoch: 49 | Batch: 261 | Loss: 0.07284130011653829\n",
            "Epoch: 49 | Batch: 262 | Loss: 0.08825749916153516\n",
            "Epoch: 49 | Batch: 263 | Loss: 0.042975068778335415\n",
            "Epoch: 49 | Batch: 264 | Loss: 0.0439378728124033\n",
            "Epoch: 49 | Batch: 265 | Loss: 0.04022792465856709\n",
            "Epoch: 49 | Batch: 266 | Loss: 0.04071615472077282\n",
            "Epoch: 49 | Batch: 267 | Loss: 0.04863544578630344\n",
            "Epoch: 49 | Batch: 268 | Loss: 0.10881495384136528\n",
            "Epoch: 49 | Batch: 269 | Loss: 0.0382302570974451\n",
            "Epoch: 49 | Batch: 270 | Loss: 0.07437296264628762\n",
            "Epoch: 49 | Batch: 271 | Loss: 0.0692877555739797\n",
            "Epoch: 49 | Batch: 272 | Loss: 0.07748767079652782\n",
            "Epoch: 49 | Batch: 273 | Loss: 0.10263683695077491\n",
            "Epoch: 49 | Batch: 274 | Loss: 0.04523576053635651\n",
            "Epoch: 49 | Batch: 275 | Loss: 0.05860240289896611\n",
            "Epoch: 49 | Batch: 276 | Loss: 0.05601486356806435\n",
            "Epoch: 49 | Batch: 277 | Loss: 0.10386898345825515\n",
            "Epoch: 49 | Batch: 278 | Loss: 0.05996437670084616\n",
            "Epoch: 49 | Batch: 279 | Loss: 0.06957923606286925\n",
            "Epoch: 49 | Batch: 280 | Loss: 0.06277324352601196\n",
            "Epoch: 49 | Batch: 281 | Loss: 0.12533952486865121\n",
            "Epoch: 49 | Batch: 282 | Loss: 0.03291195180658613\n",
            "Epoch: 49 | Batch: 283 | Loss: 0.09076610393720799\n",
            "Epoch: 49 | Batch: 284 | Loss: 0.07264564885179967\n",
            "Epoch: 49 | Batch: 285 | Loss: 0.052184887639346283\n",
            "Epoch: 49 | Batch: 286 | Loss: 0.06555696269227661\n",
            "Epoch: 49 | Batch: 287 | Loss: 0.07125191684076979\n",
            "Epoch: 49 | Batch: 288 | Loss: 0.07468982531579761\n",
            "Epoch: 49 | Batch: 289 | Loss: 0.07732690522465618\n",
            "Epoch: 49 | Batch: 290 | Loss: 0.043377235113759294\n",
            "Epoch: 49 | Batch: 291 | Loss: 0.06380996614389174\n",
            "Epoch: 49 | Batch: 292 | Loss: 0.05363296190618195\n",
            "Epoch: 49 | Batch: 293 | Loss: 0.051510302162588555\n",
            "Epoch: 49 | Batch: 294 | Loss: 0.06902942069254556\n",
            "Epoch: 49 | Batch: 295 | Loss: 0.0735039421210014\n",
            "Epoch: 49 | Batch: 296 | Loss: 0.04258790201008608\n",
            "Epoch: 49 | Batch: 297 | Loss: 0.043251420522131656\n",
            "Epoch: 49 | Batch: 298 | Loss: 0.044985119519936625\n",
            "Epoch: 49 | Batch: 299 | Loss: 0.070304085927371\n",
            "Epoch: 49 | Batch: 300 | Loss: 0.0759054703417242\n",
            "Epoch: 49 | Batch: 301 | Loss: 0.04841484096448535\n",
            "Epoch: 49 | Batch: 302 | Loss: 0.052174786277321444\n",
            "Epoch: 49 | Batch: 303 | Loss: 0.047397238124927715\n",
            "Epoch: 49 | Batch: 304 | Loss: 0.07959306199050153\n",
            "Epoch: 49 | Batch: 305 | Loss: 0.06593648039287366\n",
            "Epoch: 49 | Batch: 306 | Loss: 0.0838060488220684\n",
            "Epoch: 49 | Batch: 307 | Loss: 0.11721775483472895\n",
            "Epoch: 49 | Batch: 308 | Loss: 0.08302544902104386\n",
            "Epoch: 49 | Batch: 309 | Loss: 0.06375724115330066\n",
            "Epoch: 49 | Batch: 310 | Loss: 0.05869198740626842\n",
            "Epoch: 49 | Batch: 311 | Loss: 0.05727627156820493\n",
            "Epoch: 49 | Batch: 312 | Loss: 0.05215898692602072\n",
            "Epoch: 49 | Batch: 313 | Loss: 0.09900806944279762\n",
            "Epoch: 49 | Batch: 314 | Loss: 0.04716700388881208\n",
            "Epoch: 49 | Batch: 315 | Loss: 0.051035424020284145\n",
            "Epoch: 49 | Batch: 316 | Loss: 0.05909022490978175\n",
            "Epoch: 49 | Batch: 317 | Loss: 0.04975554009837528\n",
            "Epoch: 49 | Batch: 318 | Loss: 0.06404136679492671\n",
            "Epoch: 49 | Batch: 319 | Loss: 0.047413266188245436\n",
            "Epoch: 49 | Batch: 320 | Loss: 0.07145631279941965\n",
            "Epoch: 49 | Batch: 321 | Loss: 0.06288964947150516\n",
            "Epoch: 49 | Batch: 322 | Loss: 0.0907996382620744\n",
            "Epoch: 49 | Batch: 323 | Loss: 0.03411393050162148\n",
            "Epoch: 49 | Batch: 324 | Loss: 0.052907759061478696\n",
            "Epoch: 49 | Batch: 325 | Loss: 0.06485550349039164\n",
            "Epoch: 49 | Batch: 326 | Loss: 0.06807173718688073\n",
            "Epoch: 49 | Batch: 327 | Loss: 0.07753327414055579\n",
            "Epoch: 49 | Batch: 328 | Loss: 0.05775459635949481\n",
            "Epoch: 49 | Batch: 329 | Loss: 0.12151612010923482\n",
            "Epoch: 49 | Batch: 330 | Loss: 0.13824344550702417\n",
            "Epoch: 49 | Batch: 331 | Loss: 0.08465980198790642\n",
            "Epoch: 49 | Batch: 332 | Loss: 0.060140469664346746\n",
            "Epoch: 49 | Batch: 333 | Loss: 0.06813779434665376\n",
            "Epoch: 49 | Batch: 334 | Loss: 0.08038174823089\n",
            "Epoch: 49 | Batch: 335 | Loss: 0.11271319785075991\n",
            "Epoch: 49 | Batch: 336 | Loss: 0.06589405299225225\n",
            "Epoch: 49 | Batch: 337 | Loss: 0.06165854382013741\n",
            "Epoch: 49 | Batch: 338 | Loss: 0.06102537052367596\n",
            "Epoch: 49 | Batch: 339 | Loss: 0.0846085539020958\n",
            "Epoch: 49 | Batch: 340 | Loss: 0.04882192564994648\n",
            "Epoch: 49 | Batch: 341 | Loss: 0.06287533708873011\n",
            "Epoch: 49 | Batch: 342 | Loss: 0.06782508399840206\n",
            "Epoch: 49 | Batch: 343 | Loss: 0.05290836971442428\n",
            "Epoch: 49 | Batch: 344 | Loss: 0.0585867744259765\n",
            "Epoch: 49 | Batch: 345 | Loss: 0.08145846854726004\n",
            "Epoch: 49 | Batch: 346 | Loss: 0.05518610418433132\n",
            "Epoch: 49 | Batch: 347 | Loss: 0.07111806623072259\n",
            "Epoch: 49 | Batch: 348 | Loss: 0.05372360779934636\n",
            "Epoch: 49 | Batch: 349 | Loss: 0.05939796003010483\n",
            "Epoch: 49 | Batch: 350 | Loss: 0.08365381408350604\n",
            "Epoch: 49 | Batch: 351 | Loss: 0.04708913509336284\n",
            "Epoch: 49 | Batch: 352 | Loss: 0.05867689055980051\n",
            "Epoch: 49 | Batch: 353 | Loss: 0.04784342117995059\n",
            "Epoch: 49 | Batch: 354 | Loss: 0.05849322576394891\n",
            "Epoch: 49 | Batch: 355 | Loss: 0.058167427470860567\n",
            "Epoch: 49 | Batch: 356 | Loss: 0.06250557480826156\n",
            "Epoch: 49 | Batch: 357 | Loss: 0.08472561009803527\n",
            "Epoch: 49 | Batch: 358 | Loss: 0.052631586965799906\n",
            "Epoch: 49 | Batch: 359 | Loss: 0.036034835017713554\n",
            "Epoch: 49 | Batch: 360 | Loss: 0.06685998318789987\n",
            "Epoch: 49 | Batch: 361 | Loss: 0.09152713136598828\n",
            "Epoch: 49 | Batch: 362 | Loss: 0.05916312734702542\n",
            "Epoch: 49 | Batch: 363 | Loss: 0.04228270613891435\n",
            "Epoch: 49 | Batch: 364 | Loss: 0.05820251231962863\n",
            "Epoch: 49 | Batch: 365 | Loss: 0.04301335481430316\n",
            "Epoch: 49 | Batch: 366 | Loss: 0.10422746882881626\n",
            "Epoch: 49 | Batch: 367 | Loss: 0.053951259113658584\n",
            "Epoch: 49 | Batch: 368 | Loss: 0.04996400962550167\n",
            "Epoch: 49 | Batch: 369 | Loss: 0.048695651916494186\n",
            "Epoch: 49 | Batch: 370 | Loss: 0.06149623864999626\n",
            "Epoch: 49 | Batch: 371 | Loss: 0.04837981024621063\n",
            "Epoch: 49 | Batch: 372 | Loss: 0.0535921419840828\n",
            "Epoch: 49 | Batch: 373 | Loss: 0.041741840718149806\n",
            "Epoch: 49 | Batch: 374 | Loss: 0.03731707779501646\n",
            "Epoch: 49 | Batch: 375 | Loss: 0.04449951725589826\n",
            "Epoch: 49 | Batch: 376 | Loss: 0.04496598220588023\n",
            "Epoch: 49 | Batch: 377 | Loss: 0.0322697381571378\n",
            "Epoch: 49 | Batch: 378 | Loss: 0.05181552889674262\n",
            "Epoch: 49 | Batch: 379 | Loss: 0.048179249439051525\n",
            "Epoch: 49 | Batch: 380 | Loss: 0.04276216699018634\n",
            "Epoch: 49 | Batch: 381 | Loss: 0.06276945132628567\n",
            "Epoch: 49 | Batch: 382 | Loss: 0.05607170935380611\n",
            "Epoch: 49 | Batch: 383 | Loss: 0.06876057334253262\n",
            "Epoch: 49 | Batch: 384 | Loss: 0.06058258280216531\n",
            "Epoch: 49 | Batch: 385 | Loss: 0.059280321374990994\n",
            "Epoch: 49 | Batch: 386 | Loss: 0.03786780224324238\n",
            "Epoch: 49 | Batch: 387 | Loss: 0.1075182723069969\n",
            "Epoch: 49 | Batch: 388 | Loss: 0.06743703888818432\n",
            "Epoch: 49 | Batch: 389 | Loss: 0.048532813198278464\n",
            "Epoch: 49 | Batch: 390 | Loss: 0.04895963455096612\n",
            "Epoch: 49 | Batch: 391 | Loss: 0.047057214929824356\n",
            "Epoch: 49 | Batch: 392 | Loss: 0.07263694965167099\n",
            "Epoch: 49 | Batch: 393 | Loss: 0.07372436543318474\n",
            "Epoch: 49 | Batch: 394 | Loss: 0.0695196329271834\n",
            "Epoch: 49 | Batch: 395 | Loss: 0.05001577726174304\n",
            "Epoch: 49 | Batch: 396 | Loss: 0.0349007046196252\n",
            "Epoch: 49 | Batch: 397 | Loss: 0.034944216396645064\n",
            "Epoch: 49 | Batch: 398 | Loss: 0.05191728108613587\n",
            "Epoch: 49 | Batch: 399 | Loss: 0.06819127576011708\n",
            "Epoch: 49 | Batch: 400 | Loss: 0.05978486313336214\n",
            "Epoch: 49 | Batch: 401 | Loss: 0.054720431571557544\n",
            "Epoch: 49 | Batch: 402 | Loss: 0.02818764948684118\n",
            "Epoch: 49 | Batch: 403 | Loss: 0.0468523156510465\n",
            "Epoch: 49 | Batch: 404 | Loss: 0.06169148212756994\n",
            "Epoch: 49 | Batch: 405 | Loss: 0.038190978827730024\n",
            "Epoch: 49 | Batch: 406 | Loss: 0.060241010327412185\n",
            "Epoch: 49 | Batch: 407 | Loss: 0.04749643725789646\n",
            "Epoch: 49 | Batch: 408 | Loss: 0.07044307052597586\n",
            "Epoch: 49 | Batch: 409 | Loss: 0.05413124879027608\n",
            "Epoch: 49 | Batch: 410 | Loss: 0.04127045386996943\n",
            "Epoch: 49 | Batch: 411 | Loss: 0.030599513986928336\n",
            "Epoch: 49 | Batch: 412 | Loss: 0.04291046890614477\n",
            "Epoch: 49 | Batch: 413 | Loss: 0.041363286381549555\n",
            "Epoch: 49 | Batch: 414 | Loss: 0.05381782670707771\n",
            "Epoch: 49 | Batch: 415 | Loss: 0.04848650632148181\n",
            "Epoch: 49 | Batch: 416 | Loss: 0.05736150906559388\n",
            "Epoch: 49 | Batch: 417 | Loss: 0.058547462605292214\n",
            "Epoch: 49 | Batch: 418 | Loss: 0.07465036846768844\n",
            "Epoch: 49 | Batch: 419 | Loss: 0.05076397426536258\n",
            "Epoch: 49 | Batch: 420 | Loss: 0.052314544950910036\n",
            "Epoch: 49 | Batch: 421 | Loss: 0.059593020824388394\n",
            "Epoch: 49 | Batch: 422 | Loss: 0.06753421887546898\n",
            "Epoch: 49 | Batch: 423 | Loss: 0.07795570868033415\n",
            "Epoch: 49 | Batch: 424 | Loss: 0.058264152471881187\n",
            "Epoch: 49 | Batch: 425 | Loss: 0.06862701829304439\n",
            "Epoch: 49 | Batch: 426 | Loss: 0.06756440468508042\n",
            "Epoch: 49 | Batch: 427 | Loss: 0.06675418932630055\n",
            "Epoch: 49 | Batch: 428 | Loss: 0.04677431088230047\n",
            "Epoch: 49 | Batch: 429 | Loss: 0.07990274120149951\n",
            "Epoch: 49 | Batch: 430 | Loss: 0.03592769650339378\n",
            "Epoch: 49 | Batch: 431 | Loss: 0.08597223631635834\n",
            "Epoch: 49 | Batch: 432 | Loss: 0.05186484933158488\n",
            "Epoch: 49 | Batch: 433 | Loss: 0.052148271068973955\n",
            "Epoch: 49 | Batch: 434 | Loss: 0.05695930363836497\n",
            "Epoch: 49 | Batch: 435 | Loss: 0.045948540462019835\n",
            "Epoch: 49 | Batch: 436 | Loss: 0.04936026444620077\n",
            "Epoch: 49 | Batch: 437 | Loss: 0.058875850988930924\n",
            "Epoch: 49 | Batch: 438 | Loss: 0.04596555527799968\n",
            "Epoch: 49 | Batch: 439 | Loss: 0.06738227928995354\n",
            "Epoch: 49 | Batch: 440 | Loss: 0.0587181333080013\n",
            "Epoch: 49 | Batch: 441 | Loss: 0.05553411400319625\n",
            "Epoch: 49 | Batch: 442 | Loss: 0.054371410811089406\n",
            "Epoch: 49 | Batch: 443 | Loss: 0.06778204428961386\n",
            "Epoch: 49 | Batch: 444 | Loss: 0.07194418897254971\n",
            "Epoch: 49 | Batch: 445 | Loss: 0.05786320936766466\n",
            "Epoch: 49 | Batch: 446 | Loss: 0.04752425126935536\n",
            "Epoch: 49 | Batch: 447 | Loss: 0.04339860434475945\n",
            "Epoch: 49 | Batch: 448 | Loss: 0.040965298394754324\n",
            "Epoch: 49 | Batch: 449 | Loss: 0.03523923094129372\n",
            "Epoch: 49 | Batch: 450 | Loss: 0.07691758667889517\n",
            "Epoch: 49 | Batch: 451 | Loss: 0.05282010151581692\n",
            "Epoch: 49 | Batch: 452 | Loss: 0.04415163349245218\n",
            "Epoch: 49 | Batch: 453 | Loss: 0.039085497535772624\n",
            "Epoch: 49 | Batch: 454 | Loss: 0.05627929795054257\n",
            "Epoch: 49 | Batch: 455 | Loss: 0.04756225731296021\n",
            "Epoch: 49 | Batch: 456 | Loss: 0.045826275886872825\n",
            "Epoch: 49 | Batch: 457 | Loss: 0.058833336275078044\n",
            "Epoch: 49 | Batch: 458 | Loss: 0.06662945020849269\n",
            "Epoch: 49 | Batch: 459 | Loss: 0.05049429950678397\n",
            "Epoch: 49 | Batch: 460 | Loss: 0.044540451895469645\n",
            "Epoch: 49 | Batch: 461 | Loss: 0.05290284961912263\n",
            "Epoch: 49 | Batch: 462 | Loss: 0.05719610452849274\n",
            "Epoch: 49 | Batch: 463 | Loss: 0.055171325706248775\n",
            "Epoch: 49 | Batch: 464 | Loss: 0.059062797759320385\n",
            "Epoch: 49 | Batch: 465 | Loss: 0.05622795885703212\n",
            "Epoch: 49 | Batch: 466 | Loss: 0.04385805414100985\n",
            "Epoch: 49 | Batch: 467 | Loss: 0.08065750438707472\n",
            "Epoch: 49 | Batch: 468 | Loss: 0.05469448126093084\n",
            "Epoch: 49 | Batch: 469 | Loss: 0.05020112693480909\n",
            "Epoch: 49 | Batch: 470 | Loss: 0.046009014658882366\n",
            "Epoch: 49 | Batch: 471 | Loss: 0.04976054766187858\n",
            "Epoch: 49 | Batch: 472 | Loss: 0.05665450918055864\n",
            "Epoch: 49 | Batch: 473 | Loss: 0.08222281505289564\n",
            "Epoch: 49 | Batch: 474 | Loss: 0.07038101214363693\n",
            "Epoch: 49 | Batch: 475 | Loss: 0.04646144741017633\n",
            "Epoch: 49 | Batch: 476 | Loss: 0.067075434675737\n",
            "Epoch: 49 | Batch: 477 | Loss: 0.0519857368449186\n",
            "Epoch: 49 | Batch: 478 | Loss: 0.04145836203220181\n",
            "Epoch: 49 | Batch: 479 | Loss: 0.0908940331778008\n",
            "Epoch: 49 | Batch: 480 | Loss: 0.049048069119657395\n",
            "Epoch: 49 | Batch: 481 | Loss: 0.046223516938169604\n",
            "Epoch: 49 | Batch: 482 | Loss: 0.036881255693631786\n",
            "Epoch: 49 | Batch: 483 | Loss: 0.0648722566820938\n",
            "Epoch: 49 | Batch: 484 | Loss: 0.050882562926556005\n",
            "Epoch: 49 | Batch: 485 | Loss: 0.04726302461399871\n",
            "Epoch: 49 | Batch: 486 | Loss: 0.07282871131790412\n",
            "Epoch: 49 | Batch: 487 | Loss: 0.040574884640563066\n",
            "Epoch: 49 | Batch: 488 | Loss: 0.072155040033\n",
            "Epoch: 49 | Batch: 489 | Loss: 0.05387575091642922\n",
            "Epoch: 49 | Batch: 490 | Loss: 0.06195332669498805\n",
            "Epoch: 49 | Batch: 491 | Loss: 0.03857491553693284\n",
            "Epoch: 49 | Batch: 492 | Loss: 0.05962382949474691\n",
            "Epoch: 49 | Batch: 493 | Loss: 0.060614590079745706\n",
            "Epoch: 49 | Batch: 494 | Loss: 0.06569232466663702\n",
            "Epoch: 49 | Batch: 495 | Loss: 0.05343818717972527\n",
            "Epoch: 49 | Batch: 496 | Loss: 0.0679894465562364\n",
            "Epoch: 49 | Batch: 497 | Loss: 0.0511458693919858\n",
            "Epoch: 49 | Batch: 498 | Loss: 0.09772246876979405\n",
            "Epoch: 49 | Batch: 499 | Loss: 0.05198450879556245\n",
            "Epoch: 49 | Batch: 500 | Loss: 0.042668391200892414\n",
            "Epoch: 49 | Batch: 501 | Loss: 0.07260106620761902\n",
            "Epoch: 49 | Batch: 502 | Loss: 0.06152300524090172\n",
            "Epoch: 49 | Batch: 503 | Loss: 0.05859416667282338\n",
            "Epoch: 49 | Batch: 504 | Loss: 0.04960481406211985\n",
            "Epoch: 49 | Batch: 505 | Loss: 0.04720006715431807\n",
            "Epoch: 49 | Batch: 506 | Loss: 0.05900819751661865\n",
            "Epoch: 49 | Batch: 507 | Loss: 0.045914897871594904\n",
            "Epoch: 49 | Batch: 508 | Loss: 0.052932344998319704\n",
            "Epoch: 49 | Batch: 509 | Loss: 0.0409788088370522\n",
            "Epoch: 49 | Batch: 510 | Loss: 0.06407704989196332\n",
            "Epoch: 49 | Batch: 511 | Loss: 0.04588558386538978\n",
            "Epoch: 49 | Batch: 512 | Loss: 0.057288939082319676\n",
            "Epoch: 49 | Batch: 513 | Loss: 0.051407299123196866\n",
            "Epoch: 49 | Batch: 514 | Loss: 0.037653158505159365\n",
            "Epoch: 49 | Batch: 515 | Loss: 0.03918352278960645\n",
            "Epoch: 49 | Batch: 516 | Loss: 0.05405459544597018\n",
            "Epoch: 49 | Batch: 517 | Loss: 0.0407125423522342\n",
            "Epoch: 49 | Batch: 518 | Loss: 0.055024511466417195\n",
            "Epoch: 49 | Batch: 519 | Loss: 0.04628174970570157\n",
            "Epoch: 49 | Batch: 520 | Loss: 0.045618423099185956\n",
            "Epoch: 49 | Batch: 521 | Loss: 0.04983310544231922\n",
            "Epoch: 49 | Batch: 522 | Loss: 0.03748645491933186\n",
            "Epoch: 49 | Batch: 523 | Loss: 0.09589566673769274\n",
            "Epoch: 49 | Batch: 524 | Loss: 0.03509088485800126\n",
            "Epoch: 49 | Batch: 525 | Loss: 0.047171637678951536\n",
            "Epoch: 49 | Batch: 526 | Loss: 0.039654760288772434\n",
            "Epoch: 49 | Batch: 527 | Loss: 0.04820951053150451\n",
            "Epoch: 49 | Batch: 528 | Loss: 0.05629535314019453\n",
            "Epoch: 49 | Batch: 529 | Loss: 0.07558946929341907\n",
            "Epoch: 49 | Batch: 530 | Loss: 0.04958074361705879\n",
            "Epoch: 49 | Batch: 531 | Loss: 0.04086572926919742\n",
            "Epoch: 49 | Batch: 532 | Loss: 0.04018549679695743\n",
            "Epoch: 49 | Batch: 533 | Loss: 0.05767885757913008\n",
            "Epoch: 49 | Batch: 534 | Loss: 0.06443620473929125\n",
            "Epoch: 49 | Batch: 535 | Loss: 0.0675098972838943\n",
            "Epoch: 49 | Batch: 536 | Loss: 0.05067441457801151\n",
            "Epoch: 49 | Batch: 537 | Loss: 0.050969179445073225\n",
            "Epoch: 49 | Batch: 538 | Loss: 0.09382949594134958\n",
            "Epoch: 49 | Batch: 539 | Loss: 0.03490356511910455\n",
            "Epoch: 49 | Batch: 540 | Loss: 0.040340196682413565\n",
            "Epoch: 49 | Batch: 541 | Loss: 0.0643042062150833\n",
            "Epoch: 49 | Batch: 542 | Loss: 0.07679659677024667\n",
            "Epoch: 49 | Batch: 543 | Loss: 0.054413664649914435\n",
            "Epoch: 49 | Batch: 544 | Loss: 0.06331982360521884\n",
            "Epoch: 49 | Batch: 545 | Loss: 0.06631869031224558\n",
            "Epoch: 49 | Batch: 546 | Loss: 0.048548681552219114\n",
            "Epoch: 49 | Batch: 547 | Loss: 0.08570528616965949\n",
            "Epoch: 49 | Batch: 548 | Loss: 0.03182919987377478\n",
            "Epoch: 49 | Batch: 549 | Loss: 0.03589595248151699\n",
            "Epoch: 49 | Batch: 550 | Loss: 0.042411617236371935\n",
            "Epoch: 49 | Batch: 551 | Loss: 0.06412853437187598\n",
            "Epoch: 49 | Batch: 552 | Loss: 0.054223974977077635\n",
            "Epoch: 49 | Batch: 553 | Loss: 0.06304183335649625\n",
            "Epoch: 49 | Batch: 554 | Loss: 0.07387851329549922\n",
            "Epoch: 49 | Batch: 555 | Loss: 0.08683610587831597\n",
            "Epoch: 49 | Batch: 556 | Loss: 0.09307253733249793\n",
            "Epoch: 49 | Batch: 557 | Loss: 0.05638407908335154\n",
            "Epoch: 49 | Batch: 558 | Loss: 0.049365392723972286\n",
            "Epoch: 49 | Batch: 559 | Loss: 0.06848461722330237\n",
            "Epoch: 49 | Batch: 560 | Loss: 0.05598846313682368\n",
            "Epoch: 49 | Batch: 561 | Loss: 0.08253007455023986\n",
            "Epoch: 49 | Batch: 562 | Loss: 0.0359852176262227\n",
            "Epoch: 49 | Batch: 563 | Loss: 0.08901472874548849\n",
            "Epoch: 49 | Batch: 564 | Loss: 0.0640022766087269\n",
            "Epoch: 49 | Batch: 565 | Loss: 0.035349401299813156\n",
            "Epoch: 49 | Batch: 566 | Loss: 0.05051203143046916\n",
            "Epoch: 49 | Batch: 567 | Loss: 0.04472258308634878\n",
            "Epoch: 49 | Batch: 568 | Loss: 0.06099291963790674\n",
            "Epoch: 49 | Batch: 569 | Loss: 0.06867973953228243\n",
            "Epoch: 49 | Batch: 570 | Loss: 0.08751267511238184\n",
            "Epoch: 49 | Batch: 571 | Loss: 0.05769227263990592\n",
            "Epoch: 49 | Batch: 572 | Loss: 0.0398539282191292\n",
            "Epoch: 49 | Batch: 573 | Loss: 0.05814312537103344\n",
            "Epoch: 49 | Batch: 574 | Loss: 0.08674644674053744\n",
            "Epoch: 49 | Batch: 575 | Loss: 0.040229123817659654\n",
            "Epoch: 49 | Batch: 576 | Loss: 0.05623224721982792\n",
            "Epoch: 49 | Batch: 577 | Loss: 0.06393946459756109\n",
            "Epoch: 49 | Batch: 578 | Loss: 0.0535862465332726\n",
            "Epoch: 49 | Batch: 579 | Loss: 0.05815441103796995\n",
            "Epoch: 49 | Batch: 580 | Loss: 0.07365535952688007\n",
            "Epoch: 49 | Batch: 581 | Loss: 0.04793214767355262\n",
            "Epoch: 49 | Batch: 582 | Loss: 0.05459139396282142\n",
            "Epoch: 49 | Batch: 583 | Loss: 0.059204261789436885\n",
            "Epoch: 49 | Batch: 584 | Loss: 0.041609865215950836\n",
            "Epoch: 49 | Batch: 585 | Loss: 0.06768184667406509\n",
            "Epoch: 49 | Batch: 586 | Loss: 0.06753270969405652\n",
            "Epoch: 49 | Batch: 587 | Loss: 0.04977635122146159\n",
            "Epoch: 49 | Batch: 588 | Loss: 0.05915598998932734\n",
            "Epoch: 49 | Batch: 589 | Loss: 0.048032393460979476\n",
            "Epoch: 49 | Batch: 590 | Loss: 0.046514972072507384\n",
            "Epoch: 49 | Batch: 591 | Loss: 0.04316104808995476\n",
            "Epoch: 49 | Batch: 592 | Loss: 0.04070731995735147\n",
            "Epoch: 49 | Batch: 593 | Loss: 0.08740608632610221\n",
            "Epoch: 49 | Batch: 594 | Loss: 0.04818207426350198\n",
            "Epoch: 49 | Batch: 595 | Loss: 0.051825662621168965\n",
            "Epoch: 49 | Batch: 596 | Loss: 0.054335262385699384\n",
            "Epoch: 49 | Batch: 597 | Loss: 0.06583157504989139\n",
            "Epoch: 49 | Batch: 598 | Loss: 0.059334870848534234\n",
            "Epoch: 49 | Batch: 599 | Loss: 0.04299748061947684\n",
            "Epoch: 49 | Batch: 600 | Loss: 0.05519200392169929\n",
            "Epoch: 49 | Batch: 601 | Loss: 0.06528703783206234\n",
            "Epoch: 49 | Batch: 602 | Loss: 0.06478625436210977\n",
            "Epoch: 49 | Batch: 603 | Loss: 0.0965758587433031\n",
            "Epoch: 49 | Batch: 604 | Loss: 0.05727479697554441\n",
            "Epoch: 49 | Batch: 605 | Loss: 0.03862906668215374\n",
            "Epoch: 49 | Batch: 606 | Loss: 0.05063938306413221\n",
            "Epoch: 49 | Batch: 607 | Loss: 0.0585069644018168\n",
            "Epoch: 49 | Batch: 608 | Loss: 0.05032097084419503\n",
            "Epoch: 49 | Batch: 609 | Loss: 0.05252858811608883\n",
            "Epoch: 49 | Batch: 610 | Loss: 0.04987613463082875\n",
            "Epoch: 49 | Batch: 611 | Loss: 0.05631036887706815\n",
            "Epoch: 49 | Batch: 612 | Loss: 0.0840624240110606\n",
            "Epoch: 49 | Batch: 613 | Loss: 0.05864897196778718\n",
            "Epoch: 49 | Batch: 614 | Loss: 0.05369546982551565\n",
            "Epoch: 49 | Batch: 615 | Loss: 0.052804861179876504\n",
            "Epoch: 49 | Batch: 616 | Loss: 0.07211112600467975\n",
            "Epoch: 49 | Batch: 617 | Loss: 0.041195164356772916\n",
            "Epoch: 49 | Batch: 618 | Loss: 0.06862036495101317\n",
            "Epoch: 49 | Batch: 619 | Loss: 0.05061909878530627\n",
            "Epoch: 49 | Batch: 620 | Loss: 0.05198180247842686\n",
            "Epoch: 49 | Batch: 621 | Loss: 0.06557066035338355\n",
            "Epoch: 49 | Batch: 622 | Loss: 0.07480323446578202\n",
            "Epoch: 49 | Batch: 623 | Loss: 0.1369927150587789\n",
            "Epoch: 49 | Batch: 624 | Loss: 0.06447318954599432\n",
            "Epoch: 49 | Batch: 625 | Loss: 0.05915737197764839\n",
            "Epoch: 49 | Batch: 626 | Loss: 0.07808370713206411\n",
            "Epoch: 49 | Batch: 627 | Loss: 0.061063428258764485\n",
            "Epoch: 49 | Batch: 628 | Loss: 0.06270731484870927\n",
            "Epoch: 49 | Batch: 629 | Loss: 0.043604965215976565\n",
            "Epoch: 49 | Batch: 630 | Loss: 0.061702012240253776\n",
            "Epoch: 49 | Batch: 631 | Loss: 0.03810025676646636\n",
            "Epoch: 49 | Batch: 632 | Loss: 0.052079378631069095\n",
            "Epoch: 49 | Batch: 633 | Loss: 0.06148250222055532\n",
            "Epoch: 49 | Batch: 634 | Loss: 0.05580797832143604\n",
            "Epoch: 49 | Batch: 635 | Loss: 0.09673164994848352\n",
            "Epoch: 49 | Batch: 636 | Loss: 0.05874159962180421\n",
            "Epoch: 49 | Batch: 637 | Loss: 0.06620565917534275\n",
            "Epoch: 49 | Batch: 638 | Loss: 0.049755110662466226\n",
            "Epoch: 49 | Batch: 639 | Loss: 0.06434261830497949\n",
            "Epoch: 49 | Batch: 640 | Loss: 0.04089103727553996\n",
            "Epoch: 49 | Batch: 641 | Loss: 0.06348895916405667\n",
            "Epoch: 49 | Batch: 642 | Loss: 0.10313520176374644\n",
            "Epoch: 49 | Batch: 643 | Loss: 0.05626199445050765\n",
            "Epoch: 49 | Batch: 644 | Loss: 0.057028619231032654\n",
            "Epoch: 49 | Batch: 645 | Loss: 0.041520693286320826\n",
            "Epoch: 49 | Batch: 646 | Loss: 0.057849517986317586\n",
            "Epoch: 49 | Batch: 647 | Loss: 0.0825702655628114\n",
            "Epoch: 49 | Batch: 648 | Loss: 0.05332555441315071\n",
            "Epoch: 49 | Batch: 649 | Loss: 0.07915259545503722\n",
            "Epoch: 49 | Batch: 650 | Loss: 0.08900863388166312\n",
            "Epoch: 49 | Batch: 651 | Loss: 0.049742204222820455\n",
            "Epoch: 49 | Batch: 652 | Loss: 0.05999166247728422\n",
            "Epoch: 49 | Batch: 653 | Loss: 0.06041393934081363\n",
            "Epoch: 49 | Batch: 654 | Loss: 0.05536767913159052\n",
            "Epoch: 49 | Batch: 655 | Loss: 0.05881503498514208\n",
            "Epoch: 49 | Batch: 656 | Loss: 0.07223965818657826\n",
            "Epoch: 49 | Batch: 657 | Loss: 0.08697002903621408\n",
            "Epoch: 49 | Batch: 658 | Loss: 0.07081358159745998\n",
            "Epoch: 49 | Batch: 659 | Loss: 0.052978306651095416\n",
            "Epoch: 49 | Batch: 660 | Loss: 0.056389762488441755\n",
            "Epoch: 49 | Batch: 661 | Loss: 0.043913209456868066\n",
            "Epoch: 49 | Batch: 662 | Loss: 0.08552692668353203\n",
            "Epoch: 49 | Batch: 663 | Loss: 0.08974370042299822\n",
            "Epoch: 49 | Batch: 664 | Loss: 0.0894637103908826\n",
            "Epoch: 49 | Batch: 665 | Loss: 0.06512088605666061\n",
            "Epoch: 49 | Batch: 666 | Loss: 0.11097652553662636\n",
            "Epoch: 49 | Batch: 667 | Loss: 0.08855876824047368\n",
            "Epoch: 49 | Batch: 668 | Loss: 0.07605201716212003\n",
            "Epoch: 49 | Batch: 669 | Loss: 0.08238469971245022\n",
            "Epoch: 49 | Batch: 670 | Loss: 0.043547232818738055\n",
            "Epoch: 49 | Batch: 671 | Loss: 0.07248098160892423\n",
            "Epoch: 49 | Batch: 672 | Loss: 0.05534119632399909\n",
            "Epoch: 49 | Batch: 673 | Loss: 0.056884914931899164\n",
            "Epoch: 49 | Batch: 674 | Loss: 0.07608975187171557\n",
            "Epoch: 49 | Batch: 675 | Loss: 0.05777121777102332\n",
            "Epoch: 49 | Batch: 676 | Loss: 0.04625138609525699\n",
            "Epoch: 49 | Batch: 677 | Loss: 0.08881506678994538\n",
            "Epoch: 49 | Batch: 678 | Loss: 0.06921638530552572\n",
            "Epoch: 49 | Batch: 679 | Loss: 0.0854358298832002\n",
            "Epoch: 49 | Batch: 680 | Loss: 0.045357594654894286\n",
            "Epoch: 49 | Batch: 681 | Loss: 0.10498091349527568\n",
            "Epoch: 49 | Batch: 682 | Loss: 0.07714236010873803\n",
            "Epoch: 49 | Batch: 683 | Loss: 0.04801702321535706\n",
            "Epoch: 49 | Batch: 684 | Loss: 0.03929522633503088\n",
            "Epoch: 49 | Batch: 685 | Loss: 0.056542552858751136\n",
            "Epoch: 49 | Batch: 686 | Loss: 0.04416305579248257\n",
            "Epoch: 49 | Batch: 687 | Loss: 0.03957371119482064\n",
            "Epoch: 49 | Batch: 688 | Loss: 0.05878543076129235\n",
            "Epoch: 49 | Batch: 689 | Loss: 0.07837655742311231\n",
            "Epoch: 49 | Batch: 690 | Loss: 0.047954427401020135\n",
            "Epoch: 49 | Batch: 691 | Loss: 0.05468529038757372\n",
            "Epoch: 49 | Batch: 692 | Loss: 0.06972744744864816\n",
            "Epoch: 49 | Batch: 693 | Loss: 0.051713604817490336\n",
            "Epoch: 49 | Batch: 694 | Loss: 0.06968329988250874\n",
            "Epoch: 49 | Batch: 695 | Loss: 0.04842809318530289\n",
            "Epoch: 49 | Batch: 696 | Loss: 0.04302216715488407\n",
            "Epoch: 49 | Batch: 697 | Loss: 0.04051596595967065\n",
            "Epoch: 49 | Batch: 698 | Loss: 0.07325980672652271\n",
            "Epoch: 49 | Batch: 699 | Loss: 0.08291947762948282\n",
            "Epoch: 49 | Batch: 700 | Loss: 0.05948933321662129\n",
            "Epoch: 49 | Batch: 701 | Loss: 0.06697324215568493\n",
            "Epoch: 49 | Batch: 702 | Loss: 0.06305986903321267\n",
            "Epoch: 49 | Batch: 703 | Loss: 0.046821377017980344\n",
            "Epoch: 49 | Batch: 704 | Loss: 0.06741176190632063\n",
            "Epoch: 49 | Batch: 705 | Loss: 0.05579348566912267\n",
            "Epoch: 49 | Batch: 706 | Loss: 0.07665585210950746\n",
            "Epoch: 49 | Batch: 707 | Loss: 0.06664739490273283\n",
            "Epoch: 49 | Batch: 708 | Loss: 0.05101840948231063\n",
            "Epoch: 49 | Batch: 709 | Loss: 0.08221975999646944\n",
            "Epoch: 49 | Batch: 710 | Loss: 0.038664201687804586\n",
            "Epoch: 49 | Batch: 711 | Loss: 0.06053904285164166\n",
            "Epoch: 49 | Batch: 712 | Loss: 0.06272001496720421\n",
            "Epoch: 49 | Batch: 713 | Loss: 0.05369751401985102\n",
            "Epoch: 49 | Batch: 714 | Loss: 0.1156138928253141\n",
            "Epoch: 49 | Batch: 715 | Loss: 0.041402091631205645\n",
            "Epoch: 49 | Batch: 716 | Loss: 0.07230669340858834\n",
            "Epoch: 49 | Batch: 717 | Loss: 0.05744163239998929\n",
            "Epoch: 49 | Batch: 718 | Loss: 0.08692924200306068\n",
            "Epoch: 49 | Batch: 719 | Loss: 0.038309242831548795\n",
            "Epoch: 49 | Batch: 720 | Loss: 0.07818118048910415\n",
            "Epoch: 49 | Batch: 721 | Loss: 0.03796821866592156\n",
            "Epoch: 49 | Batch: 722 | Loss: 0.041445673577065564\n",
            "Epoch: 49 | Batch: 723 | Loss: 0.06723188898366372\n",
            "Epoch: 49 | Batch: 724 | Loss: 0.061923659531046164\n",
            "Epoch: 49 | Batch: 725 | Loss: 0.052780381726079434\n",
            "Epoch: 49 | Batch: 726 | Loss: 0.07868582123266764\n",
            "Epoch: 49 | Batch: 727 | Loss: 0.07086077823053111\n",
            "Epoch: 49 | Batch: 728 | Loss: 0.06871394245240278\n",
            "Epoch: 49 | Batch: 729 | Loss: 0.05029373434670931\n",
            "Epoch: 49 | Batch: 730 | Loss: 0.06615882189749761\n",
            "Epoch: 49 | Batch: 731 | Loss: 0.041934159934691156\n",
            "Epoch: 49 | Batch: 732 | Loss: 0.06395141364989482\n",
            "Epoch: 49 | Batch: 733 | Loss: 0.055128047399615965\n",
            "Epoch: 49 | Batch: 734 | Loss: 0.05717491027959187\n",
            "Epoch: 49 | Batch: 735 | Loss: 0.07487314532239032\n",
            "Epoch: 49 | Batch: 736 | Loss: 0.08943208908634481\n",
            "Epoch: 49 | Batch: 737 | Loss: 0.07753711390463594\n",
            "Epoch: 49 | Batch: 738 | Loss: 0.0910300226564429\n",
            "Epoch: 49 | Batch: 739 | Loss: 0.0529814759306962\n",
            "Epoch: 49 | Batch: 740 | Loss: 0.06717681750863944\n",
            "Epoch: 49 | Batch: 741 | Loss: 0.056640940292769025\n",
            "Epoch: 49 | Batch: 742 | Loss: 0.064019486444667\n",
            "Epoch: 49 | Batch: 743 | Loss: 0.08981731313920586\n",
            "Epoch: 49 | Batch: 744 | Loss: 0.07907578859538306\n",
            "Epoch: 49 | Batch: 745 | Loss: 0.09997503548681207\n",
            "Epoch: 49 | Batch: 746 | Loss: 0.056797451825091536\n",
            "Epoch: 49 | Batch: 747 | Loss: 0.046259910932567996\n",
            "Epoch: 49 | Batch: 748 | Loss: 0.0427785347897055\n",
            "Epoch: 49 | Batch: 749 | Loss: 0.06613495490380537\n",
            "Epoch: 49 | Batch: 750 | Loss: 0.058958138397441504\n",
            "Epoch: 49 | Batch: 751 | Loss: 0.07672803653347765\n",
            "Epoch: 49 | Batch: 752 | Loss: 0.05840166983656303\n",
            "Epoch: 49 | Batch: 753 | Loss: 0.0657816463809501\n",
            "Epoch: 49 | Batch: 754 | Loss: 0.07152643655882612\n",
            "Epoch: 49 | Batch: 755 | Loss: 0.056523710746672916\n",
            "Epoch: 49 | Batch: 756 | Loss: 0.06903589976784918\n",
            "Epoch: 49 | Batch: 757 | Loss: 0.05469089395348387\n",
            "Epoch: 49 | Batch: 758 | Loss: 0.04741229101083008\n",
            "Epoch: 49 | Batch: 759 | Loss: 0.04819957940269041\n",
            "Epoch: 49 | Batch: 760 | Loss: 0.04772933024881898\n",
            "Epoch: 49 | Batch: 761 | Loss: 0.07510029401811479\n",
            "Epoch: 49 | Batch: 762 | Loss: 0.05898470137370082\n",
            "Epoch: 49 | Batch: 763 | Loss: 0.04347258482217242\n",
            "Epoch: 49 | Batch: 764 | Loss: 0.061219350686811044\n",
            "Epoch: 49 | Batch: 765 | Loss: 0.05699403570612924\n",
            "Epoch: 49 | Batch: 766 | Loss: 0.055455676450085006\n",
            "Epoch: 49 | Batch: 767 | Loss: 0.08458653692231212\n",
            "Epoch: 49 | Batch: 768 | Loss: 0.031401072164198005\n",
            "Epoch: 49 | Batch: 769 | Loss: 0.047856224350576744\n",
            "Epoch: 49 | Batch: 770 | Loss: 0.05541793664031676\n",
            "Epoch: 49 | Batch: 771 | Loss: 0.06146479333353318\n",
            "Epoch: 49 | Batch: 772 | Loss: 0.04916839842887714\n",
            "Epoch: 49 | Batch: 773 | Loss: 0.07868449471785414\n",
            "Epoch: 49 | Batch: 774 | Loss: 0.034467926451916805\n",
            "Epoch: 49 | Batch: 775 | Loss: 0.07145051728836264\n",
            "Epoch: 49 | Batch: 776 | Loss: 0.03475710267959352\n",
            "Epoch: 49 | Batch: 777 | Loss: 0.06651516718339402\n",
            "Epoch: 49 | Batch: 778 | Loss: 0.043321169749452215\n",
            "Epoch: 49 | Batch: 779 | Loss: 0.04734810643085374\n",
            "Epoch: 49 | Batch: 780 | Loss: 0.039967989795170154\n",
            "Epoch: 49 | Batch: 781 | Loss: 0.060074249439406216\n",
            "Epoch: 49 | Batch: 782 | Loss: 0.04773436556241216\n",
            "Epoch: 49 | Batch: 783 | Loss: 0.13954840754815084\n",
            "Epoch: 49 | Batch: 784 | Loss: 0.05686191097101995\n",
            "Epoch: 49 | Batch: 785 | Loss: 0.12358924448283815\n",
            "Epoch: 49 | Batch: 786 | Loss: 0.04859362203292351\n",
            "Epoch: 49 | Batch: 787 | Loss: 0.05199003252075419\n",
            "Epoch: 49 | Batch: 788 | Loss: 0.04234532574445558\n",
            "Epoch: 49 | Batch: 789 | Loss: 0.048218569493822624\n",
            "Epoch: 49 | Batch: 790 | Loss: 0.04480853804832556\n",
            "Epoch: 49 | Batch: 791 | Loss: 0.06602402643941215\n",
            "Epoch: 49 | Batch: 792 | Loss: 0.040251969349807154\n",
            "Epoch: 49 | Batch: 793 | Loss: 0.04362161078351436\n",
            "Epoch: 49 | Batch: 794 | Loss: 0.059178336913789556\n",
            "Epoch: 49 | Batch: 795 | Loss: 0.05666783765510352\n",
            "Epoch: 49 | Batch: 796 | Loss: 0.08962101535921282\n",
            "Epoch: 49 | Batch: 797 | Loss: 0.043848227325519004\n",
            "Epoch: 49 | Batch: 798 | Loss: 0.05911801904755494\n",
            "Epoch: 49 | Batch: 799 | Loss: 0.06484952682536117\n",
            "Epoch: 49 | Batch: 800 | Loss: 0.04278786162414748\n",
            "Epoch: 49 | Batch: 801 | Loss: 0.043594849516166226\n",
            "Epoch: 49 | Batch: 802 | Loss: 0.06802499471583079\n",
            "Epoch: 49 | Batch: 803 | Loss: 0.08349637223536702\n",
            "Epoch: 49 | Batch: 804 | Loss: 0.07431904545271381\n",
            "Epoch: 49 | Batch: 805 | Loss: 0.041682859753210046\n",
            "Epoch: 49 | Batch: 806 | Loss: 0.05793052971230233\n",
            "Epoch: 49 | Batch: 807 | Loss: 0.05577454049068199\n",
            "Epoch: 49 | Batch: 808 | Loss: 0.033031386429948455\n",
            "Epoch: 49 | Batch: 809 | Loss: 0.03932112879862773\n",
            "Epoch: 49 | Batch: 810 | Loss: 0.03693661779839516\n",
            "Epoch: 49 | Batch: 811 | Loss: 0.03746442258839325\n",
            "Epoch: 49 | Batch: 812 | Loss: 0.062104400526326736\n",
            "Epoch: 49 | Batch: 813 | Loss: 0.08858117223781946\n",
            "Epoch: 49 | Batch: 814 | Loss: 0.06373338824798483\n",
            "Epoch: 49 | Batch: 815 | Loss: 0.06202260129049611\n",
            "Epoch: 49 | Batch: 816 | Loss: 0.03565424760427845\n",
            "Epoch: 49 | Batch: 817 | Loss: 0.06282407552853177\n",
            "Epoch: 49 | Batch: 818 | Loss: 0.06666107053615203\n",
            "Epoch: 49 | Batch: 819 | Loss: 0.07061806882243615\n",
            "Epoch: 49 | Batch: 820 | Loss: 0.04816603720998762\n",
            "Epoch: 49 | Batch: 821 | Loss: 0.055391207672529225\n",
            "Epoch: 49 | Batch: 822 | Loss: 0.06465670331735787\n",
            "Epoch: 49 | Batch: 823 | Loss: 0.06067829165476131\n",
            "Epoch: 49 | Batch: 824 | Loss: 0.044759050116223484\n",
            "Epoch: 49 | Batch: 825 | Loss: 0.10591542764566214\n",
            "Epoch: 49 | Batch: 826 | Loss: 0.04533039561484517\n",
            "Epoch: 49 | Batch: 827 | Loss: 0.043931221744854025\n",
            "Epoch: 49 | Batch: 828 | Loss: 0.05446068821672943\n",
            "Epoch: 49 | Batch: 829 | Loss: 0.05816873266170153\n",
            "Epoch: 49 | Batch: 830 | Loss: 0.034617598698523516\n",
            "Epoch: 49 | Batch: 831 | Loss: 0.05252017425788379\n",
            "Epoch: 49 | Batch: 832 | Loss: 0.04596557826632436\n",
            "Epoch: 49 | Batch: 833 | Loss: 0.06789867777079153\n",
            "Epoch: 49 | Batch: 834 | Loss: 0.06039060702795815\n",
            "Epoch: 49 | Batch: 835 | Loss: 0.048608420192288775\n",
            "Epoch: 49 | Batch: 836 | Loss: 0.06295147006428045\n",
            "Epoch: 49 | Batch: 837 | Loss: 0.055301626976070606\n",
            "Epoch: 49 | Batch: 838 | Loss: 0.08341063699206361\n",
            "Epoch: 49 | Batch: 839 | Loss: 0.05878740185216604\n",
            "Epoch: 49 | Batch: 840 | Loss: 0.06043397287570105\n",
            "Epoch: 49 | Batch: 841 | Loss: 0.04865953098783159\n",
            "Epoch: 49 | Batch: 842 | Loss: 0.06734477378435666\n",
            "Epoch: 49 | Batch: 843 | Loss: 0.05996858726070569\n",
            "Epoch: 49 | Batch: 844 | Loss: 0.059401425388791965\n",
            "Epoch: 49 | Batch: 845 | Loss: 0.049992148599495134\n",
            "Epoch: 49 | Batch: 846 | Loss: 0.08147966070225847\n",
            "Epoch: 49 | Batch: 847 | Loss: 0.06973857942554412\n",
            "Epoch: 49 | Batch: 848 | Loss: 0.1282388703938626\n",
            "Epoch: 49 | Batch: 849 | Loss: 0.05852294162909512\n",
            "Epoch: 49 | Batch: 850 | Loss: 0.046595073834471826\n",
            "Epoch: 49 | Batch: 851 | Loss: 0.05725479590791951\n",
            "Epoch: 49 | Batch: 852 | Loss: 0.07342325835214049\n",
            "Epoch: 49 | Batch: 853 | Loss: 0.03348969211493023\n",
            "Epoch: 49 | Batch: 854 | Loss: 0.047879045203293516\n",
            "Epoch: 49 | Batch: 855 | Loss: 0.08069710261231805\n",
            "Epoch: 49 | Batch: 856 | Loss: 0.05893303193350374\n",
            "Epoch: 49 | Batch: 857 | Loss: 0.03900115970528376\n",
            "Epoch: 49 | Batch: 858 | Loss: 0.07022309394314363\n",
            "Epoch: 49 | Batch: 859 | Loss: 0.04529539307224861\n",
            "Epoch: 49 | Batch: 860 | Loss: 0.08748501391034114\n",
            "Epoch: 49 | Batch: 861 | Loss: 0.09483337089962286\n",
            "Epoch: 49 | Batch: 862 | Loss: 0.0594960879033747\n",
            "Epoch: 49 | Batch: 863 | Loss: 0.04724335560389144\n",
            "Epoch: 49 | Batch: 864 | Loss: 0.06397921248014908\n",
            "Epoch: 49 | Batch: 865 | Loss: 0.05325539358932479\n",
            "Epoch: 49 | Batch: 866 | Loss: 0.056203869243381804\n",
            "Epoch: 49 | Batch: 867 | Loss: 0.06980090675562622\n",
            "Epoch: 49 | Batch: 868 | Loss: 0.05089008474247929\n",
            "Epoch: 49 | Batch: 869 | Loss: 0.06412535823399254\n",
            "Epoch: 49 | Batch: 870 | Loss: 0.07905835736480366\n",
            "Epoch: 49 | Batch: 871 | Loss: 0.07773560953781367\n",
            "Epoch: 49 | Batch: 872 | Loss: 0.09204354563929819\n",
            "Epoch: 49 | Batch: 873 | Loss: 0.0662249522792234\n",
            "Epoch: 49 | Batch: 874 | Loss: 0.06673258160795884\n",
            "Epoch: 49 | Batch: 875 | Loss: 0.0660993908979864\n",
            "Epoch: 49 | Batch: 876 | Loss: 0.05116190276358253\n",
            "Epoch: 49 | Batch: 877 | Loss: 0.07423013857171702\n",
            "Epoch: 49 | Batch: 878 | Loss: 0.07662423467423307\n",
            "Epoch: 49 | Batch: 879 | Loss: 0.08320903149872043\n",
            "Epoch: 49 | Batch: 880 | Loss: 0.06668852056397337\n",
            "Epoch: 49 | Batch: 881 | Loss: 0.06891148673734586\n",
            "Epoch: 49 | Batch: 882 | Loss: 0.05909081711573795\n",
            "Epoch: 49 | Batch: 883 | Loss: 0.05335159542637578\n",
            "Epoch: 49 | Batch: 884 | Loss: 0.04470137013956157\n",
            "Epoch: 49 | Batch: 885 | Loss: 0.04309748765182513\n",
            "Epoch: 49 | Batch: 886 | Loss: 0.03086087694248028\n",
            "Epoch: 49 | Batch: 887 | Loss: 0.08733471152317121\n",
            "Epoch: 49 | Batch: 888 | Loss: 0.05572370378462261\n",
            "Epoch: 49 | Batch: 889 | Loss: 0.03593255207227144\n",
            "Epoch: 49 | Batch: 890 | Loss: 0.04174281375339671\n",
            "Epoch: 49 | Batch: 891 | Loss: 0.05515765837125306\n",
            "Epoch: 49 | Batch: 892 | Loss: 0.038191070662071676\n",
            "Epoch: 49 | Batch: 893 | Loss: 0.03287831000839052\n",
            "Epoch: 49 | Batch: 894 | Loss: 0.03806449247513859\n",
            "Epoch: 49 | Batch: 895 | Loss: 0.05461008898091484\n",
            "Epoch: 49 | Batch: 896 | Loss: 0.08103591492369772\n",
            "Epoch: 49 | Batch: 897 | Loss: 0.052684691766545944\n",
            "Epoch: 49 | Batch: 898 | Loss: 0.0708317138317526\n",
            "Epoch: 49 | Batch: 899 | Loss: 0.04988130037519434\n",
            "Epoch: 49 | Batch: 900 | Loss: 0.03166432100147491\n",
            "Epoch: 49 | Batch: 901 | Loss: 0.06146719198819224\n",
            "Epoch: 49 | Batch: 902 | Loss: 0.03604312580653495\n",
            "Epoch: 49 | Batch: 903 | Loss: 0.051628942063930414\n",
            "Epoch: 49 | Batch: 904 | Loss: 0.03920751486582709\n",
            "Epoch: 49 | Batch: 905 | Loss: 0.0549150882277482\n",
            "Epoch: 49 | Batch: 906 | Loss: 0.04052103988723728\n",
            "Epoch: 49 | Batch: 907 | Loss: 0.07435169271100837\n",
            "Epoch: 49 | Batch: 908 | Loss: 0.057664575571186316\n",
            "Epoch: 49 | Batch: 909 | Loss: 0.08120115312066828\n",
            "Epoch: 49 | Batch: 910 | Loss: 0.09028182478757732\n",
            "Epoch: 49 | Batch: 911 | Loss: 0.09418062414813903\n",
            "Epoch: 49 | Batch: 912 | Loss: 0.0322123976448598\n",
            "Epoch: 49 | Batch: 913 | Loss: 0.06862213304877282\n",
            "Epoch: 49 | Batch: 914 | Loss: 0.06761009756661587\n",
            "Epoch: 49 | Batch: 915 | Loss: 0.04029715256621518\n",
            "Epoch: 49 | Batch: 916 | Loss: 0.09903715490602447\n",
            "Epoch: 49 | Batch: 917 | Loss: 0.061762933114508305\n",
            "Epoch: 49 | Batch: 918 | Loss: 0.06174042275963754\n",
            "Epoch: 49 | Batch: 919 | Loss: 0.08036944829596519\n",
            "Epoch: 49 | Batch: 920 | Loss: 0.06765093887639109\n",
            "Epoch: 49 | Batch: 921 | Loss: 0.10149177383886107\n",
            "Epoch: 49 | Batch: 922 | Loss: 0.05899001786997886\n",
            "Epoch: 49 | Batch: 923 | Loss: 0.059934264909647136\n",
            "Epoch: 49 | Batch: 924 | Loss: 0.03984236743734279\n",
            "Epoch: 49 | Batch: 925 | Loss: 0.057331167270712816\n",
            "Epoch: 49 | Batch: 926 | Loss: 0.06499038845289153\n",
            "Epoch: 49 | Batch: 927 | Loss: 0.0873854531601275\n",
            "Epoch: 49 | Batch: 928 | Loss: 0.05471266949661699\n",
            "Epoch: 49 | Batch: 929 | Loss: 0.0560884733076691\n",
            "Epoch: 49 | Batch: 930 | Loss: 0.06568048554300034\n",
            "Epoch: 49 | Batch: 931 | Loss: 0.09238238919816553\n",
            "Epoch: 49 | Batch: 932 | Loss: 0.08473961645257495\n",
            "Epoch: 49 | Batch: 933 | Loss: 0.0656384127057572\n",
            "Epoch: 49 | Batch: 934 | Loss: 0.06175819243522568\n",
            "Epoch: 49 | Batch: 935 | Loss: 0.051735391724795986\n",
            "Epoch: 49 | Batch: 936 | Loss: 0.05692327751538141\n",
            "Epoch: 49 | Batch: 937 | Loss: 0.06914276937087387\n",
            "Epoch: 49 | Batch: 938 | Loss: 0.06368194632014675\n",
            "Epoch: 49 | Batch: 939 | Loss: 0.05227730423624522\n",
            "Epoch: 49 | Batch: 940 | Loss: 0.06195859008080093\n",
            "Epoch: 49 | Batch: 941 | Loss: 0.15648124671397495\n",
            "Epoch: 49 | Batch: 942 | Loss: 0.07980354624214173\n",
            "Epoch: 49 | Batch: 943 | Loss: 0.0810082094784634\n",
            "Epoch: 49 | Batch: 944 | Loss: 0.06970174714525391\n",
            "Epoch: 49 | Batch: 945 | Loss: 0.055942895414877854\n",
            "Epoch: 49 | Batch: 946 | Loss: 0.057639645938899406\n",
            "Epoch: 49 | Batch: 947 | Loss: 0.060600937705683866\n",
            "Epoch: 49 | Batch: 948 | Loss: 0.11064735634010026\n",
            "Epoch: 49 | Batch: 949 | Loss: 0.06519271305243408\n",
            "Epoch: 49 | Batch: 950 | Loss: 0.06464425009505315\n",
            "Epoch: 49 | Batch: 951 | Loss: 0.057390212011041414\n",
            "Epoch: 49 | Batch: 952 | Loss: 0.05027397806526834\n",
            "Epoch: 49 | Batch: 953 | Loss: 0.06750633044110468\n",
            "Epoch: 49 | Batch: 954 | Loss: 0.10632343195605887\n",
            "Epoch: 49 | Batch: 955 | Loss: 0.04100322752749358\n",
            "Epoch: 49 | Batch: 956 | Loss: 0.07856477074900588\n",
            "Epoch: 49 | Batch: 957 | Loss: 0.05998157449299585\n",
            "Epoch: 49 | Batch: 958 | Loss: 0.05014347225374652\n",
            "Epoch: 49 | Batch: 959 | Loss: 0.0714566434343826\n",
            "Epoch: 49 | Batch: 960 | Loss: 0.048161011445481974\n",
            "Epoch: 49 | Batch: 961 | Loss: 0.05960329492812399\n",
            "Epoch: 49 | Batch: 962 | Loss: 0.07313486556142233\n",
            "Epoch: 49 | Batch: 963 | Loss: 0.042674573878446656\n",
            "Epoch: 49 | Batch: 964 | Loss: 0.06024390434717266\n",
            "Epoch: 49 | Batch: 965 | Loss: 0.043516318991042253\n",
            "Epoch: 49 | Batch: 966 | Loss: 0.12227859261068832\n",
            "Epoch: 49 | Batch: 967 | Loss: 0.06381145798537978\n",
            "Epoch: 49 | Batch: 968 | Loss: 0.0610351853377071\n",
            "Epoch: 49 | Batch: 969 | Loss: 0.06612190021497459\n",
            "Epoch: 49 | Batch: 970 | Loss: 0.04512389983518455\n",
            "Epoch: 49 | Batch: 971 | Loss: 0.06385657262057241\n",
            "Epoch: 49 | Batch: 972 | Loss: 0.05234176154279806\n",
            "Epoch: 49 | Batch: 973 | Loss: 0.04910649474974818\n",
            "Epoch: 49 | Batch: 974 | Loss: 0.07324205257592038\n",
            "Epoch: 49 | Batch: 975 | Loss: 0.044758048861271514\n",
            "Epoch: 49 | Batch: 976 | Loss: 0.05738207524037944\n",
            "Epoch: 49 | Batch: 977 | Loss: 0.08895024484513751\n",
            "Epoch: 49 | Batch: 978 | Loss: 0.04356503702578758\n",
            "Epoch: 49 | Batch: 979 | Loss: 0.10323865059669511\n",
            "Epoch: 49 | Batch: 980 | Loss: 0.0579988122909234\n",
            "Epoch: 49 | Batch: 981 | Loss: 0.07225100031488713\n",
            "Epoch: 49 | Batch: 982 | Loss: 0.05613452699534831\n",
            "Epoch: 49 | Batch: 983 | Loss: 0.05672944914715736\n",
            "Epoch: 49 | Batch: 984 | Loss: 0.045655368695729094\n",
            "Epoch: 49 | Batch: 985 | Loss: 0.048878527613117125\n",
            "Epoch: 49 | Batch: 986 | Loss: 0.06778437222464077\n",
            "Epoch: 49 | Batch: 987 | Loss: 0.04893845565146325\n",
            "Epoch: 49 | Batch: 988 | Loss: 0.05709241067347093\n",
            "Epoch: 49 | Batch: 989 | Loss: 0.046374817390761915\n",
            "Epoch: 49 | Batch: 990 | Loss: 0.04927076744364532\n",
            "Epoch: 49 | Batch: 991 | Loss: 0.04537696436482534\n",
            "Epoch: 49 | Batch: 992 | Loss: 0.05065601895060108\n",
            "Epoch: 49 | Batch: 993 | Loss: 0.04645796119107204\n",
            "Epoch: 49 | Batch: 994 | Loss: 0.046250615466874825\n",
            "Epoch: 49 | Batch: 995 | Loss: 0.06953326730532688\n",
            "Epoch: 49 | Batch: 996 | Loss: 0.08811551075580686\n",
            "Epoch: 49 | Batch: 997 | Loss: 0.04271014705953068\n",
            "Epoch: 49 | Batch: 998 | Loss: 0.0681946255944233\n",
            "Epoch: 49 | Batch: 999 | Loss: 0.06438871951992936\n",
            "Epoch: 49 | Batch: 1000 | Loss: 0.057742626325098786\n",
            "Epoch: 49 | Batch: 1001 | Loss: 0.07229481317912653\n",
            "Epoch: 49 | Batch: 1002 | Loss: 0.07052394559577951\n",
            "Epoch: 49 | Batch: 1003 | Loss: 0.04220981831793032\n",
            "Epoch: 49 | Batch: 1004 | Loss: 0.0771310670125337\n",
            "Epoch: 49 | Batch: 1005 | Loss: 0.07901302884923594\n",
            "Epoch: 49 | Batch: 1006 | Loss: 0.05615030452251738\n",
            "Epoch: 49 | Batch: 1007 | Loss: 0.08429232823853264\n",
            "Epoch: 49 | Batch: 1008 | Loss: 0.034709039568618635\n",
            "Epoch: 49 | Batch: 1009 | Loss: 0.07049674840547487\n",
            "Epoch: 49 | Batch: 1010 | Loss: 0.030588765562103052\n",
            "Epoch: 49 | Batch: 1011 | Loss: 0.1056386293328429\n",
            "Epoch: 49 | Batch: 1012 | Loss: 0.04901546986742571\n",
            "Epoch: 49 | Batch: 1013 | Loss: 0.0749324294283729\n",
            "Epoch: 49 | Batch: 1014 | Loss: 0.06142318163303588\n",
            "Epoch: 49 | Batch: 1015 | Loss: 0.07702089643135611\n",
            "Epoch: 49 | Batch: 1016 | Loss: 0.05801931916005458\n",
            "Epoch: 49 | Batch: 1017 | Loss: 0.05616728227730007\n",
            "Epoch: 49 | Batch: 1018 | Loss: 0.06205137873854943\n",
            "Epoch: 49 | Batch: 1019 | Loss: 0.06914668555052127\n",
            "Epoch: 49 | Batch: 1020 | Loss: 0.07804806116077632\n",
            "Epoch: 49 | Batch: 1021 | Loss: 0.06691645988631387\n",
            "Epoch: 49 | Batch: 1022 | Loss: 0.08039197220740384\n",
            "Epoch: 49 | Batch: 1023 | Loss: 0.06796751363815406\n",
            "Epoch: 49 | Batch: 1024 | Loss: 0.06189976352396747\n",
            "Epoch: 49 | Batch: 1025 | Loss: 0.07268551293184322\n",
            "Epoch: 49 | Batch: 1026 | Loss: 0.07749659324734362\n",
            "Epoch: 49 | Batch: 1027 | Loss: 0.03727622404515531\n",
            "Epoch: 49 | Batch: 1028 | Loss: 0.061836254073045056\n",
            "Epoch: 49 | Batch: 1029 | Loss: 0.1271654112498638\n",
            "Epoch: 49 | Batch: 1030 | Loss: 0.045380503114583776\n",
            "Epoch: 49 | Batch: 1031 | Loss: 0.06283735460019238\n",
            "Epoch: 49 | Batch: 1032 | Loss: 0.057377055987789756\n",
            "Epoch: 49 | Batch: 1033 | Loss: 0.05124730635481817\n",
            "Epoch: 49 | Batch: 1034 | Loss: 0.050440193516167096\n",
            "Epoch: 49 | Batch: 1035 | Loss: 0.044735533276938064\n",
            "Epoch: 49 | Batch: 1036 | Loss: 0.07257841633601719\n",
            "Epoch: 49 | Batch: 1037 | Loss: 0.0614438123688289\n",
            "Epoch: 49 | Batch: 1038 | Loss: 0.057330676372701464\n",
            "Epoch: 49 | Batch: 1039 | Loss: 0.04806473064411161\n",
            "Epoch: 49 | Batch: 1040 | Loss: 0.06639239104765367\n",
            "Epoch: 49 | Batch: 1041 | Loss: 0.05743450632618939\n",
            "Epoch: 49 | Batch: 1042 | Loss: 0.04596787343794458\n",
            "Epoch: 49 | Batch: 1043 | Loss: 0.05568269666007747\n",
            "Epoch: 49 | Batch: 1044 | Loss: 0.059759578482789025\n",
            "Epoch: 49 | Batch: 1045 | Loss: 0.04783010012343622\n",
            "Epoch: 49 | Batch: 1046 | Loss: 0.04900296651065918\n",
            "Epoch: 49 | Batch: 1047 | Loss: 0.048994184130585025\n",
            "Epoch: 49 | Batch: 1048 | Loss: 0.05027947736617773\n",
            "Epoch: 49 | Batch: 1049 | Loss: 0.039874527096415494\n",
            "Epoch: 49 | Batch: 1050 | Loss: 0.06191205041401165\n",
            "Epoch: 49 | Batch: 1051 | Loss: 0.04920192317052627\n",
            "Epoch: 49 | Batch: 1052 | Loss: 0.04772573055325327\n",
            "Epoch: 49 | Batch: 1053 | Loss: 0.049624528692716524\n",
            "Epoch: 49 | Batch: 1054 | Loss: 0.0779417505082867\n",
            "Epoch: 49 | Batch: 1055 | Loss: 0.05005562141190724\n",
            "Epoch: 49 | Batch: 1056 | Loss: 0.07985417162307093\n",
            "Epoch: 49 | Batch: 1057 | Loss: 0.07102172411339921\n",
            "Epoch: 49 | Batch: 1058 | Loss: 0.06930053406560707\n",
            "Epoch: 49 | Batch: 1059 | Loss: 0.054448201981437835\n",
            "Epoch: 49 | Batch: 1060 | Loss: 0.08452094749772598\n",
            "Epoch: 49 | Batch: 1061 | Loss: 0.06369711684049399\n",
            "Epoch: 49 | Batch: 1062 | Loss: 0.07114362322215542\n",
            "Epoch: 49 | Batch: 1063 | Loss: 0.04255969681946226\n",
            "Epoch: 49 | Batch: 1064 | Loss: 0.05341926984485091\n",
            "Epoch: 49 | Batch: 1065 | Loss: 0.036762331969623\n",
            "Epoch: 49 | Batch: 1066 | Loss: 0.05983428945214357\n",
            "Epoch: 49 | Batch: 1067 | Loss: 0.0564967207180089\n",
            "Epoch: 49 | Batch: 1068 | Loss: 0.064989634450356\n",
            "Epoch: 49 | Batch: 1069 | Loss: 0.04887406186417369\n",
            "Epoch: 49 | Batch: 1070 | Loss: 0.06206752129617247\n",
            "Epoch: 49 | Batch: 1071 | Loss: 0.05741579974672646\n",
            "Epoch: 49 | Batch: 1072 | Loss: 0.056743233089675285\n",
            "Epoch: 49 | Batch: 1073 | Loss: 0.07271067491052262\n",
            "Epoch: 49 | Batch: 1074 | Loss: 0.058864040496350196\n",
            "Epoch: 49 | Batch: 1075 | Loss: 0.0731788781472985\n",
            "Epoch: 49 | Batch: 1076 | Loss: 0.06940135615824519\n",
            "Epoch: 49 | Batch: 1077 | Loss: 0.04454353158796972\n",
            "Epoch: 49 | Batch: 1078 | Loss: 0.04363429720034617\n",
            "Epoch: 49 | Batch: 1079 | Loss: 0.03414214672504328\n",
            "Epoch: 49 | Batch: 1080 | Loss: 0.06385820792026041\n",
            "Epoch: 49 | Batch: 1081 | Loss: 0.05600019202649046\n",
            "Epoch: 49 | Batch: 1082 | Loss: 0.05514343423774026\n",
            "Epoch: 49 | Batch: 1083 | Loss: 0.0789244808437602\n",
            "Epoch: 49 | Batch: 1084 | Loss: 0.061026319088834026\n",
            "Epoch: 49 | Batch: 1085 | Loss: 0.06714737282406229\n",
            "Epoch: 49 | Batch: 1086 | Loss: 0.03962113503757453\n",
            "Epoch: 49 | Batch: 1087 | Loss: 0.07272610260981113\n",
            "Epoch: 49 | Batch: 1088 | Loss: 0.04119037869490809\n",
            "Epoch: 49 | Batch: 1089 | Loss: 0.03893457920153168\n",
            "Epoch: 49 | Batch: 1090 | Loss: 0.06227977846567016\n",
            "Epoch: 49 | Batch: 1091 | Loss: 0.04265089613125431\n",
            "Epoch: 49 | Batch: 1092 | Loss: 0.03908831081910942\n",
            "Epoch: 49 | Batch: 1093 | Loss: 0.03960034981061248\n",
            "Epoch: 49 | Batch: 1094 | Loss: 0.045118846021001455\n",
            "Epoch: 49 | Batch: 1095 | Loss: 0.05764675530360845\n",
            "Epoch: 49 | Batch: 1096 | Loss: 0.048984201308179286\n",
            "Epoch: 49 | Batch: 1097 | Loss: 0.05538525141918884\n",
            "Epoch: 49 | Batch: 1098 | Loss: 0.05299709373197636\n",
            "Epoch: 49 | Batch: 1099 | Loss: 0.05382578374126591\n",
            "Epoch: 49 | Batch: 1100 | Loss: 0.06519676348234091\n",
            "Epoch: 49 | Batch: 1101 | Loss: 0.07039949145568938\n",
            "Epoch: 49 | Batch: 1102 | Loss: 0.05679931228607\n",
            "Epoch: 49 | Batch: 1103 | Loss: 0.06296803476891899\n",
            "Epoch: 49 | Batch: 1104 | Loss: 0.06734742420511806\n",
            "Epoch: 49 | Batch: 1105 | Loss: 0.0671544576173852\n",
            "Epoch: 49 | Batch: 1106 | Loss: 0.0463541227877505\n",
            "Epoch: 49 | Batch: 1107 | Loss: 0.05636007425988898\n",
            "Epoch: 49 | Batch: 1108 | Loss: 0.05249250301733849\n",
            "Epoch: 49 | Batch: 1109 | Loss: 0.040962505313508854\n",
            "Epoch: 49 | Batch: 1110 | Loss: 0.0695823158441596\n",
            "Epoch: 49 | Batch: 1111 | Loss: 0.08413415351207011\n",
            "Epoch: 49 | Batch: 1112 | Loss: 0.054044649447897594\n",
            "Epoch: 49 | Batch: 1113 | Loss: 0.05201577764355709\n",
            "Epoch: 49 | Batch: 1114 | Loss: 0.0698927453669498\n",
            "Epoch: 49 | Batch: 1115 | Loss: 0.04027262545050878\n",
            "Epoch: 49 | Batch: 1116 | Loss: 0.05674726629317896\n",
            "Epoch: 49 | Batch: 1117 | Loss: 0.06501165554499673\n",
            "Epoch: 49 | Batch: 1118 | Loss: 0.059657776934755116\n",
            "Epoch: 49 | Batch: 1119 | Loss: 0.06483113616438753\n",
            "Epoch: 49 | Batch: 1120 | Loss: 0.03660545168938532\n",
            "Epoch: 49 | Batch: 1121 | Loss: 0.035835486660639085\n",
            "Epoch: 49 | Batch: 1122 | Loss: 0.04736548689573733\n",
            "Epoch: 49 | Batch: 1123 | Loss: 0.038287349997193465\n",
            "Epoch: 49 | Batch: 1124 | Loss: 0.07136549268415614\n",
            "Epoch: 49 | Batch: 1125 | Loss: 0.06042205772756349\n",
            "Epoch: 49 | Batch: 1126 | Loss: 0.04414438934526607\n",
            "Epoch: 49 | Batch: 1127 | Loss: 0.05429961842386184\n",
            "Epoch: 49 | Batch: 1128 | Loss: 0.0335447216633313\n",
            "Epoch: 49 | Batch: 1129 | Loss: 0.04290105891856781\n",
            "Epoch: 49 | Batch: 1130 | Loss: 0.07590228192442709\n",
            "Epoch: 49 | Batch: 1131 | Loss: 0.04485431642234444\n",
            "Epoch: 49 | Batch: 1132 | Loss: 0.048810914150072396\n",
            "Epoch: 49 | Batch: 1133 | Loss: 0.05510780763874286\n",
            "Epoch: 49 | Batch: 1134 | Loss: 0.09657460296884815\n",
            "Epoch: 49 | Batch: 1135 | Loss: 0.05756889506794283\n",
            "Epoch: 49 | Batch: 1136 | Loss: 0.09005582718151878\n",
            "Epoch: 49 | Batch: 1137 | Loss: 0.05513191503559917\n",
            "Epoch: 49 | Batch: 1138 | Loss: 0.05611727922912788\n",
            "Epoch: 49 | Batch: 1139 | Loss: 0.0471968450391586\n",
            "Epoch: 49 | Batch: 1140 | Loss: 0.05071993325713085\n",
            "Epoch: 49 | Batch: 1141 | Loss: 0.03784649026574359\n",
            "Epoch: 49 | Batch: 1142 | Loss: 0.0415919354887217\n",
            "Epoch: 49 | Batch: 1143 | Loss: 0.07239587208342724\n",
            "Epoch: 49 | Batch: 1144 | Loss: 0.08503738154533205\n",
            "Epoch: 49 | Batch: 1145 | Loss: 0.05512942414261391\n",
            "Epoch: 49 | Batch: 1146 | Loss: 0.06922839840462108\n",
            "Epoch: 49 | Batch: 1147 | Loss: 0.04364856311192996\n",
            "Epoch: 49 | Batch: 1148 | Loss: 0.055109647154895025\n",
            "Epoch: 49 | Batch: 1149 | Loss: 0.045754651602615\n",
            "Epoch: 49 | Batch: 1150 | Loss: 0.05785567943797455\n",
            "Epoch: 49 | Batch: 1151 | Loss: 0.06364000626717135\n",
            "Epoch: 49 | Batch: 1152 | Loss: 0.07307569515022488\n",
            "Epoch: 49 | Batch: 1153 | Loss: 0.08081695727874448\n",
            "Epoch: 49 | Batch: 1154 | Loss: 0.08356471336944796\n",
            "Epoch: 49 | Batch: 1155 | Loss: 0.06338220202468144\n",
            "Epoch: 49 | Batch: 1156 | Loss: 0.07157580574696629\n",
            "Epoch: 49 | Batch: 1157 | Loss: 0.11043662832862879\n",
            "Epoch: 49 | Batch: 1158 | Loss: 0.05741515201832461\n",
            "Epoch: 49 | Batch: 1159 | Loss: 0.043784776358602354\n",
            "Epoch: 49 | Batch: 1160 | Loss: 0.06905913860615163\n",
            "Epoch: 49 | Batch: 1161 | Loss: 0.09095332927448316\n",
            "Epoch: 49 | Batch: 1162 | Loss: 0.03760195247413291\n",
            "Epoch: 49 | Batch: 1163 | Loss: 0.06744820620907024\n",
            "Epoch: 49 | Batch: 1164 | Loss: 0.050097543640447065\n",
            "Epoch: 49 | Batch: 1165 | Loss: 0.050404013154999504\n",
            "Epoch: 49 | Batch: 1166 | Loss: 0.04553246039883396\n",
            "Epoch: 49 | Batch: 1167 | Loss: 0.10034910292919688\n",
            "Epoch: 49 | Batch: 1168 | Loss: 0.09299953046147584\n",
            "Epoch: 49 | Batch: 1169 | Loss: 0.04784437213724189\n",
            "Epoch: 49 | Batch: 1170 | Loss: 0.04755301484264487\n",
            "Epoch: 49 | Batch: 1171 | Loss: 0.045240217591153944\n",
            "Epoch: 49 | Batch: 1172 | Loss: 0.043957514763978106\n",
            "Epoch: 49 | Batch: 1173 | Loss: 0.0612181067260988\n",
            "Epoch: 49 | Batch: 1174 | Loss: 0.05107956670907944\n",
            "Epoch: 49 | Batch: 1175 | Loss: 0.046437255242999666\n",
            "Epoch: 49 | Batch: 1176 | Loss: 0.051393629145989175\n",
            "Epoch: 49 | Batch: 1177 | Loss: 0.049773666860459045\n",
            "Epoch: 49 | Batch: 1178 | Loss: 0.06261264822962771\n",
            "Epoch: 49 | Batch: 1179 | Loss: 0.06251423982950022\n",
            "Epoch: 49 | Batch: 1180 | Loss: 0.05740173647453939\n",
            "Epoch: 49 | Batch: 1181 | Loss: 0.08848287797930789\n",
            "Epoch: 49 | Batch: 1182 | Loss: 0.0913219098573497\n",
            "Epoch: 49 | Batch: 1183 | Loss: 0.06030438170878712\n",
            "Epoch: 49 | Batch: 1184 | Loss: 0.07976151992045197\n",
            "Epoch: 49 | Batch: 1185 | Loss: 0.03566229773952999\n",
            "Epoch: 49 | Batch: 1186 | Loss: 0.05929767652217706\n",
            "Epoch: 49 | Batch: 1187 | Loss: 0.07646657047481042\n",
            "Epoch: 49 | Batch: 1188 | Loss: 0.06351482113646864\n",
            "Epoch: 49 | Batch: 1189 | Loss: 0.042331902581107556\n",
            "Epoch: 49 | Batch: 1190 | Loss: 0.07277812305668097\n",
            "Epoch: 49 | Batch: 1191 | Loss: 0.05073682419291892\n",
            "Epoch: 49 | Batch: 1192 | Loss: 0.048073748336620974\n",
            "Epoch: 49 | Batch: 1193 | Loss: 0.09547456210158045\n",
            "Epoch: 49 | Batch: 1194 | Loss: 0.07167322935465376\n",
            "Epoch: 49 | Batch: 1195 | Loss: 0.052634261468646776\n",
            "Epoch: 49 | Batch: 1196 | Loss: 0.06271953321279286\n",
            "Epoch: 49 | Batch: 1197 | Loss: 0.07083319827552327\n",
            "Epoch: 49 | Batch: 1198 | Loss: 0.07621740524267648\n",
            "Epoch: 49 | Batch: 1199 | Loss: 0.06656928533091226\n",
            "Epoch: 49 | Batch: 1200 | Loss: 0.06716238841116967\n",
            "Epoch: 49 | Batch: 1201 | Loss: 0.045092187058114755\n",
            "Epoch: 49 | Batch: 1202 | Loss: 0.08014188240936078\n",
            "Epoch: 49 | Batch: 1203 | Loss: 0.038155596621458024\n",
            "Epoch: 49 | Batch: 1204 | Loss: 0.08781472252010293\n",
            "Epoch: 49 | Batch: 1205 | Loss: 0.07819285109702782\n",
            "Epoch: 49 | Batch: 1206 | Loss: 0.06395243020729857\n",
            "Epoch: 49 | Batch: 1207 | Loss: 0.07121280273808261\n",
            "Epoch: 49 | Batch: 1208 | Loss: 0.06315624151847683\n",
            "Epoch: 49 | Batch: 1209 | Loss: 0.04326015245340771\n",
            "Epoch: 49 | Batch: 1210 | Loss: 0.07812913954484463\n",
            "Epoch: 49 | Batch: 1211 | Loss: 0.07653629318257459\n",
            "Epoch: 49 | Batch: 1212 | Loss: 0.07426510910371574\n",
            "Epoch: 49 | Batch: 1213 | Loss: 0.07539398837599359\n",
            "Epoch: 49 | Batch: 1214 | Loss: 0.10015709817024239\n",
            "Epoch: 49 | Batch: 1215 | Loss: 0.04567141658665196\n",
            "Epoch: 49 | Batch: 1216 | Loss: 0.042079275030465255\n",
            "Epoch: 49 | Batch: 1217 | Loss: 0.06842601991324998\n",
            "Epoch: 49 | Batch: 1218 | Loss: 0.04863802325163006\n",
            "Epoch: 49 | Batch: 1219 | Loss: 0.06492537644569388\n",
            "Epoch: 49 | Batch: 1220 | Loss: 0.06865770378736175\n",
            "Epoch: 49 | Batch: 1221 | Loss: 0.10397571105003735\n",
            "Epoch: 49 | Batch: 1222 | Loss: 0.07417150042513505\n",
            "Epoch: 49 | Batch: 1223 | Loss: 0.06525726664781548\n",
            "Epoch: 49 | Batch: 1224 | Loss: 0.045699389745352634\n",
            "Epoch: 49 | Batch: 1225 | Loss: 0.0587455579174807\n",
            "Epoch: 49 | Batch: 1226 | Loss: 0.05160890802882955\n",
            "Epoch: 49 | Batch: 1227 | Loss: 0.07518125851818062\n",
            "Epoch: 49 | Batch: 1228 | Loss: 0.061656697534432474\n",
            "Epoch: 49 | Batch: 1229 | Loss: 0.048366751191118704\n",
            "Epoch: 49 | Batch: 1230 | Loss: 0.0396571272176099\n",
            "Epoch: 49 | Batch: 1231 | Loss: 0.04255465958357637\n",
            "Epoch: 49 | Batch: 1232 | Loss: 0.05622350297139293\n",
            "Epoch: 49 | Batch: 1233 | Loss: 0.05712126396386448\n",
            "Epoch: 49 | Batch: 1234 | Loss: 0.02949956955320305\n",
            "Epoch: 49 | Batch: 1235 | Loss: 0.07710867663413118\n",
            "Epoch: 49 | Batch: 1236 | Loss: 0.05954112427787819\n",
            "Epoch: 49 | Batch: 1237 | Loss: 0.04561585216720941\n",
            "Epoch: 49 | Batch: 1238 | Loss: 0.04903936127822468\n",
            "Epoch: 49 | Batch: 1239 | Loss: 0.04808520847427498\n",
            "Epoch: 49 | Batch: 1240 | Loss: 0.07741742839402323\n",
            "Epoch: 49 | Batch: 1241 | Loss: 0.1082461090122872\n",
            "Epoch: 49 | Batch: 1242 | Loss: 0.0426368196763348\n",
            "Epoch: 49 | Batch: 1243 | Loss: 0.05505115921013547\n",
            "Epoch: 49 | Batch: 1244 | Loss: 0.09006063680626109\n",
            "Epoch: 49 | Batch: 1245 | Loss: 0.07176257990937919\n",
            "Epoch: 49 | Batch: 1246 | Loss: 0.06638641366563254\n",
            "Epoch: 49 | Batch: 1247 | Loss: 0.0795205537705623\n",
            "Epoch: 49 | Batch: 1248 | Loss: 0.05456492270372387\n",
            "Epoch: 49 | Batch: 1249 | Loss: 0.03836708065436488\n",
            "Epoch: 49 | Batch: 1250 | Loss: 0.06436975265169813\n",
            "Epoch: 49 | Batch: 1251 | Loss: 0.04699557788578198\n",
            "Epoch: 49 | Batch: 1252 | Loss: 0.06951013224697787\n",
            "Epoch: 49 | Batch: 1253 | Loss: 0.06635952459387037\n",
            "Epoch: 49 | Batch: 1254 | Loss: 0.03138945525043804\n",
            "Epoch: 49 | Batch: 1255 | Loss: 0.04244089708925888\n",
            "Epoch: 49 | Batch: 1256 | Loss: 0.06972729711852058\n",
            "Epoch: 49 | Batch: 1257 | Loss: 0.06205094886849423\n",
            "Epoch: 49 | Batch: 1258 | Loss: 0.05670791337095456\n",
            "Epoch: 49 | Batch: 1259 | Loss: 0.03703333514794445\n",
            "Epoch: 49 | Batch: 1260 | Loss: 0.09819527297613895\n",
            "Epoch: 49 | Batch: 1261 | Loss: 0.04155809273853239\n",
            "Epoch: 49 | Batch: 1262 | Loss: 0.06465346455211572\n",
            "Epoch: 49 | Batch: 1263 | Loss: 0.04340999277536052\n",
            "Epoch: 49 | Batch: 1264 | Loss: 0.07009607647144962\n",
            "Epoch: 49 | Batch: 1265 | Loss: 0.04519524174101679\n",
            "Epoch: 49 | Batch: 1266 | Loss: 0.053504487067262296\n",
            "Epoch: 49 | Batch: 1267 | Loss: 0.045871841618005615\n",
            "Epoch: 49 | Batch: 1268 | Loss: 0.12898875388109046\n",
            "Epoch: 49 | Batch: 1269 | Loss: 0.0573531035691557\n",
            "Epoch: 49 | Batch: 1270 | Loss: 0.0837518521781627\n",
            "Epoch: 49 | Batch: 1271 | Loss: 0.06908564714802548\n",
            "Epoch: 49 | Batch: 1272 | Loss: 0.06347089543349779\n",
            "Epoch: 49 | Batch: 1273 | Loss: 0.04677566940029895\n",
            "Epoch: 49 | Batch: 1274 | Loss: 0.0736396845598413\n",
            "Epoch: 49 | Batch: 1275 | Loss: 0.05342583953621146\n",
            "Epoch: 49 | Batch: 1276 | Loss: 0.04682808803319456\n",
            "Epoch: 49 | Batch: 1277 | Loss: 0.09672603357065201\n",
            "Epoch: 49 | Batch: 1278 | Loss: 0.08652234601592226\n",
            "Epoch: 49 | Batch: 1279 | Loss: 0.07527028117553507\n",
            "Epoch: 49 | Batch: 1280 | Loss: 0.048793291822418546\n",
            "Epoch: 49 | Batch: 1281 | Loss: 0.037356974343696746\n",
            "Epoch: 49 | Batch: 1282 | Loss: 0.08269020965090239\n",
            "Epoch: 49 | Batch: 1283 | Loss: 0.05147321579015468\n",
            "Epoch: 49 | Batch: 1284 | Loss: 0.058109536905876426\n",
            "Epoch: 49 | Batch: 1285 | Loss: 0.03471309166150752\n",
            "Epoch: 49 | Batch: 1286 | Loss: 0.07353801578634635\n",
            "Epoch: 49 | Batch: 1287 | Loss: 0.05502265204375195\n",
            "Epoch: 49 | Batch: 1288 | Loss: 0.05507274643892932\n",
            "Epoch: 49 | Batch: 1289 | Loss: 0.05891415233066755\n",
            "Epoch: 49 | Batch: 1290 | Loss: 0.060556996782246894\n",
            "Epoch: 49 | Batch: 1291 | Loss: 0.041045293370634076\n",
            "Epoch: 49 | Batch: 1292 | Loss: 0.048500236615973885\n",
            "Epoch: 49 | Batch: 1293 | Loss: 0.06417925960302237\n",
            "Epoch: 49 | Batch: 1294 | Loss: 0.07569203194366844\n",
            "Epoch: 49 | Batch: 1295 | Loss: 0.1143605097240157\n",
            "Epoch: 49 | Batch: 1296 | Loss: 0.044452019446860856\n",
            "Epoch: 49 | Batch: 1297 | Loss: 0.05681918075247616\n",
            "Epoch: 49 | Batch: 1298 | Loss: 0.05053743140356735\n",
            "Epoch: 49 | Batch: 1299 | Loss: 0.06085653010071013\n",
            "Epoch: 49 | Batch: 1300 | Loss: 0.03713021011465699\n",
            "Epoch: 49 | Batch: 1301 | Loss: 0.0533726652894817\n",
            "Epoch: 49 | Batch: 1302 | Loss: 0.08449255795255663\n",
            "Epoch: 49 | Batch: 1303 | Loss: 0.05952572939716006\n",
            "Epoch: 49 | Batch: 1304 | Loss: 0.06562066866633817\n",
            "Epoch: 49 | Batch: 1305 | Loss: 0.052005169095070095\n",
            "Epoch: 49 | Batch: 1306 | Loss: 0.05580034005208222\n",
            "Epoch: 49 | Batch: 1307 | Loss: 0.08446274136082343\n",
            "Epoch: 49 | Batch: 1308 | Loss: 0.06510586345461682\n",
            "Epoch: 49 | Batch: 1309 | Loss: 0.07016948202473448\n",
            "Epoch: 49 | Batch: 1310 | Loss: 0.07769245115109902\n",
            "Epoch: 49 | Batch: 1311 | Loss: 0.04769361512854546\n",
            "Epoch: 49 | Batch: 1312 | Loss: 0.052587376324870816\n",
            "Epoch: 49 | Batch: 1313 | Loss: 0.07398959272910458\n",
            "Epoch: 49 | Batch: 1314 | Loss: 0.08415518671112669\n",
            "Epoch: 49 | Batch: 1315 | Loss: 0.06202699985422924\n",
            "Epoch: 49 | Batch: 1316 | Loss: 0.04578480347721473\n",
            "Epoch: 49 | Batch: 1317 | Loss: 0.05077306196422865\n",
            "Epoch: 49 | Batch: 1318 | Loss: 0.059830428383682153\n",
            "Epoch: 49 | Batch: 1319 | Loss: 0.05561061705149936\n",
            "Epoch: 49 | Batch: 1320 | Loss: 0.07232662375550142\n",
            "Epoch: 49 | Batch: 1321 | Loss: 0.042661194857101306\n",
            "Epoch: 49 | Batch: 1322 | Loss: 0.06495164035451587\n",
            "Epoch: 49 | Batch: 1323 | Loss: 0.057344246816241076\n",
            "Epoch: 49 | Batch: 1324 | Loss: 0.04686794304311005\n",
            "Epoch: 49 | Batch: 1325 | Loss: 0.06406385284422567\n",
            "Epoch: 49 | Batch: 1326 | Loss: 0.03885404770716256\n",
            "Epoch: 49 | Batch: 1327 | Loss: 0.060136755314913845\n",
            "Epoch: 49 | Batch: 1328 | Loss: 0.0646097537147762\n",
            "Epoch: 49 | Batch: 1329 | Loss: 0.06968183496679503\n",
            "Epoch: 49 | Batch: 1330 | Loss: 0.04425829037464363\n",
            "Epoch: 49 | Batch: 1331 | Loss: 0.06377337262993239\n",
            "Epoch: 49 | Batch: 1332 | Loss: 0.04514590861698926\n",
            "Epoch: 49 | Batch: 1333 | Loss: 0.07390387310174071\n",
            "Epoch: 49 | Batch: 1334 | Loss: 0.04550755635800299\n",
            "Epoch: 49 | Batch: 1335 | Loss: 0.05242351243782796\n",
            "Epoch: 49 | Batch: 1336 | Loss: 0.04385522657498146\n",
            "Epoch: 49 | Batch: 1337 | Loss: 0.05752767803177946\n",
            "Epoch: 49 | Batch: 1338 | Loss: 0.09252393255822654\n",
            "Epoch: 49 | Batch: 1339 | Loss: 0.06561208674718326\n",
            "Epoch: 49 | Batch: 1340 | Loss: 0.06258126766895437\n",
            "Epoch: 49 | Batch: 1341 | Loss: 0.054265256484213015\n",
            "Epoch: 49 | Batch: 1342 | Loss: 0.1171368683776423\n",
            "Epoch: 49 | Batch: 1343 | Loss: 0.06658621794308725\n",
            "Epoch: 49 | Batch: 1344 | Loss: 0.04572973644035146\n",
            "Epoch: 49 | Batch: 1345 | Loss: 0.059096142439287874\n",
            "Epoch: 49 | Batch: 1346 | Loss: 0.09987811208275371\n",
            "Epoch: 49 | Batch: 1347 | Loss: 0.08571498327718965\n",
            "Epoch: 49 | Batch: 1348 | Loss: 0.047940464576992754\n",
            "Epoch: 49 | Batch: 1349 | Loss: 0.0485116255653444\n",
            "Epoch: 49 | Batch: 1350 | Loss: 0.04571450630760269\n",
            "Epoch: 49 | Batch: 1351 | Loss: 0.05682012032346344\n",
            "Epoch: 49 | Batch: 1352 | Loss: 0.06140733342757406\n",
            "Epoch: 49 | Batch: 1353 | Loss: 0.0835103595016585\n",
            "Epoch: 49 | Batch: 1354 | Loss: 0.05419119601952102\n",
            "Epoch: 49 | Batch: 1355 | Loss: 0.051947826824730946\n",
            "Epoch: 49 | Batch: 1356 | Loss: 0.07497794910414834\n",
            "Epoch: 49 | Batch: 1357 | Loss: 0.05118574775638057\n",
            "Epoch: 49 | Batch: 1358 | Loss: 0.10478174439665572\n",
            "Epoch: 49 | Batch: 1359 | Loss: 0.09982931680107143\n",
            "Epoch: 49 | Batch: 1360 | Loss: 0.05586738847459185\n",
            "Epoch: 49 | Batch: 1361 | Loss: 0.07103155237291037\n",
            "Epoch: 49 | Batch: 1362 | Loss: 0.05356156910754999\n",
            "Epoch: 49 | Batch: 1363 | Loss: 0.04860331717732501\n",
            "Epoch: 49 | Batch: 1364 | Loss: 0.05787154443498448\n",
            "Epoch: 49 | Batch: 1365 | Loss: 0.0686165469709536\n",
            "Epoch: 49 | Batch: 1366 | Loss: 0.07567248618538534\n",
            "Epoch: 49 | Batch: 1367 | Loss: 0.05965086331331395\n",
            "Epoch: 49 | Batch: 1368 | Loss: 0.04467358190048891\n",
            "Epoch: 49 | Batch: 1369 | Loss: 0.05466361363776749\n",
            "Epoch: 49 | Batch: 1370 | Loss: 0.07452216024335477\n",
            "Epoch: 49 | Batch: 1371 | Loss: 0.06398542381910054\n",
            "Epoch: 49 | Batch: 1372 | Loss: 0.037548469452407945\n",
            "Epoch: 49 | Batch: 1373 | Loss: 0.04833404056571922\n",
            "Epoch: 49 | Batch: 1374 | Loss: 0.06374351577047281\n",
            "Epoch: 49 | Batch: 1375 | Loss: 0.04549567709821224\n",
            "Epoch: 49 | Batch: 1376 | Loss: 0.08142797197263389\n",
            "Epoch: 49 | Batch: 1377 | Loss: 0.0555368496313807\n",
            "Epoch: 49 | Batch: 1378 | Loss: 0.05209012060533843\n",
            "Epoch: 49 | Batch: 1379 | Loss: 0.04707831871657627\n",
            "Epoch: 49 | Batch: 1380 | Loss: 0.04664813207994825\n",
            "Epoch: 49 | Batch: 1381 | Loss: 0.11830482716959673\n",
            "Epoch: 49 | Batch: 1382 | Loss: 0.039519936560802965\n",
            "Epoch: 49 | Batch: 1383 | Loss: 0.07191098445984169\n",
            "Epoch: 49 | Batch: 1384 | Loss: 0.04913900691907939\n",
            "Epoch: 49 | Batch: 1385 | Loss: 0.04509947008715435\n",
            "Epoch: 49 | Batch: 1386 | Loss: 0.04531286734064942\n",
            "Epoch: 49 | Batch: 1387 | Loss: 0.061001896251113116\n",
            "Epoch: 49 | Batch: 1388 | Loss: 0.057867127829558496\n",
            "Epoch: 49 | Batch: 1389 | Loss: 0.05096208192750743\n",
            "Epoch: 49 | Batch: 1390 | Loss: 0.0647082244643882\n",
            "Epoch: 49 | Batch: 1391 | Loss: 0.10073626390379253\n",
            "Epoch: 49 | Batch: 1392 | Loss: 0.056975857736576874\n",
            "Epoch: 49 | Batch: 1393 | Loss: 0.05804262153481933\n",
            "Epoch: 49 | Batch: 1394 | Loss: 0.07893110597448827\n",
            "Epoch: 49 | Batch: 1395 | Loss: 0.05636725847786983\n",
            "Epoch: 49 | Batch: 1396 | Loss: 0.069596899357458\n",
            "Epoch: 49 | Batch: 1397 | Loss: 0.08146536758329781\n",
            "Epoch: 49 | Batch: 1398 | Loss: 0.07714215429559924\n",
            "Epoch: 49 | Batch: 1399 | Loss: 0.09342917530756345\n",
            "Epoch: 49 | Batch: 1400 | Loss: 0.06791193652867077\n",
            "Epoch: 49 | Batch: 1401 | Loss: 0.08587278675124238\n",
            "Epoch: 49 | Batch: 1402 | Loss: 0.11075158703958343\n",
            "Epoch: 49 | Batch: 1403 | Loss: 0.04916145197820013\n",
            "Epoch: 49 | Batch: 1404 | Loss: 0.09206887675929976\n",
            "Epoch: 49 | Batch: 1405 | Loss: 0.06884435535590536\n",
            "Epoch: 49 | Batch: 1406 | Loss: 0.06033997991850056\n",
            "Epoch: 49 | Batch: 1407 | Loss: 0.06809934689874628\n",
            "Epoch: 49 | Batch: 1408 | Loss: 0.12123585534936013\n",
            "Epoch: 49 | Batch: 1409 | Loss: 0.10868491357421649\n",
            "Epoch: 49 | Batch: 1410 | Loss: 0.08012129809240616\n",
            "Epoch: 49 | Batch: 1411 | Loss: 0.06668497755137948\n",
            "Epoch: 49 | Batch: 1412 | Loss: 0.06181185982249439\n",
            "Epoch: 49 | Batch: 1413 | Loss: 0.05544807116710143\n",
            "Epoch: 49 | Batch: 1414 | Loss: 0.06428776372628023\n",
            "Epoch: 49 | Batch: 1415 | Loss: 0.07773227500419923\n",
            "Epoch: 49 | Batch: 1416 | Loss: 0.04791096825516323\n",
            "Epoch: 49 | Batch: 1417 | Loss: 0.046878577792585266\n",
            "Epoch: 49 | Batch: 1418 | Loss: 0.06357852930336913\n",
            "Epoch: 49 | Batch: 1419 | Loss: 0.05546062004822884\n",
            "Epoch: 49 | Batch: 1420 | Loss: 0.077458991161181\n",
            "Epoch: 49 | Batch: 1421 | Loss: 0.06555076920397945\n",
            "Epoch: 49 | Batch: 1422 | Loss: 0.06492842931321963\n",
            "Epoch: 49 | Batch: 1423 | Loss: 0.05220716033273172\n",
            "Epoch: 49 | Batch: 1424 | Loss: 0.07547530028383913\n",
            "Epoch: 49 | Batch: 1425 | Loss: 0.07040319545126841\n",
            "Epoch: 49 | Batch: 1426 | Loss: 0.05243070992471299\n",
            "Epoch: 49 | Batch: 1427 | Loss: 0.06509001873440158\n",
            "Epoch: 49 | Batch: 1428 | Loss: 0.06102331377816613\n",
            "Epoch: 49 | Batch: 1429 | Loss: 0.03142100039094774\n",
            "Epoch: 49 | Batch: 1430 | Loss: 0.04904806097118375\n",
            "Epoch: 49 | Batch: 1431 | Loss: 0.07371158558806117\n",
            "Epoch: 49 | Batch: 1432 | Loss: 0.11602870125940455\n",
            "Epoch: 49 | Batch: 1433 | Loss: 0.045170113600573256\n",
            "Epoch: 49 | Batch: 1434 | Loss: 0.05656465621882094\n",
            "Epoch: 49 | Batch: 1435 | Loss: 0.08045686553080367\n",
            "Epoch: 49 | Batch: 1436 | Loss: 0.07315519200530488\n",
            "Epoch: 49 | Batch: 1437 | Loss: 0.05555067348524985\n",
            "Epoch: 49 | Batch: 1438 | Loss: 0.07065931038832281\n",
            "Epoch: 49 | Batch: 1439 | Loss: 0.06641863409903012\n",
            "Epoch: 49 | Batch: 1440 | Loss: 0.06501537195033785\n",
            "Epoch: 49 | Batch: 1441 | Loss: 0.0671077190647339\n",
            "Epoch: 49 | Batch: 1442 | Loss: 0.07911866353752145\n",
            "Epoch: 49 | Batch: 1443 | Loss: 0.052154878535478566\n",
            "Epoch: 49 | Batch: 1444 | Loss: 0.08266192345777215\n",
            "Epoch: 49 | Batch: 1445 | Loss: 0.05567187190107963\n",
            "Epoch: 49 | Batch: 1446 | Loss: 0.057514468153853165\n",
            "Epoch: 49 | Batch: 1447 | Loss: 0.05035257054625308\n",
            "Epoch: 49 | Batch: 1448 | Loss: 0.04739709271974482\n",
            "Epoch: 49 | Batch: 1449 | Loss: 0.06524235186177757\n",
            "Epoch: 49 | Batch: 1450 | Loss: 0.05793510248529293\n",
            "Epoch: 49 | Batch: 1451 | Loss: 0.05907162601306831\n",
            "Epoch: 49 | Batch: 1452 | Loss: 0.055255618233713846\n",
            "Epoch: 49 | Batch: 1453 | Loss: 0.08391167283772423\n",
            "Epoch: 49 | Batch: 1454 | Loss: 0.06630352256438825\n",
            "Epoch: 49 | Batch: 1455 | Loss: 0.0582630640818588\n",
            "Epoch: 49 | Batch: 1456 | Loss: 0.08448013030165942\n",
            "Epoch: 49 | Batch: 1457 | Loss: 0.06419898563271986\n",
            "Epoch: 49 | Batch: 1458 | Loss: 0.05971312033156234\n",
            "Epoch: 49 | Batch: 1459 | Loss: 0.08018002540759639\n",
            "Epoch: 49 | Batch: 1460 | Loss: 0.056800681676751126\n",
            "Epoch: 49 | Batch: 1461 | Loss: 0.0640508138647\n",
            "Epoch: 49 | Batch: 1462 | Loss: 0.06510187058877731\n",
            "Epoch: 49 | Batch: 1463 | Loss: 0.07231293851274105\n",
            "Epoch: 49 | Batch: 1464 | Loss: 0.058745754767310795\n",
            "Epoch: 49 | Batch: 1465 | Loss: 0.0683892955800083\n",
            "Epoch: 49 | Batch: 1466 | Loss: 0.07353891669496834\n",
            "Epoch: 49 | Batch: 1467 | Loss: 0.04610856020717462\n",
            "Epoch: 49 | Batch: 1468 | Loss: 0.04142234353697709\n",
            "Epoch: 49 | Batch: 1469 | Loss: 0.03286798860417821\n",
            "Epoch: 49 | Batch: 1470 | Loss: 0.06499484770884528\n",
            "Epoch: 49 | Batch: 1471 | Loss: 0.05513752331011039\n",
            "Epoch: 49 | Batch: 1472 | Loss: 0.059174381106427525\n",
            "Epoch: 49 | Batch: 1473 | Loss: 0.0669835357135043\n",
            "Epoch: 49 | Batch: 1474 | Loss: 0.05183056941544874\n",
            "Epoch: 49 | Batch: 1475 | Loss: 0.06392290486652462\n",
            "Epoch: 49 | Batch: 1476 | Loss: 0.0638767005213328\n",
            "Epoch: 49 | Batch: 1477 | Loss: 0.0852975753147973\n",
            "Epoch: 49 | Batch: 1478 | Loss: 0.04384887295519382\n",
            "Epoch: 49 | Batch: 1479 | Loss: 0.061006625950387416\n",
            "Epoch: 49 | Batch: 1480 | Loss: 0.046215046754090876\n",
            "Epoch: 49 | Batch: 1481 | Loss: 0.08221171467579985\n",
            "Epoch: 49 | Batch: 1482 | Loss: 0.0629666125505482\n",
            "Epoch: 49 | Batch: 1483 | Loss: 0.05843142152776229\n",
            "Epoch: 49 | Batch: 1484 | Loss: 0.04585083680751803\n",
            "Epoch: 49 | Batch: 1485 | Loss: 0.0522005326962728\n",
            "Epoch: 49 | Batch: 1486 | Loss: 0.06806639821315884\n",
            "Epoch: 49 | Batch: 1487 | Loss: 0.06281301549938122\n",
            "Epoch: 49 | Batch: 1488 | Loss: 0.13096356391402594\n",
            "Epoch: 49 | Batch: 1489 | Loss: 0.07807362607145352\n",
            "Epoch: 49 | Batch: 1490 | Loss: 0.06392116152919405\n",
            "Epoch: 49 | Batch: 1491 | Loss: 0.06441478395412978\n",
            "Epoch: 49 | Batch: 1492 | Loss: 0.10614122566859072\n",
            "Epoch: 49 | Batch: 1493 | Loss: 0.08728685813259038\n",
            "Epoch: 49 | Batch: 1494 | Loss: 0.05113346903658615\n",
            "Epoch: 49 | Batch: 1495 | Loss: 0.06368683351989532\n",
            "Epoch: 49 | Batch: 1496 | Loss: 0.06405740003611723\n",
            "Epoch: 49 | Batch: 1497 | Loss: 0.04765612545574572\n",
            "Epoch: 49 | Batch: 1498 | Loss: 0.09132173526583964\n",
            "Epoch: 49 | Batch: 1499 | Loss: 0.03801633744778945\n",
            "Epoch: 49 | Batch: 1500 | Loss: 0.0483620589534275\n",
            "Epoch: 49 | Batch: 1501 | Loss: 0.046314840176078245\n",
            "Epoch: 49 | Batch: 1502 | Loss: 0.05292410434484128\n",
            "Epoch: 49 | Batch: 1503 | Loss: 0.08685877251433496\n",
            "Epoch: 49 | Batch: 1504 | Loss: 0.05394433011808462\n",
            "Epoch: 49 | Batch: 1505 | Loss: 0.07224060289115695\n",
            "Epoch: 49 | Batch: 1506 | Loss: 0.04801884791061248\n",
            "Epoch: 49 | Batch: 1507 | Loss: 0.07927628787604775\n",
            "Epoch: 49 | Batch: 1508 | Loss: 0.05088744223424142\n",
            "Epoch: 49 | Batch: 1509 | Loss: 0.04099440936769706\n",
            "Epoch: 49 | Batch: 1510 | Loss: 0.08066220876472972\n",
            "Epoch: 49 | Batch: 1511 | Loss: 0.06454389795561856\n",
            "Epoch: 49 | Batch: 1512 | Loss: 0.06562308298589609\n",
            "Epoch: 49 | Batch: 1513 | Loss: 0.07002225701384401\n",
            "Epoch: 49 | Batch: 1514 | Loss: 0.0491289782385098\n",
            "Epoch: 49 | Batch: 1515 | Loss: 0.05626353350955066\n",
            "Epoch: 49 | Batch: 1516 | Loss: 0.05402629176296571\n",
            "Epoch: 49 | Batch: 1517 | Loss: 0.07654392671803342\n",
            "Epoch: 49 | Batch: 1518 | Loss: 0.06362432230654433\n",
            "Epoch: 49 | Batch: 1519 | Loss: 0.05514526794142591\n",
            "Epoch: 49 | Batch: 1520 | Loss: 0.062279597344474566\n",
            "Epoch: 49 | Batch: 1521 | Loss: 0.06499046006291123\n",
            "Epoch: 49 | Batch: 1522 | Loss: 0.05867962015703895\n",
            "Epoch: 49 | Batch: 1523 | Loss: 0.07088876092496094\n",
            "Epoch: 49 | Batch: 1524 | Loss: 0.05960732030078512\n",
            "Epoch: 49 | Batch: 1525 | Loss: 0.043805266034423064\n",
            "Epoch: 49 | Batch: 1526 | Loss: 0.051377604038083405\n",
            "Epoch: 49 | Batch: 1527 | Loss: 0.05587775255837533\n",
            "Epoch: 49 | Batch: 1528 | Loss: 0.056598920266866234\n",
            "Epoch: 49 | Batch: 1529 | Loss: 0.06145591842520277\n",
            "Epoch: 49 | Batch: 1530 | Loss: 0.04568169669439635\n",
            "Epoch: 49 | Batch: 1531 | Loss: 0.06479275935881643\n",
            "Epoch: 49 | Batch: 1532 | Loss: 0.06142263443718679\n",
            "Epoch: 49 | Batch: 1533 | Loss: 0.029019090086882977\n",
            "Epoch: 49 | Batch: 1534 | Loss: 0.061666609887212\n",
            "Epoch: 49 | Batch: 1535 | Loss: 0.05024447769794525\n",
            "Epoch: 49 | Batch: 1536 | Loss: 0.06251546326994276\n",
            "Epoch: 49 | Batch: 1537 | Loss: 0.06838106985631645\n",
            "Epoch: 49 | Batch: 1538 | Loss: 0.06940890005190406\n",
            "Epoch: 49 | Batch: 1539 | Loss: 0.07495087985329349\n",
            "Epoch: 49 | Batch: 1540 | Loss: 0.08167173242329517\n",
            "Epoch: 49 | Batch: 1541 | Loss: 0.046480475069702855\n",
            "Epoch: 49 | Batch: 1542 | Loss: 0.05785711590634788\n",
            "Epoch: 49 | Batch: 1543 | Loss: 0.08092787344422674\n",
            "Epoch: 49 | Batch: 1544 | Loss: 0.06473775306177858\n",
            "Epoch: 49 | Batch: 1545 | Loss: 0.04889745330421392\n",
            "Epoch: 49 | Batch: 1546 | Loss: 0.10650137884755323\n",
            "Epoch: 49 | Batch: 1547 | Loss: 0.07807521538754575\n",
            "Epoch: 49 | Batch: 1548 | Loss: 0.0681194307715743\n",
            "Epoch: 49 | Batch: 1549 | Loss: 0.1560561493429254\n",
            "Epoch: 49 | Batch: 1550 | Loss: 0.057966001863036375\n",
            "Epoch: 49 | Batch: 1551 | Loss: 0.07241229372547234\n",
            "Epoch: 49 | Batch: 1552 | Loss: 0.05509815280663559\n",
            "Epoch: 49 | Batch: 1553 | Loss: 0.08563296943674853\n",
            "Epoch: 49 | Batch: 1554 | Loss: 0.050155692160294474\n",
            "Epoch: 49 | Batch: 1555 | Loss: 0.08952282304349052\n",
            "Epoch: 49 | Batch: 1556 | Loss: 0.08995563039565607\n",
            "Epoch: 49 | Batch: 1557 | Loss: 0.04751495291581606\n",
            "Epoch: 49 | Batch: 1558 | Loss: 0.06171152754790973\n",
            "Epoch: 49 | Batch: 1559 | Loss: 0.05548823527884079\n",
            "Epoch: 49 | Batch: 1560 | Loss: 0.07184670936062727\n",
            "Epoch: 49 | Batch: 1561 | Loss: 0.04042140033281333\n",
            "Epoch: 49 | Batch: 1562 | Loss: 0.05147493485415483\n",
            "Epoch: 49 | Batch: 1563 | Loss: 0.05979971930074809\n",
            "Epoch: 49 | Batch: 1564 | Loss: 0.07987373479252885\n",
            "Epoch: 49 | Batch: 1565 | Loss: 0.044447052138999577\n",
            "Epoch: 49 | Batch: 1566 | Loss: 0.06689944659099585\n",
            "Epoch: 49 | Batch: 1567 | Loss: 0.06152012710235804\n",
            "Epoch: 49 | Batch: 1568 | Loss: 0.07321956552565782\n",
            "Epoch: 49 | Batch: 1569 | Loss: 0.0854680417156374\n",
            "Epoch: 49 | Batch: 1570 | Loss: 0.06237206261874236\n",
            "Epoch: 49 | Batch: 1571 | Loss: 0.07186226178248677\n",
            "Epoch: 49 | Batch: 1572 | Loss: 0.08800947384568401\n",
            "Epoch: 49 | Batch: 1573 | Loss: 0.044446128848871044\n",
            "Epoch: 49 | Batch: 1574 | Loss: 0.07056250343705395\n",
            "Epoch: 49 | Batch: 1575 | Loss: 0.07592030903904459\n",
            "Epoch: 49 | Batch: 1576 | Loss: 0.060915145147861144\n",
            "Epoch: 49 | Batch: 1577 | Loss: 0.05172715716538208\n",
            "Epoch: 49 | Batch: 1578 | Loss: 0.044931663165909755\n",
            "Epoch: 49 | Batch: 1579 | Loss: 0.04887253996410691\n",
            "Epoch: 49 | Batch: 1580 | Loss: 0.05459392801045586\n",
            "Epoch: 49 | Batch: 1581 | Loss: 0.05256625104001503\n",
            "Epoch: 49 | Batch: 1582 | Loss: 0.07071965832505415\n",
            "Epoch: 49 | Batch: 1583 | Loss: 0.060092831874355365\n",
            "Epoch: 49 | Batch: 1584 | Loss: 0.03898424679416242\n",
            "Epoch: 49 | Batch: 1585 | Loss: 0.043630842900910786\n",
            "Epoch: 49 | Batch: 1586 | Loss: 0.08997683894309358\n",
            "Epoch: 49 | Batch: 1587 | Loss: 0.0766345180465301\n",
            "Epoch: 49 | Batch: 1588 | Loss: 0.05897465233909763\n",
            "Epoch: 49 | Batch: 1589 | Loss: 0.06472592179714161\n",
            "Epoch: 49 | Batch: 1590 | Loss: 0.07569015539844921\n",
            "Epoch: 49 | Batch: 1591 | Loss: 0.038884707990703385\n",
            "Epoch: 49 | Batch: 1592 | Loss: 0.07109333053934123\n",
            "Epoch: 49 | Batch: 1593 | Loss: 0.04788932336363679\n",
            "Epoch: 49 | Batch: 1594 | Loss: 0.04939754126705602\n",
            "Epoch: 49 | Batch: 1595 | Loss: 0.1277981670077118\n",
            "Epoch: 49 | Batch: 1596 | Loss: 0.05872752502924116\n",
            "Epoch: 49 | Batch: 1597 | Loss: 0.07644895747433014\n",
            "Epoch: 49 | Batch: 1598 | Loss: 0.059265547754165177\n",
            "Epoch: 49 | Batch: 1599 | Loss: 0.060846380816318255\n",
            "Epoch: 49 | Batch: 1600 | Loss: 0.06301299752440476\n",
            "Epoch: 49 | Batch: 1601 | Loss: 0.08671791755887502\n",
            "Epoch: 49 | Batch: 1602 | Loss: 0.06556998076594453\n",
            "Epoch: 49 | Batch: 1603 | Loss: 0.052527777350168954\n",
            "Epoch: 49 | Batch: 1604 | Loss: 0.07099914787393444\n",
            "Epoch: 49 | Batch: 1605 | Loss: 0.06620642816943317\n",
            "Epoch: 49 | Batch: 1606 | Loss: 0.06721836173624716\n",
            "Epoch: 49 | Batch: 1607 | Loss: 0.08526731179710408\n",
            "Epoch: 49 | Batch: 1608 | Loss: 0.04430234101817858\n",
            "Epoch: 49 | Batch: 1609 | Loss: 0.059243958286509545\n",
            "Epoch: 49 | Batch: 1610 | Loss: 0.06077721613857308\n",
            "Epoch: 49 | Batch: 1611 | Loss: 0.08721128241593405\n",
            "Epoch: 49 | Batch: 1612 | Loss: 0.06033678718455851\n",
            "Epoch: 49 | Batch: 1613 | Loss: 0.06129911100612134\n",
            "Epoch: 49 | Batch: 1614 | Loss: 0.04636193149725483\n",
            "Epoch: 49 | Batch: 1615 | Loss: 0.04759351770551496\n",
            "Epoch: 49 | Batch: 1616 | Loss: 0.039358150789703235\n",
            "Epoch: 49 | Batch: 1617 | Loss: 0.052734045636902\n",
            "Epoch: 49 | Batch: 1618 | Loss: 0.050670777814821294\n",
            "Epoch: 49 | Batch: 1619 | Loss: 0.05765054544097115\n",
            "Epoch: 49 | Batch: 1620 | Loss: 0.0909346554021213\n",
            "Epoch: 49 | Batch: 1621 | Loss: 0.06705552567585668\n",
            "Epoch: 49 | Batch: 1622 | Loss: 0.07854430774033293\n",
            "Epoch: 49 | Batch: 1623 | Loss: 0.11902820436681319\n",
            "Epoch: 49 | Batch: 1624 | Loss: 0.06702242216981918\n",
            "Epoch: 49 | Batch: 1625 | Loss: 0.03781539787741588\n",
            "Epoch: 49 | Batch: 1626 | Loss: 0.06482944508329239\n",
            "Epoch: 49 | Batch: 1627 | Loss: 0.05771864118841049\n",
            "Epoch: 49 | Batch: 1628 | Loss: 0.07789221541651536\n",
            "Epoch: 49 | Batch: 1629 | Loss: 0.07375053215913369\n",
            "Epoch: 49 | Batch: 1630 | Loss: 0.05501814101695137\n",
            "Epoch: 49 | Batch: 1631 | Loss: 0.05902513828898027\n",
            "Epoch: 49 | Batch: 1632 | Loss: 0.07264623901594154\n",
            "Epoch: 49 | Batch: 1633 | Loss: 0.051002344369031706\n",
            "Epoch: 49 | Batch: 1634 | Loss: 0.04012660016085018\n",
            "Epoch: 49 | Batch: 1635 | Loss: 0.0615624035158242\n",
            "Epoch: 49 | Batch: 1636 | Loss: 0.036067263179206804\n",
            "Epoch: 49 | Batch: 1637 | Loss: 0.06036429553005987\n",
            "Epoch: 49 | Batch: 1638 | Loss: 0.06473107610604291\n",
            "Epoch: 49 | Batch: 1639 | Loss: 0.06066853936942658\n",
            "Epoch: 49 | Batch: 1640 | Loss: 0.04326819314869961\n",
            "Epoch: 49 | Batch: 1641 | Loss: 0.07704988869416322\n",
            "Epoch: 49 | Batch: 1642 | Loss: 0.0428885797431339\n",
            "Epoch: 49 | Batch: 1643 | Loss: 0.07580610282101888\n",
            "Epoch: 49 | Batch: 1644 | Loss: 0.05009985932497696\n",
            "Epoch: 49 | Batch: 1645 | Loss: 0.03854338728289215\n",
            "Epoch: 49 | Batch: 1646 | Loss: 0.05020480522227512\n",
            "Epoch: 49 | Batch: 1647 | Loss: 0.0859161085325823\n",
            "Epoch: 49 | Batch: 1648 | Loss: 0.05809675926660829\n",
            "Epoch: 49 | Batch: 1649 | Loss: 0.06385247878612603\n",
            "Epoch: 49 | Batch: 1650 | Loss: 0.05013920688824375\n",
            "Epoch: 49 | Batch: 1651 | Loss: 0.04438201520510256\n",
            "Epoch: 49 | Batch: 1652 | Loss: 0.04650757602787109\n",
            "Epoch: 49 | Batch: 1653 | Loss: 0.046049746024011316\n",
            "Epoch: 49 | Batch: 1654 | Loss: 0.07892855469954996\n",
            "Epoch: 49 | Batch: 1655 | Loss: 0.04529456634952117\n",
            "Epoch: 49 | Batch: 1656 | Loss: 0.03148028554735181\n",
            "Epoch: 49 | Batch: 1657 | Loss: 0.04866427019270882\n",
            "Epoch: 49 | Batch: 1658 | Loss: 0.05667537853734303\n",
            "Epoch: 49 | Batch: 1659 | Loss: 0.07523077394917162\n",
            "Epoch: 49 | Batch: 1660 | Loss: 0.0609435419025246\n",
            "Epoch: 49 | Batch: 1661 | Loss: 0.07197332134836956\n",
            "Epoch: 49 | Batch: 1662 | Loss: 0.09222851180359581\n",
            "Epoch: 49 | Batch: 1663 | Loss: 0.07646498330519022\n",
            "Epoch: 49 | Batch: 1664 | Loss: 0.06886338452911028\n",
            "Epoch: 49 | Batch: 1665 | Loss: 0.04282665643803989\n",
            "Epoch: 49 | Batch: 1666 | Loss: 0.04786654556733633\n",
            "Epoch: 49 | Batch: 1667 | Loss: 0.06217720973201918\n",
            "Epoch: 49 | Batch: 1668 | Loss: 0.05173326039094328\n",
            "Epoch: 49 | Batch: 1669 | Loss: 0.0489752078866496\n",
            "Epoch: 49 | Batch: 1670 | Loss: 0.0410309843530096\n",
            "Epoch: 49 | Batch: 1671 | Loss: 0.07217315608834286\n",
            "Epoch: 49 | Batch: 1672 | Loss: 0.04701333939269918\n",
            "Epoch: 49 | Batch: 1673 | Loss: 0.06759046303084011\n",
            "Epoch: 49 | Batch: 1674 | Loss: 0.0615819040589313\n",
            "Epoch: 49 | Batch: 1675 | Loss: 0.058792429010694536\n",
            "Epoch: 49 | Batch: 1676 | Loss: 0.036890122361434484\n",
            "Epoch: 49 | Batch: 1677 | Loss: 0.05763888262098643\n",
            "Epoch: 49 | Batch: 1678 | Loss: 0.0910557223378117\n",
            "Epoch: 49 | Batch: 1679 | Loss: 0.063670409071197\n",
            "Epoch: 49 | Batch: 1680 | Loss: 0.05024320612563377\n",
            "Epoch: 49 | Batch: 1681 | Loss: 0.039346469439327986\n",
            "Epoch: 49 | Batch: 1682 | Loss: 0.06107476290299316\n",
            "Epoch: 49 | Batch: 1683 | Loss: 0.03458513473613568\n",
            "Epoch: 49 | Batch: 1684 | Loss: 0.05555978435577448\n",
            "Epoch: 49 | Batch: 1685 | Loss: 0.07321893436012399\n",
            "Epoch: 49 | Batch: 1686 | Loss: 0.03712978032561516\n",
            "Epoch: 49 | Batch: 1687 | Loss: 0.07367384966079958\n",
            "Epoch: 49 | Batch: 1688 | Loss: 0.03544086910350804\n",
            "Epoch: 49 | Batch: 1689 | Loss: 0.08322984039887625\n",
            "Epoch: 49 | Batch: 1690 | Loss: 0.050381740719812745\n",
            "Epoch: 49 | Batch: 1691 | Loss: 0.04056916602785218\n",
            "Epoch: 49 | Batch: 1692 | Loss: 0.07358962978835869\n",
            "Epoch: 49 | Batch: 1693 | Loss: 0.046640929620080845\n",
            "Epoch: 49 | Batch: 1694 | Loss: 0.04932997460867301\n",
            "Epoch: 49 | Batch: 1695 | Loss: 0.07553711293970616\n",
            "Epoch: 49 | Batch: 1696 | Loss: 0.07116337965534514\n",
            "Epoch: 49 | Batch: 1697 | Loss: 0.06140490780607081\n",
            "Epoch: 49 | Batch: 1698 | Loss: 0.07960389241811705\n",
            "Epoch: 49 | Batch: 1699 | Loss: 0.05893552895734045\n",
            "Epoch: 49 | Batch: 1700 | Loss: 0.04718168430521372\n",
            "Epoch: 49 | Batch: 1701 | Loss: 0.049310684835169614\n",
            "Epoch: 49 | Batch: 1702 | Loss: 0.06067195842462722\n",
            "Epoch: 49 | Batch: 1703 | Loss: 0.06705898630959832\n",
            "Epoch: 49 | Batch: 1704 | Loss: 0.09465409379647208\n",
            "Epoch: 49 | Batch: 1705 | Loss: 0.06747161933684925\n",
            "Epoch: 49 | Batch: 1706 | Loss: 0.05165868935900949\n",
            "Epoch: 49 | Batch: 1707 | Loss: 0.06394233480008973\n",
            "Epoch: 49 | Batch: 1708 | Loss: 0.0632970126749252\n",
            "Epoch: 49 | Batch: 1709 | Loss: 0.08209210092576334\n",
            "Epoch: 49 | Batch: 1710 | Loss: 0.05366368053865727\n",
            "Epoch: 49 | Batch: 1711 | Loss: 0.04506520651654994\n",
            "Epoch: 49 | Batch: 1712 | Loss: 0.07021201170301225\n",
            "Epoch: 49 | Batch: 1713 | Loss: 0.09496595187431617\n",
            "Epoch: 49 | Batch: 1714 | Loss: 0.05107368738023246\n",
            "Epoch: 49 | Batch: 1715 | Loss: 0.05381623368234093\n",
            "Epoch: 49 | Batch: 1716 | Loss: 0.06383961983726741\n",
            "Epoch: 49 | Batch: 1717 | Loss: 0.07886356636706582\n",
            "Epoch: 49 | Batch: 1718 | Loss: 0.06802488170152386\n",
            "Epoch: 49 | Batch: 1719 | Loss: 0.042277219958357704\n",
            "Epoch: 49 | Batch: 1720 | Loss: 0.10877955975982151\n",
            "Epoch: 49 | Batch: 1721 | Loss: 0.049396158875956886\n",
            "Epoch: 49 | Batch: 1722 | Loss: 0.06915904946096052\n",
            "Epoch: 49 | Batch: 1723 | Loss: 0.11791679319384091\n",
            "Epoch: 49 | Batch: 1724 | Loss: 0.05068754424837837\n",
            "Epoch: 49 | Batch: 1725 | Loss: 0.07229687589074235\n",
            "Epoch: 49 | Batch: 1726 | Loss: 0.05978735105299343\n",
            "Epoch: 49 | Batch: 1727 | Loss: 0.045931959059437415\n",
            "Epoch: 49 | Batch: 1728 | Loss: 0.047783987410346174\n",
            "Epoch: 49 | Batch: 1729 | Loss: 0.0733741960351633\n",
            "Epoch: 49 | Batch: 1730 | Loss: 0.04966736942120914\n",
            "Epoch: 49 | Batch: 1731 | Loss: 0.04262587918450035\n",
            "Epoch: 49 | Batch: 1732 | Loss: 0.05400945209779075\n",
            "Epoch: 49 | Batch: 1733 | Loss: 0.06364931218746792\n",
            "Epoch: 49 | Batch: 1734 | Loss: 0.056814708220399524\n",
            "Epoch: 49 | Batch: 1735 | Loss: 0.05813652269191846\n",
            "Epoch: 49 | Batch: 1736 | Loss: 0.04109139326520938\n",
            "Epoch: 49 | Batch: 1737 | Loss: 0.07239270111061682\n",
            "Epoch: 49 | Batch: 1738 | Loss: 0.035505870763494235\n",
            "Epoch: 49 | Batch: 1739 | Loss: 0.06252931494239373\n",
            "Epoch: 49 | Batch: 1740 | Loss: 0.07709517634443054\n",
            "Epoch: 49 | Batch: 1741 | Loss: 0.05108061401747847\n",
            "Epoch: 49 | Batch: 1742 | Loss: 0.05758198945365338\n",
            "Epoch: 49 | Batch: 1743 | Loss: 0.06839287596771468\n",
            "Epoch: 49 | Batch: 1744 | Loss: 0.08723600505626944\n",
            "Epoch: 49 | Batch: 1745 | Loss: 0.07074036670700981\n",
            "Epoch: 49 | Batch: 1746 | Loss: 0.04099337252310145\n",
            "Epoch: 49 | Batch: 1747 | Loss: 0.03549941769732369\n",
            "Epoch: 49 | Batch: 1748 | Loss: 0.07892421877177884\n",
            "Epoch: 49 | Batch: 1749 | Loss: 0.07015755178666686\n",
            "Epoch: 49 | Batch: 1750 | Loss: 0.058808280487989764\n",
            "Epoch: 49 | Batch: 1751 | Loss: 0.06553555251697776\n",
            "Epoch: 49 | Batch: 1752 | Loss: 0.05917787930715828\n",
            "Epoch: 49 | Batch: 1753 | Loss: 0.05362839268972631\n",
            "Epoch: 49 | Batch: 1754 | Loss: 0.06254571660794402\n",
            "Epoch: 49 | Batch: 1755 | Loss: 0.054328196984342436\n",
            "Epoch: 49 | Batch: 1756 | Loss: 0.04867456883971612\n",
            "Epoch: 49 | Batch: 1757 | Loss: 0.06038841441719672\n",
            "Epoch: 49 | Batch: 1758 | Loss: 0.04038843517848957\n",
            "Epoch: 49 | Batch: 1759 | Loss: 0.07123056005830858\n",
            "Epoch: 49 | Batch: 1760 | Loss: 0.05146495363601689\n",
            "Epoch: 49 | Batch: 1761 | Loss: 0.09450524303573908\n",
            "Epoch: 49 | Batch: 1762 | Loss: 0.04767842110713488\n",
            "Epoch: 49 | Batch: 1763 | Loss: 0.04024463885046757\n",
            "Epoch: 49 | Batch: 1764 | Loss: 0.04532883038121661\n",
            "Epoch: 49 | Batch: 1765 | Loss: 0.07172352082140512\n",
            "Epoch: 49 | Batch: 1766 | Loss: 0.0527393184706232\n",
            "Epoch: 49 | Batch: 1767 | Loss: 0.0602161060693277\n",
            "Epoch: 49 | Batch: 1768 | Loss: 0.06114620114019205\n",
            "Epoch: 49 | Batch: 1769 | Loss: 0.0538195075875104\n",
            "Epoch: 49 | Batch: 1770 | Loss: 0.055050024125473926\n",
            "Epoch: 49 | Batch: 1771 | Loss: 0.0549287149934623\n",
            "Epoch: 49 | Batch: 1772 | Loss: 0.06279175974302974\n",
            "Epoch: 49 | Batch: 1773 | Loss: 0.0527509527762513\n",
            "Epoch: 49 | Batch: 1774 | Loss: 0.05832724815500366\n",
            "Epoch: 49 | Batch: 1775 | Loss: 0.053585059339596564\n",
            "Epoch: 49 | Batch: 1776 | Loss: 0.03970240722856315\n",
            "Epoch: 49 | Batch: 1777 | Loss: 0.05458692237140789\n",
            "Epoch: 49 | Batch: 1778 | Loss: 0.04631401643171032\n",
            "Epoch: 49 | Batch: 1779 | Loss: 0.05164893805649888\n",
            "Epoch: 49 | Batch: 1780 | Loss: 0.055306534985660155\n",
            "Epoch: 49 | Batch: 1781 | Loss: 0.060862095374929336\n",
            "Epoch: 49 | Batch: 1782 | Loss: 0.069374394041501\n",
            "Epoch: 49 | Batch: 1783 | Loss: 0.05605794311652368\n",
            "Epoch: 49 | Batch: 1784 | Loss: 0.03393874078457578\n",
            "Epoch: 49 | Batch: 1785 | Loss: 0.062212494038900404\n",
            "Epoch: 49 | Batch: 1786 | Loss: 0.058235973034553246\n",
            "Epoch: 49 | Batch: 1787 | Loss: 0.03911937744963414\n",
            "Epoch: 49 | Batch: 1788 | Loss: 0.04976759310143286\n",
            "Epoch: 49 | Batch: 1789 | Loss: 0.05683743464054192\n",
            "Epoch: 49 | Batch: 1790 | Loss: 0.03467378630368319\n",
            "Epoch: 49 | Batch: 1791 | Loss: 0.052902440594970054\n",
            "Epoch: 49 | Batch: 1792 | Loss: 0.060462470103270986\n",
            "Epoch: 49 | Batch: 1793 | Loss: 0.046376628892298606\n",
            "Epoch: 49 | Batch: 1794 | Loss: 0.060738857421538936\n",
            "Epoch: 49 | Batch: 1795 | Loss: 0.05498642692632423\n",
            "Epoch: 49 | Batch: 1796 | Loss: 0.08335653850522459\n",
            "Epoch: 49 | Batch: 1797 | Loss: 0.0683306704636305\n",
            "Epoch: 49 | Batch: 1798 | Loss: 0.04709943392016739\n",
            "Epoch: 49 | Batch: 1799 | Loss: 0.052135898416966454\n",
            "Epoch: 49 | Batch: 1800 | Loss: 0.0482651352761566\n",
            "Epoch: 49 | Batch: 1801 | Loss: 0.047989698094116365\n",
            "Epoch: 49 | Batch: 1802 | Loss: 0.09167266597820556\n",
            "Epoch: 49 | Batch: 1803 | Loss: 0.055699301461224024\n",
            "Epoch: 49 | Batch: 1804 | Loss: 0.055200403589493845\n",
            "Epoch: 49 | Batch: 1805 | Loss: 0.05227823158098169\n",
            "Epoch: 49 | Batch: 1806 | Loss: 0.053092047130708496\n",
            "Epoch: 49 | Batch: 1807 | Loss: 0.05905036729552525\n",
            "Epoch: 49 | Batch: 1808 | Loss: 0.06361498119187034\n",
            "Epoch: 49 | Batch: 1809 | Loss: 0.06120600221749359\n",
            "Epoch: 49 | Batch: 1810 | Loss: 0.05719034544201644\n",
            "Epoch: 49 | Batch: 1811 | Loss: 0.07377431740876679\n",
            "Epoch: 49 | Batch: 1812 | Loss: 0.055666113905848316\n",
            "Epoch: 49 | Batch: 1813 | Loss: 0.05172316809233095\n",
            "Epoch: 49 | Batch: 1814 | Loss: 0.04519592415142305\n",
            "Epoch: 49 | Batch: 1815 | Loss: 0.06442381745766744\n",
            "Epoch: 49 | Batch: 1816 | Loss: 0.04366320828079763\n",
            "Epoch: 49 | Batch: 1817 | Loss: 0.062097306117694526\n",
            "Epoch: 49 | Batch: 1818 | Loss: 0.052494761794562486\n",
            "Epoch: 49 | Batch: 1819 | Loss: 0.05467345049164181\n",
            "Epoch: 49 | Batch: 1820 | Loss: 0.05007097390891653\n",
            "Epoch: 49 | Batch: 1821 | Loss: 0.03761542385947056\n",
            "Epoch: 49 | Batch: 1822 | Loss: 0.06952016356454278\n",
            "Epoch: 49 | Batch: 1823 | Loss: 0.07014566459793892\n",
            "Epoch: 49 | Batch: 1824 | Loss: 0.052860917548479075\n",
            "Epoch: 49 | Batch: 1825 | Loss: 0.05904385301485736\n",
            "Epoch: 49 | Batch: 1826 | Loss: 0.06777676771937494\n",
            "Epoch: 49 | Batch: 1827 | Loss: 0.0501943204424055\n",
            "Epoch: 49 | Batch: 1828 | Loss: 0.09014007900656254\n",
            "Epoch: 49 | Batch: 1829 | Loss: 0.07275231556189862\n",
            "Epoch: 49 | Batch: 1830 | Loss: 0.06374601401229373\n",
            "Epoch: 49 | Batch: 1831 | Loss: 0.08266151916635739\n",
            "Epoch: 49 | Batch: 1832 | Loss: 0.04795336831233145\n",
            "Epoch: 49 | Batch: 1833 | Loss: 0.06674607906603419\n",
            "Epoch: 49 | Batch: 1834 | Loss: 0.04773463128154726\n",
            "Epoch: 49 | Batch: 1835 | Loss: 0.05269085196287948\n",
            "Epoch: 49 | Batch: 1836 | Loss: 0.052639416962331834\n",
            "Epoch: 49 | Batch: 1837 | Loss: 0.08701202524714771\n",
            "Epoch: 49 | Batch: 1838 | Loss: 0.08505246200070868\n",
            "Epoch: 49 | Batch: 1839 | Loss: 0.04518394167013658\n",
            "Epoch: 49 | Batch: 1840 | Loss: 0.06290791098298104\n",
            "Epoch: 49 | Batch: 1841 | Loss: 0.0682465254879127\n",
            "Epoch: 49 | Batch: 1842 | Loss: 0.04895353631197573\n",
            "Epoch: 49 | Batch: 1843 | Loss: 0.07716805410861906\n",
            "Epoch: 49 | Batch: 1844 | Loss: 0.06479311986300022\n",
            "Epoch: 49 | Batch: 1845 | Loss: 0.05375972479963569\n",
            "Epoch: 49 | Batch: 1846 | Loss: 0.07428111903994886\n",
            "Epoch: 49 | Batch: 1847 | Loss: 0.040559101489531485\n",
            "Epoch: 49 | Batch: 1848 | Loss: 0.08770097103862506\n",
            "Epoch: 49 | Batch: 1849 | Loss: 0.053020037174992\n",
            "Epoch: 49 | Batch: 1850 | Loss: 0.05754438071773921\n",
            "Epoch: 49 | Batch: 1851 | Loss: 0.046872936394992154\n",
            "Epoch: 49 | Batch: 1852 | Loss: 0.06337801653266144\n",
            "Epoch: 49 | Batch: 1853 | Loss: 0.04568257058619814\n",
            "Epoch: 49 | Batch: 1854 | Loss: 0.041699703155550244\n",
            "Epoch: 49 | Batch: 1855 | Loss: 0.061512666724168955\n",
            "Epoch: 49 | Batch: 1856 | Loss: 0.07604510973514488\n",
            "Epoch: 49 | Batch: 1857 | Loss: 0.04377326088204831\n",
            "Epoch: 49 | Batch: 1858 | Loss: 0.05903789089303886\n",
            "Epoch: 49 | Batch: 1859 | Loss: 0.09074915731171213\n",
            "Epoch: 49 | Batch: 1860 | Loss: 0.04141176736974908\n",
            "Epoch: 49 | Batch: 1861 | Loss: 0.05794194987558229\n",
            "Epoch: 49 | Batch: 1862 | Loss: 0.05421300252818982\n",
            "Epoch: 49 | Batch: 1863 | Loss: 0.03912728607537755\n",
            "Epoch: 49 | Batch: 1864 | Loss: 0.038054142717941976\n",
            "Epoch: 49 | Batch: 1865 | Loss: 0.06429977733964605\n",
            "Epoch: 49 | Batch: 1866 | Loss: 0.0390213929454508\n",
            "Epoch: 49 | Batch: 1867 | Loss: 0.04718123221271939\n",
            "Epoch: 49 | Batch: 1868 | Loss: 0.06101335978450008\n",
            "Epoch: 49 | Batch: 1869 | Loss: 0.06045151758578213\n",
            "Epoch: 49 | Batch: 1870 | Loss: 0.056728304806452544\n",
            "Epoch: 49 | Batch: 1871 | Loss: 0.061869084969642774\n",
            "Epoch: 49 | Batch: 1872 | Loss: 0.04691704916986368\n",
            "Epoch: 49 | Batch: 1873 | Loss: 0.033354105330982264\n",
            "Epoch: 49 | Batch: 1874 | Loss: 0.06022758296292693\n",
            "Epoch: 49 | Batch: 1875 | Loss: 0.06659525562501235\n",
            "Epoch: 49 | Batch: 1876 | Loss: 0.08353617567767906\n",
            "Epoch: 49 | Batch: 1877 | Loss: 0.051975060907098344\n",
            "Epoch: 49 | Batch: 1878 | Loss: 0.06423152739642227\n",
            "Epoch: 49 | Batch: 1879 | Loss: 0.09752284833771382\n",
            "Epoch: 49 | Batch: 1880 | Loss: 0.05219686641794353\n",
            "Epoch: 49 | Batch: 1881 | Loss: 0.05283992875633991\n",
            "Epoch: 49 | Batch: 1882 | Loss: 0.0592069551463907\n",
            "Epoch: 49 | Batch: 1883 | Loss: 0.06438846967837948\n",
            "Epoch: 49 | Batch: 1884 | Loss: 0.051295632211169506\n",
            "Epoch: 49 | Batch: 1885 | Loss: 0.09739110270686448\n",
            "Epoch: 49 | Batch: 1886 | Loss: 0.04369216779644779\n",
            "Epoch: 49 | Batch: 1887 | Loss: 0.0482874203317747\n",
            "Epoch: 49 | Batch: 1888 | Loss: 0.03771026342344888\n",
            "Epoch: 49 | Batch: 1889 | Loss: 0.04222048873393726\n",
            "Epoch: 49 | Batch: 1890 | Loss: 0.04706842755363492\n",
            "Epoch: 49 | Batch: 1891 | Loss: 0.07917463630733286\n",
            "Epoch: 49 | Batch: 1892 | Loss: 0.06329449445564625\n",
            "Epoch: 49 | Batch: 1893 | Loss: 0.05044707320987054\n",
            "Epoch: 49 | Batch: 1894 | Loss: 0.06711430890924984\n",
            "Epoch: 49 | Batch: 1895 | Loss: 0.0670832394165596\n",
            "Epoch: 49 | Batch: 1896 | Loss: 0.059577082563195986\n",
            "Epoch: 49 | Batch: 1897 | Loss: 0.06132851634703923\n",
            "Epoch: 49 | Batch: 1898 | Loss: 0.08651973252644268\n",
            "Epoch: 49 | Batch: 1899 | Loss: 0.048360120383049224\n",
            "Epoch: 49 | Batch: 1900 | Loss: 0.07516745607351083\n",
            "Epoch: 49 | Batch: 1901 | Loss: 0.04678913260839457\n",
            "Epoch: 49 | Batch: 1902 | Loss: 0.03204877068306354\n",
            "Epoch: 49 | Batch: 1903 | Loss: 0.04573408720613388\n",
            "Epoch: 49 | Batch: 1904 | Loss: 0.06766692156081675\n",
            "Epoch: 49 | Batch: 1905 | Loss: 0.06488882248074532\n",
            "Epoch: 49 | Batch: 1906 | Loss: 0.06889692910842989\n",
            "Epoch: 49 | Batch: 1907 | Loss: 0.06329970569220744\n",
            "Epoch: 49 | Batch: 1908 | Loss: 0.08450562162116096\n",
            "Epoch: 49 | Batch: 1909 | Loss: 0.07361239333096749\n",
            "Epoch: 49 | Batch: 1910 | Loss: 0.04202457103664747\n",
            "Epoch: 49 | Batch: 1911 | Loss: 0.0788176866284104\n",
            "Epoch: 49 | Batch: 1912 | Loss: 0.0792107498478814\n",
            "Epoch: 49 | Batch: 1913 | Loss: 0.04875449506214658\n",
            "Epoch: 49 | Batch: 1914 | Loss: 0.10373154553281927\n",
            "Epoch: 49 | Batch: 1915 | Loss: 0.045834213813314026\n",
            "Epoch: 49 | Batch: 1916 | Loss: 0.04625665993811032\n",
            "Epoch: 49 | Batch: 1917 | Loss: 0.06679132876534681\n",
            "Epoch: 49 | Batch: 1918 | Loss: 0.06401258577344429\n",
            "Epoch: 49 | Batch: 1919 | Loss: 0.07234962613289882\n",
            "Epoch: 49 | Batch: 1920 | Loss: 0.0472323515806819\n",
            "Epoch: 49 | Batch: 1921 | Loss: 0.043326123733084906\n",
            "Epoch: 49 | Batch: 1922 | Loss: 0.05909829409834698\n",
            "Epoch: 49 | Batch: 1923 | Loss: 0.06359794984508918\n",
            "Epoch: 49 | Batch: 1924 | Loss: 0.04500359268617364\n",
            "Epoch: 49 | Batch: 1925 | Loss: 0.08234573762103235\n",
            "Epoch: 49 | Batch: 1926 | Loss: 0.044935234649850074\n",
            "Epoch: 49 | Batch: 1927 | Loss: 0.06768561981477017\n",
            "Epoch: 49 | Batch: 1928 | Loss: 0.08134029305917505\n",
            "Epoch: 49 | Batch: 1929 | Loss: 0.05242937744451239\n",
            "Epoch: 49 | Batch: 1930 | Loss: 0.07915339167763977\n",
            "Epoch: 49 | Batch: 1931 | Loss: 0.04090547838041293\n",
            "Epoch: 49 | Batch: 1932 | Loss: 0.04167709331582211\n",
            "Epoch: 49 | Batch: 1933 | Loss: 0.051250368133245426\n",
            "Epoch: 49 | Batch: 1934 | Loss: 0.05105869034583329\n",
            "Epoch: 49 | Batch: 1935 | Loss: 0.08054144817804368\n",
            "Epoch: 49 | Batch: 1936 | Loss: 0.04916410382330898\n",
            "Epoch: 49 | Batch: 1937 | Loss: 0.061457548440882914\n",
            "Epoch: 49 | Batch: 1938 | Loss: 0.046305883706505194\n",
            "Epoch: 49 | Batch: 1939 | Loss: 0.0967844346172832\n",
            "Epoch: 49 | Batch: 1940 | Loss: 0.05209253579299353\n",
            "Epoch: 49 | Batch: 1941 | Loss: 0.04557219475111444\n",
            "Epoch: 49 | Batch: 1942 | Loss: 0.059617200046279926\n",
            "Epoch: 49 | Batch: 1943 | Loss: 0.05833544618074869\n",
            "Epoch: 49 | Batch: 1944 | Loss: 0.04153789153926682\n",
            "Epoch: 49 | Batch: 1945 | Loss: 0.08485914308549312\n",
            "Epoch: 49 | Batch: 1946 | Loss: 0.05814566345082067\n",
            "Epoch: 49 | Batch: 1947 | Loss: 0.06200487858989962\n",
            "Epoch: 49 | Batch: 1948 | Loss: 0.04902052046213104\n",
            "Epoch: 49 | Batch: 1949 | Loss: 0.0618429191410443\n",
            "Epoch: 49 | Batch: 1950 | Loss: 0.06299208989421885\n",
            "Epoch: 49 | Batch: 1951 | Loss: 0.04002590316152292\n",
            "Epoch: 49 | Batch: 1952 | Loss: 0.07415684890169458\n",
            "Epoch: 49 | Batch: 1953 | Loss: 0.0505658114219171\n",
            "Epoch: 49 | Batch: 1954 | Loss: 0.04027368530112384\n",
            "Epoch: 49 | Batch: 1955 | Loss: 0.08505317634982958\n",
            "Epoch: 49 | Batch: 1956 | Loss: 0.057550926924119505\n",
            "Epoch: 49 | Batch: 1957 | Loss: 0.04955697132849568\n",
            "Epoch: 49 | Batch: 1958 | Loss: 0.06203192310629414\n",
            "Epoch: 49 | Batch: 1959 | Loss: 0.05762138417664212\n",
            "Epoch: 49 | Batch: 1960 | Loss: 0.05109845448342119\n",
            "Epoch: 49 | Batch: 1961 | Loss: 0.0572250491997243\n",
            "Epoch: 49 | Batch: 1962 | Loss: 0.06980086808202966\n",
            "Epoch: 49 | Batch: 1963 | Loss: 0.05947173371793499\n",
            "Epoch: 49 | Batch: 1964 | Loss: 0.056602655361412665\n",
            "Epoch: 49 | Batch: 1965 | Loss: 0.05599891091455111\n",
            "Epoch: 49 | Batch: 1966 | Loss: 0.0698821446988052\n",
            "Epoch: 49 | Batch: 1967 | Loss: 0.04229164819833211\n",
            "Epoch: 49 | Batch: 1968 | Loss: 0.05288427553307181\n",
            "Epoch: 49 | Batch: 1969 | Loss: 0.04028801402094939\n",
            "Epoch: 49 | Batch: 1970 | Loss: 0.05374869610868602\n",
            "Epoch: 49 | Batch: 1971 | Loss: 0.0661958925079895\n",
            "Epoch: 49 | Batch: 1972 | Loss: 0.0440200536391643\n",
            "Epoch: 49 | Batch: 1973 | Loss: 0.06170268547284693\n",
            "Epoch: 49 | Batch: 1974 | Loss: 0.06002616231678135\n",
            "Epoch: 49 | Batch: 1975 | Loss: 0.07683642717350765\n",
            "Epoch: 49 | Batch: 1976 | Loss: 0.09038136143190562\n",
            "Epoch: 49 | Batch: 1977 | Loss: 0.0739359026667875\n",
            "Epoch: 49 | Batch: 1978 | Loss: 0.05274753708159703\n",
            "Epoch: 49 | Batch: 1979 | Loss: 0.07078931135030708\n",
            "Epoch: 49 | Batch: 1980 | Loss: 0.043786808837676654\n",
            "Epoch: 49 | Batch: 1981 | Loss: 0.06820375367898009\n",
            "Epoch: 49 | Batch: 1982 | Loss: 0.0773570308687358\n",
            "Epoch: 49 | Batch: 1983 | Loss: 0.07358944513576268\n",
            "Epoch: 49 | Batch: 1984 | Loss: 0.07739700445665294\n",
            "Epoch: 49 | Batch: 1985 | Loss: 0.05220451303303067\n",
            "Epoch: 49 | Batch: 1986 | Loss: 0.05308690006565567\n",
            "Epoch: 49 | Batch: 1987 | Loss: 0.04059796615148953\n",
            "Epoch: 49 | Batch: 1988 | Loss: 0.07514194128761582\n",
            "Epoch: 49 | Batch: 1989 | Loss: 0.056412349358273134\n",
            "Epoch: 49 | Batch: 1990 | Loss: 0.08558357888812525\n",
            "Epoch: 49 | Batch: 1991 | Loss: 0.04619157356646422\n",
            "Epoch: 49 | Batch: 1992 | Loss: 0.04073677643761142\n",
            "Epoch: 49 | Batch: 1993 | Loss: 0.07545216162827023\n",
            "Epoch: 49 | Batch: 1994 | Loss: 0.08540994351458685\n",
            "Epoch: 49 | Batch: 1995 | Loss: 0.04670157369701508\n",
            "Epoch: 49 | Batch: 1996 | Loss: 0.045463441023582365\n",
            "Epoch: 49 | Batch: 1997 | Loss: 0.04356802701244764\n",
            "Epoch: 49 | Batch: 1998 | Loss: 0.06685980204534431\n",
            "Epoch: 49 | Batch: 1999 | Loss: 0.03292827514866907\n",
            "Epoch: 49 | Batch: 2000 | Loss: 0.03244830024074458\n",
            "Epoch: 49 | Batch: 2001 | Loss: 0.06930496170461417\n",
            "Epoch: 49 | Batch: 2002 | Loss: 0.06269072345493382\n",
            "Epoch: 49 | Batch: 2003 | Loss: 0.10786941893653243\n",
            "Epoch: 49 | Batch: 2004 | Loss: 0.06922499691013383\n",
            "Epoch: 49 | Batch: 2005 | Loss: 0.08499691147967424\n",
            "Epoch: 49 | Batch: 2006 | Loss: 0.05750420838491044\n",
            "Epoch: 49 | Batch: 2007 | Loss: 0.06541294779164711\n",
            "Epoch: 49 | Batch: 2008 | Loss: 0.053208705473191106\n",
            "Epoch: 49 | Batch: 2009 | Loss: 0.0780724111225964\n",
            "Epoch: 49 | Batch: 2010 | Loss: 0.07900758074580301\n",
            "Epoch: 49 | Batch: 2011 | Loss: 0.07872900855640935\n",
            "Epoch: 49 | Batch: 2012 | Loss: 0.05766401818216454\n",
            "Epoch: 49 | Batch: 2013 | Loss: 0.052518005590866126\n",
            "Epoch: 49 | Batch: 2014 | Loss: 0.060580261858659015\n",
            "Epoch: 49 | Batch: 2015 | Loss: 0.044215200563693824\n",
            "Epoch: 49 | Batch: 2016 | Loss: 0.05085406902681692\n",
            "Epoch: 49 | Batch: 2017 | Loss: 0.04802255246834369\n",
            "Epoch: 49 | Batch: 2018 | Loss: 0.07720842960891179\n",
            "Epoch: 49 | Batch: 2019 | Loss: 0.07247003584828032\n",
            "Epoch: 49 | Batch: 2020 | Loss: 0.06362933459317491\n",
            "Epoch: 49 | Batch: 2021 | Loss: 0.04701098914614015\n",
            "Epoch: 49 | Batch: 2022 | Loss: 0.038328703122221724\n",
            "Epoch: 49 | Batch: 2023 | Loss: 0.04719370720048795\n",
            "Epoch: 49 | Batch: 2024 | Loss: 0.05244001117448016\n",
            "Epoch: 49 | Batch: 2025 | Loss: 0.07082974625870125\n",
            "Epoch: 49 | Batch: 2026 | Loss: 0.0958557134454883\n",
            "Epoch: 49 | Batch: 2027 | Loss: 0.04908079451838164\n",
            "Epoch: 49 | Batch: 2028 | Loss: 0.05155113472448292\n",
            "Epoch: 49 | Batch: 2029 | Loss: 0.05697861466433857\n",
            "Epoch: 49 | Batch: 2030 | Loss: 0.06890656250805591\n",
            "Epoch: 49 | Batch: 2031 | Loss: 0.06659383295482624\n",
            "Epoch: 49 | Batch: 2032 | Loss: 0.09040729698196098\n",
            "Epoch: 49 | Batch: 2033 | Loss: 0.05480146980978575\n",
            "Epoch: 49 | Batch: 2034 | Loss: 0.0846030235825029\n",
            "Epoch: 49 | Batch: 2035 | Loss: 0.049551743899119045\n",
            "Epoch: 49 | Batch: 2036 | Loss: 0.07390744196457993\n",
            "Epoch: 49 | Batch: 2037 | Loss: 0.1187935186647319\n",
            "Epoch: 49 | Batch: 2038 | Loss: 0.08769467951159668\n",
            "Epoch: 49 | Batch: 2039 | Loss: 0.07491939551293547\n",
            "Epoch: 49 | Batch: 2040 | Loss: 0.06825917864924139\n",
            "Epoch: 49 | Batch: 2041 | Loss: 0.06341515475626794\n",
            "Epoch: 49 | Batch: 2042 | Loss: 0.048502369318623985\n",
            "Epoch: 49 | Batch: 2043 | Loss: 0.07219405439298376\n",
            "Epoch: 49 | Batch: 2044 | Loss: 0.038014585721441715\n",
            "Epoch: 49 | Batch: 2045 | Loss: 0.0631493206808836\n",
            "Epoch: 49 | Batch: 2046 | Loss: 0.06424577204576655\n",
            "Epoch: 49 | Batch: 2047 | Loss: 0.09860135490310801\n",
            "Epoch: 49 | Batch: 2048 | Loss: 0.05852283607618986\n",
            "Epoch: 49 | Batch: 2049 | Loss: 0.06737757863630103\n",
            "Epoch: 49 | Batch: 2050 | Loss: 0.0976136212251691\n",
            "Epoch: 49 | Batch: 2051 | Loss: 0.05991493856918243\n",
            "Epoch: 49 | Batch: 2052 | Loss: 0.1101062720712874\n",
            "Epoch: 49 | Batch: 2053 | Loss: 0.08758026461732588\n",
            "Epoch: 49 | Batch: 2054 | Loss: 0.06632659845375573\n",
            "Epoch: 49 | Batch: 2055 | Loss: 0.08238852814225327\n",
            "Epoch: 49 | Batch: 2056 | Loss: 0.06784008395423073\n",
            "Epoch: 49 | Batch: 2057 | Loss: 0.11885225352504668\n",
            "Epoch: 49 | Batch: 2058 | Loss: 0.06305416874883933\n",
            "Epoch: 49 | Batch: 2059 | Loss: 0.075372953308768\n",
            "Epoch: 49 | Batch: 2060 | Loss: 0.06389468244143454\n",
            "Epoch: 49 | Batch: 2061 | Loss: 0.06673620990260895\n",
            "Epoch: 49 | Batch: 2062 | Loss: 0.05029319784068345\n",
            "Epoch: 49 | Batch: 2063 | Loss: 0.05616438875880186\n",
            "Epoch: 49 | Batch: 2064 | Loss: 0.06791199615209594\n",
            "Epoch: 49 | Batch: 2065 | Loss: 0.0622417026327321\n",
            "Epoch: 49 | Batch: 2066 | Loss: 0.06582402124442871\n",
            "Epoch: 49 | Batch: 2067 | Loss: 0.0767729717740439\n",
            "Epoch: 49 | Batch: 2068 | Loss: 0.05907825841898373\n",
            "Epoch: 49 | Batch: 2069 | Loss: 0.08484978952374182\n",
            "Epoch: 49 | Batch: 2070 | Loss: 0.06231487373878998\n",
            "Epoch: 49 | Batch: 2071 | Loss: 0.11120777507031106\n",
            "Epoch: 49 | Batch: 2072 | Loss: 0.09217816410840352\n",
            "Epoch: 49 | Batch: 2073 | Loss: 0.05970790489585316\n",
            "Epoch: 49 | Batch: 2074 | Loss: 0.07692036624919572\n",
            "Epoch: 49 | Batch: 2075 | Loss: 0.075120327789813\n",
            "Epoch: 49 | Batch: 2076 | Loss: 0.05515098284014095\n",
            "Epoch: 49 | Batch: 2077 | Loss: 0.0591271788250632\n",
            "Epoch: 49 | Batch: 2078 | Loss: 0.06154655774572357\n",
            "Epoch: 49 | Batch: 2079 | Loss: 0.061990979169105606\n",
            "Epoch: 49 | Batch: 2080 | Loss: 0.06102616073706177\n",
            "Epoch: 49 | Batch: 2081 | Loss: 0.09280186611078653\n",
            "Epoch: 49 | Batch: 2082 | Loss: 0.06659332259442657\n",
            "Epoch: 49 | Batch: 2083 | Loss: 0.09240566324559403\n",
            "Epoch: 49 | Batch: 2084 | Loss: 0.0631107049494524\n",
            "Epoch: 49 | Batch: 2085 | Loss: 0.07386458536735671\n",
            "Epoch: 49 | Batch: 2086 | Loss: 0.060721336361845235\n",
            "Epoch: 49 | Batch: 2087 | Loss: 0.05529682652387366\n",
            "Epoch: 49 | Batch: 2088 | Loss: 0.07003615860436534\n",
            "Epoch: 49 | Batch: 2089 | Loss: 0.06935412536092592\n",
            "Epoch: 49 | Batch: 2090 | Loss: 0.06227774158641923\n",
            "Epoch: 49 | Batch: 2091 | Loss: 0.10016154169108354\n",
            "Epoch: 49 | Batch: 2092 | Loss: 0.08466189378731633\n",
            "Epoch: 49 | Batch: 2093 | Loss: 0.0638283903061633\n",
            "Epoch: 49 | Batch: 2094 | Loss: 0.03935192500862746\n",
            "Epoch: 49 | Batch: 2095 | Loss: 0.1028445345022856\n",
            "Epoch: 49 | Batch: 2096 | Loss: 0.11716510041689952\n",
            "Epoch: 49 | Batch: 2097 | Loss: 0.05822931308153681\n",
            "Epoch: 49 | Batch: 2098 | Loss: 0.03875531129809898\n",
            "Epoch: 49 | Batch: 2099 | Loss: 0.061727617980048756\n",
            "Epoch: 49 | Batch: 2100 | Loss: 0.08802867640807448\n",
            "Epoch: 49 | Batch: 2101 | Loss: 0.041993110068401715\n",
            "Epoch: 49 | Batch: 2102 | Loss: 0.04624783857732507\n",
            "Epoch: 49 | Batch: 2103 | Loss: 0.06153520474004225\n",
            "Epoch: 49 | Batch: 2104 | Loss: 0.06817521704223709\n",
            "Epoch: 49 | Batch: 2105 | Loss: 0.049103369837622306\n",
            "Epoch: 49 | Batch: 2106 | Loss: 0.056339428280347874\n",
            "Epoch: 49 | Batch: 2107 | Loss: 0.06197745908984009\n",
            "Epoch: 49 | Batch: 2108 | Loss: 0.06299271326611025\n",
            "Epoch: 49 | Batch: 2109 | Loss: 0.058027852612322656\n",
            "Epoch: 49 | Batch: 2110 | Loss: 0.05441399628932882\n",
            "Epoch: 49 | Batch: 2111 | Loss: 0.04164854595865485\n",
            "Epoch: 49 | Batch: 2112 | Loss: 0.0661030640180903\n",
            "Epoch: 49 | Batch: 2113 | Loss: 0.05448268088274495\n",
            "Epoch: 49 | Batch: 2114 | Loss: 0.07234773643944552\n",
            "Epoch: 49 | Batch: 2115 | Loss: 0.06879721039604624\n",
            "Epoch: 49 | Batch: 2116 | Loss: 0.06510795168429559\n",
            "Epoch: 49 | Batch: 2117 | Loss: 0.06995898332949506\n",
            "Epoch: 49 | Batch: 2118 | Loss: 0.05937678064441487\n",
            "Epoch: 49 | Batch: 2119 | Loss: 0.10132012473181283\n",
            "Epoch: 49 | Batch: 2120 | Loss: 0.061175123484239584\n",
            "Epoch: 49 | Batch: 2121 | Loss: 0.06655506098625096\n",
            "Epoch: 49 | Batch: 2122 | Loss: 0.06607556004813973\n",
            "Epoch: 49 | Batch: 2123 | Loss: 0.08206534082497835\n",
            "Epoch: 49 | Batch: 2124 | Loss: 0.04759231397777064\n",
            "Epoch: 49 | Batch: 2125 | Loss: 0.05343371960515802\n",
            "Epoch: 49 | Batch: 2126 | Loss: 0.06315083972143014\n",
            "Epoch: 49 | Batch: 2127 | Loss: 0.0651287790688338\n",
            "Epoch: 49 | Batch: 2128 | Loss: 0.059961114568795236\n",
            "Epoch: 49 | Batch: 2129 | Loss: 0.05700284026979495\n",
            "Epoch: 49 | Batch: 2130 | Loss: 0.06926102569563837\n",
            "Epoch: 49 | Batch: 2131 | Loss: 0.0620782864158445\n",
            "Epoch: 49 | Batch: 2132 | Loss: 0.06862905961636849\n",
            "Epoch: 49 | Batch: 2133 | Loss: 0.04067043735887246\n",
            "Epoch: 49 | Batch: 2134 | Loss: 0.04485447405107204\n",
            "Epoch: 49 | Batch: 2135 | Loss: 0.04694810104874374\n",
            "Epoch: 49 | Batch: 2136 | Loss: 0.05385201696940914\n",
            "Epoch: 49 | Batch: 2137 | Loss: 0.05114199078992611\n",
            "Epoch: 49 | Batch: 2138 | Loss: 0.05557099194856813\n",
            "Epoch: 49 | Batch: 2139 | Loss: 0.04048191478098974\n",
            "Epoch: 49 | Batch: 2140 | Loss: 0.04068576510181861\n",
            "Epoch: 49 | Batch: 2141 | Loss: 0.10833645952001952\n",
            "Epoch: 49 | Batch: 2142 | Loss: 0.04174516088432392\n",
            "Epoch: 49 | Batch: 2143 | Loss: 0.08833392440945957\n",
            "Epoch: 49 | Batch: 2144 | Loss: 0.06823790217182439\n",
            "Epoch: 49 | Batch: 2145 | Loss: 0.05860662547941997\n",
            "Epoch: 49 | Batch: 2146 | Loss: 0.09962249948062041\n",
            "Epoch: 49 | Batch: 2147 | Loss: 0.0711711152002277\n",
            "Epoch: 49 | Batch: 2148 | Loss: 0.037101706831473874\n",
            "Epoch: 49 | Batch: 2149 | Loss: 0.07242879594793233\n",
            "Epoch: 49 | Batch: 2150 | Loss: 0.04886921801066456\n",
            "Epoch: 49 | Batch: 2151 | Loss: 0.05466392228040441\n",
            "Epoch: 49 | Batch: 2152 | Loss: 0.04823238960372872\n",
            "Epoch: 49 | Batch: 2153 | Loss: 0.056996985659740554\n",
            "Epoch: 49 | Batch: 2154 | Loss: 0.03781888469337036\n",
            "Epoch: 49 | Batch: 2155 | Loss: 0.05075853189729484\n",
            "Epoch: 49 | Batch: 2156 | Loss: 0.043751589314427894\n",
            "Epoch: 49 | Batch: 2157 | Loss: 0.06445674079227234\n",
            "Epoch: 49 | Batch: 2158 | Loss: 0.06863439300524833\n",
            "Epoch: 49 | Batch: 2159 | Loss: 0.06428753526526909\n",
            "Epoch: 49 | Batch: 2160 | Loss: 0.0584071324245074\n",
            "Epoch: 49 | Batch: 2161 | Loss: 0.04761874344149712\n",
            "Epoch: 49 | Batch: 2162 | Loss: 0.05213062587351982\n",
            "Epoch: 49 | Batch: 2163 | Loss: 0.039428619470299915\n",
            "Epoch: 49 | Batch: 2164 | Loss: 0.036088837709210966\n",
            "Epoch: 49 | Batch: 2165 | Loss: 0.062124360128643\n",
            "Epoch: 49 | Batch: 2166 | Loss: 0.05828482617483524\n",
            "Epoch: 49 | Batch: 2167 | Loss: 0.05221418866781044\n",
            "Epoch: 49 | Batch: 2168 | Loss: 0.06568339709435095\n",
            "Epoch: 49 | Batch: 2169 | Loss: 0.10613382276966113\n",
            "Epoch: 49 | Batch: 2170 | Loss: 0.05149071371390979\n",
            "Epoch: 49 | Batch: 2171 | Loss: 0.06846374438143121\n",
            "Epoch: 49 | Batch: 2172 | Loss: 0.05465207318755142\n",
            "Epoch: 49 | Batch: 2173 | Loss: 0.05101627794384954\n",
            "Epoch: 49 | Batch: 2174 | Loss: 0.03920467416716162\n",
            "Epoch: 49 | Batch: 2175 | Loss: 0.05012675607243447\n",
            "Epoch: 49 | Batch: 2176 | Loss: 0.05743497235605495\n",
            "Epoch: 49 | Batch: 2177 | Loss: 0.05181600869261317\n",
            "Epoch: 49 | Batch: 2178 | Loss: 0.06775024761010079\n",
            "Epoch: 49 | Batch: 2179 | Loss: 0.035871658086696734\n",
            "Epoch: 49 | Batch: 2180 | Loss: 0.07823362734568455\n",
            "Epoch: 49 | Batch: 2181 | Loss: 0.05590650221824645\n",
            "Epoch: 49 | Batch: 2182 | Loss: 0.0703298460831017\n",
            "Epoch: 49 | Batch: 2183 | Loss: 0.03587133543148602\n",
            "Epoch: 49 | Batch: 2184 | Loss: 0.06764339297669184\n",
            "Epoch: 49 | Batch: 2185 | Loss: 0.06385994455083485\n",
            "Epoch: 49 | Batch: 2186 | Loss: 0.08478228894321747\n",
            "Epoch: 49 | Batch: 2187 | Loss: 0.046000940256313155\n",
            "Epoch: 49 | Batch: 2188 | Loss: 0.0411856010662625\n",
            "Epoch: 49 | Batch: 2189 | Loss: 0.0829515803244962\n",
            "Epoch: 49 | Batch: 2190 | Loss: 0.05841376280272487\n",
            "Epoch: 49 | Batch: 2191 | Loss: 0.07219269148697063\n",
            "Epoch: 50 | Batch: 1 | Loss: 0.06514789853351896\n",
            "Epoch: 50 | Batch: 2 | Loss: 0.09476233546775549\n",
            "Epoch: 50 | Batch: 3 | Loss: 0.06736567908737723\n",
            "Epoch: 50 | Batch: 4 | Loss: 0.10183690056990156\n",
            "Epoch: 50 | Batch: 5 | Loss: 0.0814946596385194\n",
            "Epoch: 50 | Batch: 6 | Loss: 0.04684154597599689\n",
            "Epoch: 50 | Batch: 7 | Loss: 0.04969210168439891\n",
            "Epoch: 50 | Batch: 8 | Loss: 0.05138473027665683\n",
            "Epoch: 50 | Batch: 9 | Loss: 0.05715855083133792\n",
            "Epoch: 50 | Batch: 10 | Loss: 0.05956037217767621\n",
            "Epoch: 50 | Batch: 11 | Loss: 0.05837997691001323\n",
            "Epoch: 50 | Batch: 12 | Loss: 0.04912695771379667\n",
            "Epoch: 50 | Batch: 13 | Loss: 0.05763137970931323\n",
            "Epoch: 50 | Batch: 14 | Loss: 0.03820839152376686\n",
            "Epoch: 50 | Batch: 15 | Loss: 0.044731142445782635\n",
            "Epoch: 50 | Batch: 16 | Loss: 0.0568465187467965\n",
            "Epoch: 50 | Batch: 17 | Loss: 0.051900022128855076\n",
            "Epoch: 50 | Batch: 18 | Loss: 0.05191780606206957\n",
            "Epoch: 50 | Batch: 19 | Loss: 0.07866110604422845\n",
            "Epoch: 50 | Batch: 20 | Loss: 0.04660476016259697\n",
            "Epoch: 50 | Batch: 21 | Loss: 0.04495822391478968\n",
            "Epoch: 50 | Batch: 22 | Loss: 0.044730046607324866\n",
            "Epoch: 50 | Batch: 23 | Loss: 0.05225671846733738\n",
            "Epoch: 50 | Batch: 24 | Loss: 0.1079833282153374\n",
            "Epoch: 50 | Batch: 25 | Loss: 0.057681208500157635\n",
            "Epoch: 50 | Batch: 26 | Loss: 0.06593254334851348\n",
            "Epoch: 50 | Batch: 27 | Loss: 0.06698668467096042\n",
            "Epoch: 50 | Batch: 28 | Loss: 0.034101406078280515\n",
            "Epoch: 50 | Batch: 29 | Loss: 0.054584270418407216\n",
            "Epoch: 50 | Batch: 30 | Loss: 0.06668866686242171\n",
            "Epoch: 50 | Batch: 31 | Loss: 0.04759918013137292\n",
            "Epoch: 50 | Batch: 32 | Loss: 0.0887965863229978\n",
            "Epoch: 50 | Batch: 33 | Loss: 0.09217031848705758\n",
            "Epoch: 50 | Batch: 34 | Loss: 0.06581544681690724\n",
            "Epoch: 50 | Batch: 35 | Loss: 0.053892288298541605\n",
            "Epoch: 50 | Batch: 36 | Loss: 0.055211539710883356\n",
            "Epoch: 50 | Batch: 37 | Loss: 0.0656668220934982\n",
            "Epoch: 50 | Batch: 38 | Loss: 0.05412193305036837\n",
            "Epoch: 50 | Batch: 39 | Loss: 0.06494726345891703\n",
            "Epoch: 50 | Batch: 40 | Loss: 0.0916028102944527\n",
            "Epoch: 50 | Batch: 41 | Loss: 0.05248634977209994\n",
            "Epoch: 50 | Batch: 42 | Loss: 0.05061260551672085\n",
            "Epoch: 50 | Batch: 43 | Loss: 0.04479297151165472\n",
            "Epoch: 50 | Batch: 44 | Loss: 0.03391415101769766\n",
            "Epoch: 50 | Batch: 45 | Loss: 0.07629901986126525\n",
            "Epoch: 50 | Batch: 46 | Loss: 0.08755082266428173\n",
            "Epoch: 50 | Batch: 47 | Loss: 0.04948806386873872\n",
            "Epoch: 50 | Batch: 48 | Loss: 0.05648132194867062\n",
            "Epoch: 50 | Batch: 49 | Loss: 0.04904473263936778\n",
            "Epoch: 50 | Batch: 50 | Loss: 0.06860191609590369\n",
            "Epoch: 50 | Batch: 51 | Loss: 0.04890790275205509\n",
            "Epoch: 50 | Batch: 52 | Loss: 0.0329661979459637\n",
            "Epoch: 50 | Batch: 53 | Loss: 0.0382687941657814\n",
            "Epoch: 50 | Batch: 54 | Loss: 0.04343566603863497\n",
            "Epoch: 50 | Batch: 55 | Loss: 0.07011654612955744\n",
            "Epoch: 50 | Batch: 56 | Loss: 0.09444679451629309\n",
            "Epoch: 50 | Batch: 57 | Loss: 0.08121395724215597\n",
            "Epoch: 50 | Batch: 58 | Loss: 0.12183415154086727\n",
            "Epoch: 50 | Batch: 59 | Loss: 0.051390463034922784\n",
            "Epoch: 50 | Batch: 60 | Loss: 0.05028312391071477\n",
            "Epoch: 50 | Batch: 61 | Loss: 0.1152710568021592\n",
            "Epoch: 50 | Batch: 62 | Loss: 0.0847621727467216\n",
            "Epoch: 50 | Batch: 63 | Loss: 0.06753677121994492\n",
            "Epoch: 50 | Batch: 64 | Loss: 0.09065431498851526\n",
            "Epoch: 50 | Batch: 65 | Loss: 0.06636870714198112\n",
            "Epoch: 50 | Batch: 66 | Loss: 0.0377289992872335\n",
            "Epoch: 50 | Batch: 67 | Loss: 0.07836997305302885\n",
            "Epoch: 50 | Batch: 68 | Loss: 0.06497974773917378\n",
            "Epoch: 50 | Batch: 69 | Loss: 0.05756734115365354\n",
            "Epoch: 50 | Batch: 70 | Loss: 0.05765661126262232\n",
            "Epoch: 50 | Batch: 71 | Loss: 0.0501835240364366\n",
            "Epoch: 50 | Batch: 72 | Loss: 0.07276597397922957\n",
            "Epoch: 50 | Batch: 73 | Loss: 0.07095277404362295\n",
            "Epoch: 50 | Batch: 74 | Loss: 0.03738663406452265\n",
            "Epoch: 50 | Batch: 75 | Loss: 0.10014416738735525\n",
            "Epoch: 50 | Batch: 76 | Loss: 0.04579589257192597\n",
            "Epoch: 50 | Batch: 77 | Loss: 0.058965513635613434\n",
            "Epoch: 50 | Batch: 78 | Loss: 0.058566250849273416\n",
            "Epoch: 50 | Batch: 79 | Loss: 0.08002098946661922\n",
            "Epoch: 50 | Batch: 80 | Loss: 0.09147362961919153\n",
            "Epoch: 50 | Batch: 81 | Loss: 0.0505112626952873\n",
            "Epoch: 50 | Batch: 82 | Loss: 0.08119081313518546\n",
            "Epoch: 50 | Batch: 83 | Loss: 0.06695990743631165\n",
            "Epoch: 50 | Batch: 84 | Loss: 0.06896506864725875\n",
            "Epoch: 50 | Batch: 85 | Loss: 0.06861628157038022\n",
            "Epoch: 50 | Batch: 86 | Loss: 0.09576149489160331\n",
            "Epoch: 50 | Batch: 87 | Loss: 0.05335421375521897\n",
            "Epoch: 50 | Batch: 88 | Loss: 0.07152756746212843\n",
            "Epoch: 50 | Batch: 89 | Loss: 0.07977375623396929\n",
            "Epoch: 50 | Batch: 90 | Loss: 0.06818022814226497\n",
            "Epoch: 50 | Batch: 91 | Loss: 0.09013112886732563\n",
            "Epoch: 50 | Batch: 92 | Loss: 0.07771653358609702\n",
            "Epoch: 50 | Batch: 93 | Loss: 0.07622508487305521\n",
            "Epoch: 50 | Batch: 94 | Loss: 0.104218257577564\n",
            "Epoch: 50 | Batch: 95 | Loss: 0.04536378707895816\n",
            "Epoch: 50 | Batch: 96 | Loss: 0.11722376322341593\n",
            "Epoch: 50 | Batch: 97 | Loss: 0.05791994919183903\n",
            "Epoch: 50 | Batch: 98 | Loss: 0.052247642883020216\n",
            "Epoch: 50 | Batch: 99 | Loss: 0.06614844544729387\n",
            "Epoch: 50 | Batch: 100 | Loss: 0.07372137602064753\n",
            "Epoch: 50 | Batch: 101 | Loss: 0.07352252279833922\n",
            "Epoch: 50 | Batch: 102 | Loss: 0.07574340483450323\n",
            "Epoch: 50 | Batch: 103 | Loss: 0.06207142665201826\n",
            "Epoch: 50 | Batch: 104 | Loss: 0.06519473365778283\n",
            "Epoch: 50 | Batch: 105 | Loss: 0.06483747383019736\n",
            "Epoch: 50 | Batch: 106 | Loss: 0.051117315241280666\n",
            "Epoch: 50 | Batch: 107 | Loss: 0.05232689499479268\n",
            "Epoch: 50 | Batch: 108 | Loss: 0.0839591603201354\n",
            "Epoch: 50 | Batch: 109 | Loss: 0.08629940854537975\n",
            "Epoch: 50 | Batch: 110 | Loss: 0.06355953545089056\n",
            "Epoch: 50 | Batch: 111 | Loss: 0.033045007602050355\n",
            "Epoch: 50 | Batch: 112 | Loss: 0.06332871195963327\n",
            "Epoch: 50 | Batch: 113 | Loss: 0.06084681236223542\n",
            "Epoch: 50 | Batch: 114 | Loss: 0.06767618535192163\n",
            "Epoch: 50 | Batch: 115 | Loss: 0.0864793218112954\n",
            "Epoch: 50 | Batch: 116 | Loss: 0.0777328419009626\n",
            "Epoch: 50 | Batch: 117 | Loss: 0.07683118193189195\n",
            "Epoch: 50 | Batch: 118 | Loss: 0.053190454480423234\n",
            "Epoch: 50 | Batch: 119 | Loss: 0.04689342443822713\n",
            "Epoch: 50 | Batch: 120 | Loss: 0.06384523375833605\n",
            "Epoch: 50 | Batch: 121 | Loss: 0.03759553158178923\n",
            "Epoch: 50 | Batch: 122 | Loss: 0.06073040705811874\n",
            "Epoch: 50 | Batch: 123 | Loss: 0.05329378302997122\n",
            "Epoch: 50 | Batch: 124 | Loss: 0.05010601584610143\n",
            "Epoch: 50 | Batch: 125 | Loss: 0.05803403230744853\n",
            "Epoch: 50 | Batch: 126 | Loss: 0.040731096951641226\n",
            "Epoch: 50 | Batch: 127 | Loss: 0.04770179993800605\n",
            "Epoch: 50 | Batch: 128 | Loss: 0.06271494625687574\n",
            "Epoch: 50 | Batch: 129 | Loss: 0.062115855118715355\n",
            "Epoch: 50 | Batch: 130 | Loss: 0.06294858922911198\n",
            "Epoch: 50 | Batch: 131 | Loss: 0.05259179588500017\n",
            "Epoch: 50 | Batch: 132 | Loss: 0.04402748425950398\n",
            "Epoch: 50 | Batch: 133 | Loss: 0.05133790952358022\n",
            "Epoch: 50 | Batch: 134 | Loss: 0.04211780656269326\n",
            "Epoch: 50 | Batch: 135 | Loss: 0.04913633563104591\n",
            "Epoch: 50 | Batch: 136 | Loss: 0.07697862585923308\n",
            "Epoch: 50 | Batch: 137 | Loss: 0.05869715735522955\n",
            "Epoch: 50 | Batch: 138 | Loss: 0.0411005721144269\n",
            "Epoch: 50 | Batch: 139 | Loss: 0.08635383112260579\n",
            "Epoch: 50 | Batch: 140 | Loss: 0.06762655363514586\n",
            "Epoch: 50 | Batch: 141 | Loss: 0.060992703890131325\n",
            "Epoch: 50 | Batch: 142 | Loss: 0.05042952681723134\n",
            "Epoch: 50 | Batch: 143 | Loss: 0.08358844950627649\n",
            "Epoch: 50 | Batch: 144 | Loss: 0.06429472331020947\n",
            "Epoch: 50 | Batch: 145 | Loss: 0.07814418755939269\n",
            "Epoch: 50 | Batch: 146 | Loss: 0.07637482827381518\n",
            "Epoch: 50 | Batch: 147 | Loss: 0.05896248171644838\n",
            "Epoch: 50 | Batch: 148 | Loss: 0.051239902176217746\n",
            "Epoch: 50 | Batch: 149 | Loss: 0.09049646314303056\n",
            "Epoch: 50 | Batch: 150 | Loss: 0.05486525190465226\n",
            "Epoch: 50 | Batch: 151 | Loss: 0.08609839232077007\n",
            "Epoch: 50 | Batch: 152 | Loss: 0.03971554109779672\n",
            "Epoch: 50 | Batch: 153 | Loss: 0.13652194310734386\n",
            "Epoch: 50 | Batch: 154 | Loss: 0.05451434387126253\n",
            "Epoch: 50 | Batch: 155 | Loss: 0.05102506668109477\n",
            "Epoch: 50 | Batch: 156 | Loss: 0.03934522314508822\n",
            "Epoch: 50 | Batch: 157 | Loss: 0.061406431560590544\n",
            "Epoch: 50 | Batch: 158 | Loss: 0.05480474873838795\n",
            "Epoch: 50 | Batch: 159 | Loss: 0.07406320049359302\n",
            "Epoch: 50 | Batch: 160 | Loss: 0.12818320757551444\n",
            "Epoch: 50 | Batch: 161 | Loss: 0.07108891518790697\n",
            "Epoch: 50 | Batch: 162 | Loss: 0.04228859662053878\n",
            "Epoch: 50 | Batch: 163 | Loss: 0.07646629928750893\n",
            "Epoch: 50 | Batch: 164 | Loss: 0.11673423433688432\n",
            "Epoch: 50 | Batch: 165 | Loss: 0.06074959219179477\n",
            "Epoch: 50 | Batch: 166 | Loss: 0.05395010354992294\n",
            "Epoch: 50 | Batch: 167 | Loss: 0.04626687427792488\n",
            "Epoch: 50 | Batch: 168 | Loss: 0.0989771199933751\n",
            "Epoch: 50 | Batch: 169 | Loss: 0.07953894688887053\n",
            "Epoch: 50 | Batch: 170 | Loss: 0.0669705696635705\n",
            "Epoch: 50 | Batch: 171 | Loss: 0.06606905184211029\n",
            "Epoch: 50 | Batch: 172 | Loss: 0.08104040805202849\n",
            "Epoch: 50 | Batch: 173 | Loss: 0.06213968373970338\n",
            "Epoch: 50 | Batch: 174 | Loss: 0.06215705074996557\n",
            "Epoch: 50 | Batch: 175 | Loss: 0.06424348194190252\n",
            "Epoch: 50 | Batch: 176 | Loss: 0.04310598687940036\n",
            "Epoch: 50 | Batch: 177 | Loss: 0.0723171754084459\n",
            "Epoch: 50 | Batch: 178 | Loss: 0.042005495395510274\n",
            "Epoch: 50 | Batch: 179 | Loss: 0.07510176579771163\n",
            "Epoch: 50 | Batch: 180 | Loss: 0.09681840043252761\n",
            "Epoch: 50 | Batch: 181 | Loss: 0.05237249283657139\n",
            "Epoch: 50 | Batch: 182 | Loss: 0.060068964051667166\n",
            "Epoch: 50 | Batch: 183 | Loss: 0.0662171767882365\n",
            "Epoch: 50 | Batch: 184 | Loss: 0.06581021306118873\n",
            "Epoch: 50 | Batch: 185 | Loss: 0.04543897478731505\n",
            "Epoch: 50 | Batch: 186 | Loss: 0.04052026102764445\n",
            "Epoch: 50 | Batch: 187 | Loss: 0.0625564160868456\n",
            "Epoch: 50 | Batch: 188 | Loss: 0.061840688605535196\n",
            "Epoch: 50 | Batch: 189 | Loss: 0.05309105422303527\n",
            "Epoch: 50 | Batch: 190 | Loss: 0.07997988052790232\n",
            "Epoch: 50 | Batch: 191 | Loss: 0.051337189799990475\n",
            "Epoch: 50 | Batch: 192 | Loss: 0.09107359961172998\n",
            "Epoch: 50 | Batch: 193 | Loss: 0.05580224515335615\n",
            "Epoch: 50 | Batch: 194 | Loss: 0.061968065997069555\n",
            "Epoch: 50 | Batch: 195 | Loss: 0.07693762721775127\n",
            "Epoch: 50 | Batch: 196 | Loss: 0.052602988099736486\n",
            "Epoch: 50 | Batch: 197 | Loss: 0.04166449172816152\n",
            "Epoch: 50 | Batch: 198 | Loss: 0.0436497380456375\n",
            "Epoch: 50 | Batch: 199 | Loss: 0.06299365044996576\n",
            "Epoch: 50 | Batch: 200 | Loss: 0.05634173415233828\n",
            "Epoch: 50 | Batch: 201 | Loss: 0.07654070853260607\n",
            "Epoch: 50 | Batch: 202 | Loss: 0.03998736513168425\n",
            "Epoch: 50 | Batch: 203 | Loss: 0.07331870070488392\n",
            "Epoch: 50 | Batch: 204 | Loss: 0.08105101707703044\n",
            "Epoch: 50 | Batch: 205 | Loss: 0.06237672019215717\n",
            "Epoch: 50 | Batch: 206 | Loss: 0.03762963539119785\n",
            "Epoch: 50 | Batch: 207 | Loss: 0.07731625754906105\n",
            "Epoch: 50 | Batch: 208 | Loss: 0.07075213431311515\n",
            "Epoch: 50 | Batch: 209 | Loss: 0.04923133499822913\n",
            "Epoch: 50 | Batch: 210 | Loss: 0.04322973536498113\n",
            "Epoch: 50 | Batch: 211 | Loss: 0.07212218301145891\n",
            "Epoch: 50 | Batch: 212 | Loss: 0.04754709843021416\n",
            "Epoch: 50 | Batch: 213 | Loss: 0.06943862732330278\n",
            "Epoch: 50 | Batch: 214 | Loss: 0.03684622164688455\n",
            "Epoch: 50 | Batch: 215 | Loss: 0.0851052254441696\n",
            "Epoch: 50 | Batch: 216 | Loss: 0.06786439257195373\n",
            "Epoch: 50 | Batch: 217 | Loss: 0.08285888769117483\n",
            "Epoch: 50 | Batch: 218 | Loss: 0.0604108286997648\n",
            "Epoch: 50 | Batch: 219 | Loss: 0.06688681753725631\n",
            "Epoch: 50 | Batch: 220 | Loss: 0.06333661490104837\n",
            "Epoch: 50 | Batch: 221 | Loss: 0.05850956129659644\n",
            "Epoch: 50 | Batch: 222 | Loss: 0.06712597072022058\n",
            "Epoch: 50 | Batch: 223 | Loss: 0.06041443335245136\n",
            "Epoch: 50 | Batch: 224 | Loss: 0.06900041288984501\n",
            "Epoch: 50 | Batch: 225 | Loss: 0.04438622559273113\n",
            "Epoch: 50 | Batch: 226 | Loss: 0.057474426862027375\n",
            "Epoch: 50 | Batch: 227 | Loss: 0.057255051417822875\n",
            "Epoch: 50 | Batch: 228 | Loss: 0.07369957342275192\n",
            "Epoch: 50 | Batch: 229 | Loss: 0.05939501488192963\n",
            "Epoch: 50 | Batch: 230 | Loss: 0.07348778369670032\n",
            "Epoch: 50 | Batch: 231 | Loss: 0.05689427611842754\n",
            "Epoch: 50 | Batch: 232 | Loss: 0.06498503742994073\n",
            "Epoch: 50 | Batch: 233 | Loss: 0.05557153829535591\n",
            "Epoch: 50 | Batch: 234 | Loss: 0.09421623250775352\n",
            "Epoch: 50 | Batch: 235 | Loss: 0.046348750513629064\n",
            "Epoch: 50 | Batch: 236 | Loss: 0.043116704685120806\n",
            "Epoch: 50 | Batch: 237 | Loss: 0.07830751164099582\n",
            "Epoch: 50 | Batch: 238 | Loss: 0.030534706180710233\n",
            "Epoch: 50 | Batch: 239 | Loss: 0.06355766950416757\n",
            "Epoch: 50 | Batch: 240 | Loss: 0.04805962770075724\n",
            "Epoch: 50 | Batch: 241 | Loss: 0.05014485828183317\n",
            "Epoch: 50 | Batch: 242 | Loss: 0.08005668444245043\n",
            "Epoch: 50 | Batch: 243 | Loss: 0.0639004626079971\n",
            "Epoch: 50 | Batch: 244 | Loss: 0.03575695539812247\n",
            "Epoch: 50 | Batch: 245 | Loss: 0.07177443972578999\n",
            "Epoch: 50 | Batch: 246 | Loss: 0.11209527582537307\n",
            "Epoch: 50 | Batch: 247 | Loss: 0.07560174988036926\n",
            "Epoch: 50 | Batch: 248 | Loss: 0.09350216002700668\n",
            "Epoch: 50 | Batch: 249 | Loss: 0.08339412403826275\n",
            "Epoch: 50 | Batch: 250 | Loss: 0.10217768098361758\n",
            "Epoch: 50 | Batch: 251 | Loss: 0.06713699047243363\n",
            "Epoch: 50 | Batch: 252 | Loss: 0.04750421542007933\n",
            "Epoch: 50 | Batch: 253 | Loss: 0.07064714189632623\n",
            "Epoch: 50 | Batch: 254 | Loss: 0.0481244546863991\n",
            "Epoch: 50 | Batch: 255 | Loss: 0.0773394975825783\n",
            "Epoch: 50 | Batch: 256 | Loss: 0.08058879979359046\n",
            "Epoch: 50 | Batch: 257 | Loss: 0.11017342075965636\n",
            "Epoch: 50 | Batch: 258 | Loss: 0.05873741559820306\n",
            "Epoch: 50 | Batch: 259 | Loss: 0.03946304546680646\n",
            "Epoch: 50 | Batch: 260 | Loss: 0.039727058175497335\n",
            "Epoch: 50 | Batch: 261 | Loss: 0.06996594324472283\n",
            "Epoch: 50 | Batch: 262 | Loss: 0.04096105397991762\n",
            "Epoch: 50 | Batch: 263 | Loss: 0.06411224790064905\n",
            "Epoch: 50 | Batch: 264 | Loss: 0.051366311903185864\n",
            "Epoch: 50 | Batch: 265 | Loss: 0.06769179903461642\n",
            "Epoch: 50 | Batch: 266 | Loss: 0.07328523420331022\n",
            "Epoch: 50 | Batch: 267 | Loss: 0.10170102459198532\n",
            "Epoch: 50 | Batch: 268 | Loss: 0.05633331535455074\n",
            "Epoch: 50 | Batch: 269 | Loss: 0.04821572615445624\n",
            "Epoch: 50 | Batch: 270 | Loss: 0.04806956550091965\n",
            "Epoch: 50 | Batch: 271 | Loss: 0.06442892746734119\n",
            "Epoch: 50 | Batch: 272 | Loss: 0.07009273169382962\n",
            "Epoch: 50 | Batch: 273 | Loss: 0.07956036991397988\n",
            "Epoch: 50 | Batch: 274 | Loss: 0.07276356598699057\n",
            "Epoch: 50 | Batch: 275 | Loss: 0.05859547096591224\n",
            "Epoch: 50 | Batch: 276 | Loss: 0.04071551470173028\n",
            "Epoch: 50 | Batch: 277 | Loss: 0.06411200192445118\n",
            "Epoch: 50 | Batch: 278 | Loss: 0.06714316060768061\n",
            "Epoch: 50 | Batch: 279 | Loss: 0.06650733838046739\n",
            "Epoch: 50 | Batch: 280 | Loss: 0.06367614499959012\n",
            "Epoch: 50 | Batch: 281 | Loss: 0.04233863160891306\n",
            "Epoch: 50 | Batch: 282 | Loss: 0.07300212246968875\n",
            "Epoch: 50 | Batch: 283 | Loss: 0.03453091733245613\n",
            "Epoch: 50 | Batch: 284 | Loss: 0.09235110658901713\n",
            "Epoch: 50 | Batch: 285 | Loss: 0.04012989254663786\n",
            "Epoch: 50 | Batch: 286 | Loss: 0.0431484430735504\n",
            "Epoch: 50 | Batch: 287 | Loss: 0.06271166957416785\n",
            "Epoch: 50 | Batch: 288 | Loss: 0.03696891014787551\n",
            "Epoch: 50 | Batch: 289 | Loss: 0.07153678879968184\n",
            "Epoch: 50 | Batch: 290 | Loss: 0.06225169772799605\n",
            "Epoch: 50 | Batch: 291 | Loss: 0.043928906861961166\n",
            "Epoch: 50 | Batch: 292 | Loss: 0.051013220673821344\n",
            "Epoch: 50 | Batch: 293 | Loss: 0.039888328167572346\n",
            "Epoch: 50 | Batch: 294 | Loss: 0.04058504777545156\n",
            "Epoch: 50 | Batch: 295 | Loss: 0.06140659111185599\n",
            "Epoch: 50 | Batch: 296 | Loss: 0.038875598374620006\n",
            "Epoch: 50 | Batch: 297 | Loss: 0.0552971150466498\n",
            "Epoch: 50 | Batch: 298 | Loss: 0.04650598878106412\n",
            "Epoch: 50 | Batch: 299 | Loss: 0.041580579618365796\n",
            "Epoch: 50 | Batch: 300 | Loss: 0.07958809089417768\n",
            "Epoch: 50 | Batch: 301 | Loss: 0.07023712349671418\n",
            "Epoch: 50 | Batch: 302 | Loss: 0.1006083762273389\n",
            "Epoch: 50 | Batch: 303 | Loss: 0.07441117256206879\n",
            "Epoch: 50 | Batch: 304 | Loss: 0.06956735750551257\n",
            "Epoch: 50 | Batch: 305 | Loss: 0.08654108463312982\n",
            "Epoch: 50 | Batch: 306 | Loss: 0.06320500571097024\n",
            "Epoch: 50 | Batch: 307 | Loss: 0.055402233785512886\n",
            "Epoch: 50 | Batch: 308 | Loss: 0.0731222327912488\n",
            "Epoch: 50 | Batch: 309 | Loss: 0.05274868143237485\n",
            "Epoch: 50 | Batch: 310 | Loss: 0.07084877993829422\n",
            "Epoch: 50 | Batch: 311 | Loss: 0.06546912020401181\n",
            "Epoch: 50 | Batch: 312 | Loss: 0.05675318174108859\n",
            "Epoch: 50 | Batch: 313 | Loss: 0.044169235823538405\n",
            "Epoch: 50 | Batch: 314 | Loss: 0.05358788530721216\n",
            "Epoch: 50 | Batch: 315 | Loss: 0.0468579678867953\n",
            "Epoch: 50 | Batch: 316 | Loss: 0.06567353225363659\n",
            "Epoch: 50 | Batch: 317 | Loss: 0.042990379599802175\n",
            "Epoch: 50 | Batch: 318 | Loss: 0.04987955643149347\n",
            "Epoch: 50 | Batch: 319 | Loss: 0.06782847079864435\n",
            "Epoch: 50 | Batch: 320 | Loss: 0.054777513492244564\n",
            "Epoch: 50 | Batch: 321 | Loss: 0.03821922280279151\n",
            "Epoch: 50 | Batch: 322 | Loss: 0.05181137362077754\n",
            "Epoch: 50 | Batch: 323 | Loss: 0.08236805479956393\n",
            "Epoch: 50 | Batch: 324 | Loss: 0.04425372197002198\n",
            "Epoch: 50 | Batch: 325 | Loss: 0.03289924276104392\n",
            "Epoch: 50 | Batch: 326 | Loss: 0.06733868136598067\n",
            "Epoch: 50 | Batch: 327 | Loss: 0.09116129782735456\n",
            "Epoch: 50 | Batch: 328 | Loss: 0.07218356457075706\n",
            "Epoch: 50 | Batch: 329 | Loss: 0.052772651449109226\n",
            "Epoch: 50 | Batch: 330 | Loss: 0.052383546344066924\n",
            "Epoch: 50 | Batch: 331 | Loss: 0.034869960414386995\n",
            "Epoch: 50 | Batch: 332 | Loss: 0.07124455056092535\n",
            "Epoch: 50 | Batch: 333 | Loss: 0.04301775268575668\n",
            "Epoch: 50 | Batch: 334 | Loss: 0.10917642968013269\n",
            "Epoch: 50 | Batch: 335 | Loss: 0.07513591609546204\n",
            "Epoch: 50 | Batch: 336 | Loss: 0.06445733441653193\n",
            "Epoch: 50 | Batch: 337 | Loss: 0.05124802792649748\n",
            "Epoch: 50 | Batch: 338 | Loss: 0.06184590116135361\n",
            "Epoch: 50 | Batch: 339 | Loss: 0.04049184349126478\n",
            "Epoch: 50 | Batch: 340 | Loss: 0.05677406015147575\n",
            "Epoch: 50 | Batch: 341 | Loss: 0.06506516710932228\n",
            "Epoch: 50 | Batch: 342 | Loss: 0.04001250416830311\n",
            "Epoch: 50 | Batch: 343 | Loss: 0.04226281033800527\n",
            "Epoch: 50 | Batch: 344 | Loss: 0.041944896031666935\n",
            "Epoch: 50 | Batch: 345 | Loss: 0.06295508114439757\n",
            "Epoch: 50 | Batch: 346 | Loss: 0.0526993301568485\n",
            "Epoch: 50 | Batch: 347 | Loss: 0.04742249774912112\n",
            "Epoch: 50 | Batch: 348 | Loss: 0.11677072861845988\n",
            "Epoch: 50 | Batch: 349 | Loss: 0.04899118714762013\n",
            "Epoch: 50 | Batch: 350 | Loss: 0.04673842495616683\n",
            "Epoch: 50 | Batch: 351 | Loss: 0.04683656166608846\n",
            "Epoch: 50 | Batch: 352 | Loss: 0.05134854350402626\n",
            "Epoch: 50 | Batch: 353 | Loss: 0.044494081538551604\n",
            "Epoch: 50 | Batch: 354 | Loss: 0.05762764723185327\n",
            "Epoch: 50 | Batch: 355 | Loss: 0.05792051452161187\n",
            "Epoch: 50 | Batch: 356 | Loss: 0.05026015384517196\n",
            "Epoch: 50 | Batch: 357 | Loss: 0.05756620216551918\n",
            "Epoch: 50 | Batch: 358 | Loss: 0.04932241992315072\n",
            "Epoch: 50 | Batch: 359 | Loss: 0.0710168404048479\n",
            "Epoch: 50 | Batch: 360 | Loss: 0.04786428568005295\n",
            "Epoch: 50 | Batch: 361 | Loss: 0.052332256732227016\n",
            "Epoch: 50 | Batch: 362 | Loss: 0.043213600147934156\n",
            "Epoch: 50 | Batch: 363 | Loss: 0.040838740592131086\n",
            "Epoch: 50 | Batch: 364 | Loss: 0.0637093227951042\n",
            "Epoch: 50 | Batch: 365 | Loss: 0.07924678714873776\n",
            "Epoch: 50 | Batch: 366 | Loss: 0.06024389828605101\n",
            "Epoch: 50 | Batch: 367 | Loss: 0.04864815026191861\n",
            "Epoch: 50 | Batch: 368 | Loss: 0.05088884046097492\n",
            "Epoch: 50 | Batch: 369 | Loss: 0.06085582677950355\n",
            "Epoch: 50 | Batch: 370 | Loss: 0.04912475698533755\n",
            "Epoch: 50 | Batch: 371 | Loss: 0.053620322821929196\n",
            "Epoch: 50 | Batch: 372 | Loss: 0.07226946598473792\n",
            "Epoch: 50 | Batch: 373 | Loss: 0.04644490743414423\n",
            "Epoch: 50 | Batch: 374 | Loss: 0.06410318772626901\n",
            "Epoch: 50 | Batch: 375 | Loss: 0.03998566514092662\n",
            "Epoch: 50 | Batch: 376 | Loss: 0.06502378340988402\n",
            "Epoch: 50 | Batch: 377 | Loss: 0.06398787514680668\n",
            "Epoch: 50 | Batch: 378 | Loss: 0.0468322028274677\n",
            "Epoch: 50 | Batch: 379 | Loss: 0.07108761606613057\n",
            "Epoch: 50 | Batch: 380 | Loss: 0.07490536051019638\n",
            "Epoch: 50 | Batch: 381 | Loss: 0.06503676694137143\n",
            "Epoch: 50 | Batch: 382 | Loss: 0.03970355624705507\n",
            "Epoch: 50 | Batch: 383 | Loss: 0.061042872452281974\n",
            "Epoch: 50 | Batch: 384 | Loss: 0.05987370815789192\n",
            "Epoch: 50 | Batch: 385 | Loss: 0.0537021497209044\n",
            "Epoch: 50 | Batch: 386 | Loss: 0.056431501691891595\n",
            "Epoch: 50 | Batch: 387 | Loss: 0.05955646567227209\n",
            "Epoch: 50 | Batch: 388 | Loss: 0.08901565344449322\n",
            "Epoch: 50 | Batch: 389 | Loss: 0.0571308882108813\n",
            "Epoch: 50 | Batch: 390 | Loss: 0.06412646802920413\n",
            "Epoch: 50 | Batch: 391 | Loss: 0.052184542014255854\n",
            "Epoch: 50 | Batch: 392 | Loss: 0.06361452732714859\n",
            "Epoch: 50 | Batch: 393 | Loss: 0.09796369539003334\n",
            "Epoch: 50 | Batch: 394 | Loss: 0.09029955797638156\n",
            "Epoch: 50 | Batch: 395 | Loss: 0.0481974803825438\n",
            "Epoch: 50 | Batch: 396 | Loss: 0.045786165979862854\n",
            "Epoch: 50 | Batch: 397 | Loss: 0.0508795205347947\n",
            "Epoch: 50 | Batch: 398 | Loss: 0.08001004596275302\n",
            "Epoch: 50 | Batch: 399 | Loss: 0.06468770585805689\n",
            "Epoch: 50 | Batch: 400 | Loss: 0.04834775574807275\n",
            "Epoch: 50 | Batch: 401 | Loss: 0.05452878494188186\n",
            "Epoch: 50 | Batch: 402 | Loss: 0.05104037970027214\n",
            "Epoch: 50 | Batch: 403 | Loss: 0.03135952975996461\n",
            "Epoch: 50 | Batch: 404 | Loss: 0.05211226490723035\n",
            "Epoch: 50 | Batch: 405 | Loss: 0.06266152290768642\n",
            "Epoch: 50 | Batch: 406 | Loss: 0.05690208803298434\n",
            "Epoch: 50 | Batch: 407 | Loss: 0.0956909243012443\n",
            "Epoch: 50 | Batch: 408 | Loss: 0.09690053651187955\n",
            "Epoch: 50 | Batch: 409 | Loss: 0.10535518879374972\n",
            "Epoch: 50 | Batch: 410 | Loss: 0.0666257374166845\n",
            "Epoch: 50 | Batch: 411 | Loss: 0.05235754683488541\n",
            "Epoch: 50 | Batch: 412 | Loss: 0.04588799036067119\n",
            "Epoch: 50 | Batch: 413 | Loss: 0.046640525701725506\n",
            "Epoch: 50 | Batch: 414 | Loss: 0.05574566072963889\n",
            "Epoch: 50 | Batch: 415 | Loss: 0.08397714916520278\n",
            "Epoch: 50 | Batch: 416 | Loss: 0.0917185291627409\n",
            "Epoch: 50 | Batch: 417 | Loss: 0.03989489701195398\n",
            "Epoch: 50 | Batch: 418 | Loss: 0.059979317865597105\n",
            "Epoch: 50 | Batch: 419 | Loss: 0.046954829578507884\n",
            "Epoch: 50 | Batch: 420 | Loss: 0.038467653683498505\n",
            "Epoch: 50 | Batch: 421 | Loss: 0.07002277295650991\n",
            "Epoch: 50 | Batch: 422 | Loss: 0.04249606473075393\n",
            "Epoch: 50 | Batch: 423 | Loss: 0.05530232352560252\n",
            "Epoch: 50 | Batch: 424 | Loss: 0.040641939651620516\n",
            "Epoch: 50 | Batch: 425 | Loss: 0.04687546429317092\n",
            "Epoch: 50 | Batch: 426 | Loss: 0.04816872189184094\n",
            "Epoch: 50 | Batch: 427 | Loss: 0.05561671478368884\n",
            "Epoch: 50 | Batch: 428 | Loss: 0.0783484795653311\n",
            "Epoch: 50 | Batch: 429 | Loss: 0.04152059354215867\n",
            "Epoch: 50 | Batch: 430 | Loss: 0.056516856744738206\n",
            "Epoch: 50 | Batch: 431 | Loss: 0.0404819545397028\n",
            "Epoch: 50 | Batch: 432 | Loss: 0.03462649454040789\n",
            "Epoch: 50 | Batch: 433 | Loss: 0.05757434914252532\n",
            "Epoch: 50 | Batch: 434 | Loss: 0.04728211827821128\n",
            "Epoch: 50 | Batch: 435 | Loss: 0.049900402215232155\n",
            "Epoch: 50 | Batch: 436 | Loss: 0.06540010667357464\n",
            "Epoch: 50 | Batch: 437 | Loss: 0.09205892199224276\n",
            "Epoch: 50 | Batch: 438 | Loss: 0.07996633814757763\n",
            "Epoch: 50 | Batch: 439 | Loss: 0.05800264423152191\n",
            "Epoch: 50 | Batch: 440 | Loss: 0.04711472657681\n",
            "Epoch: 50 | Batch: 441 | Loss: 0.054761343908460686\n",
            "Epoch: 50 | Batch: 442 | Loss: 0.03919971542450813\n",
            "Epoch: 50 | Batch: 443 | Loss: 0.05638027573279826\n",
            "Epoch: 50 | Batch: 444 | Loss: 0.05419685397747323\n",
            "Epoch: 50 | Batch: 445 | Loss: 0.08580445854485227\n",
            "Epoch: 50 | Batch: 446 | Loss: 0.0487791955177022\n",
            "Epoch: 50 | Batch: 447 | Loss: 0.04820229595003702\n",
            "Epoch: 50 | Batch: 448 | Loss: 0.07017435889238449\n",
            "Epoch: 50 | Batch: 449 | Loss: 0.033918587025843466\n",
            "Epoch: 50 | Batch: 450 | Loss: 0.051858106858084695\n",
            "Epoch: 50 | Batch: 451 | Loss: 0.05829053135850705\n",
            "Epoch: 50 | Batch: 452 | Loss: 0.04692902539403056\n",
            "Epoch: 50 | Batch: 453 | Loss: 0.04206117976726313\n",
            "Epoch: 50 | Batch: 454 | Loss: 0.04724288320244457\n",
            "Epoch: 50 | Batch: 455 | Loss: 0.06586441192385194\n",
            "Epoch: 50 | Batch: 456 | Loss: 0.07994725338750217\n",
            "Epoch: 50 | Batch: 457 | Loss: 0.05256673608792749\n",
            "Epoch: 50 | Batch: 458 | Loss: 0.043133809040397715\n",
            "Epoch: 50 | Batch: 459 | Loss: 0.03730760523694146\n",
            "Epoch: 50 | Batch: 460 | Loss: 0.04361282375372566\n",
            "Epoch: 50 | Batch: 461 | Loss: 0.05348394473964879\n",
            "Epoch: 50 | Batch: 462 | Loss: 0.056856875844087704\n",
            "Epoch: 50 | Batch: 463 | Loss: 0.0453693407948337\n",
            "Epoch: 50 | Batch: 464 | Loss: 0.049553096648181076\n",
            "Epoch: 50 | Batch: 465 | Loss: 0.048466897946834155\n",
            "Epoch: 50 | Batch: 466 | Loss: 0.06031186098297445\n",
            "Epoch: 50 | Batch: 467 | Loss: 0.042355090183458274\n",
            "Epoch: 50 | Batch: 468 | Loss: 0.05037285830064264\n",
            "Epoch: 50 | Batch: 469 | Loss: 0.055949455660260786\n",
            "Epoch: 50 | Batch: 470 | Loss: 0.06622684705629991\n",
            "Epoch: 50 | Batch: 471 | Loss: 0.07007209321061877\n",
            "Epoch: 50 | Batch: 472 | Loss: 0.030877283084510168\n",
            "Epoch: 50 | Batch: 473 | Loss: 0.0677621395034524\n",
            "Epoch: 50 | Batch: 474 | Loss: 0.0635580997230908\n",
            "Epoch: 50 | Batch: 475 | Loss: 0.03846942179267502\n",
            "Epoch: 50 | Batch: 476 | Loss: 0.04063549206231455\n",
            "Epoch: 50 | Batch: 477 | Loss: 0.05670335011359962\n",
            "Epoch: 50 | Batch: 478 | Loss: 0.04439492771557155\n",
            "Epoch: 50 | Batch: 479 | Loss: 0.03975636838157614\n",
            "Epoch: 50 | Batch: 480 | Loss: 0.044013986301347265\n",
            "Epoch: 50 | Batch: 481 | Loss: 0.07736163153659005\n",
            "Epoch: 50 | Batch: 482 | Loss: 0.05444570771362714\n",
            "Epoch: 50 | Batch: 483 | Loss: 0.0485893857819657\n",
            "Epoch: 50 | Batch: 484 | Loss: 0.07066560660391447\n",
            "Epoch: 50 | Batch: 485 | Loss: 0.07690158333217771\n",
            "Epoch: 50 | Batch: 486 | Loss: 0.06439839814554052\n",
            "Epoch: 50 | Batch: 487 | Loss: 0.046405648865792924\n",
            "Epoch: 50 | Batch: 488 | Loss: 0.05286577735744485\n",
            "Epoch: 50 | Batch: 489 | Loss: 0.13551512304415358\n",
            "Epoch: 50 | Batch: 490 | Loss: 0.043991446309571205\n",
            "Epoch: 50 | Batch: 491 | Loss: 0.04043400808545484\n",
            "Epoch: 50 | Batch: 492 | Loss: 0.033838181007722554\n",
            "Epoch: 50 | Batch: 493 | Loss: 0.04190883945660742\n",
            "Epoch: 50 | Batch: 494 | Loss: 0.045394635295873606\n",
            "Epoch: 50 | Batch: 495 | Loss: 0.06137722751507317\n",
            "Epoch: 50 | Batch: 496 | Loss: 0.09566242109405014\n",
            "Epoch: 50 | Batch: 497 | Loss: 0.04111642316607174\n",
            "Epoch: 50 | Batch: 498 | Loss: 0.03979572270821566\n",
            "Epoch: 50 | Batch: 499 | Loss: 0.04590000881810012\n",
            "Epoch: 50 | Batch: 500 | Loss: 0.05031880823851527\n",
            "Epoch: 50 | Batch: 501 | Loss: 0.06713402062361844\n",
            "Epoch: 50 | Batch: 502 | Loss: 0.04143638497573631\n",
            "Epoch: 50 | Batch: 503 | Loss: 0.038425415920240555\n",
            "Epoch: 50 | Batch: 504 | Loss: 0.08172956392795953\n",
            "Epoch: 50 | Batch: 505 | Loss: 0.06422471171829192\n",
            "Epoch: 50 | Batch: 506 | Loss: 0.04903291903242958\n",
            "Epoch: 50 | Batch: 507 | Loss: 0.0410938126226863\n",
            "Epoch: 50 | Batch: 508 | Loss: 0.04663671566119272\n",
            "Epoch: 50 | Batch: 509 | Loss: 0.05668049352313499\n",
            "Epoch: 50 | Batch: 510 | Loss: 0.04672171529109062\n",
            "Epoch: 50 | Batch: 511 | Loss: 0.07677210672835778\n",
            "Epoch: 50 | Batch: 512 | Loss: 0.058342254268773076\n",
            "Epoch: 50 | Batch: 513 | Loss: 0.05799785101420046\n",
            "Epoch: 50 | Batch: 514 | Loss: 0.05411280719737641\n",
            "Epoch: 50 | Batch: 515 | Loss: 0.06769046379102317\n",
            "Epoch: 50 | Batch: 516 | Loss: 0.09458206987228557\n",
            "Epoch: 50 | Batch: 517 | Loss: 0.04006492799166196\n",
            "Epoch: 50 | Batch: 518 | Loss: 0.0475362125348988\n",
            "Epoch: 50 | Batch: 519 | Loss: 0.055004101306352124\n",
            "Epoch: 50 | Batch: 520 | Loss: 0.05543633053041945\n",
            "Epoch: 50 | Batch: 521 | Loss: 0.051317059240655306\n",
            "Epoch: 50 | Batch: 522 | Loss: 0.07774459054082165\n",
            "Epoch: 50 | Batch: 523 | Loss: 0.08297937555686691\n",
            "Epoch: 50 | Batch: 524 | Loss: 0.06871800193610823\n",
            "Epoch: 50 | Batch: 525 | Loss: 0.056955787168792515\n",
            "Epoch: 50 | Batch: 526 | Loss: 0.0777576137406679\n",
            "Epoch: 50 | Batch: 527 | Loss: 0.10557339611198857\n",
            "Epoch: 50 | Batch: 528 | Loss: 0.04621429334054468\n",
            "Epoch: 50 | Batch: 529 | Loss: 0.07916518466910272\n",
            "Epoch: 50 | Batch: 530 | Loss: 0.06573073012738048\n",
            "Epoch: 50 | Batch: 531 | Loss: 0.04826794488707264\n",
            "Epoch: 50 | Batch: 532 | Loss: 0.061791723026117795\n",
            "Epoch: 50 | Batch: 533 | Loss: 0.047091809315142154\n",
            "Epoch: 50 | Batch: 534 | Loss: 0.0442042138320448\n",
            "Epoch: 50 | Batch: 535 | Loss: 0.04972387723056194\n",
            "Epoch: 50 | Batch: 536 | Loss: 0.04859265550210551\n",
            "Epoch: 50 | Batch: 537 | Loss: 0.07146381395412141\n",
            "Epoch: 50 | Batch: 538 | Loss: 0.04223800063575084\n",
            "Epoch: 50 | Batch: 539 | Loss: 0.07568982461954062\n",
            "Epoch: 50 | Batch: 540 | Loss: 0.0509736015486315\n",
            "Epoch: 50 | Batch: 541 | Loss: 0.04894186917964487\n",
            "Epoch: 50 | Batch: 542 | Loss: 0.07108871891637608\n",
            "Epoch: 50 | Batch: 543 | Loss: 0.06607353259960873\n",
            "Epoch: 50 | Batch: 544 | Loss: 0.07042409752790899\n",
            "Epoch: 50 | Batch: 545 | Loss: 0.06584843078323778\n",
            "Epoch: 50 | Batch: 546 | Loss: 0.06366564326299479\n",
            "Epoch: 50 | Batch: 547 | Loss: 0.08043526939628583\n",
            "Epoch: 50 | Batch: 548 | Loss: 0.061180673652158526\n",
            "Epoch: 50 | Batch: 549 | Loss: 0.07326850638846064\n",
            "Epoch: 50 | Batch: 550 | Loss: 0.056280030514811924\n",
            "Epoch: 50 | Batch: 551 | Loss: 0.057215941600242765\n",
            "Epoch: 50 | Batch: 552 | Loss: 0.07928145830926839\n",
            "Epoch: 50 | Batch: 553 | Loss: 0.048653388188472285\n",
            "Epoch: 50 | Batch: 554 | Loss: 0.07502518312164036\n",
            "Epoch: 50 | Batch: 555 | Loss: 0.028542933134672696\n",
            "Epoch: 50 | Batch: 556 | Loss: 0.05156311689525541\n",
            "Epoch: 50 | Batch: 557 | Loss: 0.07605359489808845\n",
            "Epoch: 50 | Batch: 558 | Loss: 0.054201454227629835\n",
            "Epoch: 50 | Batch: 559 | Loss: 0.07029544194035589\n",
            "Epoch: 50 | Batch: 560 | Loss: 0.07054212038111941\n",
            "Epoch: 50 | Batch: 561 | Loss: 0.05830019692740089\n",
            "Epoch: 50 | Batch: 562 | Loss: 0.06610357489538723\n",
            "Epoch: 50 | Batch: 563 | Loss: 0.05271507807819999\n",
            "Epoch: 50 | Batch: 564 | Loss: 0.057404158442778144\n",
            "Epoch: 50 | Batch: 565 | Loss: 0.05139747667953697\n",
            "Epoch: 50 | Batch: 566 | Loss: 0.05963097914088229\n",
            "Epoch: 50 | Batch: 567 | Loss: 0.04591157242407788\n",
            "Epoch: 50 | Batch: 568 | Loss: 0.10177718415054618\n",
            "Epoch: 50 | Batch: 569 | Loss: 0.049556264727073196\n",
            "Epoch: 50 | Batch: 570 | Loss: 0.09019938310988314\n",
            "Epoch: 50 | Batch: 571 | Loss: 0.05799754820458952\n",
            "Epoch: 50 | Batch: 572 | Loss: 0.06729771008963682\n",
            "Epoch: 50 | Batch: 573 | Loss: 0.060032507311467836\n",
            "Epoch: 50 | Batch: 574 | Loss: 0.04406532410770206\n",
            "Epoch: 50 | Batch: 575 | Loss: 0.06472530107450193\n",
            "Epoch: 50 | Batch: 576 | Loss: 0.0621096919153216\n",
            "Epoch: 50 | Batch: 577 | Loss: 0.046725791511177325\n",
            "Epoch: 50 | Batch: 578 | Loss: 0.04776763836158679\n",
            "Epoch: 50 | Batch: 579 | Loss: 0.03948342025018034\n",
            "Epoch: 50 | Batch: 580 | Loss: 0.03943066451426222\n",
            "Epoch: 50 | Batch: 581 | Loss: 0.039161408546482306\n",
            "Epoch: 50 | Batch: 582 | Loss: 0.048259694992679514\n",
            "Epoch: 50 | Batch: 583 | Loss: 0.027839137002830437\n",
            "Epoch: 50 | Batch: 584 | Loss: 0.07382165874618836\n",
            "Epoch: 50 | Batch: 585 | Loss: 0.05979268498996871\n",
            "Epoch: 50 | Batch: 586 | Loss: 0.045510490751136216\n",
            "Epoch: 50 | Batch: 587 | Loss: 0.043821255767121814\n",
            "Epoch: 50 | Batch: 588 | Loss: 0.04559330663244536\n",
            "Epoch: 50 | Batch: 589 | Loss: 0.050052975063559504\n",
            "Epoch: 50 | Batch: 590 | Loss: 0.051092892938214424\n",
            "Epoch: 50 | Batch: 591 | Loss: 0.06324831791984853\n",
            "Epoch: 50 | Batch: 592 | Loss: 0.09791667806132216\n",
            "Epoch: 50 | Batch: 593 | Loss: 0.04412678683103681\n",
            "Epoch: 50 | Batch: 594 | Loss: 0.04360907409143594\n",
            "Epoch: 50 | Batch: 595 | Loss: 0.05961413250239472\n",
            "Epoch: 50 | Batch: 596 | Loss: 0.051774233752153065\n",
            "Epoch: 50 | Batch: 597 | Loss: 0.04348342847096402\n",
            "Epoch: 50 | Batch: 598 | Loss: 0.050823173947597194\n",
            "Epoch: 50 | Batch: 599 | Loss: 0.054955476373817105\n",
            "Epoch: 50 | Batch: 600 | Loss: 0.04759472620541824\n",
            "Epoch: 50 | Batch: 601 | Loss: 0.05170772806271876\n",
            "Epoch: 50 | Batch: 602 | Loss: 0.0802689336159354\n",
            "Epoch: 50 | Batch: 603 | Loss: 0.0467561933099879\n",
            "Epoch: 50 | Batch: 604 | Loss: 0.040379816757945\n",
            "Epoch: 50 | Batch: 605 | Loss: 0.04543714379587256\n",
            "Epoch: 50 | Batch: 606 | Loss: 0.07519418215134313\n",
            "Epoch: 50 | Batch: 607 | Loss: 0.04518024105931961\n",
            "Epoch: 50 | Batch: 608 | Loss: 0.09635073167313202\n",
            "Epoch: 50 | Batch: 609 | Loss: 0.05256202390221603\n",
            "Epoch: 50 | Batch: 610 | Loss: 0.04496923789103957\n",
            "Epoch: 50 | Batch: 611 | Loss: 0.05291534415841808\n",
            "Epoch: 50 | Batch: 612 | Loss: 0.06434020598205656\n",
            "Epoch: 50 | Batch: 613 | Loss: 0.045359704979679644\n",
            "Epoch: 50 | Batch: 614 | Loss: 0.08582186034530259\n",
            "Epoch: 50 | Batch: 615 | Loss: 0.06155627583248433\n",
            "Epoch: 50 | Batch: 616 | Loss: 0.04578970274021763\n",
            "Epoch: 50 | Batch: 617 | Loss: 0.05937657860610848\n",
            "Epoch: 50 | Batch: 618 | Loss: 0.04616429420688035\n",
            "Epoch: 50 | Batch: 619 | Loss: 0.03627885848813575\n",
            "Epoch: 50 | Batch: 620 | Loss: 0.05564811071625066\n",
            "Epoch: 50 | Batch: 621 | Loss: 0.04372653826842904\n",
            "Epoch: 50 | Batch: 622 | Loss: 0.07544229777780753\n",
            "Epoch: 50 | Batch: 623 | Loss: 0.050347213390974685\n",
            "Epoch: 50 | Batch: 624 | Loss: 0.06043920055087507\n",
            "Epoch: 50 | Batch: 625 | Loss: 0.07044378691209703\n",
            "Epoch: 50 | Batch: 626 | Loss: 0.06057527969064924\n",
            "Epoch: 50 | Batch: 627 | Loss: 0.05652929544736737\n",
            "Epoch: 50 | Batch: 628 | Loss: 0.050151740538540795\n",
            "Epoch: 50 | Batch: 629 | Loss: 0.07026028459450709\n",
            "Epoch: 50 | Batch: 630 | Loss: 0.05429458032819528\n",
            "Epoch: 50 | Batch: 631 | Loss: 0.08356083858630801\n",
            "Epoch: 50 | Batch: 632 | Loss: 0.05075463749890059\n",
            "Epoch: 50 | Batch: 633 | Loss: 0.04432193660889558\n",
            "Epoch: 50 | Batch: 634 | Loss: 0.05773534330197594\n",
            "Epoch: 50 | Batch: 635 | Loss: 0.06160300933579069\n",
            "Epoch: 50 | Batch: 636 | Loss: 0.05337908666608978\n",
            "Epoch: 50 | Batch: 637 | Loss: 0.07442380752992706\n",
            "Epoch: 50 | Batch: 638 | Loss: 0.06514446537917253\n",
            "Epoch: 50 | Batch: 639 | Loss: 0.07632017489520554\n",
            "Epoch: 50 | Batch: 640 | Loss: 0.05039848765075286\n",
            "Epoch: 50 | Batch: 641 | Loss: 0.05205990703120522\n",
            "Epoch: 50 | Batch: 642 | Loss: 0.039476763960271874\n",
            "Epoch: 50 | Batch: 643 | Loss: 0.0732290135157918\n",
            "Epoch: 50 | Batch: 644 | Loss: 0.07087450082802646\n",
            "Epoch: 50 | Batch: 645 | Loss: 0.08027857045454552\n",
            "Epoch: 50 | Batch: 646 | Loss: 0.05768096249687893\n",
            "Epoch: 50 | Batch: 647 | Loss: 0.05367071292188553\n",
            "Epoch: 50 | Batch: 648 | Loss: 0.040083000619513615\n",
            "Epoch: 50 | Batch: 649 | Loss: 0.0715571732757712\n",
            "Epoch: 50 | Batch: 650 | Loss: 0.04929231072694421\n",
            "Epoch: 50 | Batch: 651 | Loss: 0.0642535312954904\n",
            "Epoch: 50 | Batch: 652 | Loss: 0.041974780412352884\n",
            "Epoch: 50 | Batch: 653 | Loss: 0.045106911595654026\n",
            "Epoch: 50 | Batch: 654 | Loss: 0.07290012637546857\n",
            "Epoch: 50 | Batch: 655 | Loss: 0.059913898631466504\n",
            "Epoch: 50 | Batch: 656 | Loss: 0.040555881721402405\n",
            "Epoch: 50 | Batch: 657 | Loss: 0.0647683250008434\n",
            "Epoch: 50 | Batch: 658 | Loss: 0.0890857198891545\n",
            "Epoch: 50 | Batch: 659 | Loss: 0.032503906552894674\n",
            "Epoch: 50 | Batch: 660 | Loss: 0.09739338177392282\n",
            "Epoch: 50 | Batch: 661 | Loss: 0.07772379722869831\n",
            "Epoch: 50 | Batch: 662 | Loss: 0.06053700148989922\n",
            "Epoch: 50 | Batch: 663 | Loss: 0.040413792628209676\n",
            "Epoch: 50 | Batch: 664 | Loss: 0.06458054233224186\n",
            "Epoch: 50 | Batch: 665 | Loss: 0.044716688315176445\n",
            "Epoch: 50 | Batch: 666 | Loss: 0.06265853988061619\n",
            "Epoch: 50 | Batch: 667 | Loss: 0.04220728567595569\n",
            "Epoch: 50 | Batch: 668 | Loss: 0.10373315135546071\n",
            "Epoch: 50 | Batch: 669 | Loss: 0.06681512204837878\n",
            "Epoch: 50 | Batch: 670 | Loss: 0.06499824867941073\n",
            "Epoch: 50 | Batch: 671 | Loss: 0.045448744550886114\n",
            "Epoch: 50 | Batch: 672 | Loss: 0.03875971339819585\n",
            "Epoch: 50 | Batch: 673 | Loss: 0.07814916842939033\n",
            "Epoch: 50 | Batch: 674 | Loss: 0.057040107935022746\n",
            "Epoch: 50 | Batch: 675 | Loss: 0.08575783554026643\n",
            "Epoch: 50 | Batch: 676 | Loss: 0.05345971237912471\n",
            "Epoch: 50 | Batch: 677 | Loss: 0.06395579927156453\n",
            "Epoch: 50 | Batch: 678 | Loss: 0.04667445075253727\n",
            "Epoch: 50 | Batch: 679 | Loss: 0.08215565699076983\n",
            "Epoch: 50 | Batch: 680 | Loss: 0.08825862348001612\n",
            "Epoch: 50 | Batch: 681 | Loss: 0.05023318659335365\n",
            "Epoch: 50 | Batch: 682 | Loss: 0.04166419893785219\n",
            "Epoch: 50 | Batch: 683 | Loss: 0.04752375111821505\n",
            "Epoch: 50 | Batch: 684 | Loss: 0.08915302185031537\n",
            "Epoch: 50 | Batch: 685 | Loss: 0.06214644122086924\n",
            "Epoch: 50 | Batch: 686 | Loss: 0.07502763528612032\n",
            "Epoch: 50 | Batch: 687 | Loss: 0.06027550262505575\n",
            "Epoch: 50 | Batch: 688 | Loss: 0.03660752537030713\n",
            "Epoch: 50 | Batch: 689 | Loss: 0.05798977590870707\n",
            "Epoch: 50 | Batch: 690 | Loss: 0.04273679019226541\n",
            "Epoch: 50 | Batch: 691 | Loss: 0.07137822623448299\n",
            "Epoch: 50 | Batch: 692 | Loss: 0.05998662281752738\n",
            "Epoch: 50 | Batch: 693 | Loss: 0.06513611344272702\n",
            "Epoch: 50 | Batch: 694 | Loss: 0.06286363707868298\n",
            "Epoch: 50 | Batch: 695 | Loss: 0.06580122213515328\n",
            "Epoch: 50 | Batch: 696 | Loss: 0.061976663659783875\n",
            "Epoch: 50 | Batch: 697 | Loss: 0.06523261199175731\n",
            "Epoch: 50 | Batch: 698 | Loss: 0.07563238788114493\n",
            "Epoch: 50 | Batch: 699 | Loss: 0.06092618808277307\n",
            "Epoch: 50 | Batch: 700 | Loss: 0.04861467849951122\n",
            "Epoch: 50 | Batch: 701 | Loss: 0.06017475955263778\n",
            "Epoch: 50 | Batch: 702 | Loss: 0.04551812484171304\n",
            "Epoch: 50 | Batch: 703 | Loss: 0.04358884072349091\n",
            "Epoch: 50 | Batch: 704 | Loss: 0.06806458163068053\n",
            "Epoch: 50 | Batch: 705 | Loss: 0.053275319965009914\n",
            "Epoch: 50 | Batch: 706 | Loss: 0.09852554601952254\n",
            "Epoch: 50 | Batch: 707 | Loss: 0.06255828775747299\n",
            "Epoch: 50 | Batch: 708 | Loss: 0.0501685078059817\n",
            "Epoch: 50 | Batch: 709 | Loss: 0.06137247886752447\n",
            "Epoch: 50 | Batch: 710 | Loss: 0.0786313558425673\n",
            "Epoch: 50 | Batch: 711 | Loss: 0.056138049931757146\n",
            "Epoch: 50 | Batch: 712 | Loss: 0.09308999403728081\n",
            "Epoch: 50 | Batch: 713 | Loss: 0.04651403833301502\n",
            "Epoch: 50 | Batch: 714 | Loss: 0.0480251497286916\n",
            "Epoch: 50 | Batch: 715 | Loss: 0.05693027974499741\n",
            "Epoch: 50 | Batch: 716 | Loss: 0.049574773980669805\n",
            "Epoch: 50 | Batch: 717 | Loss: 0.04368193602063536\n",
            "Epoch: 50 | Batch: 718 | Loss: 0.0734374148366841\n",
            "Epoch: 50 | Batch: 719 | Loss: 0.08235527629997291\n",
            "Epoch: 50 | Batch: 720 | Loss: 0.03684770777254153\n",
            "Epoch: 50 | Batch: 721 | Loss: 0.07219029936637478\n",
            "Epoch: 50 | Batch: 722 | Loss: 0.07764061507422623\n",
            "Epoch: 50 | Batch: 723 | Loss: 0.056591313343637144\n",
            "Epoch: 50 | Batch: 724 | Loss: 0.07056641462447123\n",
            "Epoch: 50 | Batch: 725 | Loss: 0.06281544276463777\n",
            "Epoch: 50 | Batch: 726 | Loss: 0.05875117019797058\n",
            "Epoch: 50 | Batch: 727 | Loss: 0.059373223289925774\n",
            "Epoch: 50 | Batch: 728 | Loss: 0.04664522661433818\n",
            "Epoch: 50 | Batch: 729 | Loss: 0.0845608368058431\n",
            "Epoch: 50 | Batch: 730 | Loss: 0.04348608909539638\n",
            "Epoch: 50 | Batch: 731 | Loss: 0.059122089541297204\n",
            "Epoch: 50 | Batch: 732 | Loss: 0.08167291633693585\n",
            "Epoch: 50 | Batch: 733 | Loss: 0.04229034121616198\n",
            "Epoch: 50 | Batch: 734 | Loss: 0.051283422955738844\n",
            "Epoch: 50 | Batch: 735 | Loss: 0.05081199984628104\n",
            "Epoch: 50 | Batch: 736 | Loss: 0.04422513360945418\n",
            "Epoch: 50 | Batch: 737 | Loss: 0.04824652662148994\n",
            "Epoch: 50 | Batch: 738 | Loss: 0.09163769146160095\n",
            "Epoch: 50 | Batch: 739 | Loss: 0.05658221069093448\n",
            "Epoch: 50 | Batch: 740 | Loss: 0.0651485436388218\n",
            "Epoch: 50 | Batch: 741 | Loss: 0.04173786244834012\n",
            "Epoch: 50 | Batch: 742 | Loss: 0.043094140052471794\n",
            "Epoch: 50 | Batch: 743 | Loss: 0.04683481449535021\n",
            "Epoch: 50 | Batch: 744 | Loss: 0.047774309370534965\n",
            "Epoch: 50 | Batch: 745 | Loss: 0.060633892198657585\n",
            "Epoch: 50 | Batch: 746 | Loss: 0.049232316354803116\n",
            "Epoch: 50 | Batch: 747 | Loss: 0.04425893481911052\n",
            "Epoch: 50 | Batch: 748 | Loss: 0.07459349401781376\n",
            "Epoch: 50 | Batch: 749 | Loss: 0.06959601843672973\n",
            "Epoch: 50 | Batch: 750 | Loss: 0.055925448508375594\n",
            "Epoch: 50 | Batch: 751 | Loss: 0.08940759476642839\n",
            "Epoch: 50 | Batch: 752 | Loss: 0.05573509359062665\n",
            "Epoch: 50 | Batch: 753 | Loss: 0.05719264691191857\n",
            "Epoch: 50 | Batch: 754 | Loss: 0.04909392481292177\n",
            "Epoch: 50 | Batch: 755 | Loss: 0.07755223516859738\n",
            "Epoch: 50 | Batch: 756 | Loss: 0.06709076786218235\n",
            "Epoch: 50 | Batch: 757 | Loss: 0.03753434755107237\n",
            "Epoch: 50 | Batch: 758 | Loss: 0.06599800532383265\n",
            "Epoch: 50 | Batch: 759 | Loss: 0.054705348359622874\n",
            "Epoch: 50 | Batch: 760 | Loss: 0.13073116925580044\n",
            "Epoch: 50 | Batch: 761 | Loss: 0.06609771538003442\n",
            "Epoch: 50 | Batch: 762 | Loss: 0.05947492220440484\n",
            "Epoch: 50 | Batch: 763 | Loss: 0.09505777064303214\n",
            "Epoch: 50 | Batch: 764 | Loss: 0.03691455784718639\n",
            "Epoch: 50 | Batch: 765 | Loss: 0.06119694764171435\n",
            "Epoch: 50 | Batch: 766 | Loss: 0.05420108667703616\n",
            "Epoch: 50 | Batch: 767 | Loss: 0.05834739002151945\n",
            "Epoch: 50 | Batch: 768 | Loss: 0.06311218148333424\n",
            "Epoch: 50 | Batch: 769 | Loss: 0.0731097374476\n",
            "Epoch: 50 | Batch: 770 | Loss: 0.07089074873434353\n",
            "Epoch: 50 | Batch: 771 | Loss: 0.08044986906144608\n",
            "Epoch: 50 | Batch: 772 | Loss: 0.05843331164735102\n",
            "Epoch: 50 | Batch: 773 | Loss: 0.1120479178280426\n",
            "Epoch: 50 | Batch: 774 | Loss: 0.05066370442044172\n",
            "Epoch: 50 | Batch: 775 | Loss: 0.11958115903349743\n",
            "Epoch: 50 | Batch: 776 | Loss: 0.06856109360574092\n",
            "Epoch: 50 | Batch: 777 | Loss: 0.07675745888675453\n",
            "Epoch: 50 | Batch: 778 | Loss: 0.06369328643700733\n",
            "Epoch: 50 | Batch: 779 | Loss: 0.04177129138498209\n",
            "Epoch: 50 | Batch: 780 | Loss: 0.052773615120599984\n",
            "Epoch: 50 | Batch: 781 | Loss: 0.06144063535892838\n",
            "Epoch: 50 | Batch: 782 | Loss: 0.061804007430250205\n",
            "Epoch: 50 | Batch: 783 | Loss: 0.05803852530985932\n",
            "Epoch: 50 | Batch: 784 | Loss: 0.05286201462700295\n",
            "Epoch: 50 | Batch: 785 | Loss: 0.05941697565927155\n",
            "Epoch: 50 | Batch: 786 | Loss: 0.07108414491259696\n",
            "Epoch: 50 | Batch: 787 | Loss: 0.04506174112569717\n",
            "Epoch: 50 | Batch: 788 | Loss: 0.05120104079317158\n",
            "Epoch: 50 | Batch: 789 | Loss: 0.06612525163680114\n",
            "Epoch: 50 | Batch: 790 | Loss: 0.09205678315312411\n",
            "Epoch: 50 | Batch: 791 | Loss: 0.07065994523955468\n",
            "Epoch: 50 | Batch: 792 | Loss: 0.03661131307963762\n",
            "Epoch: 50 | Batch: 793 | Loss: 0.08058839846171609\n",
            "Epoch: 50 | Batch: 794 | Loss: 0.04376264260811472\n",
            "Epoch: 50 | Batch: 795 | Loss: 0.06884510730039341\n",
            "Epoch: 50 | Batch: 796 | Loss: 0.042599389957926614\n",
            "Epoch: 50 | Batch: 797 | Loss: 0.046510304387978846\n",
            "Epoch: 50 | Batch: 798 | Loss: 0.058928157076680185\n",
            "Epoch: 50 | Batch: 799 | Loss: 0.0640165868592737\n",
            "Epoch: 50 | Batch: 800 | Loss: 0.06621573267798847\n",
            "Epoch: 50 | Batch: 801 | Loss: 0.041759378860637034\n",
            "Epoch: 50 | Batch: 802 | Loss: 0.06737943637218145\n",
            "Epoch: 50 | Batch: 803 | Loss: 0.05729203986047584\n",
            "Epoch: 50 | Batch: 804 | Loss: 0.0474421951430896\n",
            "Epoch: 50 | Batch: 805 | Loss: 0.05369022432172965\n",
            "Epoch: 50 | Batch: 806 | Loss: 0.049070408655115805\n",
            "Epoch: 50 | Batch: 807 | Loss: 0.09372042243608537\n",
            "Epoch: 50 | Batch: 808 | Loss: 0.04660352783072634\n",
            "Epoch: 50 | Batch: 809 | Loss: 0.04548010303919196\n",
            "Epoch: 50 | Batch: 810 | Loss: 0.060649655308950626\n",
            "Epoch: 50 | Batch: 811 | Loss: 0.05962684825113238\n",
            "Epoch: 50 | Batch: 812 | Loss: 0.10239972156306189\n",
            "Epoch: 50 | Batch: 813 | Loss: 0.05744621255278186\n",
            "Epoch: 50 | Batch: 814 | Loss: 0.054101529986685444\n",
            "Epoch: 50 | Batch: 815 | Loss: 0.06146871690737178\n",
            "Epoch: 50 | Batch: 816 | Loss: 0.045323577795572334\n",
            "Epoch: 50 | Batch: 817 | Loss: 0.04014742645221171\n",
            "Epoch: 50 | Batch: 818 | Loss: 0.05497619493806439\n",
            "Epoch: 50 | Batch: 819 | Loss: 0.05768570125101038\n",
            "Epoch: 50 | Batch: 820 | Loss: 0.05114047857642555\n",
            "Epoch: 50 | Batch: 821 | Loss: 0.08705157079385331\n",
            "Epoch: 50 | Batch: 822 | Loss: 0.07154976096242609\n",
            "Epoch: 50 | Batch: 823 | Loss: 0.039704186045119355\n",
            "Epoch: 50 | Batch: 824 | Loss: 0.04902555298880777\n",
            "Epoch: 50 | Batch: 825 | Loss: 0.040172213135339724\n",
            "Epoch: 50 | Batch: 826 | Loss: 0.08032674572443027\n",
            "Epoch: 50 | Batch: 827 | Loss: 0.09169162634192524\n",
            "Epoch: 50 | Batch: 828 | Loss: 0.04972495029975174\n",
            "Epoch: 50 | Batch: 829 | Loss: 0.03668124966036182\n",
            "Epoch: 50 | Batch: 830 | Loss: 0.04899952535290098\n",
            "Epoch: 50 | Batch: 831 | Loss: 0.046563207064562004\n",
            "Epoch: 50 | Batch: 832 | Loss: 0.07513482655671222\n",
            "Epoch: 50 | Batch: 833 | Loss: 0.04414971925378271\n",
            "Epoch: 50 | Batch: 834 | Loss: 0.04441241431186119\n",
            "Epoch: 50 | Batch: 835 | Loss: 0.049299378193093546\n",
            "Epoch: 50 | Batch: 836 | Loss: 0.06355422925033183\n",
            "Epoch: 50 | Batch: 837 | Loss: 0.05803620894589359\n",
            "Epoch: 50 | Batch: 838 | Loss: 0.05730849673521966\n",
            "Epoch: 50 | Batch: 839 | Loss: 0.0849345350174541\n",
            "Epoch: 50 | Batch: 840 | Loss: 0.047560480511390384\n",
            "Epoch: 50 | Batch: 841 | Loss: 0.06572258331003118\n",
            "Epoch: 50 | Batch: 842 | Loss: 0.052537929071753836\n",
            "Epoch: 50 | Batch: 843 | Loss: 0.05904074356343329\n",
            "Epoch: 50 | Batch: 844 | Loss: 0.03643435675606525\n",
            "Epoch: 50 | Batch: 845 | Loss: 0.05571944596069174\n",
            "Epoch: 50 | Batch: 846 | Loss: 0.05893676713344084\n",
            "Epoch: 50 | Batch: 847 | Loss: 0.04906466104437489\n",
            "Epoch: 50 | Batch: 848 | Loss: 0.04273073178299454\n",
            "Epoch: 50 | Batch: 849 | Loss: 0.05759755181855515\n",
            "Epoch: 50 | Batch: 850 | Loss: 0.052680391584467454\n",
            "Epoch: 50 | Batch: 851 | Loss: 0.07910860762662002\n",
            "Epoch: 50 | Batch: 852 | Loss: 0.06568248476892692\n",
            "Epoch: 50 | Batch: 853 | Loss: 0.04312750214742334\n",
            "Epoch: 50 | Batch: 854 | Loss: 0.0777469470887198\n",
            "Epoch: 50 | Batch: 855 | Loss: 0.040563144242866736\n",
            "Epoch: 50 | Batch: 856 | Loss: 0.060277885504606124\n",
            "Epoch: 50 | Batch: 857 | Loss: 0.0631628186506942\n",
            "Epoch: 50 | Batch: 858 | Loss: 0.08395012504433139\n",
            "Epoch: 50 | Batch: 859 | Loss: 0.05437455114025319\n",
            "Epoch: 50 | Batch: 860 | Loss: 0.13744043730523828\n",
            "Epoch: 50 | Batch: 861 | Loss: 0.048811437035685065\n",
            "Epoch: 50 | Batch: 862 | Loss: 0.053346150837364895\n",
            "Epoch: 50 | Batch: 863 | Loss: 0.052609441069698906\n",
            "Epoch: 50 | Batch: 864 | Loss: 0.06354904082195109\n",
            "Epoch: 50 | Batch: 865 | Loss: 0.09616039686544345\n",
            "Epoch: 50 | Batch: 866 | Loss: 0.0466803808134995\n",
            "Epoch: 50 | Batch: 867 | Loss: 0.09985089561631397\n",
            "Epoch: 50 | Batch: 868 | Loss: 0.08487200991227689\n",
            "Epoch: 50 | Batch: 869 | Loss: 0.07845318729028194\n",
            "Epoch: 50 | Batch: 870 | Loss: 0.07670343024042486\n",
            "Epoch: 50 | Batch: 871 | Loss: 0.0452314979749676\n",
            "Epoch: 50 | Batch: 872 | Loss: 0.04468558918878213\n",
            "Epoch: 50 | Batch: 873 | Loss: 0.03981540422009451\n",
            "Epoch: 50 | Batch: 874 | Loss: 0.07103212061394948\n",
            "Epoch: 50 | Batch: 875 | Loss: 0.036853838710879286\n",
            "Epoch: 50 | Batch: 876 | Loss: 0.05388050280379442\n",
            "Epoch: 50 | Batch: 877 | Loss: 0.03164622333108899\n",
            "Epoch: 50 | Batch: 878 | Loss: 0.07914441254814744\n",
            "Epoch: 50 | Batch: 879 | Loss: 0.06036782083983476\n",
            "Epoch: 50 | Batch: 880 | Loss: 0.058997904558463564\n",
            "Epoch: 50 | Batch: 881 | Loss: 0.05965282921809084\n",
            "Epoch: 50 | Batch: 882 | Loss: 0.043286491116720074\n",
            "Epoch: 50 | Batch: 883 | Loss: 0.06444636444120042\n",
            "Epoch: 50 | Batch: 884 | Loss: 0.04864760885701445\n",
            "Epoch: 50 | Batch: 885 | Loss: 0.075757393999514\n",
            "Epoch: 50 | Batch: 886 | Loss: 0.06021124131282245\n",
            "Epoch: 50 | Batch: 887 | Loss: 0.08680055618330967\n",
            "Epoch: 50 | Batch: 888 | Loss: 0.08076505996682697\n",
            "Epoch: 50 | Batch: 889 | Loss: 0.07382647957511837\n",
            "Epoch: 50 | Batch: 890 | Loss: 0.06895418351431014\n",
            "Epoch: 50 | Batch: 891 | Loss: 0.08906613724502593\n",
            "Epoch: 50 | Batch: 892 | Loss: 0.08373757478402113\n",
            "Epoch: 50 | Batch: 893 | Loss: 0.053063835382401864\n",
            "Epoch: 50 | Batch: 894 | Loss: 0.0774293834568207\n",
            "Epoch: 50 | Batch: 895 | Loss: 0.05337907194945402\n",
            "Epoch: 50 | Batch: 896 | Loss: 0.051409047803394795\n",
            "Epoch: 50 | Batch: 897 | Loss: 0.04660935720986491\n",
            "Epoch: 50 | Batch: 898 | Loss: 0.06685549052991084\n",
            "Epoch: 50 | Batch: 899 | Loss: 0.03670047174220943\n",
            "Epoch: 50 | Batch: 900 | Loss: 0.05470255612989262\n",
            "Epoch: 50 | Batch: 901 | Loss: 0.07434030467066362\n",
            "Epoch: 50 | Batch: 902 | Loss: 0.04464829504552878\n",
            "Epoch: 50 | Batch: 903 | Loss: 0.057445919366926376\n",
            "Epoch: 50 | Batch: 904 | Loss: 0.06178615231324696\n",
            "Epoch: 50 | Batch: 905 | Loss: 0.06313281113481103\n",
            "Epoch: 50 | Batch: 906 | Loss: 0.045398282041338126\n",
            "Epoch: 50 | Batch: 907 | Loss: 0.07696839524331898\n",
            "Epoch: 50 | Batch: 908 | Loss: 0.041280064154140005\n",
            "Epoch: 50 | Batch: 909 | Loss: 0.054906190519589324\n",
            "Epoch: 50 | Batch: 910 | Loss: 0.07642403610374317\n",
            "Epoch: 50 | Batch: 911 | Loss: 0.06507327930104954\n",
            "Epoch: 50 | Batch: 912 | Loss: 0.07674697564566883\n",
            "Epoch: 50 | Batch: 913 | Loss: 0.054535851514760605\n",
            "Epoch: 50 | Batch: 914 | Loss: 0.07144868027723374\n",
            "Epoch: 50 | Batch: 915 | Loss: 0.0339355449114236\n",
            "Epoch: 50 | Batch: 916 | Loss: 0.06611647149638389\n",
            "Epoch: 50 | Batch: 917 | Loss: 0.04407171433274411\n",
            "Epoch: 50 | Batch: 918 | Loss: 0.06191171745642522\n",
            "Epoch: 50 | Batch: 919 | Loss: 0.03952053279644516\n",
            "Epoch: 50 | Batch: 920 | Loss: 0.06435193923646279\n",
            "Epoch: 50 | Batch: 921 | Loss: 0.055939453797307324\n",
            "Epoch: 50 | Batch: 922 | Loss: 0.06668031731659584\n",
            "Epoch: 50 | Batch: 923 | Loss: 0.05681225117929524\n",
            "Epoch: 50 | Batch: 924 | Loss: 0.04993388526296846\n",
            "Epoch: 50 | Batch: 925 | Loss: 0.046251531831706424\n",
            "Epoch: 50 | Batch: 926 | Loss: 0.05727113216235864\n",
            "Epoch: 50 | Batch: 927 | Loss: 0.06534054134654176\n",
            "Epoch: 50 | Batch: 928 | Loss: 0.04786046238713475\n",
            "Epoch: 50 | Batch: 929 | Loss: 0.053187638599083945\n",
            "Epoch: 50 | Batch: 930 | Loss: 0.03457971506273601\n",
            "Epoch: 50 | Batch: 931 | Loss: 0.07357260946689673\n",
            "Epoch: 50 | Batch: 932 | Loss: 0.05278053070897939\n",
            "Epoch: 50 | Batch: 933 | Loss: 0.05710427853355032\n",
            "Epoch: 50 | Batch: 934 | Loss: 0.057808295437541395\n",
            "Epoch: 50 | Batch: 935 | Loss: 0.045141058037291994\n",
            "Epoch: 50 | Batch: 936 | Loss: 0.039875734822262636\n",
            "Epoch: 50 | Batch: 937 | Loss: 0.05617449597327458\n",
            "Epoch: 50 | Batch: 938 | Loss: 0.08144088673186628\n",
            "Epoch: 50 | Batch: 939 | Loss: 0.03952808493435382\n",
            "Epoch: 50 | Batch: 940 | Loss: 0.07717398371643108\n",
            "Epoch: 50 | Batch: 941 | Loss: 0.056953948856162395\n",
            "Epoch: 50 | Batch: 942 | Loss: 0.0494971696639037\n",
            "Epoch: 50 | Batch: 943 | Loss: 0.059505414833857864\n",
            "Epoch: 50 | Batch: 944 | Loss: 0.048275882790406094\n",
            "Epoch: 50 | Batch: 945 | Loss: 0.05405887193184664\n",
            "Epoch: 50 | Batch: 946 | Loss: 0.07840585613355774\n",
            "Epoch: 50 | Batch: 947 | Loss: 0.12806893758271015\n",
            "Epoch: 50 | Batch: 948 | Loss: 0.0697124020507088\n",
            "Epoch: 50 | Batch: 949 | Loss: 0.06602997166618038\n",
            "Epoch: 50 | Batch: 950 | Loss: 0.047023707478658874\n",
            "Epoch: 50 | Batch: 951 | Loss: 0.049863337934328886\n",
            "Epoch: 50 | Batch: 952 | Loss: 0.08322272515366094\n",
            "Epoch: 50 | Batch: 953 | Loss: 0.05867270821348596\n",
            "Epoch: 50 | Batch: 954 | Loss: 0.06132272636585712\n",
            "Epoch: 50 | Batch: 955 | Loss: 0.08956810365247773\n",
            "Epoch: 50 | Batch: 956 | Loss: 0.06442584121879168\n",
            "Epoch: 50 | Batch: 957 | Loss: 0.05036229876691877\n",
            "Epoch: 50 | Batch: 958 | Loss: 0.06284513260261111\n",
            "Epoch: 50 | Batch: 959 | Loss: 0.0700012694163093\n",
            "Epoch: 50 | Batch: 960 | Loss: 0.04410523990246164\n",
            "Epoch: 50 | Batch: 961 | Loss: 0.060734986238098004\n",
            "Epoch: 50 | Batch: 962 | Loss: 0.05718710126323968\n",
            "Epoch: 50 | Batch: 963 | Loss: 0.0654792886507469\n",
            "Epoch: 50 | Batch: 964 | Loss: 0.04413652874470661\n",
            "Epoch: 50 | Batch: 965 | Loss: 0.07429702941025457\n",
            "Epoch: 50 | Batch: 966 | Loss: 0.07375276211528647\n",
            "Epoch: 50 | Batch: 967 | Loss: 0.04657367908421512\n",
            "Epoch: 50 | Batch: 968 | Loss: 0.0547245272978122\n",
            "Epoch: 50 | Batch: 969 | Loss: 0.07055929874862683\n",
            "Epoch: 50 | Batch: 970 | Loss: 0.08843374154942087\n",
            "Epoch: 50 | Batch: 971 | Loss: 0.06352469215876161\n",
            "Epoch: 50 | Batch: 972 | Loss: 0.08814856537564135\n",
            "Epoch: 50 | Batch: 973 | Loss: 0.045967078351025314\n",
            "Epoch: 50 | Batch: 974 | Loss: 0.04739003229106942\n",
            "Epoch: 50 | Batch: 975 | Loss: 0.0858065228632825\n",
            "Epoch: 50 | Batch: 976 | Loss: 0.09571139004164751\n",
            "Epoch: 50 | Batch: 977 | Loss: 0.07816486970446178\n",
            "Epoch: 50 | Batch: 978 | Loss: 0.06342143576368492\n",
            "Epoch: 50 | Batch: 979 | Loss: 0.07288553383957017\n",
            "Epoch: 50 | Batch: 980 | Loss: 0.05228991532074141\n",
            "Epoch: 50 | Batch: 981 | Loss: 0.09219682049930461\n",
            "Epoch: 50 | Batch: 982 | Loss: 0.07976096111894189\n",
            "Epoch: 50 | Batch: 983 | Loss: 0.059325669895446645\n",
            "Epoch: 50 | Batch: 984 | Loss: 0.08288406763900512\n",
            "Epoch: 50 | Batch: 985 | Loss: 0.0776780655654586\n",
            "Epoch: 50 | Batch: 986 | Loss: 0.04910496895967836\n",
            "Epoch: 50 | Batch: 987 | Loss: 0.08077943192001852\n",
            "Epoch: 50 | Batch: 988 | Loss: 0.054366166633151185\n",
            "Epoch: 50 | Batch: 989 | Loss: 0.05357804533790211\n",
            "Epoch: 50 | Batch: 990 | Loss: 0.06785312433672061\n",
            "Epoch: 50 | Batch: 991 | Loss: 0.05237973618419889\n",
            "Epoch: 50 | Batch: 992 | Loss: 0.05410489578121639\n",
            "Epoch: 50 | Batch: 993 | Loss: 0.04766411698707582\n",
            "Epoch: 50 | Batch: 994 | Loss: 0.07708529323600644\n",
            "Epoch: 50 | Batch: 995 | Loss: 0.044550878264132975\n",
            "Epoch: 50 | Batch: 996 | Loss: 0.07332258338183191\n",
            "Epoch: 50 | Batch: 997 | Loss: 0.0470472499188055\n",
            "Epoch: 50 | Batch: 998 | Loss: 0.07072970997004668\n",
            "Epoch: 50 | Batch: 999 | Loss: 0.05214098245025928\n",
            "Epoch: 50 | Batch: 1000 | Loss: 0.050019034453124445\n",
            "Epoch: 50 | Batch: 1001 | Loss: 0.04720231369734374\n",
            "Epoch: 50 | Batch: 1002 | Loss: 0.12156955087208172\n",
            "Epoch: 50 | Batch: 1003 | Loss: 0.04838535604165955\n",
            "Epoch: 50 | Batch: 1004 | Loss: 0.07268496658612898\n",
            "Epoch: 50 | Batch: 1005 | Loss: 0.0583061465300172\n",
            "Epoch: 50 | Batch: 1006 | Loss: 0.04915270787586419\n",
            "Epoch: 50 | Batch: 1007 | Loss: 0.10121160827135602\n",
            "Epoch: 50 | Batch: 1008 | Loss: 0.04897237053203503\n",
            "Epoch: 50 | Batch: 1009 | Loss: 0.050332564645674295\n",
            "Epoch: 50 | Batch: 1010 | Loss: 0.07065144014222051\n",
            "Epoch: 50 | Batch: 1011 | Loss: 0.051815788616275046\n",
            "Epoch: 50 | Batch: 1012 | Loss: 0.042526001892799356\n",
            "Epoch: 50 | Batch: 1013 | Loss: 0.07999435375713942\n",
            "Epoch: 50 | Batch: 1014 | Loss: 0.04139116998394056\n",
            "Epoch: 50 | Batch: 1015 | Loss: 0.044934324006782406\n",
            "Epoch: 50 | Batch: 1016 | Loss: 0.05868346099171502\n",
            "Epoch: 50 | Batch: 1017 | Loss: 0.0599155513349363\n",
            "Epoch: 50 | Batch: 1018 | Loss: 0.04742230460325897\n",
            "Epoch: 50 | Batch: 1019 | Loss: 0.05787956735501412\n",
            "Epoch: 50 | Batch: 1020 | Loss: 0.051630807758046196\n",
            "Epoch: 50 | Batch: 1021 | Loss: 0.05675754236269645\n",
            "Epoch: 50 | Batch: 1022 | Loss: 0.056406818721501994\n",
            "Epoch: 50 | Batch: 1023 | Loss: 0.04990954270728476\n",
            "Epoch: 50 | Batch: 1024 | Loss: 0.04503614019918756\n",
            "Epoch: 50 | Batch: 1025 | Loss: 0.0767390690549096\n",
            "Epoch: 50 | Batch: 1026 | Loss: 0.04306290911233309\n",
            "Epoch: 50 | Batch: 1027 | Loss: 0.0541131312816455\n",
            "Epoch: 50 | Batch: 1028 | Loss: 0.05923774454021845\n",
            "Epoch: 50 | Batch: 1029 | Loss: 0.05981341933688578\n",
            "Epoch: 50 | Batch: 1030 | Loss: 0.05391480870309261\n",
            "Epoch: 50 | Batch: 1031 | Loss: 0.11993978422684928\n",
            "Epoch: 50 | Batch: 1032 | Loss: 0.06258647430069053\n",
            "Epoch: 50 | Batch: 1033 | Loss: 0.07189043352315379\n",
            "Epoch: 50 | Batch: 1034 | Loss: 0.06301287923211835\n",
            "Epoch: 50 | Batch: 1035 | Loss: 0.0776484735021643\n",
            "Epoch: 50 | Batch: 1036 | Loss: 0.09859786594381195\n",
            "Epoch: 50 | Batch: 1037 | Loss: 0.03561370062568618\n",
            "Epoch: 50 | Batch: 1038 | Loss: 0.07066767478227572\n",
            "Epoch: 50 | Batch: 1039 | Loss: 0.04917519955087982\n",
            "Epoch: 50 | Batch: 1040 | Loss: 0.06443859269556548\n",
            "Epoch: 50 | Batch: 1041 | Loss: 0.09177139307372353\n",
            "Epoch: 50 | Batch: 1042 | Loss: 0.08384620994217792\n",
            "Epoch: 50 | Batch: 1043 | Loss: 0.09435246550138326\n",
            "Epoch: 50 | Batch: 1044 | Loss: 0.04895549785809025\n",
            "Epoch: 50 | Batch: 1045 | Loss: 0.058991685411328196\n",
            "Epoch: 50 | Batch: 1046 | Loss: 0.056855884693083836\n",
            "Epoch: 50 | Batch: 1047 | Loss: 0.07709090229187877\n",
            "Epoch: 50 | Batch: 1048 | Loss: 0.053284166555834386\n",
            "Epoch: 50 | Batch: 1049 | Loss: 0.06316330438741323\n",
            "Epoch: 50 | Batch: 1050 | Loss: 0.07173668502405134\n",
            "Epoch: 50 | Batch: 1051 | Loss: 0.0542902334123772\n",
            "Epoch: 50 | Batch: 1052 | Loss: 0.06015521637645873\n",
            "Epoch: 50 | Batch: 1053 | Loss: 0.08425950006616933\n",
            "Epoch: 50 | Batch: 1054 | Loss: 0.05183175399564287\n",
            "Epoch: 50 | Batch: 1055 | Loss: 0.07060084070403369\n",
            "Epoch: 50 | Batch: 1056 | Loss: 0.04903998100225651\n",
            "Epoch: 50 | Batch: 1057 | Loss: 0.05866874324129697\n",
            "Epoch: 50 | Batch: 1058 | Loss: 0.059860293550525454\n",
            "Epoch: 50 | Batch: 1059 | Loss: 0.05282100548281826\n",
            "Epoch: 50 | Batch: 1060 | Loss: 0.05943108517771774\n",
            "Epoch: 50 | Batch: 1061 | Loss: 0.059696705267337155\n",
            "Epoch: 50 | Batch: 1062 | Loss: 0.04994802113188121\n",
            "Epoch: 50 | Batch: 1063 | Loss: 0.05306354893243015\n",
            "Epoch: 50 | Batch: 1064 | Loss: 0.08428439569949639\n",
            "Epoch: 50 | Batch: 1065 | Loss: 0.08999243495398468\n",
            "Epoch: 50 | Batch: 1066 | Loss: 0.0880782313207261\n",
            "Epoch: 50 | Batch: 1067 | Loss: 0.042110727258646966\n",
            "Epoch: 50 | Batch: 1068 | Loss: 0.0917864393164815\n",
            "Epoch: 50 | Batch: 1069 | Loss: 0.06471080189110308\n",
            "Epoch: 50 | Batch: 1070 | Loss: 0.09109271867994743\n",
            "Epoch: 50 | Batch: 1071 | Loss: 0.09452512326585649\n",
            "Epoch: 50 | Batch: 1072 | Loss: 0.05939763966472743\n",
            "Epoch: 50 | Batch: 1073 | Loss: 0.07398238207110643\n",
            "Epoch: 50 | Batch: 1074 | Loss: 0.05678770487478131\n",
            "Epoch: 50 | Batch: 1075 | Loss: 0.04311265630051303\n",
            "Epoch: 50 | Batch: 1076 | Loss: 0.04889174678873277\n",
            "Epoch: 50 | Batch: 1077 | Loss: 0.06525612740260729\n",
            "Epoch: 50 | Batch: 1078 | Loss: 0.05511461595650629\n",
            "Epoch: 50 | Batch: 1079 | Loss: 0.059058422165884\n",
            "Epoch: 50 | Batch: 1080 | Loss: 0.06493853662610512\n",
            "Epoch: 50 | Batch: 1081 | Loss: 0.05425733138991015\n",
            "Epoch: 50 | Batch: 1082 | Loss: 0.07648644211397054\n",
            "Epoch: 50 | Batch: 1083 | Loss: 0.0509330031537316\n",
            "Epoch: 50 | Batch: 1084 | Loss: 0.05380724799647735\n",
            "Epoch: 50 | Batch: 1085 | Loss: 0.09979940372807537\n",
            "Epoch: 50 | Batch: 1086 | Loss: 0.06838298105690785\n",
            "Epoch: 50 | Batch: 1087 | Loss: 0.06740721538923301\n",
            "Epoch: 50 | Batch: 1088 | Loss: 0.07288776463293024\n",
            "Epoch: 50 | Batch: 1089 | Loss: 0.04532437159223254\n",
            "Epoch: 50 | Batch: 1090 | Loss: 0.05204383780259442\n",
            "Epoch: 50 | Batch: 1091 | Loss: 0.06067101707342598\n",
            "Epoch: 50 | Batch: 1092 | Loss: 0.05941300635609078\n",
            "Epoch: 50 | Batch: 1093 | Loss: 0.05121255248859567\n",
            "Epoch: 50 | Batch: 1094 | Loss: 0.054127911884614924\n",
            "Epoch: 50 | Batch: 1095 | Loss: 0.06500816936804273\n",
            "Epoch: 50 | Batch: 1096 | Loss: 0.04388180237976065\n",
            "Epoch: 50 | Batch: 1097 | Loss: 0.04678381188515891\n",
            "Epoch: 50 | Batch: 1098 | Loss: 0.0995204310867319\n",
            "Epoch: 50 | Batch: 1099 | Loss: 0.08397858201475526\n",
            "Epoch: 50 | Batch: 1100 | Loss: 0.06569073486305135\n",
            "Epoch: 50 | Batch: 1101 | Loss: 0.08547678299111727\n",
            "Epoch: 50 | Batch: 1102 | Loss: 0.04796285088002247\n",
            "Epoch: 50 | Batch: 1103 | Loss: 0.07741299607655139\n",
            "Epoch: 50 | Batch: 1104 | Loss: 0.061776402915501266\n",
            "Epoch: 50 | Batch: 1105 | Loss: 0.06293945884839758\n",
            "Epoch: 50 | Batch: 1106 | Loss: 0.06307221997694938\n",
            "Epoch: 50 | Batch: 1107 | Loss: 0.04389965311694516\n",
            "Epoch: 50 | Batch: 1108 | Loss: 0.06848278701109772\n",
            "Epoch: 50 | Batch: 1109 | Loss: 0.03698855942500872\n",
            "Epoch: 50 | Batch: 1110 | Loss: 0.05914190664106082\n",
            "Epoch: 50 | Batch: 1111 | Loss: 0.052446699418753365\n",
            "Epoch: 50 | Batch: 1112 | Loss: 0.049658413532462434\n",
            "Epoch: 50 | Batch: 1113 | Loss: 0.07816515543287693\n",
            "Epoch: 50 | Batch: 1114 | Loss: 0.04956075343591415\n",
            "Epoch: 50 | Batch: 1115 | Loss: 0.06506251828301635\n",
            "Epoch: 50 | Batch: 1116 | Loss: 0.04741640722480123\n",
            "Epoch: 50 | Batch: 1117 | Loss: 0.052066061942661154\n",
            "Epoch: 50 | Batch: 1118 | Loss: 0.06462942613147851\n",
            "Epoch: 50 | Batch: 1119 | Loss: 0.05473835016304875\n",
            "Epoch: 50 | Batch: 1120 | Loss: 0.052097402139887616\n",
            "Epoch: 50 | Batch: 1121 | Loss: 0.0393292958231212\n",
            "Epoch: 50 | Batch: 1122 | Loss: 0.09608647190447601\n",
            "Epoch: 50 | Batch: 1123 | Loss: 0.07805495459527016\n",
            "Epoch: 50 | Batch: 1124 | Loss: 0.06055239006087389\n",
            "Epoch: 50 | Batch: 1125 | Loss: 0.08525178657287687\n",
            "Epoch: 50 | Batch: 1126 | Loss: 0.04281981257296727\n",
            "Epoch: 50 | Batch: 1127 | Loss: 0.055915204855434435\n",
            "Epoch: 50 | Batch: 1128 | Loss: 0.05157109902735316\n",
            "Epoch: 50 | Batch: 1129 | Loss: 0.05245174875489318\n",
            "Epoch: 50 | Batch: 1130 | Loss: 0.06799151955984482\n",
            "Epoch: 50 | Batch: 1131 | Loss: 0.08488714203328412\n",
            "Epoch: 50 | Batch: 1132 | Loss: 0.046951318242307236\n",
            "Epoch: 50 | Batch: 1133 | Loss: 0.0627890754547147\n",
            "Epoch: 50 | Batch: 1134 | Loss: 0.06882423028199838\n",
            "Epoch: 50 | Batch: 1135 | Loss: 0.06295700184805084\n",
            "Epoch: 50 | Batch: 1136 | Loss: 0.057328290691228814\n",
            "Epoch: 50 | Batch: 1137 | Loss: 0.051607048279465155\n",
            "Epoch: 50 | Batch: 1138 | Loss: 0.06528491604229347\n",
            "Epoch: 50 | Batch: 1139 | Loss: 0.07913723311101137\n",
            "Epoch: 50 | Batch: 1140 | Loss: 0.09368604489576762\n",
            "Epoch: 50 | Batch: 1141 | Loss: 0.04141110845118651\n",
            "Epoch: 50 | Batch: 1142 | Loss: 0.048702166476170886\n",
            "Epoch: 50 | Batch: 1143 | Loss: 0.04109752434784682\n",
            "Epoch: 50 | Batch: 1144 | Loss: 0.06364859976983221\n",
            "Epoch: 50 | Batch: 1145 | Loss: 0.061015041087932625\n",
            "Epoch: 50 | Batch: 1146 | Loss: 0.0884128846593728\n",
            "Epoch: 50 | Batch: 1147 | Loss: 0.04458676589865054\n",
            "Epoch: 50 | Batch: 1148 | Loss: 0.04276474919089805\n",
            "Epoch: 50 | Batch: 1149 | Loss: 0.061631088318775396\n",
            "Epoch: 50 | Batch: 1150 | Loss: 0.054955117499354944\n",
            "Epoch: 50 | Batch: 1151 | Loss: 0.0811411183057207\n",
            "Epoch: 50 | Batch: 1152 | Loss: 0.06116157960090411\n",
            "Epoch: 50 | Batch: 1153 | Loss: 0.041656192694099134\n",
            "Epoch: 50 | Batch: 1154 | Loss: 0.06880177755047837\n",
            "Epoch: 50 | Batch: 1155 | Loss: 0.06046845505291312\n",
            "Epoch: 50 | Batch: 1156 | Loss: 0.050419412197834294\n",
            "Epoch: 50 | Batch: 1157 | Loss: 0.06463033943349289\n",
            "Epoch: 50 | Batch: 1158 | Loss: 0.05983477481935959\n",
            "Epoch: 50 | Batch: 1159 | Loss: 0.042961279146016385\n",
            "Epoch: 50 | Batch: 1160 | Loss: 0.07383108786009397\n",
            "Epoch: 50 | Batch: 1161 | Loss: 0.05371149633454281\n",
            "Epoch: 50 | Batch: 1162 | Loss: 0.057472350576877745\n",
            "Epoch: 50 | Batch: 1163 | Loss: 0.06155019323132991\n",
            "Epoch: 50 | Batch: 1164 | Loss: 0.04936920571356428\n",
            "Epoch: 50 | Batch: 1165 | Loss: 0.06133008219438614\n",
            "Epoch: 50 | Batch: 1166 | Loss: 0.0664443103752444\n",
            "Epoch: 50 | Batch: 1167 | Loss: 0.06598938126726117\n",
            "Epoch: 50 | Batch: 1168 | Loss: 0.05781364777113678\n",
            "Epoch: 50 | Batch: 1169 | Loss: 0.046532054499068\n",
            "Epoch: 50 | Batch: 1170 | Loss: 0.044605426123008204\n",
            "Epoch: 50 | Batch: 1171 | Loss: 0.07251984859664924\n",
            "Epoch: 50 | Batch: 1172 | Loss: 0.043913013515803\n",
            "Epoch: 50 | Batch: 1173 | Loss: 0.0771807930149888\n",
            "Epoch: 50 | Batch: 1174 | Loss: 0.03923670318143666\n",
            "Epoch: 50 | Batch: 1175 | Loss: 0.11652860244107205\n",
            "Epoch: 50 | Batch: 1176 | Loss: 0.0631554769068926\n",
            "Epoch: 50 | Batch: 1177 | Loss: 0.057149563140133836\n",
            "Epoch: 50 | Batch: 1178 | Loss: 0.04348158882573144\n",
            "Epoch: 50 | Batch: 1179 | Loss: 0.04615423802914069\n",
            "Epoch: 50 | Batch: 1180 | Loss: 0.053172419642691274\n",
            "Epoch: 50 | Batch: 1181 | Loss: 0.07267103657873204\n",
            "Epoch: 50 | Batch: 1182 | Loss: 0.06487215138874668\n",
            "Epoch: 50 | Batch: 1183 | Loss: 0.11729390619466362\n",
            "Epoch: 50 | Batch: 1184 | Loss: 0.07315344986026658\n",
            "Epoch: 50 | Batch: 1185 | Loss: 0.0938805047159452\n",
            "Epoch: 50 | Batch: 1186 | Loss: 0.06904438849745334\n",
            "Epoch: 50 | Batch: 1187 | Loss: 0.06629084408949726\n",
            "Epoch: 50 | Batch: 1188 | Loss: 0.08550507446066341\n",
            "Epoch: 50 | Batch: 1189 | Loss: 0.053899391322907365\n",
            "Epoch: 50 | Batch: 1190 | Loss: 0.06614919864698726\n",
            "Epoch: 50 | Batch: 1191 | Loss: 0.07762983444016479\n",
            "Epoch: 50 | Batch: 1192 | Loss: 0.07056804039215933\n",
            "Epoch: 50 | Batch: 1193 | Loss: 0.06638232508283629\n",
            "Epoch: 50 | Batch: 1194 | Loss: 0.06101412415771509\n",
            "Epoch: 50 | Batch: 1195 | Loss: 0.07231171356780144\n",
            "Epoch: 50 | Batch: 1196 | Loss: 0.07227131986517045\n",
            "Epoch: 50 | Batch: 1197 | Loss: 0.06258872597903632\n",
            "Epoch: 50 | Batch: 1198 | Loss: 0.06729518483788502\n",
            "Epoch: 50 | Batch: 1199 | Loss: 0.0696613854001851\n",
            "Epoch: 50 | Batch: 1200 | Loss: 0.10334067796383395\n",
            "Epoch: 50 | Batch: 1201 | Loss: 0.04477871616551502\n",
            "Epoch: 50 | Batch: 1202 | Loss: 0.1071733245463057\n",
            "Epoch: 50 | Batch: 1203 | Loss: 0.07937231142838759\n",
            "Epoch: 50 | Batch: 1204 | Loss: 0.07302892615046569\n",
            "Epoch: 50 | Batch: 1205 | Loss: 0.09626992021663937\n",
            "Epoch: 50 | Batch: 1206 | Loss: 0.08058304737386757\n",
            "Epoch: 50 | Batch: 1207 | Loss: 0.09086240875305927\n",
            "Epoch: 50 | Batch: 1208 | Loss: 0.07833959769385554\n",
            "Epoch: 50 | Batch: 1209 | Loss: 0.04169875390064458\n",
            "Epoch: 50 | Batch: 1210 | Loss: 0.08343739515257478\n",
            "Epoch: 50 | Batch: 1211 | Loss: 0.03904318053799362\n",
            "Epoch: 50 | Batch: 1212 | Loss: 0.06508588931700812\n",
            "Epoch: 50 | Batch: 1213 | Loss: 0.05953485650352094\n",
            "Epoch: 50 | Batch: 1214 | Loss: 0.05280981008315417\n",
            "Epoch: 50 | Batch: 1215 | Loss: 0.06420507005412862\n",
            "Epoch: 50 | Batch: 1216 | Loss: 0.043629845081870344\n",
            "Epoch: 50 | Batch: 1217 | Loss: 0.06777278296731647\n",
            "Epoch: 50 | Batch: 1218 | Loss: 0.06161366205655654\n",
            "Epoch: 50 | Batch: 1219 | Loss: 0.06457595712385887\n",
            "Epoch: 50 | Batch: 1220 | Loss: 0.06113997189743481\n",
            "Epoch: 50 | Batch: 1221 | Loss: 0.05068595916423778\n",
            "Epoch: 50 | Batch: 1222 | Loss: 0.04034464640555834\n",
            "Epoch: 50 | Batch: 1223 | Loss: 0.06585320774009765\n",
            "Epoch: 50 | Batch: 1224 | Loss: 0.06239750635100474\n",
            "Epoch: 50 | Batch: 1225 | Loss: 0.054747458741639624\n",
            "Epoch: 50 | Batch: 1226 | Loss: 0.0673579022102259\n",
            "Epoch: 50 | Batch: 1227 | Loss: 0.03651117095331284\n",
            "Epoch: 50 | Batch: 1228 | Loss: 0.06408224284234627\n",
            "Epoch: 50 | Batch: 1229 | Loss: 0.08042125614551102\n",
            "Epoch: 50 | Batch: 1230 | Loss: 0.06436079077248921\n",
            "Epoch: 50 | Batch: 1231 | Loss: 0.06108841599635084\n",
            "Epoch: 50 | Batch: 1232 | Loss: 0.06441117136956975\n",
            "Epoch: 50 | Batch: 1233 | Loss: 0.049232354100252715\n",
            "Epoch: 50 | Batch: 1234 | Loss: 0.04505113782456571\n",
            "Epoch: 50 | Batch: 1235 | Loss: 0.06795438857444691\n",
            "Epoch: 50 | Batch: 1236 | Loss: 0.043938750334210755\n",
            "Epoch: 50 | Batch: 1237 | Loss: 0.052324706336353194\n",
            "Epoch: 50 | Batch: 1238 | Loss: 0.03687817197770789\n",
            "Epoch: 50 | Batch: 1239 | Loss: 0.06867009408823381\n",
            "Epoch: 50 | Batch: 1240 | Loss: 0.05883834968451408\n",
            "Epoch: 50 | Batch: 1241 | Loss: 0.04867315040878231\n",
            "Epoch: 50 | Batch: 1242 | Loss: 0.08131898642590843\n",
            "Epoch: 50 | Batch: 1243 | Loss: 0.036301563455060956\n",
            "Epoch: 50 | Batch: 1244 | Loss: 0.06901139009382527\n",
            "Epoch: 50 | Batch: 1245 | Loss: 0.11586323609144081\n",
            "Epoch: 50 | Batch: 1246 | Loss: 0.0722094040376301\n",
            "Epoch: 50 | Batch: 1247 | Loss: 0.08614455221518492\n",
            "Epoch: 50 | Batch: 1248 | Loss: 0.05902819627638538\n",
            "Epoch: 50 | Batch: 1249 | Loss: 0.08190094712799399\n",
            "Epoch: 50 | Batch: 1250 | Loss: 0.03642648338837154\n",
            "Epoch: 50 | Batch: 1251 | Loss: 0.050912490570615206\n",
            "Epoch: 50 | Batch: 1252 | Loss: 0.051184696704243415\n",
            "Epoch: 50 | Batch: 1253 | Loss: 0.06009762537658407\n",
            "Epoch: 50 | Batch: 1254 | Loss: 0.05082706101045476\n",
            "Epoch: 50 | Batch: 1255 | Loss: 0.04949863790823958\n",
            "Epoch: 50 | Batch: 1256 | Loss: 0.056279547587165905\n",
            "Epoch: 50 | Batch: 1257 | Loss: 0.0634979082729674\n",
            "Epoch: 50 | Batch: 1258 | Loss: 0.09187450658169156\n",
            "Epoch: 50 | Batch: 1259 | Loss: 0.054395093302933406\n",
            "Epoch: 50 | Batch: 1260 | Loss: 0.05817899829467904\n",
            "Epoch: 50 | Batch: 1261 | Loss: 0.05146656239784474\n",
            "Epoch: 50 | Batch: 1262 | Loss: 0.07196666958921698\n",
            "Epoch: 50 | Batch: 1263 | Loss: 0.039910971569194494\n",
            "Epoch: 50 | Batch: 1264 | Loss: 0.037537917687117076\n",
            "Epoch: 50 | Batch: 1265 | Loss: 0.07980513292642889\n",
            "Epoch: 50 | Batch: 1266 | Loss: 0.04323097094590752\n",
            "Epoch: 50 | Batch: 1267 | Loss: 0.045447832735927694\n",
            "Epoch: 50 | Batch: 1268 | Loss: 0.05906529361022091\n",
            "Epoch: 50 | Batch: 1269 | Loss: 0.05839725532846285\n",
            "Epoch: 50 | Batch: 1270 | Loss: 0.06815225006563685\n",
            "Epoch: 50 | Batch: 1271 | Loss: 0.04777263997590124\n",
            "Epoch: 50 | Batch: 1272 | Loss: 0.06008303214761462\n",
            "Epoch: 50 | Batch: 1273 | Loss: 0.0642338793153553\n",
            "Epoch: 50 | Batch: 1274 | Loss: 0.058687732847111276\n",
            "Epoch: 50 | Batch: 1275 | Loss: 0.04430522208757037\n",
            "Epoch: 50 | Batch: 1276 | Loss: 0.04066910715591874\n",
            "Epoch: 50 | Batch: 1277 | Loss: 0.11684360542455847\n",
            "Epoch: 50 | Batch: 1278 | Loss: 0.055357078897032945\n",
            "Epoch: 50 | Batch: 1279 | Loss: 0.06694553719612012\n",
            "Epoch: 50 | Batch: 1280 | Loss: 0.07312122197233269\n",
            "Epoch: 50 | Batch: 1281 | Loss: 0.08049267765082731\n",
            "Epoch: 50 | Batch: 1282 | Loss: 0.0644870441277506\n",
            "Epoch: 50 | Batch: 1283 | Loss: 0.06132386835178174\n",
            "Epoch: 50 | Batch: 1284 | Loss: 0.07294707446210388\n",
            "Epoch: 50 | Batch: 1285 | Loss: 0.07219068850826794\n",
            "Epoch: 50 | Batch: 1286 | Loss: 0.04923203747251049\n",
            "Epoch: 50 | Batch: 1287 | Loss: 0.03588175353032043\n",
            "Epoch: 50 | Batch: 1288 | Loss: 0.06362280848246617\n",
            "Epoch: 50 | Batch: 1289 | Loss: 0.04796244082290598\n",
            "Epoch: 50 | Batch: 1290 | Loss: 0.06391138646664642\n",
            "Epoch: 50 | Batch: 1291 | Loss: 0.05331021272090912\n",
            "Epoch: 50 | Batch: 1292 | Loss: 0.08945071769458884\n",
            "Epoch: 50 | Batch: 1293 | Loss: 0.06969171101860408\n",
            "Epoch: 50 | Batch: 1294 | Loss: 0.07794349679766843\n",
            "Epoch: 50 | Batch: 1295 | Loss: 0.06731092505220071\n",
            "Epoch: 50 | Batch: 1296 | Loss: 0.04616849853443991\n",
            "Epoch: 50 | Batch: 1297 | Loss: 0.07946459853851379\n",
            "Epoch: 50 | Batch: 1298 | Loss: 0.05358530481246378\n",
            "Epoch: 50 | Batch: 1299 | Loss: 0.07227696141253058\n",
            "Epoch: 50 | Batch: 1300 | Loss: 0.12784003453185128\n",
            "Epoch: 50 | Batch: 1301 | Loss: 0.04896370065436497\n",
            "Epoch: 50 | Batch: 1302 | Loss: 0.06841888231211356\n",
            "Epoch: 50 | Batch: 1303 | Loss: 0.06110945876484483\n",
            "Epoch: 50 | Batch: 1304 | Loss: 0.040499589507799735\n",
            "Epoch: 50 | Batch: 1305 | Loss: 0.05016670355032948\n",
            "Epoch: 50 | Batch: 1306 | Loss: 0.09539444710546777\n",
            "Epoch: 50 | Batch: 1307 | Loss: 0.06378727770068603\n",
            "Epoch: 50 | Batch: 1308 | Loss: 0.04597393769381386\n",
            "Epoch: 50 | Batch: 1309 | Loss: 0.05875247466918404\n",
            "Epoch: 50 | Batch: 1310 | Loss: 0.0525538415926443\n",
            "Epoch: 50 | Batch: 1311 | Loss: 0.0721447429837411\n",
            "Epoch: 50 | Batch: 1312 | Loss: 0.12118971412783604\n",
            "Epoch: 50 | Batch: 1313 | Loss: 0.08351903916800282\n",
            "Epoch: 50 | Batch: 1314 | Loss: 0.05208781906958053\n",
            "Epoch: 50 | Batch: 1315 | Loss: 0.0588458528421455\n",
            "Epoch: 50 | Batch: 1316 | Loss: 0.06850463937151052\n",
            "Epoch: 50 | Batch: 1317 | Loss: 0.07405517618762031\n",
            "Epoch: 50 | Batch: 1318 | Loss: 0.04510235716363892\n",
            "Epoch: 50 | Batch: 1319 | Loss: 0.08240867651634783\n",
            "Epoch: 50 | Batch: 1320 | Loss: 0.0811906579994254\n",
            "Epoch: 50 | Batch: 1321 | Loss: 0.08508193994089883\n",
            "Epoch: 50 | Batch: 1322 | Loss: 0.05119232674838021\n",
            "Epoch: 50 | Batch: 1323 | Loss: 0.06173537634374118\n",
            "Epoch: 50 | Batch: 1324 | Loss: 0.05049920233367923\n",
            "Epoch: 50 | Batch: 1325 | Loss: 0.0734799094264884\n",
            "Epoch: 50 | Batch: 1326 | Loss: 0.04615790220312588\n",
            "Epoch: 50 | Batch: 1327 | Loss: 0.044192366972779173\n",
            "Epoch: 50 | Batch: 1328 | Loss: 0.08554082395715021\n",
            "Epoch: 50 | Batch: 1329 | Loss: 0.051445765958980386\n",
            "Epoch: 50 | Batch: 1330 | Loss: 0.10748073358214011\n",
            "Epoch: 50 | Batch: 1331 | Loss: 0.07030096027370503\n",
            "Epoch: 50 | Batch: 1332 | Loss: 0.06158865138587005\n",
            "Epoch: 50 | Batch: 1333 | Loss: 0.08461041358210625\n",
            "Epoch: 50 | Batch: 1334 | Loss: 0.07082965241391415\n",
            "Epoch: 50 | Batch: 1335 | Loss: 0.05545149312707627\n",
            "Epoch: 50 | Batch: 1336 | Loss: 0.05539448968058972\n",
            "Epoch: 50 | Batch: 1337 | Loss: 0.08485606925350926\n",
            "Epoch: 50 | Batch: 1338 | Loss: 0.05043771969780684\n",
            "Epoch: 50 | Batch: 1339 | Loss: 0.05868007426242035\n",
            "Epoch: 50 | Batch: 1340 | Loss: 0.04232032695703723\n",
            "Epoch: 50 | Batch: 1341 | Loss: 0.07038519820967312\n",
            "Epoch: 50 | Batch: 1342 | Loss: 0.07965053021229111\n",
            "Epoch: 50 | Batch: 1343 | Loss: 0.04774141524693283\n",
            "Epoch: 50 | Batch: 1344 | Loss: 0.04568536502184399\n",
            "Epoch: 50 | Batch: 1345 | Loss: 0.052839662526092394\n",
            "Epoch: 50 | Batch: 1346 | Loss: 0.05679881408962244\n",
            "Epoch: 50 | Batch: 1347 | Loss: 0.07439169868214832\n",
            "Epoch: 50 | Batch: 1348 | Loss: 0.10274529471700797\n",
            "Epoch: 50 | Batch: 1349 | Loss: 0.05052295780246718\n",
            "Epoch: 50 | Batch: 1350 | Loss: 0.08895406239600756\n",
            "Epoch: 50 | Batch: 1351 | Loss: 0.05573569740847161\n",
            "Epoch: 50 | Batch: 1352 | Loss: 0.0966033782007343\n",
            "Epoch: 50 | Batch: 1353 | Loss: 0.06885953561924298\n",
            "Epoch: 50 | Batch: 1354 | Loss: 0.06184060129854481\n",
            "Epoch: 50 | Batch: 1355 | Loss: 0.03813149131544195\n",
            "Epoch: 50 | Batch: 1356 | Loss: 0.05474175386573535\n",
            "Epoch: 50 | Batch: 1357 | Loss: 0.05045613469297403\n",
            "Epoch: 50 | Batch: 1358 | Loss: 0.10554515770362782\n",
            "Epoch: 50 | Batch: 1359 | Loss: 0.0587075536742884\n",
            "Epoch: 50 | Batch: 1360 | Loss: 0.035921460549316046\n",
            "Epoch: 50 | Batch: 1361 | Loss: 0.04300273398518579\n",
            "Epoch: 50 | Batch: 1362 | Loss: 0.07679932316412781\n",
            "Epoch: 50 | Batch: 1363 | Loss: 0.043421893747225625\n",
            "Epoch: 50 | Batch: 1364 | Loss: 0.06802654388865681\n",
            "Epoch: 50 | Batch: 1365 | Loss: 0.06033222544083593\n",
            "Epoch: 50 | Batch: 1366 | Loss: 0.08858372010055698\n",
            "Epoch: 50 | Batch: 1367 | Loss: 0.06650223521735216\n",
            "Epoch: 50 | Batch: 1368 | Loss: 0.06007761867777315\n",
            "Epoch: 50 | Batch: 1369 | Loss: 0.0802165821404994\n",
            "Epoch: 50 | Batch: 1370 | Loss: 0.08211205125386421\n",
            "Epoch: 50 | Batch: 1371 | Loss: 0.07239880851328978\n",
            "Epoch: 50 | Batch: 1372 | Loss: 0.04353996719504158\n",
            "Epoch: 50 | Batch: 1373 | Loss: 0.05000317010212832\n",
            "Epoch: 50 | Batch: 1374 | Loss: 0.04466607353914426\n",
            "Epoch: 50 | Batch: 1375 | Loss: 0.07278588638828333\n",
            "Epoch: 50 | Batch: 1376 | Loss: 0.059534986828406244\n",
            "Epoch: 50 | Batch: 1377 | Loss: 0.05965195321213928\n",
            "Epoch: 50 | Batch: 1378 | Loss: 0.0766029076237616\n",
            "Epoch: 50 | Batch: 1379 | Loss: 0.08023148067561847\n",
            "Epoch: 50 | Batch: 1380 | Loss: 0.05776428368503533\n",
            "Epoch: 50 | Batch: 1381 | Loss: 0.08858341939654438\n",
            "Epoch: 50 | Batch: 1382 | Loss: 0.05663840784100082\n",
            "Epoch: 50 | Batch: 1383 | Loss: 0.06789727123024232\n",
            "Epoch: 50 | Batch: 1384 | Loss: 0.05941958473113699\n",
            "Epoch: 50 | Batch: 1385 | Loss: 0.07961500696715192\n",
            "Epoch: 50 | Batch: 1386 | Loss: 0.047479233442931784\n",
            "Epoch: 50 | Batch: 1387 | Loss: 0.07556588640740028\n",
            "Epoch: 50 | Batch: 1388 | Loss: 0.06139975644180912\n",
            "Epoch: 50 | Batch: 1389 | Loss: 0.059009613853761314\n",
            "Epoch: 50 | Batch: 1390 | Loss: 0.08240520885124164\n",
            "Epoch: 50 | Batch: 1391 | Loss: 0.06740511171338215\n",
            "Epoch: 50 | Batch: 1392 | Loss: 0.11718286462448667\n",
            "Epoch: 50 | Batch: 1393 | Loss: 0.07797193028866878\n",
            "Epoch: 50 | Batch: 1394 | Loss: 0.07315428625508553\n",
            "Epoch: 50 | Batch: 1395 | Loss: 0.056011752463248216\n",
            "Epoch: 50 | Batch: 1396 | Loss: 0.04682189658902552\n",
            "Epoch: 50 | Batch: 1397 | Loss: 0.05236413779713389\n",
            "Epoch: 50 | Batch: 1398 | Loss: 0.046419144366962775\n",
            "Epoch: 50 | Batch: 1399 | Loss: 0.04810158281478644\n",
            "Epoch: 50 | Batch: 1400 | Loss: 0.04095112880944041\n",
            "Epoch: 50 | Batch: 1401 | Loss: 0.043469842356015254\n",
            "Epoch: 50 | Batch: 1402 | Loss: 0.04821247540400932\n",
            "Epoch: 50 | Batch: 1403 | Loss: 0.0539085079240312\n",
            "Epoch: 50 | Batch: 1404 | Loss: 0.05987980772138829\n",
            "Epoch: 50 | Batch: 1405 | Loss: 0.05123825302819124\n",
            "Epoch: 50 | Batch: 1406 | Loss: 0.05085075004087267\n",
            "Epoch: 50 | Batch: 1407 | Loss: 0.056127387532681254\n",
            "Epoch: 50 | Batch: 1408 | Loss: 0.06395496965792634\n",
            "Epoch: 50 | Batch: 1409 | Loss: 0.06428929276903993\n",
            "Epoch: 50 | Batch: 1410 | Loss: 0.07607349083932344\n",
            "Epoch: 50 | Batch: 1411 | Loss: 0.04902925890791279\n",
            "Epoch: 50 | Batch: 1412 | Loss: 0.04298672882056377\n",
            "Epoch: 50 | Batch: 1413 | Loss: 0.05072651061062443\n",
            "Epoch: 50 | Batch: 1414 | Loss: 0.040599628130687834\n",
            "Epoch: 50 | Batch: 1415 | Loss: 0.06675902845804069\n",
            "Epoch: 50 | Batch: 1416 | Loss: 0.04087551228002337\n",
            "Epoch: 50 | Batch: 1417 | Loss: 0.07212404737777225\n",
            "Epoch: 50 | Batch: 1418 | Loss: 0.04438133933266006\n",
            "Epoch: 50 | Batch: 1419 | Loss: 0.07321790100175228\n",
            "Epoch: 50 | Batch: 1420 | Loss: 0.06954896731855448\n",
            "Epoch: 50 | Batch: 1421 | Loss: 0.08546716069041993\n",
            "Epoch: 50 | Batch: 1422 | Loss: 0.04363975102144631\n",
            "Epoch: 50 | Batch: 1423 | Loss: 0.07259437736638037\n",
            "Epoch: 50 | Batch: 1424 | Loss: 0.08767380878035276\n",
            "Epoch: 50 | Batch: 1425 | Loss: 0.09157151012983221\n",
            "Epoch: 50 | Batch: 1426 | Loss: 0.07353188499663951\n",
            "Epoch: 50 | Batch: 1427 | Loss: 0.07776616270381603\n",
            "Epoch: 50 | Batch: 1428 | Loss: 0.05359923565516979\n",
            "Epoch: 50 | Batch: 1429 | Loss: 0.08764549323647663\n",
            "Epoch: 50 | Batch: 1430 | Loss: 0.06068793566607233\n",
            "Epoch: 50 | Batch: 1431 | Loss: 0.07151149206931848\n",
            "Epoch: 50 | Batch: 1432 | Loss: 0.0499373809726658\n",
            "Epoch: 50 | Batch: 1433 | Loss: 0.08874382810530776\n",
            "Epoch: 50 | Batch: 1434 | Loss: 0.06077037680845229\n",
            "Epoch: 50 | Batch: 1435 | Loss: 0.0351493044184176\n",
            "Epoch: 50 | Batch: 1436 | Loss: 0.05551888312041415\n",
            "Epoch: 50 | Batch: 1437 | Loss: 0.08304907693270196\n",
            "Epoch: 50 | Batch: 1438 | Loss: 0.05376660404904465\n",
            "Epoch: 50 | Batch: 1439 | Loss: 0.04864368937654001\n",
            "Epoch: 50 | Batch: 1440 | Loss: 0.05976664686173827\n",
            "Epoch: 50 | Batch: 1441 | Loss: 0.08904562928037012\n",
            "Epoch: 50 | Batch: 1442 | Loss: 0.04636365023197184\n",
            "Epoch: 50 | Batch: 1443 | Loss: 0.037595928756147985\n",
            "Epoch: 50 | Batch: 1444 | Loss: 0.044730073483145893\n",
            "Epoch: 50 | Batch: 1445 | Loss: 0.038989560177809135\n",
            "Epoch: 50 | Batch: 1446 | Loss: 0.044237775459218795\n",
            "Epoch: 50 | Batch: 1447 | Loss: 0.05863313699588015\n",
            "Epoch: 50 | Batch: 1448 | Loss: 0.06024098766320464\n",
            "Epoch: 50 | Batch: 1449 | Loss: 0.07539406361086676\n",
            "Epoch: 50 | Batch: 1450 | Loss: 0.05812111779401595\n",
            "Epoch: 50 | Batch: 1451 | Loss: 0.04497313131990424\n",
            "Epoch: 50 | Batch: 1452 | Loss: 0.05083029152458526\n",
            "Epoch: 50 | Batch: 1453 | Loss: 0.05747180780709235\n",
            "Epoch: 50 | Batch: 1454 | Loss: 0.03901293494875809\n",
            "Epoch: 50 | Batch: 1455 | Loss: 0.048892965574947184\n",
            "Epoch: 50 | Batch: 1456 | Loss: 0.045738491005253706\n",
            "Epoch: 50 | Batch: 1457 | Loss: 0.06784836962002233\n",
            "Epoch: 50 | Batch: 1458 | Loss: 0.05593609416193933\n",
            "Epoch: 50 | Batch: 1459 | Loss: 0.05163767201555451\n",
            "Epoch: 50 | Batch: 1460 | Loss: 0.03443619949298418\n",
            "Epoch: 50 | Batch: 1461 | Loss: 0.07299604269876661\n",
            "Epoch: 50 | Batch: 1462 | Loss: 0.06865986409704292\n",
            "Epoch: 50 | Batch: 1463 | Loss: 0.05405225205993096\n",
            "Epoch: 50 | Batch: 1464 | Loss: 0.08754377077092879\n",
            "Epoch: 50 | Batch: 1465 | Loss: 0.08433852128630843\n",
            "Epoch: 50 | Batch: 1466 | Loss: 0.04846836244098403\n",
            "Epoch: 50 | Batch: 1467 | Loss: 0.046868196924751915\n",
            "Epoch: 50 | Batch: 1468 | Loss: 0.06801066037346482\n",
            "Epoch: 50 | Batch: 1469 | Loss: 0.0432382591757556\n",
            "Epoch: 50 | Batch: 1470 | Loss: 0.0844725701448787\n",
            "Epoch: 50 | Batch: 1471 | Loss: 0.06090534352070044\n",
            "Epoch: 50 | Batch: 1472 | Loss: 0.07831415475592532\n",
            "Epoch: 50 | Batch: 1473 | Loss: 0.06995262080454927\n",
            "Epoch: 50 | Batch: 1474 | Loss: 0.044901054831342734\n",
            "Epoch: 50 | Batch: 1475 | Loss: 0.05128682910823833\n",
            "Epoch: 50 | Batch: 1476 | Loss: 0.05402483451393925\n",
            "Epoch: 50 | Batch: 1477 | Loss: 0.06359137625822459\n",
            "Epoch: 50 | Batch: 1478 | Loss: 0.09675181102644527\n",
            "Epoch: 50 | Batch: 1479 | Loss: 0.09541231713839668\n",
            "Epoch: 50 | Batch: 1480 | Loss: 0.053728779027083874\n",
            "Epoch: 50 | Batch: 1481 | Loss: 0.0664213144208664\n",
            "Epoch: 50 | Batch: 1482 | Loss: 0.04462275459265001\n",
            "Epoch: 50 | Batch: 1483 | Loss: 0.06193889394643317\n",
            "Epoch: 50 | Batch: 1484 | Loss: 0.05788976420812017\n",
            "Epoch: 50 | Batch: 1485 | Loss: 0.07559769878561302\n",
            "Epoch: 50 | Batch: 1486 | Loss: 0.05296408102763107\n",
            "Epoch: 50 | Batch: 1487 | Loss: 0.0635271763472538\n",
            "Epoch: 50 | Batch: 1488 | Loss: 0.06398045932743228\n",
            "Epoch: 50 | Batch: 1489 | Loss: 0.04745486311610199\n",
            "Epoch: 50 | Batch: 1490 | Loss: 0.07358233542556188\n",
            "Epoch: 50 | Batch: 1491 | Loss: 0.05741678816451662\n",
            "Epoch: 50 | Batch: 1492 | Loss: 0.05496433358964974\n",
            "Epoch: 50 | Batch: 1493 | Loss: 0.045497914940394374\n",
            "Epoch: 50 | Batch: 1494 | Loss: 0.07639940490022766\n",
            "Epoch: 50 | Batch: 1495 | Loss: 0.046322587907589016\n",
            "Epoch: 50 | Batch: 1496 | Loss: 0.048515263471950835\n",
            "Epoch: 50 | Batch: 1497 | Loss: 0.06326020131815935\n",
            "Epoch: 50 | Batch: 1498 | Loss: 0.055346841267033736\n",
            "Epoch: 50 | Batch: 1499 | Loss: 0.057460082220943946\n",
            "Epoch: 50 | Batch: 1500 | Loss: 0.06334126625818147\n",
            "Epoch: 50 | Batch: 1501 | Loss: 0.06844538172743707\n",
            "Epoch: 50 | Batch: 1502 | Loss: 0.06707922797958323\n",
            "Epoch: 50 | Batch: 1503 | Loss: 0.06569964516518688\n",
            "Epoch: 50 | Batch: 1504 | Loss: 0.0769811306095766\n",
            "Epoch: 50 | Batch: 1505 | Loss: 0.051147467141200394\n",
            "Epoch: 50 | Batch: 1506 | Loss: 0.05491689159768055\n",
            "Epoch: 50 | Batch: 1507 | Loss: 0.0573798642210849\n",
            "Epoch: 50 | Batch: 1508 | Loss: 0.051806492832286194\n",
            "Epoch: 50 | Batch: 1509 | Loss: 0.0548933705407246\n",
            "Epoch: 50 | Batch: 1510 | Loss: 0.048027662163654034\n",
            "Epoch: 50 | Batch: 1511 | Loss: 0.07006110837583573\n",
            "Epoch: 50 | Batch: 1512 | Loss: 0.05780001293670971\n",
            "Epoch: 50 | Batch: 1513 | Loss: 0.05126606493217993\n",
            "Epoch: 50 | Batch: 1514 | Loss: 0.09122283646827595\n",
            "Epoch: 50 | Batch: 1515 | Loss: 0.0525069835427308\n",
            "Epoch: 50 | Batch: 1516 | Loss: 0.08091175940986486\n",
            "Epoch: 50 | Batch: 1517 | Loss: 0.07499266598293501\n",
            "Epoch: 50 | Batch: 1518 | Loss: 0.0745826098101762\n",
            "Epoch: 50 | Batch: 1519 | Loss: 0.052333452488485255\n",
            "Epoch: 50 | Batch: 1520 | Loss: 0.06222919498982322\n",
            "Epoch: 50 | Batch: 1521 | Loss: 0.057382155448660876\n",
            "Epoch: 50 | Batch: 1522 | Loss: 0.05160772096709103\n",
            "Epoch: 50 | Batch: 1523 | Loss: 0.10867342857877835\n",
            "Epoch: 50 | Batch: 1524 | Loss: 0.05649024484073652\n",
            "Epoch: 50 | Batch: 1525 | Loss: 0.06959294113778233\n",
            "Epoch: 50 | Batch: 1526 | Loss: 0.03560154733877295\n",
            "Epoch: 50 | Batch: 1527 | Loss: 0.05898233837308053\n",
            "Epoch: 50 | Batch: 1528 | Loss: 0.05543294848691749\n",
            "Epoch: 50 | Batch: 1529 | Loss: 0.03469514248497461\n",
            "Epoch: 50 | Batch: 1530 | Loss: 0.06572336699200308\n",
            "Epoch: 50 | Batch: 1531 | Loss: 0.05443954176533383\n",
            "Epoch: 50 | Batch: 1532 | Loss: 0.04542079326530844\n",
            "Epoch: 50 | Batch: 1533 | Loss: 0.08554279944364429\n",
            "Epoch: 50 | Batch: 1534 | Loss: 0.08063449634397393\n",
            "Epoch: 50 | Batch: 1535 | Loss: 0.06362235811416193\n",
            "Epoch: 50 | Batch: 1536 | Loss: 0.05657040684811368\n",
            "Epoch: 50 | Batch: 1537 | Loss: 0.047891887907016116\n",
            "Epoch: 50 | Batch: 1538 | Loss: 0.0660889196097135\n",
            "Epoch: 50 | Batch: 1539 | Loss: 0.10057100002913505\n",
            "Epoch: 50 | Batch: 1540 | Loss: 0.07978904435307901\n",
            "Epoch: 50 | Batch: 1541 | Loss: 0.06859686295952785\n",
            "Epoch: 50 | Batch: 1542 | Loss: 0.06778877842540851\n",
            "Epoch: 50 | Batch: 1543 | Loss: 0.04573963922281488\n",
            "Epoch: 50 | Batch: 1544 | Loss: 0.04628254279749853\n",
            "Epoch: 50 | Batch: 1545 | Loss: 0.06903189718397192\n",
            "Epoch: 50 | Batch: 1546 | Loss: 0.07440472579673166\n",
            "Epoch: 50 | Batch: 1547 | Loss: 0.05856750446656515\n",
            "Epoch: 50 | Batch: 1548 | Loss: 0.06557839942564099\n",
            "Epoch: 50 | Batch: 1549 | Loss: 0.07259380194443904\n",
            "Epoch: 50 | Batch: 1550 | Loss: 0.06668596124289371\n",
            "Epoch: 50 | Batch: 1551 | Loss: 0.06606404522815704\n",
            "Epoch: 50 | Batch: 1552 | Loss: 0.05635803049858554\n",
            "Epoch: 50 | Batch: 1553 | Loss: 0.06035910882263798\n",
            "Epoch: 50 | Batch: 1554 | Loss: 0.06136103945270084\n",
            "Epoch: 50 | Batch: 1555 | Loss: 0.07124079705992478\n",
            "Epoch: 50 | Batch: 1556 | Loss: 0.0879153901916789\n",
            "Epoch: 50 | Batch: 1557 | Loss: 0.08604477777877236\n",
            "Epoch: 50 | Batch: 1558 | Loss: 0.04933197269901025\n",
            "Epoch: 50 | Batch: 1559 | Loss: 0.06128620790567913\n",
            "Epoch: 50 | Batch: 1560 | Loss: 0.04262943596637597\n",
            "Epoch: 50 | Batch: 1561 | Loss: 0.08373802969147193\n",
            "Epoch: 50 | Batch: 1562 | Loss: 0.046155267886639754\n",
            "Epoch: 50 | Batch: 1563 | Loss: 0.05740178860658607\n",
            "Epoch: 50 | Batch: 1564 | Loss: 0.04759375832292655\n",
            "Epoch: 50 | Batch: 1565 | Loss: 0.05115246771443574\n",
            "Epoch: 50 | Batch: 1566 | Loss: 0.05443530307830197\n",
            "Epoch: 50 | Batch: 1567 | Loss: 0.05494362282569654\n",
            "Epoch: 50 | Batch: 1568 | Loss: 0.05880883924149\n",
            "Epoch: 50 | Batch: 1569 | Loss: 0.03961995849621196\n",
            "Epoch: 50 | Batch: 1570 | Loss: 0.10125128757293339\n",
            "Epoch: 50 | Batch: 1571 | Loss: 0.04441179064205284\n",
            "Epoch: 50 | Batch: 1572 | Loss: 0.05162334236224585\n",
            "Epoch: 50 | Batch: 1573 | Loss: 0.08005254476492077\n",
            "Epoch: 50 | Batch: 1574 | Loss: 0.05990074831942427\n",
            "Epoch: 50 | Batch: 1575 | Loss: 0.0564133823251461\n",
            "Epoch: 50 | Batch: 1576 | Loss: 0.05305280556514956\n",
            "Epoch: 50 | Batch: 1577 | Loss: 0.067237501112645\n",
            "Epoch: 50 | Batch: 1578 | Loss: 0.05761772835312452\n",
            "Epoch: 50 | Batch: 1579 | Loss: 0.0817095269583569\n",
            "Epoch: 50 | Batch: 1580 | Loss: 0.15108375494384013\n",
            "Epoch: 50 | Batch: 1581 | Loss: 0.061994487905047704\n",
            "Epoch: 50 | Batch: 1582 | Loss: 0.059247670215543086\n",
            "Epoch: 50 | Batch: 1583 | Loss: 0.04998796571884399\n",
            "Epoch: 50 | Batch: 1584 | Loss: 0.05934694723085217\n",
            "Epoch: 50 | Batch: 1585 | Loss: 0.05533797831680048\n",
            "Epoch: 50 | Batch: 1586 | Loss: 0.06808621363504945\n",
            "Epoch: 50 | Batch: 1587 | Loss: 0.07394120776247107\n",
            "Epoch: 50 | Batch: 1588 | Loss: 0.04247698650007935\n",
            "Epoch: 50 | Batch: 1589 | Loss: 0.05173733365724674\n",
            "Epoch: 50 | Batch: 1590 | Loss: 0.06564950640613376\n",
            "Epoch: 50 | Batch: 1591 | Loss: 0.05894567972553766\n",
            "Epoch: 50 | Batch: 1592 | Loss: 0.04831019031945596\n",
            "Epoch: 50 | Batch: 1593 | Loss: 0.06392493828123971\n",
            "Epoch: 50 | Batch: 1594 | Loss: 0.0523837450154326\n",
            "Epoch: 50 | Batch: 1595 | Loss: 0.05799478161275044\n",
            "Epoch: 50 | Batch: 1596 | Loss: 0.05130858375022527\n",
            "Epoch: 50 | Batch: 1597 | Loss: 0.05852050186739731\n",
            "Epoch: 50 | Batch: 1598 | Loss: 0.0518215837827326\n",
            "Epoch: 50 | Batch: 1599 | Loss: 0.06717353646252935\n",
            "Epoch: 50 | Batch: 1600 | Loss: 0.07070876469613116\n",
            "Epoch: 50 | Batch: 1601 | Loss: 0.07057833885397703\n",
            "Epoch: 50 | Batch: 1602 | Loss: 0.044056407470620555\n",
            "Epoch: 50 | Batch: 1603 | Loss: 0.04402694139509053\n",
            "Epoch: 50 | Batch: 1604 | Loss: 0.0614721352222713\n",
            "Epoch: 50 | Batch: 1605 | Loss: 0.04690992933449542\n",
            "Epoch: 50 | Batch: 1606 | Loss: 0.058422560935203316\n",
            "Epoch: 50 | Batch: 1607 | Loss: 0.06762963546295322\n",
            "Epoch: 50 | Batch: 1608 | Loss: 0.07032510458390318\n",
            "Epoch: 50 | Batch: 1609 | Loss: 0.05032055151955915\n",
            "Epoch: 50 | Batch: 1610 | Loss: 0.08289898001647505\n",
            "Epoch: 50 | Batch: 1611 | Loss: 0.0612534019534219\n",
            "Epoch: 50 | Batch: 1612 | Loss: 0.07182249699314308\n",
            "Epoch: 50 | Batch: 1613 | Loss: 0.08195062771887951\n",
            "Epoch: 50 | Batch: 1614 | Loss: 0.03538770557961336\n",
            "Epoch: 50 | Batch: 1615 | Loss: 0.1301439458524779\n",
            "Epoch: 50 | Batch: 1616 | Loss: 0.04520252977813648\n",
            "Epoch: 50 | Batch: 1617 | Loss: 0.05124893873287063\n",
            "Epoch: 50 | Batch: 1618 | Loss: 0.05813487255134761\n",
            "Epoch: 50 | Batch: 1619 | Loss: 0.05309926315682191\n",
            "Epoch: 50 | Batch: 1620 | Loss: 0.04745411751480996\n",
            "Epoch: 50 | Batch: 1621 | Loss: 0.05776238554145249\n",
            "Epoch: 50 | Batch: 1622 | Loss: 0.04406170460475145\n",
            "Epoch: 50 | Batch: 1623 | Loss: 0.06878272740800086\n",
            "Epoch: 50 | Batch: 1624 | Loss: 0.04928501792267075\n",
            "Epoch: 50 | Batch: 1625 | Loss: 0.05034462615965281\n",
            "Epoch: 50 | Batch: 1626 | Loss: 0.04370851537275509\n",
            "Epoch: 50 | Batch: 1627 | Loss: 0.052996414362572804\n",
            "Epoch: 50 | Batch: 1628 | Loss: 0.05629773725830691\n",
            "Epoch: 50 | Batch: 1629 | Loss: 0.03841181156000608\n",
            "Epoch: 50 | Batch: 1630 | Loss: 0.056716346430372995\n",
            "Epoch: 50 | Batch: 1631 | Loss: 0.05233992211647\n",
            "Epoch: 50 | Batch: 1632 | Loss: 0.05610342255820649\n",
            "Epoch: 50 | Batch: 1633 | Loss: 0.04589200315423999\n",
            "Epoch: 50 | Batch: 1634 | Loss: 0.05605625981798646\n",
            "Epoch: 50 | Batch: 1635 | Loss: 0.05227882240930789\n",
            "Epoch: 50 | Batch: 1636 | Loss: 0.04936296407153972\n",
            "Epoch: 50 | Batch: 1637 | Loss: 0.06249526863471297\n",
            "Epoch: 50 | Batch: 1638 | Loss: 0.03740180472187647\n",
            "Epoch: 50 | Batch: 1639 | Loss: 0.06136171343533267\n",
            "Epoch: 50 | Batch: 1640 | Loss: 0.056365316849589495\n",
            "Epoch: 50 | Batch: 1641 | Loss: 0.04015747435339774\n",
            "Epoch: 50 | Batch: 1642 | Loss: 0.04239147126088372\n",
            "Epoch: 50 | Batch: 1643 | Loss: 0.055836933723919485\n",
            "Epoch: 50 | Batch: 1644 | Loss: 0.08638757452879046\n",
            "Epoch: 50 | Batch: 1645 | Loss: 0.04559379043474813\n",
            "Epoch: 50 | Batch: 1646 | Loss: 0.05514493859430208\n",
            "Epoch: 50 | Batch: 1647 | Loss: 0.05608885595690284\n",
            "Epoch: 50 | Batch: 1648 | Loss: 0.05664081967071055\n",
            "Epoch: 50 | Batch: 1649 | Loss: 0.06973355225059673\n",
            "Epoch: 50 | Batch: 1650 | Loss: 0.06389597863878448\n",
            "Epoch: 50 | Batch: 1651 | Loss: 0.045750883297119925\n",
            "Epoch: 50 | Batch: 1652 | Loss: 0.06645857543493983\n",
            "Epoch: 50 | Batch: 1653 | Loss: 0.05235616820028189\n",
            "Epoch: 50 | Batch: 1654 | Loss: 0.07180907861844105\n",
            "Epoch: 50 | Batch: 1655 | Loss: 0.07627234064917213\n",
            "Epoch: 50 | Batch: 1656 | Loss: 0.05490489656739037\n",
            "Epoch: 50 | Batch: 1657 | Loss: 0.061764873268922285\n",
            "Epoch: 50 | Batch: 1658 | Loss: 0.051101013952007474\n",
            "Epoch: 50 | Batch: 1659 | Loss: 0.05922198240271847\n",
            "Epoch: 50 | Batch: 1660 | Loss: 0.061781647196867504\n",
            "Epoch: 50 | Batch: 1661 | Loss: 0.07479287650318875\n",
            "Epoch: 50 | Batch: 1662 | Loss: 0.04215826271061747\n",
            "Epoch: 50 | Batch: 1663 | Loss: 0.1293543108291014\n",
            "Epoch: 50 | Batch: 1664 | Loss: 0.06099953978049602\n",
            "Epoch: 50 | Batch: 1665 | Loss: 0.06393787176779427\n",
            "Epoch: 50 | Batch: 1666 | Loss: 0.0667589434051383\n",
            "Epoch: 50 | Batch: 1667 | Loss: 0.07291201244144545\n",
            "Epoch: 50 | Batch: 1668 | Loss: 0.08283970728048938\n",
            "Epoch: 50 | Batch: 1669 | Loss: 0.06308904095154991\n",
            "Epoch: 50 | Batch: 1670 | Loss: 0.055586834771642765\n",
            "Epoch: 50 | Batch: 1671 | Loss: 0.09470222571333978\n",
            "Epoch: 50 | Batch: 1672 | Loss: 0.045755903178165566\n",
            "Epoch: 50 | Batch: 1673 | Loss: 0.07196193685817687\n",
            "Epoch: 50 | Batch: 1674 | Loss: 0.07283595663323492\n",
            "Epoch: 50 | Batch: 1675 | Loss: 0.04503925076602268\n",
            "Epoch: 50 | Batch: 1676 | Loss: 0.05306108791264112\n",
            "Epoch: 50 | Batch: 1677 | Loss: 0.08570653320886804\n",
            "Epoch: 50 | Batch: 1678 | Loss: 0.12955376213470757\n",
            "Epoch: 50 | Batch: 1679 | Loss: 0.05527432449019574\n",
            "Epoch: 50 | Batch: 1680 | Loss: 0.04630761525354819\n",
            "Epoch: 50 | Batch: 1681 | Loss: 0.048288627843395604\n",
            "Epoch: 50 | Batch: 1682 | Loss: 0.04561904443506888\n",
            "Epoch: 50 | Batch: 1683 | Loss: 0.08540461066623432\n",
            "Epoch: 50 | Batch: 1684 | Loss: 0.06449162192733784\n",
            "Epoch: 50 | Batch: 1685 | Loss: 0.044363083023674435\n",
            "Epoch: 50 | Batch: 1686 | Loss: 0.0721518823738879\n",
            "Epoch: 50 | Batch: 1687 | Loss: 0.053487322278514146\n",
            "Epoch: 50 | Batch: 1688 | Loss: 0.04859676715257919\n",
            "Epoch: 50 | Batch: 1689 | Loss: 0.09086073223288856\n",
            "Epoch: 50 | Batch: 1690 | Loss: 0.055891595158757294\n",
            "Epoch: 50 | Batch: 1691 | Loss: 0.04135537229132173\n",
            "Epoch: 50 | Batch: 1692 | Loss: 0.044387209071598044\n",
            "Epoch: 50 | Batch: 1693 | Loss: 0.06582349433667943\n",
            "Epoch: 50 | Batch: 1694 | Loss: 0.06369303877608705\n",
            "Epoch: 50 | Batch: 1695 | Loss: 0.047062164795974054\n",
            "Epoch: 50 | Batch: 1696 | Loss: 0.04739135491922134\n",
            "Epoch: 50 | Batch: 1697 | Loss: 0.0870025763043477\n",
            "Epoch: 50 | Batch: 1698 | Loss: 0.045251881433248084\n",
            "Epoch: 50 | Batch: 1699 | Loss: 0.10539698672777788\n",
            "Epoch: 50 | Batch: 1700 | Loss: 0.052275851238078666\n",
            "Epoch: 50 | Batch: 1701 | Loss: 0.04577779301939487\n",
            "Epoch: 50 | Batch: 1702 | Loss: 0.05372201796675105\n",
            "Epoch: 50 | Batch: 1703 | Loss: 0.04163722374500247\n",
            "Epoch: 50 | Batch: 1704 | Loss: 0.05427496341455087\n",
            "Epoch: 50 | Batch: 1705 | Loss: 0.06017281356123054\n",
            "Epoch: 50 | Batch: 1706 | Loss: 0.04641813900589735\n",
            "Epoch: 50 | Batch: 1707 | Loss: 0.03871443240806767\n",
            "Epoch: 50 | Batch: 1708 | Loss: 0.07039646071199747\n",
            "Epoch: 50 | Batch: 1709 | Loss: 0.05605565099793813\n",
            "Epoch: 50 | Batch: 1710 | Loss: 0.0905253904364378\n",
            "Epoch: 50 | Batch: 1711 | Loss: 0.059399912482119406\n",
            "Epoch: 50 | Batch: 1712 | Loss: 0.0983225453955802\n",
            "Epoch: 50 | Batch: 1713 | Loss: 0.04757317221223587\n",
            "Epoch: 50 | Batch: 1714 | Loss: 0.055748459623814105\n",
            "Epoch: 50 | Batch: 1715 | Loss: 0.08414410105866586\n",
            "Epoch: 50 | Batch: 1716 | Loss: 0.0744101079779975\n",
            "Epoch: 50 | Batch: 1717 | Loss: 0.04902499877902608\n",
            "Epoch: 50 | Batch: 1718 | Loss: 0.06935240827946422\n",
            "Epoch: 50 | Batch: 1719 | Loss: 0.053589626970233006\n",
            "Epoch: 50 | Batch: 1720 | Loss: 0.05676588629068264\n",
            "Epoch: 50 | Batch: 1721 | Loss: 0.08649425365109023\n",
            "Epoch: 50 | Batch: 1722 | Loss: 0.03386863200410037\n",
            "Epoch: 50 | Batch: 1723 | Loss: 0.044892259742609214\n",
            "Epoch: 50 | Batch: 1724 | Loss: 0.05919262644829756\n",
            "Epoch: 50 | Batch: 1725 | Loss: 0.046872402279912524\n",
            "Epoch: 50 | Batch: 1726 | Loss: 0.04612845416832787\n",
            "Epoch: 50 | Batch: 1727 | Loss: 0.04808520335867264\n",
            "Epoch: 50 | Batch: 1728 | Loss: 0.04309312449796468\n",
            "Epoch: 50 | Batch: 1729 | Loss: 0.04612535675908165\n",
            "Epoch: 50 | Batch: 1730 | Loss: 0.06810461240286422\n",
            "Epoch: 50 | Batch: 1731 | Loss: 0.04453151067237804\n",
            "Epoch: 50 | Batch: 1732 | Loss: 0.05026954392067891\n",
            "Epoch: 50 | Batch: 1733 | Loss: 0.046579446862881624\n",
            "Epoch: 50 | Batch: 1734 | Loss: 0.055280007014536864\n",
            "Epoch: 50 | Batch: 1735 | Loss: 0.05912103254571544\n",
            "Epoch: 50 | Batch: 1736 | Loss: 0.07227061569079929\n",
            "Epoch: 50 | Batch: 1737 | Loss: 0.0664532975984447\n",
            "Epoch: 50 | Batch: 1738 | Loss: 0.06761197838090272\n",
            "Epoch: 50 | Batch: 1739 | Loss: 0.08883365635445309\n",
            "Epoch: 50 | Batch: 1740 | Loss: 0.04715924322061829\n",
            "Epoch: 50 | Batch: 1741 | Loss: 0.05228734345976374\n",
            "Epoch: 50 | Batch: 1742 | Loss: 0.05514578601397174\n",
            "Epoch: 50 | Batch: 1743 | Loss: 0.07749374469071565\n",
            "Epoch: 50 | Batch: 1744 | Loss: 0.05488476370267347\n",
            "Epoch: 50 | Batch: 1745 | Loss: 0.05045079661852632\n",
            "Epoch: 50 | Batch: 1746 | Loss: 0.06491220719250035\n",
            "Epoch: 50 | Batch: 1747 | Loss: 0.03826360542187712\n",
            "Epoch: 50 | Batch: 1748 | Loss: 0.08203577710473661\n",
            "Epoch: 50 | Batch: 1749 | Loss: 0.08356532400902651\n",
            "Epoch: 50 | Batch: 1750 | Loss: 0.0597821863971271\n",
            "Epoch: 50 | Batch: 1751 | Loss: 0.08281162764488371\n",
            "Epoch: 50 | Batch: 1752 | Loss: 0.0442875181649174\n",
            "Epoch: 50 | Batch: 1753 | Loss: 0.06709688038808781\n",
            "Epoch: 50 | Batch: 1754 | Loss: 0.07578024076678458\n",
            "Epoch: 50 | Batch: 1755 | Loss: 0.06036855900157527\n",
            "Epoch: 50 | Batch: 1756 | Loss: 0.048352611362599524\n",
            "Epoch: 50 | Batch: 1757 | Loss: 0.06248601187209026\n",
            "Epoch: 50 | Batch: 1758 | Loss: 0.1490678127560024\n",
            "Epoch: 50 | Batch: 1759 | Loss: 0.05871472360577825\n",
            "Epoch: 50 | Batch: 1760 | Loss: 0.0777952087053505\n",
            "Epoch: 50 | Batch: 1761 | Loss: 0.057763264109157136\n",
            "Epoch: 50 | Batch: 1762 | Loss: 0.06814371273895128\n",
            "Epoch: 50 | Batch: 1763 | Loss: 0.05156261733028418\n",
            "Epoch: 50 | Batch: 1764 | Loss: 0.07391896944344764\n",
            "Epoch: 50 | Batch: 1765 | Loss: 0.06250080544460856\n",
            "Epoch: 50 | Batch: 1766 | Loss: 0.11067532840218229\n",
            "Epoch: 50 | Batch: 1767 | Loss: 0.08633865874834856\n",
            "Epoch: 50 | Batch: 1768 | Loss: 0.11003468395181207\n",
            "Epoch: 50 | Batch: 1769 | Loss: 0.06457805614958385\n",
            "Epoch: 50 | Batch: 1770 | Loss: 0.07102319015791642\n",
            "Epoch: 50 | Batch: 1771 | Loss: 0.05863308311726381\n",
            "Epoch: 50 | Batch: 1772 | Loss: 0.0555799796719461\n",
            "Epoch: 50 | Batch: 1773 | Loss: 0.0731250868864682\n",
            "Epoch: 50 | Batch: 1774 | Loss: 0.04345594523785171\n",
            "Epoch: 50 | Batch: 1775 | Loss: 0.09045368037701079\n",
            "Epoch: 50 | Batch: 1776 | Loss: 0.05722560337823377\n",
            "Epoch: 50 | Batch: 1777 | Loss: 0.060233259203505626\n",
            "Epoch: 50 | Batch: 1778 | Loss: 0.04701028250165646\n",
            "Epoch: 50 | Batch: 1779 | Loss: 0.09843361705834242\n",
            "Epoch: 50 | Batch: 1780 | Loss: 0.07513644124809075\n",
            "Epoch: 50 | Batch: 1781 | Loss: 0.058778894423252195\n",
            "Epoch: 50 | Batch: 1782 | Loss: 0.0522516182649055\n",
            "Epoch: 50 | Batch: 1783 | Loss: 0.06975027267808409\n",
            "Epoch: 50 | Batch: 1784 | Loss: 0.03705067742554431\n",
            "Epoch: 50 | Batch: 1785 | Loss: 0.06899924776161656\n",
            "Epoch: 50 | Batch: 1786 | Loss: 0.04375001637317878\n",
            "Epoch: 50 | Batch: 1787 | Loss: 0.06286053028590381\n",
            "Epoch: 50 | Batch: 1788 | Loss: 0.05349910820401291\n",
            "Epoch: 50 | Batch: 1789 | Loss: 0.04636985465890818\n",
            "Epoch: 50 | Batch: 1790 | Loss: 0.05916596447133924\n",
            "Epoch: 50 | Batch: 1791 | Loss: 0.05395566637096839\n",
            "Epoch: 50 | Batch: 1792 | Loss: 0.04839705799537807\n",
            "Epoch: 50 | Batch: 1793 | Loss: 0.06840449452930919\n",
            "Epoch: 50 | Batch: 1794 | Loss: 0.0731669126201745\n",
            "Epoch: 50 | Batch: 1795 | Loss: 0.04188214101439676\n",
            "Epoch: 50 | Batch: 1796 | Loss: 0.04152109089600772\n",
            "Epoch: 50 | Batch: 1797 | Loss: 0.04608077011005066\n",
            "Epoch: 50 | Batch: 1798 | Loss: 0.05342441226048093\n",
            "Epoch: 50 | Batch: 1799 | Loss: 0.0467946632798991\n",
            "Epoch: 50 | Batch: 1800 | Loss: 0.05832465120148429\n",
            "Epoch: 50 | Batch: 1801 | Loss: 0.06378288855847972\n",
            "Epoch: 50 | Batch: 1802 | Loss: 0.06408503228078756\n",
            "Epoch: 50 | Batch: 1803 | Loss: 0.0375516161882518\n",
            "Epoch: 50 | Batch: 1804 | Loss: 0.04795315096602334\n",
            "Epoch: 50 | Batch: 1805 | Loss: 0.05074542540907186\n",
            "Epoch: 50 | Batch: 1806 | Loss: 0.07703813275632092\n",
            "Epoch: 50 | Batch: 1807 | Loss: 0.06156954580859077\n",
            "Epoch: 50 | Batch: 1808 | Loss: 0.07334608057028935\n",
            "Epoch: 50 | Batch: 1809 | Loss: 0.05178232091364991\n",
            "Epoch: 50 | Batch: 1810 | Loss: 0.11087908580399597\n",
            "Epoch: 50 | Batch: 1811 | Loss: 0.05181238626075394\n",
            "Epoch: 50 | Batch: 1812 | Loss: 0.09771577214688619\n",
            "Epoch: 50 | Batch: 1813 | Loss: 0.05691709150709463\n",
            "Epoch: 50 | Batch: 1814 | Loss: 0.08352647944831264\n",
            "Epoch: 50 | Batch: 1815 | Loss: 0.08381316960151532\n",
            "Epoch: 50 | Batch: 1816 | Loss: 0.10146805794642386\n",
            "Epoch: 50 | Batch: 1817 | Loss: 0.0795143896162599\n",
            "Epoch: 50 | Batch: 1818 | Loss: 0.09864372323459089\n",
            "Epoch: 50 | Batch: 1819 | Loss: 0.06850751566290883\n",
            "Epoch: 50 | Batch: 1820 | Loss: 0.051233239422044594\n",
            "Epoch: 50 | Batch: 1821 | Loss: 0.055650331577176464\n",
            "Epoch: 50 | Batch: 1822 | Loss: 0.05114549595772491\n",
            "Epoch: 50 | Batch: 1823 | Loss: 0.06991796125109839\n",
            "Epoch: 50 | Batch: 1824 | Loss: 0.10063284211879643\n",
            "Epoch: 50 | Batch: 1825 | Loss: 0.053997801645662244\n",
            "Epoch: 50 | Batch: 1826 | Loss: 0.06188066925125592\n",
            "Epoch: 50 | Batch: 1827 | Loss: 0.1427705584841426\n",
            "Epoch: 50 | Batch: 1828 | Loss: 0.07638355454637334\n",
            "Epoch: 50 | Batch: 1829 | Loss: 0.06541209160341407\n",
            "Epoch: 50 | Batch: 1830 | Loss: 0.047443357016255384\n",
            "Epoch: 50 | Batch: 1831 | Loss: 0.06133264437315661\n",
            "Epoch: 50 | Batch: 1832 | Loss: 0.047372671489867665\n",
            "Epoch: 50 | Batch: 1833 | Loss: 0.07101857133026669\n",
            "Epoch: 50 | Batch: 1834 | Loss: 0.08282014364159894\n",
            "Epoch: 50 | Batch: 1835 | Loss: 0.11368902117375373\n",
            "Epoch: 50 | Batch: 1836 | Loss: 0.0708861625597419\n",
            "Epoch: 50 | Batch: 1837 | Loss: 0.07879900160550335\n",
            "Epoch: 50 | Batch: 1838 | Loss: 0.062133367227556996\n",
            "Epoch: 50 | Batch: 1839 | Loss: 0.047448406545246805\n",
            "Epoch: 50 | Batch: 1840 | Loss: 0.07205552099193861\n",
            "Epoch: 50 | Batch: 1841 | Loss: 0.0862034977374802\n",
            "Epoch: 50 | Batch: 1842 | Loss: 0.06665872488658538\n",
            "Epoch: 50 | Batch: 1843 | Loss: 0.08508743058457534\n",
            "Epoch: 50 | Batch: 1844 | Loss: 0.043442675908735344\n",
            "Epoch: 50 | Batch: 1845 | Loss: 0.058142508127085366\n",
            "Epoch: 50 | Batch: 1846 | Loss: 0.05801058911498179\n",
            "Epoch: 50 | Batch: 1847 | Loss: 0.05130517260328147\n",
            "Epoch: 50 | Batch: 1848 | Loss: 0.06782123944567864\n",
            "Epoch: 50 | Batch: 1849 | Loss: 0.05031634624086518\n",
            "Epoch: 50 | Batch: 1850 | Loss: 0.0654833476515205\n",
            "Epoch: 50 | Batch: 1851 | Loss: 0.05306839306226512\n",
            "Epoch: 50 | Batch: 1852 | Loss: 0.06770771741756898\n",
            "Epoch: 50 | Batch: 1853 | Loss: 0.06544199571030748\n",
            "Epoch: 50 | Batch: 1854 | Loss: 0.042236069596269375\n",
            "Epoch: 50 | Batch: 1855 | Loss: 0.06802955268694531\n",
            "Epoch: 50 | Batch: 1856 | Loss: 0.060298487599633056\n",
            "Epoch: 50 | Batch: 1857 | Loss: 0.04985876285538917\n",
            "Epoch: 50 | Batch: 1858 | Loss: 0.04442769920594652\n",
            "Epoch: 50 | Batch: 1859 | Loss: 0.05033504290904835\n",
            "Epoch: 50 | Batch: 1860 | Loss: 0.0748040188984164\n",
            "Epoch: 50 | Batch: 1861 | Loss: 0.054495787433018396\n",
            "Epoch: 50 | Batch: 1862 | Loss: 0.0677327411498841\n",
            "Epoch: 50 | Batch: 1863 | Loss: 0.06334594112620162\n",
            "Epoch: 50 | Batch: 1864 | Loss: 0.058636190357109874\n",
            "Epoch: 50 | Batch: 1865 | Loss: 0.07883044863823456\n",
            "Epoch: 50 | Batch: 1866 | Loss: 0.05472591882598558\n",
            "Epoch: 50 | Batch: 1867 | Loss: 0.058385181036719275\n",
            "Epoch: 50 | Batch: 1868 | Loss: 0.06722014368295133\n",
            "Epoch: 50 | Batch: 1869 | Loss: 0.04593425475979315\n",
            "Epoch: 50 | Batch: 1870 | Loss: 0.06720150187337162\n",
            "Epoch: 50 | Batch: 1871 | Loss: 0.03889277866605263\n",
            "Epoch: 50 | Batch: 1872 | Loss: 0.0337834790911087\n",
            "Epoch: 50 | Batch: 1873 | Loss: 0.04794133281817005\n",
            "Epoch: 50 | Batch: 1874 | Loss: 0.058942422287666704\n",
            "Epoch: 50 | Batch: 1875 | Loss: 0.07851693754858781\n",
            "Epoch: 50 | Batch: 1876 | Loss: 0.04496991214921464\n",
            "Epoch: 50 | Batch: 1877 | Loss: 0.09789117394282866\n",
            "Epoch: 50 | Batch: 1878 | Loss: 0.04325882739292995\n",
            "Epoch: 50 | Batch: 1879 | Loss: 0.07124330002661555\n",
            "Epoch: 50 | Batch: 1880 | Loss: 0.038743043438424614\n",
            "Epoch: 50 | Batch: 1881 | Loss: 0.04910745284136575\n",
            "Epoch: 50 | Batch: 1882 | Loss: 0.05061599672453593\n",
            "Epoch: 50 | Batch: 1883 | Loss: 0.09490973777935055\n",
            "Epoch: 50 | Batch: 1884 | Loss: 0.04304028303434419\n",
            "Epoch: 50 | Batch: 1885 | Loss: 0.037337188582127666\n",
            "Epoch: 50 | Batch: 1886 | Loss: 0.05827877378863332\n",
            "Epoch: 50 | Batch: 1887 | Loss: 0.09848632146316282\n",
            "Epoch: 50 | Batch: 1888 | Loss: 0.07137421780468076\n",
            "Epoch: 50 | Batch: 1889 | Loss: 0.07220575523840356\n",
            "Epoch: 50 | Batch: 1890 | Loss: 0.0706593391880383\n",
            "Epoch: 50 | Batch: 1891 | Loss: 0.03591381348605094\n",
            "Epoch: 50 | Batch: 1892 | Loss: 0.06330343374330719\n",
            "Epoch: 50 | Batch: 1893 | Loss: 0.07774797438530469\n",
            "Epoch: 50 | Batch: 1894 | Loss: 0.07107886272996704\n",
            "Epoch: 50 | Batch: 1895 | Loss: 0.056734430630130325\n",
            "Epoch: 50 | Batch: 1896 | Loss: 0.037200370197675484\n",
            "Epoch: 50 | Batch: 1897 | Loss: 0.05505879845290688\n",
            "Epoch: 50 | Batch: 1898 | Loss: 0.06551535324554902\n",
            "Epoch: 50 | Batch: 1899 | Loss: 0.05532164505042213\n",
            "Epoch: 50 | Batch: 1900 | Loss: 0.0631039961965344\n",
            "Epoch: 50 | Batch: 1901 | Loss: 0.04247012676728266\n",
            "Epoch: 50 | Batch: 1902 | Loss: 0.07114875316022908\n",
            "Epoch: 50 | Batch: 1903 | Loss: 0.057540949798105326\n",
            "Epoch: 50 | Batch: 1904 | Loss: 0.049927728431446446\n",
            "Epoch: 50 | Batch: 1905 | Loss: 0.05594678460075072\n",
            "Epoch: 50 | Batch: 1906 | Loss: 0.0799497239584338\n",
            "Epoch: 50 | Batch: 1907 | Loss: 0.04739569380525108\n",
            "Epoch: 50 | Batch: 1908 | Loss: 0.046853089909820136\n",
            "Epoch: 50 | Batch: 1909 | Loss: 0.04202248543750372\n",
            "Epoch: 50 | Batch: 1910 | Loss: 0.07201254127301097\n",
            "Epoch: 50 | Batch: 1911 | Loss: 0.047889407737582684\n",
            "Epoch: 50 | Batch: 1912 | Loss: 0.043925834596312684\n",
            "Epoch: 50 | Batch: 1913 | Loss: 0.03885660436582566\n",
            "Epoch: 50 | Batch: 1914 | Loss: 0.057753175295777746\n",
            "Epoch: 50 | Batch: 1915 | Loss: 0.09755847256171528\n",
            "Epoch: 50 | Batch: 1916 | Loss: 0.060041257677919006\n",
            "Epoch: 50 | Batch: 1917 | Loss: 0.0592430328055608\n",
            "Epoch: 50 | Batch: 1918 | Loss: 0.06348093478000136\n",
            "Epoch: 50 | Batch: 1919 | Loss: 0.0962736566873161\n",
            "Epoch: 50 | Batch: 1920 | Loss: 0.06885523221021113\n",
            "Epoch: 50 | Batch: 1921 | Loss: 0.08184598019138345\n",
            "Epoch: 50 | Batch: 1922 | Loss: 0.045606852827435915\n",
            "Epoch: 50 | Batch: 1923 | Loss: 0.04621142645120392\n",
            "Epoch: 50 | Batch: 1924 | Loss: 0.07021062378829768\n",
            "Epoch: 50 | Batch: 1925 | Loss: 0.04550405035728983\n",
            "Epoch: 50 | Batch: 1926 | Loss: 0.06283980800582119\n",
            "Epoch: 50 | Batch: 1927 | Loss: 0.06697998919767269\n",
            "Epoch: 50 | Batch: 1928 | Loss: 0.07647344316992391\n",
            "Epoch: 50 | Batch: 1929 | Loss: 0.06873140763395236\n",
            "Epoch: 50 | Batch: 1930 | Loss: 0.054270635614421504\n",
            "Epoch: 50 | Batch: 1931 | Loss: 0.0756725656633024\n",
            "Epoch: 50 | Batch: 1932 | Loss: 0.05911319327377912\n",
            "Epoch: 50 | Batch: 1933 | Loss: 0.09605128209748454\n",
            "Epoch: 50 | Batch: 1934 | Loss: 0.03926026986785336\n",
            "Epoch: 50 | Batch: 1935 | Loss: 0.10458427373850727\n",
            "Epoch: 50 | Batch: 1936 | Loss: 0.045283063118033554\n",
            "Epoch: 50 | Batch: 1937 | Loss: 0.04840436161617524\n",
            "Epoch: 50 | Batch: 1938 | Loss: 0.07904456932707553\n",
            "Epoch: 50 | Batch: 1939 | Loss: 0.05195646532138845\n",
            "Epoch: 50 | Batch: 1940 | Loss: 0.053004594835481214\n",
            "Epoch: 50 | Batch: 1941 | Loss: 0.09469200215597401\n",
            "Epoch: 50 | Batch: 1942 | Loss: 0.07958325972233374\n",
            "Epoch: 50 | Batch: 1943 | Loss: 0.07265351995512181\n",
            "Epoch: 50 | Batch: 1944 | Loss: 0.06973274832912099\n",
            "Epoch: 50 | Batch: 1945 | Loss: 0.0601281078290814\n",
            "Epoch: 50 | Batch: 1946 | Loss: 0.04698590169620637\n",
            "Epoch: 50 | Batch: 1947 | Loss: 0.0512252290995486\n",
            "Epoch: 50 | Batch: 1948 | Loss: 0.05809367218916618\n",
            "Epoch: 50 | Batch: 1949 | Loss: 0.05371547118805403\n",
            "Epoch: 50 | Batch: 1950 | Loss: 0.044333345929216145\n",
            "Epoch: 50 | Batch: 1951 | Loss: 0.05976727114079981\n",
            "Epoch: 50 | Batch: 1952 | Loss: 0.0720686655052868\n",
            "Epoch: 50 | Batch: 1953 | Loss: 0.05499022724630434\n",
            "Epoch: 50 | Batch: 1954 | Loss: 0.05995785379403149\n",
            "Epoch: 50 | Batch: 1955 | Loss: 0.053185483979710346\n",
            "Epoch: 50 | Batch: 1956 | Loss: 0.058263198265955114\n",
            "Epoch: 50 | Batch: 1957 | Loss: 0.05109739307376895\n",
            "Epoch: 50 | Batch: 1958 | Loss: 0.059243191157971886\n",
            "Epoch: 50 | Batch: 1959 | Loss: 0.06271954770722779\n",
            "Epoch: 50 | Batch: 1960 | Loss: 0.05050470930266508\n",
            "Epoch: 50 | Batch: 1961 | Loss: 0.04855531086104805\n",
            "Epoch: 50 | Batch: 1962 | Loss: 0.04708895556747357\n",
            "Epoch: 50 | Batch: 1963 | Loss: 0.05266865659868028\n",
            "Epoch: 50 | Batch: 1964 | Loss: 0.051957603425821904\n",
            "Epoch: 50 | Batch: 1965 | Loss: 0.04806962278062024\n",
            "Epoch: 50 | Batch: 1966 | Loss: 0.0974605416209237\n",
            "Epoch: 50 | Batch: 1967 | Loss: 0.05079413589979886\n",
            "Epoch: 50 | Batch: 1968 | Loss: 0.08791478652637935\n",
            "Epoch: 50 | Batch: 1969 | Loss: 0.12177792770258462\n",
            "Epoch: 50 | Batch: 1970 | Loss: 0.10430977993398856\n",
            "Epoch: 50 | Batch: 1971 | Loss: 0.07495947287224322\n",
            "Epoch: 50 | Batch: 1972 | Loss: 0.08006335374470211\n",
            "Epoch: 50 | Batch: 1973 | Loss: 0.06796381328711171\n",
            "Epoch: 50 | Batch: 1974 | Loss: 0.0755826088870499\n",
            "Epoch: 50 | Batch: 1975 | Loss: 0.06394095579903539\n",
            "Epoch: 50 | Batch: 1976 | Loss: 0.0665378887677151\n",
            "Epoch: 50 | Batch: 1977 | Loss: 0.06554762842655057\n",
            "Epoch: 50 | Batch: 1978 | Loss: 0.07168738856448972\n",
            "Epoch: 50 | Batch: 1979 | Loss: 0.05601586173111145\n",
            "Epoch: 50 | Batch: 1980 | Loss: 0.08338249899089406\n",
            "Epoch: 50 | Batch: 1981 | Loss: 0.0686225826901935\n",
            "Epoch: 50 | Batch: 1982 | Loss: 0.07431318179980764\n",
            "Epoch: 50 | Batch: 1983 | Loss: 0.06065313363710728\n",
            "Epoch: 50 | Batch: 1984 | Loss: 0.06051514460460898\n",
            "Epoch: 50 | Batch: 1985 | Loss: 0.055191002623076274\n",
            "Epoch: 50 | Batch: 1986 | Loss: 0.06113971871184156\n",
            "Epoch: 50 | Batch: 1987 | Loss: 0.06800360544175671\n",
            "Epoch: 50 | Batch: 1988 | Loss: 0.057763623490460214\n",
            "Epoch: 50 | Batch: 1989 | Loss: 0.04943971804629238\n",
            "Epoch: 50 | Batch: 1990 | Loss: 0.0887026500115723\n",
            "Epoch: 50 | Batch: 1991 | Loss: 0.07217037253092207\n",
            "Epoch: 50 | Batch: 1992 | Loss: 0.08941139826785605\n",
            "Epoch: 50 | Batch: 1993 | Loss: 0.052319357637169404\n",
            "Epoch: 50 | Batch: 1994 | Loss: 0.05077795622733537\n",
            "Epoch: 50 | Batch: 1995 | Loss: 0.07781959619580348\n",
            "Epoch: 50 | Batch: 1996 | Loss: 0.06854297613196285\n",
            "Epoch: 50 | Batch: 1997 | Loss: 0.050467581169471046\n",
            "Epoch: 50 | Batch: 1998 | Loss: 0.04746639189109744\n",
            "Epoch: 50 | Batch: 1999 | Loss: 0.060988184240082066\n",
            "Epoch: 50 | Batch: 2000 | Loss: 0.052721054145040656\n",
            "Epoch: 50 | Batch: 2001 | Loss: 0.06532097068410717\n",
            "Epoch: 50 | Batch: 2002 | Loss: 0.08669898621608532\n",
            "Epoch: 50 | Batch: 2003 | Loss: 0.07166806220897057\n",
            "Epoch: 50 | Batch: 2004 | Loss: 0.055500045346388915\n",
            "Epoch: 50 | Batch: 2005 | Loss: 0.0536820190825208\n",
            "Epoch: 50 | Batch: 2006 | Loss: 0.06610732377443124\n",
            "Epoch: 50 | Batch: 2007 | Loss: 0.059716871588826104\n",
            "Epoch: 50 | Batch: 2008 | Loss: 0.04949644212864549\n",
            "Epoch: 50 | Batch: 2009 | Loss: 0.06652039990212293\n",
            "Epoch: 50 | Batch: 2010 | Loss: 0.03676514211911398\n",
            "Epoch: 50 | Batch: 2011 | Loss: 0.04335462151157613\n",
            "Epoch: 50 | Batch: 2012 | Loss: 0.04005514867385321\n",
            "Epoch: 50 | Batch: 2013 | Loss: 0.08625241683059942\n",
            "Epoch: 50 | Batch: 2014 | Loss: 0.059781418313365205\n",
            "Epoch: 50 | Batch: 2015 | Loss: 0.05165324067288704\n",
            "Epoch: 50 | Batch: 2016 | Loss: 0.04393062045307605\n",
            "Epoch: 50 | Batch: 2017 | Loss: 0.041182820654849725\n",
            "Epoch: 50 | Batch: 2018 | Loss: 0.04816875856924138\n",
            "Epoch: 50 | Batch: 2019 | Loss: 0.05526451210725088\n",
            "Epoch: 50 | Batch: 2020 | Loss: 0.07074684463026065\n",
            "Epoch: 50 | Batch: 2021 | Loss: 0.028050184909603336\n",
            "Epoch: 50 | Batch: 2022 | Loss: 0.07958459773534858\n",
            "Epoch: 50 | Batch: 2023 | Loss: 0.05794781664539418\n",
            "Epoch: 50 | Batch: 2024 | Loss: 0.04526204585968155\n",
            "Epoch: 50 | Batch: 2025 | Loss: 0.04933575160287473\n",
            "Epoch: 50 | Batch: 2026 | Loss: 0.08726855624309257\n",
            "Epoch: 50 | Batch: 2027 | Loss: 0.051966570308130816\n",
            "Epoch: 50 | Batch: 2028 | Loss: 0.08567074044264328\n",
            "Epoch: 50 | Batch: 2029 | Loss: 0.04476546476118264\n",
            "Epoch: 50 | Batch: 2030 | Loss: 0.05898635374553831\n",
            "Epoch: 50 | Batch: 2031 | Loss: 0.05963612857715289\n",
            "Epoch: 50 | Batch: 2032 | Loss: 0.06622889094571763\n",
            "Epoch: 50 | Batch: 2033 | Loss: 0.09140114011127279\n",
            "Epoch: 50 | Batch: 2034 | Loss: 0.04381311187881293\n",
            "Epoch: 50 | Batch: 2035 | Loss: 0.06344065377589167\n",
            "Epoch: 50 | Batch: 2036 | Loss: 0.050326433038150785\n",
            "Epoch: 50 | Batch: 2037 | Loss: 0.06492306939346408\n",
            "Epoch: 50 | Batch: 2038 | Loss: 0.04737044410660733\n",
            "Epoch: 50 | Batch: 2039 | Loss: 0.062381362641515066\n",
            "Epoch: 50 | Batch: 2040 | Loss: 0.043028518888970566\n",
            "Epoch: 50 | Batch: 2041 | Loss: 0.07586260930545373\n",
            "Epoch: 50 | Batch: 2042 | Loss: 0.058423304033363155\n",
            "Epoch: 50 | Batch: 2043 | Loss: 0.045121885953394406\n",
            "Epoch: 50 | Batch: 2044 | Loss: 0.0396252597099813\n",
            "Epoch: 50 | Batch: 2045 | Loss: 0.05408186334661694\n",
            "Epoch: 50 | Batch: 2046 | Loss: 0.061289197575821644\n",
            "Epoch: 50 | Batch: 2047 | Loss: 0.051769284650608725\n",
            "Epoch: 50 | Batch: 2048 | Loss: 0.04178797777251338\n",
            "Epoch: 50 | Batch: 2049 | Loss: 0.06397819602333148\n",
            "Epoch: 50 | Batch: 2050 | Loss: 0.04684000241471237\n",
            "Epoch: 50 | Batch: 2051 | Loss: 0.042111696729740744\n",
            "Epoch: 50 | Batch: 2052 | Loss: 0.05570365035022609\n",
            "Epoch: 50 | Batch: 2053 | Loss: 0.060232585131443944\n",
            "Epoch: 50 | Batch: 2054 | Loss: 0.038370044087228175\n",
            "Epoch: 50 | Batch: 2055 | Loss: 0.06412149186723942\n",
            "Epoch: 50 | Batch: 2056 | Loss: 0.056099976807390234\n",
            "Epoch: 50 | Batch: 2057 | Loss: 0.05843980680362615\n",
            "Epoch: 50 | Batch: 2058 | Loss: 0.05785297825861317\n",
            "Epoch: 50 | Batch: 2059 | Loss: 0.05399285272427098\n",
            "Epoch: 50 | Batch: 2060 | Loss: 0.04815166432709664\n",
            "Epoch: 50 | Batch: 2061 | Loss: 0.06191464755527713\n",
            "Epoch: 50 | Batch: 2062 | Loss: 0.06645189227429446\n",
            "Epoch: 50 | Batch: 2063 | Loss: 0.06714002225582376\n",
            "Epoch: 50 | Batch: 2064 | Loss: 0.06605363951965476\n",
            "Epoch: 50 | Batch: 2065 | Loss: 0.08775575834526113\n",
            "Epoch: 50 | Batch: 2066 | Loss: 0.04202510729524174\n",
            "Epoch: 50 | Batch: 2067 | Loss: 0.0508848778415391\n",
            "Epoch: 50 | Batch: 2068 | Loss: 0.048264293510988016\n",
            "Epoch: 50 | Batch: 2069 | Loss: 0.10233972895045729\n",
            "Epoch: 50 | Batch: 2070 | Loss: 0.05013559848964742\n",
            "Epoch: 50 | Batch: 2071 | Loss: 0.07009916651405045\n",
            "Epoch: 50 | Batch: 2072 | Loss: 0.0863692289391097\n",
            "Epoch: 50 | Batch: 2073 | Loss: 0.059525998619986045\n",
            "Epoch: 50 | Batch: 2074 | Loss: 0.04606195184514446\n",
            "Epoch: 50 | Batch: 2075 | Loss: 0.06975200220485696\n",
            "Epoch: 50 | Batch: 2076 | Loss: 0.05772359371872471\n",
            "Epoch: 50 | Batch: 2077 | Loss: 0.053621188348881785\n",
            "Epoch: 50 | Batch: 2078 | Loss: 0.06448681426357249\n",
            "Epoch: 50 | Batch: 2079 | Loss: 0.06020287897010064\n",
            "Epoch: 50 | Batch: 2080 | Loss: 0.05123970100070308\n",
            "Epoch: 50 | Batch: 2081 | Loss: 0.056023874345200696\n",
            "Epoch: 50 | Batch: 2082 | Loss: 0.057341035455357604\n",
            "Epoch: 50 | Batch: 2083 | Loss: 0.09157183324622323\n",
            "Epoch: 50 | Batch: 2084 | Loss: 0.0666122922570135\n",
            "Epoch: 50 | Batch: 2085 | Loss: 0.10156665872692863\n",
            "Epoch: 50 | Batch: 2086 | Loss: 0.07369793158216226\n",
            "Epoch: 50 | Batch: 2087 | Loss: 0.0497373667997562\n",
            "Epoch: 50 | Batch: 2088 | Loss: 0.07656402336997317\n",
            "Epoch: 50 | Batch: 2089 | Loss: 0.054132826341098644\n",
            "Epoch: 50 | Batch: 2090 | Loss: 0.07502659582578021\n",
            "Epoch: 50 | Batch: 2091 | Loss: 0.058728438875605235\n",
            "Epoch: 50 | Batch: 2092 | Loss: 0.10375412579489003\n",
            "Epoch: 50 | Batch: 2093 | Loss: 0.04326218250635176\n",
            "Epoch: 50 | Batch: 2094 | Loss: 0.052127290128052006\n",
            "Epoch: 50 | Batch: 2095 | Loss: 0.07181493666960502\n",
            "Epoch: 50 | Batch: 2096 | Loss: 0.06382720300514616\n",
            "Epoch: 50 | Batch: 2097 | Loss: 0.09221676581261919\n",
            "Epoch: 50 | Batch: 2098 | Loss: 0.06910432011169271\n",
            "Epoch: 50 | Batch: 2099 | Loss: 0.07360898639398553\n",
            "Epoch: 50 | Batch: 2100 | Loss: 0.045524935274240286\n",
            "Epoch: 50 | Batch: 2101 | Loss: 0.08277127656110855\n",
            "Epoch: 50 | Batch: 2102 | Loss: 0.07467874037213977\n",
            "Epoch: 50 | Batch: 2103 | Loss: 0.07327541620283903\n",
            "Epoch: 50 | Batch: 2104 | Loss: 0.07017105900296822\n",
            "Epoch: 50 | Batch: 2105 | Loss: 0.08830036879175297\n",
            "Epoch: 50 | Batch: 2106 | Loss: 0.06084543201660782\n",
            "Epoch: 50 | Batch: 2107 | Loss: 0.05815443644164425\n",
            "Epoch: 50 | Batch: 2108 | Loss: 0.07105395246264361\n",
            "Epoch: 50 | Batch: 2109 | Loss: 0.06099081316683415\n",
            "Epoch: 50 | Batch: 2110 | Loss: 0.09192334906412332\n",
            "Epoch: 50 | Batch: 2111 | Loss: 0.035006905115338355\n",
            "Epoch: 50 | Batch: 2112 | Loss: 0.05420938162285988\n",
            "Epoch: 50 | Batch: 2113 | Loss: 0.050502902228555135\n",
            "Epoch: 50 | Batch: 2114 | Loss: 0.08170481470155268\n",
            "Epoch: 50 | Batch: 2115 | Loss: 0.045517969778362595\n",
            "Epoch: 50 | Batch: 2116 | Loss: 0.06822983970435519\n",
            "Epoch: 50 | Batch: 2117 | Loss: 0.05503953987939467\n",
            "Epoch: 50 | Batch: 2118 | Loss: 0.051828676211733954\n",
            "Epoch: 50 | Batch: 2119 | Loss: 0.0752913415185577\n",
            "Epoch: 50 | Batch: 2120 | Loss: 0.048219489699106\n",
            "Epoch: 50 | Batch: 2121 | Loss: 0.037609158572718154\n",
            "Epoch: 50 | Batch: 2122 | Loss: 0.05010026067951186\n",
            "Epoch: 50 | Batch: 2123 | Loss: 0.060919617130169766\n",
            "Epoch: 50 | Batch: 2124 | Loss: 0.042172379321740956\n",
            "Epoch: 50 | Batch: 2125 | Loss: 0.043689287706747945\n",
            "Epoch: 50 | Batch: 2126 | Loss: 0.05200289389996024\n",
            "Epoch: 50 | Batch: 2127 | Loss: 0.043707035828753175\n",
            "Epoch: 50 | Batch: 2128 | Loss: 0.03411197109668407\n",
            "Epoch: 50 | Batch: 2129 | Loss: 0.053232361778563594\n",
            "Epoch: 50 | Batch: 2130 | Loss: 0.05040627358991363\n",
            "Epoch: 50 | Batch: 2131 | Loss: 0.06220036620128788\n",
            "Epoch: 50 | Batch: 2132 | Loss: 0.04155780772424491\n",
            "Epoch: 50 | Batch: 2133 | Loss: 0.05681766339123925\n",
            "Epoch: 50 | Batch: 2134 | Loss: 0.06626458891453578\n",
            "Epoch: 50 | Batch: 2135 | Loss: 0.07680204213012366\n",
            "Epoch: 50 | Batch: 2136 | Loss: 0.07058871713619057\n",
            "Epoch: 50 | Batch: 2137 | Loss: 0.04433350672128163\n",
            "Epoch: 50 | Batch: 2138 | Loss: 0.05178855964440551\n",
            "Epoch: 50 | Batch: 2139 | Loss: 0.041427513120603145\n",
            "Epoch: 50 | Batch: 2140 | Loss: 0.0662067148542984\n",
            "Epoch: 50 | Batch: 2141 | Loss: 0.063657521217059\n",
            "Epoch: 50 | Batch: 2142 | Loss: 0.04114020044006708\n",
            "Epoch: 50 | Batch: 2143 | Loss: 0.05656333336337905\n",
            "Epoch: 50 | Batch: 2144 | Loss: 0.05233803757437673\n",
            "Epoch: 50 | Batch: 2145 | Loss: 0.06165461716298742\n",
            "Epoch: 50 | Batch: 2146 | Loss: 0.04315002759921378\n",
            "Epoch: 50 | Batch: 2147 | Loss: 0.09518820703686165\n",
            "Epoch: 50 | Batch: 2148 | Loss: 0.041079726129353636\n",
            "Epoch: 50 | Batch: 2149 | Loss: 0.08085945527519592\n",
            "Epoch: 50 | Batch: 2150 | Loss: 0.049654677016534116\n",
            "Epoch: 50 | Batch: 2151 | Loss: 0.06630885965088765\n",
            "Epoch: 50 | Batch: 2152 | Loss: 0.04560262902171861\n",
            "Epoch: 50 | Batch: 2153 | Loss: 0.07955513096078412\n",
            "Epoch: 50 | Batch: 2154 | Loss: 0.07844232564822062\n",
            "Epoch: 50 | Batch: 2155 | Loss: 0.053104354596857486\n",
            "Epoch: 50 | Batch: 2156 | Loss: 0.044914668272281\n",
            "Epoch: 50 | Batch: 2157 | Loss: 0.0670477848672785\n",
            "Epoch: 50 | Batch: 2158 | Loss: 0.037941313863160894\n",
            "Epoch: 50 | Batch: 2159 | Loss: 0.0507549478981443\n",
            "Epoch: 50 | Batch: 2160 | Loss: 0.054050834508637464\n",
            "Epoch: 50 | Batch: 2161 | Loss: 0.04463763488438113\n",
            "Epoch: 50 | Batch: 2162 | Loss: 0.0518457180809281\n",
            "Epoch: 50 | Batch: 2163 | Loss: 0.03768565780383869\n",
            "Epoch: 50 | Batch: 2164 | Loss: 0.05157060492431266\n",
            "Epoch: 50 | Batch: 2165 | Loss: 0.0506686619330438\n",
            "Epoch: 50 | Batch: 2166 | Loss: 0.05357648994631709\n",
            "Epoch: 50 | Batch: 2167 | Loss: 0.05930111523484245\n",
            "Epoch: 50 | Batch: 2168 | Loss: 0.0383984773647577\n",
            "Epoch: 50 | Batch: 2169 | Loss: 0.058305675315547784\n",
            "Epoch: 50 | Batch: 2170 | Loss: 0.07437180173965147\n",
            "Epoch: 50 | Batch: 2171 | Loss: 0.05936389254223456\n",
            "Epoch: 50 | Batch: 2172 | Loss: 0.07285995074562011\n",
            "Epoch: 50 | Batch: 2173 | Loss: 0.06755419264912482\n",
            "Epoch: 50 | Batch: 2174 | Loss: 0.04988145717690196\n",
            "Epoch: 50 | Batch: 2175 | Loss: 0.06545265826829272\n",
            "Epoch: 50 | Batch: 2176 | Loss: 0.062059454425658085\n",
            "Epoch: 50 | Batch: 2177 | Loss: 0.04802476654403113\n",
            "Epoch: 50 | Batch: 2178 | Loss: 0.04265258415053946\n",
            "Epoch: 50 | Batch: 2179 | Loss: 0.050966789498976636\n",
            "Epoch: 50 | Batch: 2180 | Loss: 0.05310958408974634\n",
            "Epoch: 50 | Batch: 2181 | Loss: 0.05046119326663734\n",
            "Epoch: 50 | Batch: 2182 | Loss: 0.041170663591956716\n",
            "Epoch: 50 | Batch: 2183 | Loss: 0.05073074214235373\n",
            "Epoch: 50 | Batch: 2184 | Loss: 0.0514024616423794\n",
            "Epoch: 50 | Batch: 2185 | Loss: 0.05279731307206528\n",
            "Epoch: 50 | Batch: 2186 | Loss: 0.053255143238164576\n",
            "Epoch: 50 | Batch: 2187 | Loss: 0.05446801597731141\n",
            "Epoch: 50 | Batch: 2188 | Loss: 0.053982197908285894\n",
            "Epoch: 50 | Batch: 2189 | Loss: 0.0672272651573355\n",
            "Epoch: 50 | Batch: 2190 | Loss: 0.04365831574101635\n",
            "Epoch: 50 | Batch: 2191 | Loss: 0.06270898227228085\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(model,X_test,Y_test,data_df_combined_clean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "id": "QuiEGCCdzUiC",
        "outputId": "2b818a52-c5df-45a4-d7fc-542bb1d07089"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The mean square error is: 220.793580\n",
            "MAPE is: 2.542515\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ClDXrE4b2H9T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}