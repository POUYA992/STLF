{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOgiEHnziB2e"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import newaxis\n",
        "\n",
        "def load_data(data_path,P,step):\n",
        "    num_logs = P+step\n",
        "    df = pd.read_csv(data_path)\n",
        "    \n",
        "\n",
        "    data_np = np.zeros((len(df),num_logs))\n",
        "    data_df_combined = pd.DataFrame(data_np)\n",
        "    data_df_combined.loc[:,0] = df['SYSLoad'].values\n",
        "\n",
        "    for i in range(1, num_logs):\n",
        "        data_df_combined.loc[:,i] = data_df_combined.shift(-i)\n",
        "\n",
        "    data_df_combined_clean = data_df_combined.dropna()\n",
        "    data_df_combined_clean = data_df_combined_clean.reset_index()\n",
        "    data_df_combined_clean.drop('index',axis=1,inplace=True)\n",
        "    data_combined_standardized = preprocessing.scale(data_df_combined_clean)\n",
        "\n",
        "    train_split = round(0.8 * data_combined_standardized.shape[0])\n",
        "    val_split = round(0.9 * data_combined_standardized.shape[0])\n",
        "    #print(\"all len\",data_combined_standardized.shape[0])\n",
        "    #print(\"train_split\",train_split)\n",
        "\n",
        "    X = data_combined_standardized[:,:P]\n",
        "    Y = data_combined_standardized[:,P:]\n",
        "\n",
        "    X_train = X[:train_split]\n",
        "    Y_train = Y[:train_split]\n",
        "    X_test = X[train_split:]\n",
        "    Y_test = Y[train_split:]\n",
        "\n",
        "    X_train = X_train.reshape((X_train.shape[0],X_train.shape[1],1))\n",
        "    Y_train = Y_train.reshape((Y_train.shape[0],Y_train.shape[1],1))\n",
        "    X_test = X_test.reshape((X_test.shape[0],X_test.shape[1],1))\n",
        "    Y_test = Y_test.reshape((Y_test.shape[0],Y_test.shape[1],1))\n",
        "\n",
        "    return X_train,Y_train,X_test,Y_test,data_df_combined_clean\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "class TorchDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.x[idx], self.y[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "class TorchDataLoader:\n",
        "    def __init__(self,batch_size,shuffle = True):\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "    \n",
        "    def torch_dataloader(self,train_data,target_data):\n",
        "        torch_dataset = TorchDataset(train_data,target_data)\n",
        "        torch_loader = DataLoader(dataset = torch_dataset,\n",
        "                                batch_size = self.batch_size, \n",
        "                                shuffle = self.shuffle)\n",
        "        return torch_loader\n",
        "\n",
        "def plot_results(predicted_data, true_data):\n",
        "    # use in train.py \n",
        "    # plot evaluate result\n",
        "    fig = plt.figure(facecolor='white', figsize=(12, 6))\n",
        "    ax = fig.add_subplot(111)\n",
        "    ax.plot(true_data[-200:], label='True Data')\n",
        "    plt.plot(predicted_data[-200:], label='Prediction')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def ToVariable(x):\n",
        "    # use in train.py \n",
        "    # change from numpy.array to torch.variable   \n",
        "    tmp = torch.DoubleTensor(x)\n",
        "    return Variable(tmp)\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "YO_ZABu_iKsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "from torch.nn.parameter import Parameter\n",
        "import torch.nn.functional as F \n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "import numpy as np \n",
        "import h5py\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import pywt\n",
        "\n",
        "class Wavelet_RNN(nn.Module):\n",
        "    def __init__(self, seq_len, hidden_size, output_size, num_rnn_levels):\n",
        "        super(Wavelet_RNN, self).__init__()\n",
        "      \n",
        "        self.seq_len = seq_len\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.num_rnn_levels = num_rnn_levels\n",
        "\n",
        "        self.rnns = nn.ModuleList([nn.RNN(1, hidden_size, batch_first=True) for _ in range(num_rnn_levels)])\n",
        "        self.mWDNs = nn.ModuleList([nn.Linear(int(seq_len / (2 ** i)), int(seq_len / (2 ** i))) for i in range(num_rnn_levels)])\n",
        "\n",
        "        self.a_to_x = nn.AvgPool1d(2)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.output = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "        wavelet = pywt.Wavelet('db4')\n",
        "        low = wavelet.dec_lo\n",
        "        high = wavelet.dec_hi\n",
        "        self.l_filter = low\n",
        "        self.h_filter = high\n",
        "\n",
        "        self.cmp_mWDNs_H = nn.ParameterList([nn.Parameter(torch.tensor(self.create_W(int(seq_len / (2 ** i)), False, is_comp=True)).double()) for i in range(num_rnn_levels)])\n",
        "        self.cmp_mWDNs_L = nn.ParameterList([nn.Parameter(torch.tensor(self.create_W(int(seq_len / (2 ** i)), True, is_comp=True)).double()) for i in range(num_rnn_levels)])\n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "        self.mWDNs_H = nn.ModuleList([nn.Linear(int(seq_len / (2 ** i)), int(seq_len / (2 ** i))) for i in range(num_rnn_levels)])\n",
        "        self.mWDNs_L = nn.ModuleList([nn.Linear(int(seq_len / (2 ** i)), int(seq_len / (2 ** i))) for i in range(num_rnn_levels)])\n",
        "\n",
        "        for i in range(num_rnn_levels):\n",
        "            #self.cmp_mWDNs_H.append(nn.Parameter(torch.tensor(self.create_W(int(seq_len / (2 ** i)), False, is_comp=True))))\n",
        "            #self.cmp_mWDNs_L.append(nn.Parameter(torch.tensor(self.create_W(int(seq_len / (2 ** i)), True, is_comp=True))))\n",
        "            self.mWDNs_H[i].weight = nn.Parameter(torch.tensor(self.create_W(int(seq_len / (2 ** i)), False)).double())\n",
        "            self.mWDNs_L[i].weight = nn.Parameter(torch.tensor(self.create_W(int(seq_len / (2 ** i)), True)).double())\n",
        "\n",
        "    def forward(self, input, hidden_states):\n",
        "      \n",
        "        input = input.view(input.shape[0], input.shape[1])\n",
        "        hidden_states = [hidden_states[i].to(input.device) for i in range(self.num_rnn_levels)]\n",
        "        al = []\n",
        "        ah = []\n",
        "        xl =[]\n",
        "        xh =[]\n",
        "        # Wavelet decomposition layers\n",
        "        ah.append(self.sigmoid(self.mWDNs_H[0](input)))\n",
        "        al.append(self.sigmoid(self.mWDNs_L[0](input)))\n",
        "        xh.append(self.a_to_x(ah[0].view(ah[0].shape[0],1,-1)))\n",
        "        xl.append(self.a_to_x(al[0].view(al[0].shape[0],1,-1)))\n",
        "        for i in range(1,self.num_rnn_levels):\n",
        "            ah.append(self.sigmoid(self.mWDNs_H[i](xl[i-1])))\n",
        "            al.append(self.sigmoid(self.mWDNs_L[i](xl[i-1])))\n",
        "            xh.append(self.a_to_x(ah[i]))\n",
        "            xl.append(self.a_to_x(al[i]))\n",
        "\n",
        "        # Transpose and apply RNN layers\n",
        "        xh = [x.transpose(1, 2) for x in xh]\n",
        "        xl = [x.transpose(1, 2) for x in xl]\n",
        "        #to do xl[-1] append to xh\n",
        "        rnn_outputs = []\n",
        "        for i in range(self.num_rnn_levels):\n",
        "            rnn_output, _ = self.rnns[i](xh[i], hidden_states[i])\n",
        "            rnn_outputs.append(rnn_output)\n",
        "\n",
        "        rnn_outputs = torch.cat(rnn_outputs, 1)\n",
        "\n",
        "        output = self.output(rnn_outputs)\n",
        "        return output\n",
        "\n",
        "    def init_state(self, batch_size):\n",
        "        hidden_states = [Variable(torch.zeros(1, batch_size, self.hidden_size)).double()\n",
        "                         for _ in range(self.num_rnn_levels)]\n",
        "        return hidden_states\n",
        "\n",
        "    def create_W(self, P, is_l, is_comp=False):\n",
        "        if is_l:\n",
        "            filter_list = self.l_filter\n",
        "        else:\n",
        "            filter_list = self.h_filter\n",
        "\n",
        "        list_len = len(filter_list)\n",
        "\n",
        "        max_epsilon = np.min(np.abs(filter_list))\n",
        "        if is_comp:\n",
        "            weight_np = np.zeros((P, P))\n",
        "        else:\n",
        "            weight_np = np.random.randn(P, P) * 0.1 * max_epsilon\n",
        "\n",
        "        for i in range(0, P):\n",
        "            filter_index = 0\n",
        "            for j in range(i, P):\n",
        "                if filter_index < len(filter_list):\n",
        "                    weight_np[i][j] = filter_list[filter_index]\n",
        "                    filter_index += 1\n",
        "        return weight_np\n"
      ],
      "metadata": {
        "id": "791mnhYd2m5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, x_train, y_train, epochs=10, batch_size=32, alpha=0.3, beta=0.3):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.008)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    torch_dataloader = TorchDataLoader(batch_size)\n",
        "    train_loader = torch_dataloader.torch_dataloader(x_train, y_train)\n",
        "\n",
        "    x_len = x_train.shape[1]\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for batch, (X, Y) in enumerate(train_loader):\n",
        "            hidden_states = model.init_state(X.shape[0])\n",
        "            #print(hidden_states[0].shape)\n",
        "\n",
        "            output = model(X, hidden_states)\n",
        "\n",
        "            loss = criterion(output[:, -1, :], Y[:, -1, :])\n",
        "\n",
        "            # Calculate wavelet loss\n",
        "            L_loss = 0\n",
        "            H_loss = 0\n",
        "\n",
        "            W_mWDNs_H = [getattr(model.mWDNs_H[i], 'weight').data for i in range(model.num_rnn_levels)]\n",
        "            W_mWDNs_L = [getattr(model.mWDNs_L[i], 'weight').data for i in range(model.num_rnn_levels)]\n",
        "            for i in range(model.num_rnn_levels):\n",
        "                L_loss += torch.norm((W_mWDNs_L[i] - model.cmp_mWDNs_L[i]), 2)\n",
        "                H_loss += torch.norm((W_mWDNs_H[i] - model.cmp_mWDNs_H[i]), 2)\n",
        "\n",
        "            loss += alpha * L_loss + beta * H_loss\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            print('Epoch:', epoch + 1, '| Batch:', batch + 1, '| Loss:', loss.item())\n",
        "\n",
        "    torch.save(model, '/content/drive/My Drive/thesis/preprocess/modelRNN_C.pkl')\n",
        "\n",
        "\n",
        "def test(model, x_test, y_test, data_df_combined_clean):\n",
        "    model = torch.load('/content/drive/My Drive/thesis/preprocess/modelRNN_C.pkl')\n",
        "    model.eval()\n",
        "    x_test = ToVariable(x_test).double()\n",
        "    hiddens_states = model.init_state(x_test.shape[0])\n",
        "\n",
        "    pred_dat = model(x_test, hiddens_states)\n",
        "\n",
        "    pred_dat = np.array(pred_dat.detach().numpy())\n",
        "\n",
        "    # De-standardize predictions\n",
        "    preds_unstd = pred_dat * data_df_combined_clean.iloc[:, -1].std() + data_df_combined_clean.iloc[:, -1].mean()\n",
        "    y_test_unstd = y_test * data_df_combined_clean.iloc[:, -1].std() + data_df_combined_clean.iloc[:, -1].mean()\n",
        "\n",
        "    mrse = np.sqrt(((preds_unstd[:, -1, :] - y_test_unstd[:, -1, :]) ** 2)).mean(axis=0)\n",
        "    print('The mean square error is: %f' % mrse)\n",
        "    mape = np.mean(np.abs((y_test_unstd[:, -1, :] - preds_unstd[:, -1, :]) / y_test_unstd[:, -1, :])) * 100\n",
        "    print('MAPE is: %f' % mape)\n",
        "\n",
        "    plot_results(preds_unstd[:, -1, :], y_test_unstd[:, -1, :])\n"
      ],
      "metadata": {
        "id": "oKIZZYWMiZRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/drive/MyDrive/ausdata.csv'\n",
        "P = 24  # sequence length\n",
        "step = 6  # ahead predict steps\n",
        "\n",
        "X_train, Y_train, X_test, Y_test, data_df_combined_clean = load_data(data_path, P=P, step=step)\n",
        "\n",
        "#print(X_train.shape)\n",
        "#print(Y_train.shape)\n",
        "\n",
        "model = Wavelet_RNN(P, 100, 1, num_rnn_levels=3)  # seq_len, hidden_size, output_size\n",
        "model = model.double()\n",
        "\n",
        "X_train = torch.from_numpy(X_train)\n",
        "Y_train = torch.from_numpy(Y_train)\n",
        "train(model, X_train, Y_train, epochs=50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UW5ag5_1iaP2",
        "outputId": "36de4d68-edad-49cc-82af-1c08b21d7681"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch: 48 | Batch: 1574 | Loss: 0.08937727095420103\n",
            "Epoch: 48 | Batch: 1575 | Loss: 0.08200710905114222\n",
            "Epoch: 48 | Batch: 1576 | Loss: 0.09235822215598384\n",
            "Epoch: 48 | Batch: 1577 | Loss: 0.0940793348872558\n",
            "Epoch: 48 | Batch: 1578 | Loss: 0.10872026769880887\n",
            "Epoch: 48 | Batch: 1579 | Loss: 0.09104657870226152\n",
            "Epoch: 48 | Batch: 1580 | Loss: 0.09289931012548108\n",
            "Epoch: 48 | Batch: 1581 | Loss: 0.0766015554735262\n",
            "Epoch: 48 | Batch: 1582 | Loss: 0.09117070566019056\n",
            "Epoch: 48 | Batch: 1583 | Loss: 0.10659737694668095\n",
            "Epoch: 48 | Batch: 1584 | Loss: 0.10148678380552822\n",
            "Epoch: 48 | Batch: 1585 | Loss: 0.08649069936484531\n",
            "Epoch: 48 | Batch: 1586 | Loss: 0.099321286661618\n",
            "Epoch: 48 | Batch: 1587 | Loss: 0.08123690087186182\n",
            "Epoch: 48 | Batch: 1588 | Loss: 0.0871222761116861\n",
            "Epoch: 48 | Batch: 1589 | Loss: 0.07791270703481455\n",
            "Epoch: 48 | Batch: 1590 | Loss: 0.09981763350586027\n",
            "Epoch: 48 | Batch: 1591 | Loss: 0.094851649414499\n",
            "Epoch: 48 | Batch: 1592 | Loss: 0.1193678725218851\n",
            "Epoch: 48 | Batch: 1593 | Loss: 0.12003708455770107\n",
            "Epoch: 48 | Batch: 1594 | Loss: 0.10979358602657092\n",
            "Epoch: 48 | Batch: 1595 | Loss: 0.10857392909891497\n",
            "Epoch: 48 | Batch: 1596 | Loss: 0.1436505161827403\n",
            "Epoch: 48 | Batch: 1597 | Loss: 0.10637769431923641\n",
            "Epoch: 48 | Batch: 1598 | Loss: 0.09388176451631383\n",
            "Epoch: 48 | Batch: 1599 | Loss: 0.12342095380829753\n",
            "Epoch: 48 | Batch: 1600 | Loss: 0.09925467973630715\n",
            "Epoch: 48 | Batch: 1601 | Loss: 0.11898077832012185\n",
            "Epoch: 48 | Batch: 1602 | Loss: 0.0886672889314163\n",
            "Epoch: 48 | Batch: 1603 | Loss: 0.1281303675286186\n",
            "Epoch: 48 | Batch: 1604 | Loss: 0.09559590150054055\n",
            "Epoch: 48 | Batch: 1605 | Loss: 0.09125331967045727\n",
            "Epoch: 48 | Batch: 1606 | Loss: 0.08085013839351501\n",
            "Epoch: 48 | Batch: 1607 | Loss: 0.10390100387240114\n",
            "Epoch: 48 | Batch: 1608 | Loss: 0.10104964424762511\n",
            "Epoch: 48 | Batch: 1609 | Loss: 0.15492807024759075\n",
            "Epoch: 48 | Batch: 1610 | Loss: 0.11551186811421388\n",
            "Epoch: 48 | Batch: 1611 | Loss: 0.10653093102957156\n",
            "Epoch: 48 | Batch: 1612 | Loss: 0.09832841583152988\n",
            "Epoch: 48 | Batch: 1613 | Loss: 0.09913475856067601\n",
            "Epoch: 48 | Batch: 1614 | Loss: 0.08669101239304969\n",
            "Epoch: 48 | Batch: 1615 | Loss: 0.10383934224418517\n",
            "Epoch: 48 | Batch: 1616 | Loss: 0.11171139582720066\n",
            "Epoch: 48 | Batch: 1617 | Loss: 0.11542984576783288\n",
            "Epoch: 48 | Batch: 1618 | Loss: 0.08205763553775494\n",
            "Epoch: 48 | Batch: 1619 | Loss: 0.08774788969681682\n",
            "Epoch: 48 | Batch: 1620 | Loss: 0.091466015037626\n",
            "Epoch: 48 | Batch: 1621 | Loss: 0.07807485383449486\n",
            "Epoch: 48 | Batch: 1622 | Loss: 0.09149064343813573\n",
            "Epoch: 48 | Batch: 1623 | Loss: 0.13263102705560637\n",
            "Epoch: 48 | Batch: 1624 | Loss: 0.08845280697266303\n",
            "Epoch: 48 | Batch: 1625 | Loss: 0.12774566527830522\n",
            "Epoch: 48 | Batch: 1626 | Loss: 0.13390662314902924\n",
            "Epoch: 48 | Batch: 1627 | Loss: 0.11645360281534109\n",
            "Epoch: 48 | Batch: 1628 | Loss: 0.0877401854163216\n",
            "Epoch: 48 | Batch: 1629 | Loss: 0.11423174492027263\n",
            "Epoch: 48 | Batch: 1630 | Loss: 0.10448066078117049\n",
            "Epoch: 48 | Batch: 1631 | Loss: 0.10498710412237014\n",
            "Epoch: 48 | Batch: 1632 | Loss: 0.11286959853164101\n",
            "Epoch: 48 | Batch: 1633 | Loss: 0.1281118880435334\n",
            "Epoch: 48 | Batch: 1634 | Loss: 0.12819280378072762\n",
            "Epoch: 48 | Batch: 1635 | Loss: 0.1195074584180806\n",
            "Epoch: 48 | Batch: 1636 | Loss: 0.13908358721224623\n",
            "Epoch: 48 | Batch: 1637 | Loss: 0.11782262540096657\n",
            "Epoch: 48 | Batch: 1638 | Loss: 0.12014472263459179\n",
            "Epoch: 48 | Batch: 1639 | Loss: 0.09419917538848346\n",
            "Epoch: 48 | Batch: 1640 | Loss: 0.09994954480387455\n",
            "Epoch: 48 | Batch: 1641 | Loss: 0.10297615386517128\n",
            "Epoch: 48 | Batch: 1642 | Loss: 0.1009024776932946\n",
            "Epoch: 48 | Batch: 1643 | Loss: 0.1098328641382326\n",
            "Epoch: 48 | Batch: 1644 | Loss: 0.08342200151626232\n",
            "Epoch: 48 | Batch: 1645 | Loss: 0.10571535385073394\n",
            "Epoch: 48 | Batch: 1646 | Loss: 0.11075931233081869\n",
            "Epoch: 48 | Batch: 1647 | Loss: 0.09750031010659493\n",
            "Epoch: 48 | Batch: 1648 | Loss: 0.12906236380257652\n",
            "Epoch: 48 | Batch: 1649 | Loss: 0.07735209266723916\n",
            "Epoch: 48 | Batch: 1650 | Loss: 0.09291341807935953\n",
            "Epoch: 48 | Batch: 1651 | Loss: 0.10159881988958169\n",
            "Epoch: 48 | Batch: 1652 | Loss: 0.11181865721301634\n",
            "Epoch: 48 | Batch: 1653 | Loss: 0.07542494812834082\n",
            "Epoch: 48 | Batch: 1654 | Loss: 0.13137224883923\n",
            "Epoch: 48 | Batch: 1655 | Loss: 0.1177795481599619\n",
            "Epoch: 48 | Batch: 1656 | Loss: 0.10196196436328861\n",
            "Epoch: 48 | Batch: 1657 | Loss: 0.08645598048389133\n",
            "Epoch: 48 | Batch: 1658 | Loss: 0.102611549627381\n",
            "Epoch: 48 | Batch: 1659 | Loss: 0.11430713755739647\n",
            "Epoch: 48 | Batch: 1660 | Loss: 0.10976939244367954\n",
            "Epoch: 48 | Batch: 1661 | Loss: 0.09155898926636241\n",
            "Epoch: 48 | Batch: 1662 | Loss: 0.10312928619270409\n",
            "Epoch: 48 | Batch: 1663 | Loss: 0.12508620510592394\n",
            "Epoch: 48 | Batch: 1664 | Loss: 0.135253714417147\n",
            "Epoch: 48 | Batch: 1665 | Loss: 0.09952477965125275\n",
            "Epoch: 48 | Batch: 1666 | Loss: 0.09108495052551932\n",
            "Epoch: 48 | Batch: 1667 | Loss: 0.14626304947825158\n",
            "Epoch: 48 | Batch: 1668 | Loss: 0.12649752680053894\n",
            "Epoch: 48 | Batch: 1669 | Loss: 0.11877142189584347\n",
            "Epoch: 48 | Batch: 1670 | Loss: 0.13841199515073843\n",
            "Epoch: 48 | Batch: 1671 | Loss: 0.10573214281833956\n",
            "Epoch: 48 | Batch: 1672 | Loss: 0.10157016650727671\n",
            "Epoch: 48 | Batch: 1673 | Loss: 0.11727473039699089\n",
            "Epoch: 48 | Batch: 1674 | Loss: 0.15918437351500897\n",
            "Epoch: 48 | Batch: 1675 | Loss: 0.13300885665380166\n",
            "Epoch: 48 | Batch: 1676 | Loss: 0.13668706023190216\n",
            "Epoch: 48 | Batch: 1677 | Loss: 0.10226982404209392\n",
            "Epoch: 48 | Batch: 1678 | Loss: 0.15601139380207493\n",
            "Epoch: 48 | Batch: 1679 | Loss: 0.10401883991144793\n",
            "Epoch: 48 | Batch: 1680 | Loss: 0.18057055188299564\n",
            "Epoch: 48 | Batch: 1681 | Loss: 0.09074957387882436\n",
            "Epoch: 48 | Batch: 1682 | Loss: 0.11971588834161019\n",
            "Epoch: 48 | Batch: 1683 | Loss: 0.14702621948710737\n",
            "Epoch: 48 | Batch: 1684 | Loss: 0.08664826901906708\n",
            "Epoch: 48 | Batch: 1685 | Loss: 0.10047314353415296\n",
            "Epoch: 48 | Batch: 1686 | Loss: 0.1417838505539586\n",
            "Epoch: 48 | Batch: 1687 | Loss: 0.09964507338826317\n",
            "Epoch: 48 | Batch: 1688 | Loss: 0.09551846831876026\n",
            "Epoch: 48 | Batch: 1689 | Loss: 0.16415548237597205\n",
            "Epoch: 48 | Batch: 1690 | Loss: 0.09949270123420992\n",
            "Epoch: 48 | Batch: 1691 | Loss: 0.0896278261420217\n",
            "Epoch: 48 | Batch: 1692 | Loss: 0.10183522553807371\n",
            "Epoch: 48 | Batch: 1693 | Loss: 0.12010306246348813\n",
            "Epoch: 48 | Batch: 1694 | Loss: 0.09603463553345522\n",
            "Epoch: 48 | Batch: 1695 | Loss: 0.08899330305003596\n",
            "Epoch: 48 | Batch: 1696 | Loss: 0.10415462558481547\n",
            "Epoch: 48 | Batch: 1697 | Loss: 0.10598151720208004\n",
            "Epoch: 48 | Batch: 1698 | Loss: 0.06763465024862383\n",
            "Epoch: 48 | Batch: 1699 | Loss: 0.11999023091785484\n",
            "Epoch: 48 | Batch: 1700 | Loss: 0.08002239733137953\n",
            "Epoch: 48 | Batch: 1701 | Loss: 0.1027208689082022\n",
            "Epoch: 48 | Batch: 1702 | Loss: 0.1115164384374419\n",
            "Epoch: 48 | Batch: 1703 | Loss: 0.10812090107638882\n",
            "Epoch: 48 | Batch: 1704 | Loss: 0.10409995349202632\n",
            "Epoch: 48 | Batch: 1705 | Loss: 0.09886374564523917\n",
            "Epoch: 48 | Batch: 1706 | Loss: 0.08137923784046079\n",
            "Epoch: 48 | Batch: 1707 | Loss: 0.1088381987567846\n",
            "Epoch: 48 | Batch: 1708 | Loss: 0.09243690088709199\n",
            "Epoch: 48 | Batch: 1709 | Loss: 0.09052999621787455\n",
            "Epoch: 48 | Batch: 1710 | Loss: 0.085820567090618\n",
            "Epoch: 48 | Batch: 1711 | Loss: 0.08024558459216297\n",
            "Epoch: 48 | Batch: 1712 | Loss: 0.09887075651256945\n",
            "Epoch: 48 | Batch: 1713 | Loss: 0.0705641722073909\n",
            "Epoch: 48 | Batch: 1714 | Loss: 0.06947182650719486\n",
            "Epoch: 48 | Batch: 1715 | Loss: 0.07540481384938298\n",
            "Epoch: 48 | Batch: 1716 | Loss: 0.10063172736699955\n",
            "Epoch: 48 | Batch: 1717 | Loss: 0.1022208099819881\n",
            "Epoch: 48 | Batch: 1718 | Loss: 0.08868823809934614\n",
            "Epoch: 48 | Batch: 1719 | Loss: 0.10490796688303075\n",
            "Epoch: 48 | Batch: 1720 | Loss: 0.09992662736876105\n",
            "Epoch: 48 | Batch: 1721 | Loss: 0.05318682721833538\n",
            "Epoch: 48 | Batch: 1722 | Loss: 0.06332866856289314\n",
            "Epoch: 48 | Batch: 1723 | Loss: 0.12194866489286474\n",
            "Epoch: 48 | Batch: 1724 | Loss: 0.08636078392769295\n",
            "Epoch: 48 | Batch: 1725 | Loss: 0.13191394227309253\n",
            "Epoch: 48 | Batch: 1726 | Loss: 0.14607340986641026\n",
            "Epoch: 48 | Batch: 1727 | Loss: 0.12685859038230135\n",
            "Epoch: 48 | Batch: 1728 | Loss: 0.1044418831508428\n",
            "Epoch: 48 | Batch: 1729 | Loss: 0.10956990712532343\n",
            "Epoch: 48 | Batch: 1730 | Loss: 0.10478406413527194\n",
            "Epoch: 48 | Batch: 1731 | Loss: 0.10864449998913803\n",
            "Epoch: 48 | Batch: 1732 | Loss: 0.09978791908197526\n",
            "Epoch: 48 | Batch: 1733 | Loss: 0.08871930690973315\n",
            "Epoch: 48 | Batch: 1734 | Loss: 0.10123586810640817\n",
            "Epoch: 48 | Batch: 1735 | Loss: 0.08056513646578184\n",
            "Epoch: 48 | Batch: 1736 | Loss: 0.1037570038047747\n",
            "Epoch: 48 | Batch: 1737 | Loss: 0.13105187310743405\n",
            "Epoch: 48 | Batch: 1738 | Loss: 0.13374210198903974\n",
            "Epoch: 48 | Batch: 1739 | Loss: 0.09852499178082423\n",
            "Epoch: 48 | Batch: 1740 | Loss: 0.1231893599620039\n",
            "Epoch: 48 | Batch: 1741 | Loss: 0.14082002494617205\n",
            "Epoch: 48 | Batch: 1742 | Loss: 0.08295628457883919\n",
            "Epoch: 48 | Batch: 1743 | Loss: 0.07712969987628335\n",
            "Epoch: 48 | Batch: 1744 | Loss: 0.15741775642655967\n",
            "Epoch: 48 | Batch: 1745 | Loss: 0.1121100441691829\n",
            "Epoch: 48 | Batch: 1746 | Loss: 0.07922132378588462\n",
            "Epoch: 48 | Batch: 1747 | Loss: 0.14684857726560557\n",
            "Epoch: 48 | Batch: 1748 | Loss: 0.10925790653785339\n",
            "Epoch: 48 | Batch: 1749 | Loss: 0.07730139091519969\n",
            "Epoch: 48 | Batch: 1750 | Loss: 0.12628230145705982\n",
            "Epoch: 48 | Batch: 1751 | Loss: 0.12521891946421754\n",
            "Epoch: 48 | Batch: 1752 | Loss: 0.08254567213960873\n",
            "Epoch: 48 | Batch: 1753 | Loss: 0.14414479396771684\n",
            "Epoch: 48 | Batch: 1754 | Loss: 0.12332998753308484\n",
            "Epoch: 48 | Batch: 1755 | Loss: 0.0885033950874764\n",
            "Epoch: 48 | Batch: 1756 | Loss: 0.1434755711978012\n",
            "Epoch: 48 | Batch: 1757 | Loss: 0.09708130250214796\n",
            "Epoch: 48 | Batch: 1758 | Loss: 0.09510399335949979\n",
            "Epoch: 48 | Batch: 1759 | Loss: 0.08462682126810628\n",
            "Epoch: 48 | Batch: 1760 | Loss: 0.09869098991909722\n",
            "Epoch: 48 | Batch: 1761 | Loss: 0.09265240497190445\n",
            "Epoch: 48 | Batch: 1762 | Loss: 0.08785483765225421\n",
            "Epoch: 48 | Batch: 1763 | Loss: 0.10168056305637352\n",
            "Epoch: 48 | Batch: 1764 | Loss: 0.0813670417089137\n",
            "Epoch: 48 | Batch: 1765 | Loss: 0.06250267505415934\n",
            "Epoch: 48 | Batch: 1766 | Loss: 0.07501729493752167\n",
            "Epoch: 48 | Batch: 1767 | Loss: 0.12693757173340994\n",
            "Epoch: 48 | Batch: 1768 | Loss: 0.09284206316079235\n",
            "Epoch: 48 | Batch: 1769 | Loss: 0.12803051299285656\n",
            "Epoch: 48 | Batch: 1770 | Loss: 0.09322776559717338\n",
            "Epoch: 48 | Batch: 1771 | Loss: 0.07955641007728842\n",
            "Epoch: 48 | Batch: 1772 | Loss: 0.10682336078338356\n",
            "Epoch: 48 | Batch: 1773 | Loss: 0.08691063343608123\n",
            "Epoch: 48 | Batch: 1774 | Loss: 0.08049815453055464\n",
            "Epoch: 48 | Batch: 1775 | Loss: 0.09205284608041538\n",
            "Epoch: 48 | Batch: 1776 | Loss: 0.09742860472969878\n",
            "Epoch: 48 | Batch: 1777 | Loss: 0.10312970940464683\n",
            "Epoch: 48 | Batch: 1778 | Loss: 0.1257489442066587\n",
            "Epoch: 48 | Batch: 1779 | Loss: 0.12951934308638366\n",
            "Epoch: 48 | Batch: 1780 | Loss: 0.09333731370610257\n",
            "Epoch: 48 | Batch: 1781 | Loss: 0.11828855793183002\n",
            "Epoch: 48 | Batch: 1782 | Loss: 0.11570272331206562\n",
            "Epoch: 48 | Batch: 1783 | Loss: 0.07478477204107548\n",
            "Epoch: 48 | Batch: 1784 | Loss: 0.07699484025258437\n",
            "Epoch: 48 | Batch: 1785 | Loss: 0.07771279258018121\n",
            "Epoch: 48 | Batch: 1786 | Loss: 0.0919137085699353\n",
            "Epoch: 48 | Batch: 1787 | Loss: 0.07041574106194923\n",
            "Epoch: 48 | Batch: 1788 | Loss: 0.08429218450005797\n",
            "Epoch: 48 | Batch: 1789 | Loss: 0.12199085167350553\n",
            "Epoch: 48 | Batch: 1790 | Loss: 0.1481223631167647\n",
            "Epoch: 48 | Batch: 1791 | Loss: 0.07395203459038749\n",
            "Epoch: 48 | Batch: 1792 | Loss: 0.11097418333864822\n",
            "Epoch: 48 | Batch: 1793 | Loss: 0.08987999173230926\n",
            "Epoch: 48 | Batch: 1794 | Loss: 0.08276819297896457\n",
            "Epoch: 48 | Batch: 1795 | Loss: 0.08539721328858885\n",
            "Epoch: 48 | Batch: 1796 | Loss: 0.12461593641006277\n",
            "Epoch: 48 | Batch: 1797 | Loss: 0.08957273211901788\n",
            "Epoch: 48 | Batch: 1798 | Loss: 0.10554357797143477\n",
            "Epoch: 48 | Batch: 1799 | Loss: 0.10007623118136152\n",
            "Epoch: 48 | Batch: 1800 | Loss: 0.14745826669799594\n",
            "Epoch: 48 | Batch: 1801 | Loss: 0.11510980885328669\n",
            "Epoch: 48 | Batch: 1802 | Loss: 0.11003825106287132\n",
            "Epoch: 48 | Batch: 1803 | Loss: 0.11793483991044043\n",
            "Epoch: 48 | Batch: 1804 | Loss: 0.1517309257235186\n",
            "Epoch: 48 | Batch: 1805 | Loss: 0.13262993750489735\n",
            "Epoch: 48 | Batch: 1806 | Loss: 0.1422461734502058\n",
            "Epoch: 48 | Batch: 1807 | Loss: 0.12347598354274497\n",
            "Epoch: 48 | Batch: 1808 | Loss: 0.10987209766218947\n",
            "Epoch: 48 | Batch: 1809 | Loss: 0.09474802279845673\n",
            "Epoch: 48 | Batch: 1810 | Loss: 0.08370532373994882\n",
            "Epoch: 48 | Batch: 1811 | Loss: 0.08005940851033949\n",
            "Epoch: 48 | Batch: 1812 | Loss: 0.08788708314288794\n",
            "Epoch: 48 | Batch: 1813 | Loss: 0.09463946325950484\n",
            "Epoch: 48 | Batch: 1814 | Loss: 0.09370735871576555\n",
            "Epoch: 48 | Batch: 1815 | Loss: 0.09177306519404638\n",
            "Epoch: 48 | Batch: 1816 | Loss: 0.09972969658186956\n",
            "Epoch: 48 | Batch: 1817 | Loss: 0.09467285998544539\n",
            "Epoch: 48 | Batch: 1818 | Loss: 0.11923432872941622\n",
            "Epoch: 48 | Batch: 1819 | Loss: 0.1078098761636966\n",
            "Epoch: 48 | Batch: 1820 | Loss: 0.11516426015013234\n",
            "Epoch: 48 | Batch: 1821 | Loss: 0.12521958664118352\n",
            "Epoch: 48 | Batch: 1822 | Loss: 0.11761480013739446\n",
            "Epoch: 48 | Batch: 1823 | Loss: 0.12435026777436614\n",
            "Epoch: 48 | Batch: 1824 | Loss: 0.11167898197215281\n",
            "Epoch: 48 | Batch: 1825 | Loss: 0.08685277031510356\n",
            "Epoch: 48 | Batch: 1826 | Loss: 0.11841056535028346\n",
            "Epoch: 48 | Batch: 1827 | Loss: 0.11345958932390926\n",
            "Epoch: 48 | Batch: 1828 | Loss: 0.07553805775357376\n",
            "Epoch: 48 | Batch: 1829 | Loss: 0.11665200044665225\n",
            "Epoch: 48 | Batch: 1830 | Loss: 0.1188859419339203\n",
            "Epoch: 48 | Batch: 1831 | Loss: 0.08427601459431613\n",
            "Epoch: 48 | Batch: 1832 | Loss: 0.10315174083258201\n",
            "Epoch: 48 | Batch: 1833 | Loss: 0.11592842529303439\n",
            "Epoch: 48 | Batch: 1834 | Loss: 0.09671411848126643\n",
            "Epoch: 48 | Batch: 1835 | Loss: 0.0958162191350938\n",
            "Epoch: 48 | Batch: 1836 | Loss: 0.1370213859237554\n",
            "Epoch: 48 | Batch: 1837 | Loss: 0.08847700264399375\n",
            "Epoch: 48 | Batch: 1838 | Loss: 0.08534318458414827\n",
            "Epoch: 48 | Batch: 1839 | Loss: 0.08596984437148009\n",
            "Epoch: 48 | Batch: 1840 | Loss: 0.07428938427007653\n",
            "Epoch: 48 | Batch: 1841 | Loss: 0.09493225389083346\n",
            "Epoch: 48 | Batch: 1842 | Loss: 0.09748494304898482\n",
            "Epoch: 48 | Batch: 1843 | Loss: 0.09128148466475192\n",
            "Epoch: 48 | Batch: 1844 | Loss: 0.09683111360295744\n",
            "Epoch: 48 | Batch: 1845 | Loss: 0.07493846302705408\n",
            "Epoch: 48 | Batch: 1846 | Loss: 0.10950012010982846\n",
            "Epoch: 48 | Batch: 1847 | Loss: 0.10643293771959716\n",
            "Epoch: 48 | Batch: 1848 | Loss: 0.11493371685055336\n",
            "Epoch: 48 | Batch: 1849 | Loss: 0.1070399124033255\n",
            "Epoch: 48 | Batch: 1850 | Loss: 0.128582269291944\n",
            "Epoch: 48 | Batch: 1851 | Loss: 0.09921880592134932\n",
            "Epoch: 48 | Batch: 1852 | Loss: 0.09804835469155265\n",
            "Epoch: 48 | Batch: 1853 | Loss: 0.13613438660907365\n",
            "Epoch: 48 | Batch: 1854 | Loss: 0.10791393370563854\n",
            "Epoch: 48 | Batch: 1855 | Loss: 0.11421798857258213\n",
            "Epoch: 48 | Batch: 1856 | Loss: 0.12964436004072802\n",
            "Epoch: 48 | Batch: 1857 | Loss: 0.08681182092182775\n",
            "Epoch: 48 | Batch: 1858 | Loss: 0.10013048307159583\n",
            "Epoch: 48 | Batch: 1859 | Loss: 0.1553534314539171\n",
            "Epoch: 48 | Batch: 1860 | Loss: 0.14564808575457244\n",
            "Epoch: 48 | Batch: 1861 | Loss: 0.08008074044106057\n",
            "Epoch: 48 | Batch: 1862 | Loss: 0.1663850464889842\n",
            "Epoch: 48 | Batch: 1863 | Loss: 0.08898736443972624\n",
            "Epoch: 48 | Batch: 1864 | Loss: 0.08207774710013531\n",
            "Epoch: 48 | Batch: 1865 | Loss: 0.09518908554085204\n",
            "Epoch: 48 | Batch: 1866 | Loss: 0.13228697491998867\n",
            "Epoch: 48 | Batch: 1867 | Loss: 0.12438970392269635\n",
            "Epoch: 48 | Batch: 1868 | Loss: 0.22034983691565135\n",
            "Epoch: 48 | Batch: 1869 | Loss: 0.10828012327534552\n",
            "Epoch: 48 | Batch: 1870 | Loss: 0.09692633268481805\n",
            "Epoch: 48 | Batch: 1871 | Loss: 0.173179915427412\n",
            "Epoch: 48 | Batch: 1872 | Loss: 0.09538258905693103\n",
            "Epoch: 48 | Batch: 1873 | Loss: 0.09291355569142112\n",
            "Epoch: 48 | Batch: 1874 | Loss: 0.20758800145554449\n",
            "Epoch: 48 | Batch: 1875 | Loss: 0.13120977111608875\n",
            "Epoch: 48 | Batch: 1876 | Loss: 0.15670694100475308\n",
            "Epoch: 48 | Batch: 1877 | Loss: 0.26023777963730316\n",
            "Epoch: 48 | Batch: 1878 | Loss: 0.09394576709835169\n",
            "Epoch: 48 | Batch: 1879 | Loss: 0.13691871064223282\n",
            "Epoch: 48 | Batch: 1880 | Loss: 0.14806858832218273\n",
            "Epoch: 48 | Batch: 1881 | Loss: 0.12335081738261952\n",
            "Epoch: 48 | Batch: 1882 | Loss: 0.19045505940977153\n",
            "Epoch: 48 | Batch: 1883 | Loss: 0.10124434509641828\n",
            "Epoch: 48 | Batch: 1884 | Loss: 0.0975576674333429\n",
            "Epoch: 48 | Batch: 1885 | Loss: 0.0877762846208906\n",
            "Epoch: 48 | Batch: 1886 | Loss: 0.11513614394786446\n",
            "Epoch: 48 | Batch: 1887 | Loss: 0.11375969757533706\n",
            "Epoch: 48 | Batch: 1888 | Loss: 0.125954399491507\n",
            "Epoch: 48 | Batch: 1889 | Loss: 0.12778200060798223\n",
            "Epoch: 48 | Batch: 1890 | Loss: 0.13724842021171996\n",
            "Epoch: 48 | Batch: 1891 | Loss: 0.09660738892941843\n",
            "Epoch: 48 | Batch: 1892 | Loss: 0.1251275363690817\n",
            "Epoch: 48 | Batch: 1893 | Loss: 0.12673520537847252\n",
            "Epoch: 48 | Batch: 1894 | Loss: 0.10872539501823651\n",
            "Epoch: 48 | Batch: 1895 | Loss: 0.115800594025735\n",
            "Epoch: 48 | Batch: 1896 | Loss: 0.12271946699220604\n",
            "Epoch: 48 | Batch: 1897 | Loss: 0.097779073954711\n",
            "Epoch: 48 | Batch: 1898 | Loss: 0.11938097002422202\n",
            "Epoch: 48 | Batch: 1899 | Loss: 0.12345520472539291\n",
            "Epoch: 48 | Batch: 1900 | Loss: 0.13596219242895763\n",
            "Epoch: 48 | Batch: 1901 | Loss: 0.17104767642717578\n",
            "Epoch: 48 | Batch: 1902 | Loss: 0.14499237547982055\n",
            "Epoch: 48 | Batch: 1903 | Loss: 0.10269504980577263\n",
            "Epoch: 48 | Batch: 1904 | Loss: 0.1417740359042193\n",
            "Epoch: 48 | Batch: 1905 | Loss: 0.1428699147362259\n",
            "Epoch: 48 | Batch: 1906 | Loss: 0.10532666817236909\n",
            "Epoch: 48 | Batch: 1907 | Loss: 0.1650224784719193\n",
            "Epoch: 48 | Batch: 1908 | Loss: 0.13362554248900363\n",
            "Epoch: 48 | Batch: 1909 | Loss: 0.10121911223557101\n",
            "Epoch: 48 | Batch: 1910 | Loss: 0.14170475905352678\n",
            "Epoch: 48 | Batch: 1911 | Loss: 0.14201952016251562\n",
            "Epoch: 48 | Batch: 1912 | Loss: 0.12816973542942914\n",
            "Epoch: 48 | Batch: 1913 | Loss: 0.1397173115519753\n",
            "Epoch: 48 | Batch: 1914 | Loss: 0.11911026820846857\n",
            "Epoch: 48 | Batch: 1915 | Loss: 0.10420542523246482\n",
            "Epoch: 48 | Batch: 1916 | Loss: 0.14434521239541345\n",
            "Epoch: 48 | Batch: 1917 | Loss: 0.11010373264856593\n",
            "Epoch: 48 | Batch: 1918 | Loss: 0.08156128104661836\n",
            "Epoch: 48 | Batch: 1919 | Loss: 0.12947115635384004\n",
            "Epoch: 48 | Batch: 1920 | Loss: 0.10588104036063035\n",
            "Epoch: 48 | Batch: 1921 | Loss: 0.11411036735756769\n",
            "Epoch: 48 | Batch: 1922 | Loss: 0.12830465023918558\n",
            "Epoch: 48 | Batch: 1923 | Loss: 0.11286471628964734\n",
            "Epoch: 48 | Batch: 1924 | Loss: 0.09375938755716029\n",
            "Epoch: 48 | Batch: 1925 | Loss: 0.13762024208691365\n",
            "Epoch: 48 | Batch: 1926 | Loss: 0.11802627300849959\n",
            "Epoch: 48 | Batch: 1927 | Loss: 0.10454228950087846\n",
            "Epoch: 48 | Batch: 1928 | Loss: 0.10716730206992459\n",
            "Epoch: 48 | Batch: 1929 | Loss: 0.10454067040202615\n",
            "Epoch: 48 | Batch: 1930 | Loss: 0.10996448782368642\n",
            "Epoch: 48 | Batch: 1931 | Loss: 0.08982991055024432\n",
            "Epoch: 48 | Batch: 1932 | Loss: 0.08131804010524418\n",
            "Epoch: 48 | Batch: 1933 | Loss: 0.1244847210310413\n",
            "Epoch: 48 | Batch: 1934 | Loss: 0.09305627676275652\n",
            "Epoch: 48 | Batch: 1935 | Loss: 0.08673326281229346\n",
            "Epoch: 48 | Batch: 1936 | Loss: 0.08854964371111164\n",
            "Epoch: 48 | Batch: 1937 | Loss: 0.08292563162930733\n",
            "Epoch: 48 | Batch: 1938 | Loss: 0.06524464539461115\n",
            "Epoch: 48 | Batch: 1939 | Loss: 0.06521563294327448\n",
            "Epoch: 48 | Batch: 1940 | Loss: 0.07903343572325125\n",
            "Epoch: 48 | Batch: 1941 | Loss: 0.07023900874501476\n",
            "Epoch: 48 | Batch: 1942 | Loss: 0.07954801469428757\n",
            "Epoch: 48 | Batch: 1943 | Loss: 0.07683541349587678\n",
            "Epoch: 48 | Batch: 1944 | Loss: 0.08809891606563441\n",
            "Epoch: 48 | Batch: 1945 | Loss: 0.09422243955452253\n",
            "Epoch: 48 | Batch: 1946 | Loss: 0.07179418201707861\n",
            "Epoch: 48 | Batch: 1947 | Loss: 0.13424412215183051\n",
            "Epoch: 48 | Batch: 1948 | Loss: 0.08128016756422596\n",
            "Epoch: 48 | Batch: 1949 | Loss: 0.0992007954749719\n",
            "Epoch: 48 | Batch: 1950 | Loss: 0.07450015270100044\n",
            "Epoch: 48 | Batch: 1951 | Loss: 0.0996889534145163\n",
            "Epoch: 48 | Batch: 1952 | Loss: 0.08089735911699208\n",
            "Epoch: 48 | Batch: 1953 | Loss: 0.0665226796905829\n",
            "Epoch: 48 | Batch: 1954 | Loss: 0.06344644816439686\n",
            "Epoch: 48 | Batch: 1955 | Loss: 0.0656733889189344\n",
            "Epoch: 48 | Batch: 1956 | Loss: 0.09370176789687706\n",
            "Epoch: 48 | Batch: 1957 | Loss: 0.08422145395165156\n",
            "Epoch: 48 | Batch: 1958 | Loss: 0.0650600924485658\n",
            "Epoch: 48 | Batch: 1959 | Loss: 0.07576328963472691\n",
            "Epoch: 48 | Batch: 1960 | Loss: 0.08529147449653385\n",
            "Epoch: 48 | Batch: 1961 | Loss: 0.08522576128656281\n",
            "Epoch: 48 | Batch: 1962 | Loss: 0.06720645111234147\n",
            "Epoch: 48 | Batch: 1963 | Loss: 0.08696309363459148\n",
            "Epoch: 48 | Batch: 1964 | Loss: 0.09006647476012958\n",
            "Epoch: 48 | Batch: 1965 | Loss: 0.11918581798272919\n",
            "Epoch: 48 | Batch: 1966 | Loss: 0.07210111205261621\n",
            "Epoch: 48 | Batch: 1967 | Loss: 0.07814907684681892\n",
            "Epoch: 48 | Batch: 1968 | Loss: 0.08776943077975156\n",
            "Epoch: 48 | Batch: 1969 | Loss: 0.06445774373479482\n",
            "Epoch: 48 | Batch: 1970 | Loss: 0.08581575204313516\n",
            "Epoch: 48 | Batch: 1971 | Loss: 0.07633255511597117\n",
            "Epoch: 48 | Batch: 1972 | Loss: 0.06732217844497634\n",
            "Epoch: 48 | Batch: 1973 | Loss: 0.0743535897707718\n",
            "Epoch: 48 | Batch: 1974 | Loss: 0.15143830451248075\n",
            "Epoch: 48 | Batch: 1975 | Loss: 0.08005189827776917\n",
            "Epoch: 48 | Batch: 1976 | Loss: 0.08344590876864755\n",
            "Epoch: 48 | Batch: 1977 | Loss: 0.07566074975498635\n",
            "Epoch: 48 | Batch: 1978 | Loss: 0.06730199682360682\n",
            "Epoch: 48 | Batch: 1979 | Loss: 0.11461465225401757\n",
            "Epoch: 48 | Batch: 1980 | Loss: 0.09373605467513761\n",
            "Epoch: 48 | Batch: 1981 | Loss: 0.09657886096006142\n",
            "Epoch: 48 | Batch: 1982 | Loss: 0.08433316261860238\n",
            "Epoch: 48 | Batch: 1983 | Loss: 0.09516010390552737\n",
            "Epoch: 48 | Batch: 1984 | Loss: 0.08992294259311491\n",
            "Epoch: 48 | Batch: 1985 | Loss: 0.10492641377361177\n",
            "Epoch: 48 | Batch: 1986 | Loss: 0.0863606930664221\n",
            "Epoch: 48 | Batch: 1987 | Loss: 0.07276884336168914\n",
            "Epoch: 48 | Batch: 1988 | Loss: 0.1262383459747469\n",
            "Epoch: 48 | Batch: 1989 | Loss: 0.09456693845806477\n",
            "Epoch: 48 | Batch: 1990 | Loss: 0.09742204304813737\n",
            "Epoch: 48 | Batch: 1991 | Loss: 0.14599189412954944\n",
            "Epoch: 48 | Batch: 1992 | Loss: 0.10389925734060586\n",
            "Epoch: 48 | Batch: 1993 | Loss: 0.12911950094154498\n",
            "Epoch: 48 | Batch: 1994 | Loss: 0.1088669464109939\n",
            "Epoch: 48 | Batch: 1995 | Loss: 0.10523240395065211\n",
            "Epoch: 48 | Batch: 1996 | Loss: 0.07605403338562651\n",
            "Epoch: 48 | Batch: 1997 | Loss: 0.1115021373361898\n",
            "Epoch: 48 | Batch: 1998 | Loss: 0.09172935977006375\n",
            "Epoch: 48 | Batch: 1999 | Loss: 0.0692388115130893\n",
            "Epoch: 48 | Batch: 2000 | Loss: 0.10312673984036305\n",
            "Epoch: 48 | Batch: 2001 | Loss: 0.0879593373223414\n",
            "Epoch: 48 | Batch: 2002 | Loss: 0.10956943081468498\n",
            "Epoch: 48 | Batch: 2003 | Loss: 0.0788868354214026\n",
            "Epoch: 48 | Batch: 2004 | Loss: 0.08579996638436205\n",
            "Epoch: 48 | Batch: 2005 | Loss: 0.11316920587545744\n",
            "Epoch: 48 | Batch: 2006 | Loss: 0.06465809707926082\n",
            "Epoch: 48 | Batch: 2007 | Loss: 0.07330264215117774\n",
            "Epoch: 48 | Batch: 2008 | Loss: 0.12982790215870388\n",
            "Epoch: 48 | Batch: 2009 | Loss: 0.11320612485487935\n",
            "Epoch: 48 | Batch: 2010 | Loss: 0.06176418161631812\n",
            "Epoch: 48 | Batch: 2011 | Loss: 0.0793242609928151\n",
            "Epoch: 48 | Batch: 2012 | Loss: 0.0747751208813203\n",
            "Epoch: 48 | Batch: 2013 | Loss: 0.07002157695774032\n",
            "Epoch: 48 | Batch: 2014 | Loss: 0.07841415962462334\n",
            "Epoch: 48 | Batch: 2015 | Loss: 0.08732267868629609\n",
            "Epoch: 48 | Batch: 2016 | Loss: 0.11351313023389648\n",
            "Epoch: 48 | Batch: 2017 | Loss: 0.11424358117814662\n",
            "Epoch: 48 | Batch: 2018 | Loss: 0.09481733166392997\n",
            "Epoch: 48 | Batch: 2019 | Loss: 0.08842181227959123\n",
            "Epoch: 48 | Batch: 2020 | Loss: 0.08142565096484272\n",
            "Epoch: 48 | Batch: 2021 | Loss: 0.10000446851467498\n",
            "Epoch: 48 | Batch: 2022 | Loss: 0.07333744825616809\n",
            "Epoch: 48 | Batch: 2023 | Loss: 0.15108307998722348\n",
            "Epoch: 48 | Batch: 2024 | Loss: 0.16786742013890543\n",
            "Epoch: 48 | Batch: 2025 | Loss: 0.11066850415093163\n",
            "Epoch: 48 | Batch: 2026 | Loss: 0.10373584981686969\n",
            "Epoch: 48 | Batch: 2027 | Loss: 0.12412159683592831\n",
            "Epoch: 48 | Batch: 2028 | Loss: 0.11648695178253651\n",
            "Epoch: 48 | Batch: 2029 | Loss: 0.10491297022014871\n",
            "Epoch: 48 | Batch: 2030 | Loss: 0.1152721199625916\n",
            "Epoch: 48 | Batch: 2031 | Loss: 0.10474914655084655\n",
            "Epoch: 48 | Batch: 2032 | Loss: 0.08557378140062741\n",
            "Epoch: 48 | Batch: 2033 | Loss: 0.09333906902233048\n",
            "Epoch: 48 | Batch: 2034 | Loss: 0.12087502489381807\n",
            "Epoch: 48 | Batch: 2035 | Loss: 0.12203786154641139\n",
            "Epoch: 48 | Batch: 2036 | Loss: 0.10997452243950831\n",
            "Epoch: 48 | Batch: 2037 | Loss: 0.10659538485207329\n",
            "Epoch: 48 | Batch: 2038 | Loss: 0.11378291695711441\n",
            "Epoch: 48 | Batch: 2039 | Loss: 0.11864041173053416\n",
            "Epoch: 48 | Batch: 2040 | Loss: 0.10749396894224358\n",
            "Epoch: 48 | Batch: 2041 | Loss: 0.11960687139057416\n",
            "Epoch: 48 | Batch: 2042 | Loss: 0.08991148268263223\n",
            "Epoch: 48 | Batch: 2043 | Loss: 0.0986820561759178\n",
            "Epoch: 48 | Batch: 2044 | Loss: 0.1121941622192721\n",
            "Epoch: 48 | Batch: 2045 | Loss: 0.12294820602848663\n",
            "Epoch: 48 | Batch: 2046 | Loss: 0.10020609071833018\n",
            "Epoch: 48 | Batch: 2047 | Loss: 0.11316563967801911\n",
            "Epoch: 48 | Batch: 2048 | Loss: 0.10764609633981215\n",
            "Epoch: 48 | Batch: 2049 | Loss: 0.10557809959443741\n",
            "Epoch: 48 | Batch: 2050 | Loss: 0.1117136032369137\n",
            "Epoch: 48 | Batch: 2051 | Loss: 0.10223842256304211\n",
            "Epoch: 48 | Batch: 2052 | Loss: 0.09347491344923667\n",
            "Epoch: 48 | Batch: 2053 | Loss: 0.06455528269016123\n",
            "Epoch: 48 | Batch: 2054 | Loss: 0.08357672877973202\n",
            "Epoch: 48 | Batch: 2055 | Loss: 0.07850479257829956\n",
            "Epoch: 48 | Batch: 2056 | Loss: 0.11764126504244993\n",
            "Epoch: 48 | Batch: 2057 | Loss: 0.0960876220220573\n",
            "Epoch: 48 | Batch: 2058 | Loss: 0.09403302610624213\n",
            "Epoch: 48 | Batch: 2059 | Loss: 0.08238885947981221\n",
            "Epoch: 48 | Batch: 2060 | Loss: 0.10227430280300161\n",
            "Epoch: 48 | Batch: 2061 | Loss: 0.10623909248975211\n",
            "Epoch: 48 | Batch: 2062 | Loss: 0.11471386213354129\n",
            "Epoch: 48 | Batch: 2063 | Loss: 0.08842201494668561\n",
            "Epoch: 48 | Batch: 2064 | Loss: 0.07442993312782739\n",
            "Epoch: 48 | Batch: 2065 | Loss: 0.12702724072384441\n",
            "Epoch: 48 | Batch: 2066 | Loss: 0.0918779108973865\n",
            "Epoch: 48 | Batch: 2067 | Loss: 0.08880731890387436\n",
            "Epoch: 48 | Batch: 2068 | Loss: 0.072178127822707\n",
            "Epoch: 48 | Batch: 2069 | Loss: 0.08263916120545071\n",
            "Epoch: 48 | Batch: 2070 | Loss: 0.09274338881938651\n",
            "Epoch: 48 | Batch: 2071 | Loss: 0.10969746732800639\n",
            "Epoch: 48 | Batch: 2072 | Loss: 0.06922179323864752\n",
            "Epoch: 48 | Batch: 2073 | Loss: 0.09185329160215784\n",
            "Epoch: 48 | Batch: 2074 | Loss: 0.10102665135472592\n",
            "Epoch: 48 | Batch: 2075 | Loss: 0.08331700795882604\n",
            "Epoch: 48 | Batch: 2076 | Loss: 0.10209670680310534\n",
            "Epoch: 48 | Batch: 2077 | Loss: 0.08623595556154287\n",
            "Epoch: 48 | Batch: 2078 | Loss: 0.09374194851179858\n",
            "Epoch: 48 | Batch: 2079 | Loss: 0.1185927655601588\n",
            "Epoch: 48 | Batch: 2080 | Loss: 0.11133008245773457\n",
            "Epoch: 48 | Batch: 2081 | Loss: 0.11941272233725922\n",
            "Epoch: 48 | Batch: 2082 | Loss: 0.12568811167536195\n",
            "Epoch: 48 | Batch: 2083 | Loss: 0.13088078504357892\n",
            "Epoch: 48 | Batch: 2084 | Loss: 0.10983038870401757\n",
            "Epoch: 48 | Batch: 2085 | Loss: 0.12419824676111521\n",
            "Epoch: 48 | Batch: 2086 | Loss: 0.10463220467661297\n",
            "Epoch: 48 | Batch: 2087 | Loss: 0.10039112038385917\n",
            "Epoch: 48 | Batch: 2088 | Loss: 0.09014746917799978\n",
            "Epoch: 48 | Batch: 2089 | Loss: 0.09804728603143356\n",
            "Epoch: 48 | Batch: 2090 | Loss: 0.14040706580575213\n",
            "Epoch: 48 | Batch: 2091 | Loss: 0.10674438392969052\n",
            "Epoch: 48 | Batch: 2092 | Loss: 0.1273387119110444\n",
            "Epoch: 48 | Batch: 2093 | Loss: 0.10342010439726543\n",
            "Epoch: 48 | Batch: 2094 | Loss: 0.11284442345959352\n",
            "Epoch: 48 | Batch: 2095 | Loss: 0.14482682699775234\n",
            "Epoch: 48 | Batch: 2096 | Loss: 0.09023733146555352\n",
            "Epoch: 48 | Batch: 2097 | Loss: 0.11887838710833884\n",
            "Epoch: 48 | Batch: 2098 | Loss: 0.10508725825438883\n",
            "Epoch: 48 | Batch: 2099 | Loss: 0.09376640711216766\n",
            "Epoch: 48 | Batch: 2100 | Loss: 0.1380363468278758\n",
            "Epoch: 48 | Batch: 2101 | Loss: 0.11699701440461155\n",
            "Epoch: 48 | Batch: 2102 | Loss: 0.11701909630801428\n",
            "Epoch: 48 | Batch: 2103 | Loss: 0.11054975571356618\n",
            "Epoch: 48 | Batch: 2104 | Loss: 0.1086902688389304\n",
            "Epoch: 48 | Batch: 2105 | Loss: 0.07921301022641007\n",
            "Epoch: 48 | Batch: 2106 | Loss: 0.06603971806701715\n",
            "Epoch: 48 | Batch: 2107 | Loss: 0.07795647093957436\n",
            "Epoch: 48 | Batch: 2108 | Loss: 0.10059920227591472\n",
            "Epoch: 48 | Batch: 2109 | Loss: 0.10364709289587856\n",
            "Epoch: 48 | Batch: 2110 | Loss: 0.09522771250226755\n",
            "Epoch: 48 | Batch: 2111 | Loss: 0.09455526203916706\n",
            "Epoch: 48 | Batch: 2112 | Loss: 0.1349982857101425\n",
            "Epoch: 48 | Batch: 2113 | Loss: 0.1220135275773054\n",
            "Epoch: 48 | Batch: 2114 | Loss: 0.09935736929332242\n",
            "Epoch: 48 | Batch: 2115 | Loss: 0.11303843869501318\n",
            "Epoch: 48 | Batch: 2116 | Loss: 0.13309746657285343\n",
            "Epoch: 48 | Batch: 2117 | Loss: 0.09696949942331878\n",
            "Epoch: 48 | Batch: 2118 | Loss: 0.11654882122599537\n",
            "Epoch: 48 | Batch: 2119 | Loss: 0.15131428109251338\n",
            "Epoch: 48 | Batch: 2120 | Loss: 0.11262636412940202\n",
            "Epoch: 48 | Batch: 2121 | Loss: 0.1775849547929487\n",
            "Epoch: 48 | Batch: 2122 | Loss: 0.16860800804828324\n",
            "Epoch: 48 | Batch: 2123 | Loss: 0.11303004771686553\n",
            "Epoch: 48 | Batch: 2124 | Loss: 0.16932537641128653\n",
            "Epoch: 48 | Batch: 2125 | Loss: 0.16951421316810078\n",
            "Epoch: 48 | Batch: 2126 | Loss: 0.14018548272229592\n",
            "Epoch: 48 | Batch: 2127 | Loss: 0.16458150055296156\n",
            "Epoch: 48 | Batch: 2128 | Loss: 0.13285969873500364\n",
            "Epoch: 48 | Batch: 2129 | Loss: 0.12843436049520635\n",
            "Epoch: 48 | Batch: 2130 | Loss: 0.13769893395248378\n",
            "Epoch: 48 | Batch: 2131 | Loss: 0.17373628103328348\n",
            "Epoch: 48 | Batch: 2132 | Loss: 0.13403131025832543\n",
            "Epoch: 48 | Batch: 2133 | Loss: 0.12651135799622085\n",
            "Epoch: 48 | Batch: 2134 | Loss: 0.18053236741967144\n",
            "Epoch: 48 | Batch: 2135 | Loss: 0.14334978655525218\n",
            "Epoch: 48 | Batch: 2136 | Loss: 0.15566264544876002\n",
            "Epoch: 48 | Batch: 2137 | Loss: 0.20591917806726462\n",
            "Epoch: 48 | Batch: 2138 | Loss: 0.1452942548730497\n",
            "Epoch: 48 | Batch: 2139 | Loss: 0.19348958582987494\n",
            "Epoch: 48 | Batch: 2140 | Loss: 0.15256436098614062\n",
            "Epoch: 48 | Batch: 2141 | Loss: 0.10359710507696733\n",
            "Epoch: 48 | Batch: 2142 | Loss: 0.15957873971389175\n",
            "Epoch: 48 | Batch: 2143 | Loss: 0.15155530834651162\n",
            "Epoch: 48 | Batch: 2144 | Loss: 0.134053390325429\n",
            "Epoch: 48 | Batch: 2145 | Loss: 0.13757873727001807\n",
            "Epoch: 48 | Batch: 2146 | Loss: 0.16749483239820534\n",
            "Epoch: 48 | Batch: 2147 | Loss: 0.12154935556373644\n",
            "Epoch: 48 | Batch: 2148 | Loss: 0.20510189561524533\n",
            "Epoch: 48 | Batch: 2149 | Loss: 0.12489521288891778\n",
            "Epoch: 48 | Batch: 2150 | Loss: 0.149421683861495\n",
            "Epoch: 48 | Batch: 2151 | Loss: 0.11819000705917693\n",
            "Epoch: 48 | Batch: 2152 | Loss: 0.10301108256417599\n",
            "Epoch: 48 | Batch: 2153 | Loss: 0.1409394043954747\n",
            "Epoch: 48 | Batch: 2154 | Loss: 0.0926251510785145\n",
            "Epoch: 48 | Batch: 2155 | Loss: 0.12261979173969587\n",
            "Epoch: 48 | Batch: 2156 | Loss: 0.11117695981731585\n",
            "Epoch: 48 | Batch: 2157 | Loss: 0.11352815803725716\n",
            "Epoch: 48 | Batch: 2158 | Loss: 0.10892887403575906\n",
            "Epoch: 48 | Batch: 2159 | Loss: 0.12513492209949906\n",
            "Epoch: 48 | Batch: 2160 | Loss: 0.12309023415852566\n",
            "Epoch: 48 | Batch: 2161 | Loss: 0.11976440406083375\n",
            "Epoch: 48 | Batch: 2162 | Loss: 0.12600511305249457\n",
            "Epoch: 48 | Batch: 2163 | Loss: 0.1364142861112615\n",
            "Epoch: 48 | Batch: 2164 | Loss: 0.12547005985642062\n",
            "Epoch: 48 | Batch: 2165 | Loss: 0.10372347552343712\n",
            "Epoch: 48 | Batch: 2166 | Loss: 0.1348527385715494\n",
            "Epoch: 48 | Batch: 2167 | Loss: 0.17511953539374286\n",
            "Epoch: 48 | Batch: 2168 | Loss: 0.12514260887966724\n",
            "Epoch: 48 | Batch: 2169 | Loss: 0.11331299410578596\n",
            "Epoch: 48 | Batch: 2170 | Loss: 0.08568962547497415\n",
            "Epoch: 48 | Batch: 2171 | Loss: 0.10679055951934337\n",
            "Epoch: 48 | Batch: 2172 | Loss: 0.1247148591293967\n",
            "Epoch: 48 | Batch: 2173 | Loss: 0.0876569352140826\n",
            "Epoch: 48 | Batch: 2174 | Loss: 0.08398219643194574\n",
            "Epoch: 48 | Batch: 2175 | Loss: 0.15526709015958454\n",
            "Epoch: 48 | Batch: 2176 | Loss: 0.16582927827965188\n",
            "Epoch: 48 | Batch: 2177 | Loss: 0.09147695940361411\n",
            "Epoch: 48 | Batch: 2178 | Loss: 0.1285567267121511\n",
            "Epoch: 48 | Batch: 2179 | Loss: 0.1676978951052135\n",
            "Epoch: 48 | Batch: 2180 | Loss: 0.12917954517294045\n",
            "Epoch: 48 | Batch: 2181 | Loss: 0.157451637405744\n",
            "Epoch: 48 | Batch: 2182 | Loss: 0.09841923582845871\n",
            "Epoch: 48 | Batch: 2183 | Loss: 0.07283865199415758\n",
            "Epoch: 48 | Batch: 2184 | Loss: 0.12065105473116604\n",
            "Epoch: 48 | Batch: 2185 | Loss: 0.21380418162210788\n",
            "Epoch: 48 | Batch: 2186 | Loss: 0.12563738147777215\n",
            "Epoch: 48 | Batch: 2187 | Loss: 0.1356829775676623\n",
            "Epoch: 48 | Batch: 2188 | Loss: 0.15828957690081244\n",
            "Epoch: 48 | Batch: 2189 | Loss: 0.16480052143765225\n",
            "Epoch: 48 | Batch: 2190 | Loss: 0.16007749393679724\n",
            "Epoch: 48 | Batch: 2191 | Loss: 0.16718552113782426\n",
            "Epoch: 49 | Batch: 1 | Loss: 0.1894497473306978\n",
            "Epoch: 49 | Batch: 2 | Loss: 0.1536782687362653\n",
            "Epoch: 49 | Batch: 3 | Loss: 0.12309669466171595\n",
            "Epoch: 49 | Batch: 4 | Loss: 0.133091159820186\n",
            "Epoch: 49 | Batch: 5 | Loss: 0.1890397394792772\n",
            "Epoch: 49 | Batch: 6 | Loss: 0.14028687509380178\n",
            "Epoch: 49 | Batch: 7 | Loss: 0.16898109204027423\n",
            "Epoch: 49 | Batch: 8 | Loss: 0.18448606283433996\n",
            "Epoch: 49 | Batch: 9 | Loss: 0.23609355589008876\n",
            "Epoch: 49 | Batch: 10 | Loss: 0.23832126961631428\n",
            "Epoch: 49 | Batch: 11 | Loss: 0.2131549453002089\n",
            "Epoch: 49 | Batch: 12 | Loss: 0.23606820538331386\n",
            "Epoch: 49 | Batch: 13 | Loss: 0.22400255874944935\n",
            "Epoch: 49 | Batch: 14 | Loss: 0.23349279083491675\n",
            "Epoch: 49 | Batch: 15 | Loss: 0.20652563750722305\n",
            "Epoch: 49 | Batch: 16 | Loss: 0.19189291061950664\n",
            "Epoch: 49 | Batch: 17 | Loss: 0.16658493326531515\n",
            "Epoch: 49 | Batch: 18 | Loss: 0.1585489192971497\n",
            "Epoch: 49 | Batch: 19 | Loss: 0.19163928930859744\n",
            "Epoch: 49 | Batch: 20 | Loss: 0.16544727676563012\n",
            "Epoch: 49 | Batch: 21 | Loss: 0.15762490598469692\n",
            "Epoch: 49 | Batch: 22 | Loss: 0.16230629010358055\n",
            "Epoch: 49 | Batch: 23 | Loss: 0.1619198492833651\n",
            "Epoch: 49 | Batch: 24 | Loss: 0.1674639209230252\n",
            "Epoch: 49 | Batch: 25 | Loss: 0.20310199059314976\n",
            "Epoch: 49 | Batch: 26 | Loss: 0.16023244564853772\n",
            "Epoch: 49 | Batch: 27 | Loss: 0.15371749158415837\n",
            "Epoch: 49 | Batch: 28 | Loss: 0.16545673704356084\n",
            "Epoch: 49 | Batch: 29 | Loss: 0.11795923790659125\n",
            "Epoch: 49 | Batch: 30 | Loss: 0.12727840640261245\n",
            "Epoch: 49 | Batch: 31 | Loss: 0.12711556998536172\n",
            "Epoch: 49 | Batch: 32 | Loss: 0.16872487598603536\n",
            "Epoch: 49 | Batch: 33 | Loss: 0.13785945851460132\n",
            "Epoch: 49 | Batch: 34 | Loss: 0.14135045254773027\n",
            "Epoch: 49 | Batch: 35 | Loss: 0.12139711782846259\n",
            "Epoch: 49 | Batch: 36 | Loss: 0.13371202466249027\n",
            "Epoch: 49 | Batch: 37 | Loss: 0.10508622851944034\n",
            "Epoch: 49 | Batch: 38 | Loss: 0.12287358921378835\n",
            "Epoch: 49 | Batch: 39 | Loss: 0.09408391560143388\n",
            "Epoch: 49 | Batch: 40 | Loss: 0.10413313740397767\n",
            "Epoch: 49 | Batch: 41 | Loss: 0.1003825365007489\n",
            "Epoch: 49 | Batch: 42 | Loss: 0.11155219237851688\n",
            "Epoch: 49 | Batch: 43 | Loss: 0.12533157681889986\n",
            "Epoch: 49 | Batch: 44 | Loss: 0.12327526012061826\n",
            "Epoch: 49 | Batch: 45 | Loss: 0.10699487943101244\n",
            "Epoch: 49 | Batch: 46 | Loss: 0.10464342482612024\n",
            "Epoch: 49 | Batch: 47 | Loss: 0.14277564131116396\n",
            "Epoch: 49 | Batch: 48 | Loss: 0.10399134343909047\n",
            "Epoch: 49 | Batch: 49 | Loss: 0.09592073052599226\n",
            "Epoch: 49 | Batch: 50 | Loss: 0.12787776089722214\n",
            "Epoch: 49 | Batch: 51 | Loss: 0.13161541156632436\n",
            "Epoch: 49 | Batch: 52 | Loss: 0.14467326992146595\n",
            "Epoch: 49 | Batch: 53 | Loss: 0.1335554767384921\n",
            "Epoch: 49 | Batch: 54 | Loss: 0.11587476595551253\n",
            "Epoch: 49 | Batch: 55 | Loss: 0.11652367383135731\n",
            "Epoch: 49 | Batch: 56 | Loss: 0.11165518721695138\n",
            "Epoch: 49 | Batch: 57 | Loss: 0.08926809244724467\n",
            "Epoch: 49 | Batch: 58 | Loss: 0.1143546365861301\n",
            "Epoch: 49 | Batch: 59 | Loss: 0.06397580563739555\n",
            "Epoch: 49 | Batch: 60 | Loss: 0.08695012670488939\n",
            "Epoch: 49 | Batch: 61 | Loss: 0.09719408076822025\n",
            "Epoch: 49 | Batch: 62 | Loss: 0.10577344927530374\n",
            "Epoch: 49 | Batch: 63 | Loss: 0.11777673875025176\n",
            "Epoch: 49 | Batch: 64 | Loss: 0.14208401429876266\n",
            "Epoch: 49 | Batch: 65 | Loss: 0.08697261655011872\n",
            "Epoch: 49 | Batch: 66 | Loss: 0.09300346255386752\n",
            "Epoch: 49 | Batch: 67 | Loss: 0.16943174391610216\n",
            "Epoch: 49 | Batch: 68 | Loss: 0.11477361346846239\n",
            "Epoch: 49 | Batch: 69 | Loss: 0.11056391864140824\n",
            "Epoch: 49 | Batch: 70 | Loss: 0.1015466529186012\n",
            "Epoch: 49 | Batch: 71 | Loss: 0.08476855952705441\n",
            "Epoch: 49 | Batch: 72 | Loss: 0.11756459948240668\n",
            "Epoch: 49 | Batch: 73 | Loss: 0.1031453091525189\n",
            "Epoch: 49 | Batch: 74 | Loss: 0.12395802412526422\n",
            "Epoch: 49 | Batch: 75 | Loss: 0.10980184750020028\n",
            "Epoch: 49 | Batch: 76 | Loss: 0.10447331633256145\n",
            "Epoch: 49 | Batch: 77 | Loss: 0.12396659098639806\n",
            "Epoch: 49 | Batch: 78 | Loss: 0.10963061633069568\n",
            "Epoch: 49 | Batch: 79 | Loss: 0.10125845240040844\n",
            "Epoch: 49 | Batch: 80 | Loss: 0.08320778024227457\n",
            "Epoch: 49 | Batch: 81 | Loss: 0.10292691341510221\n",
            "Epoch: 49 | Batch: 82 | Loss: 0.13308411751729823\n",
            "Epoch: 49 | Batch: 83 | Loss: 0.09540213538177572\n",
            "Epoch: 49 | Batch: 84 | Loss: 0.10052842775204007\n",
            "Epoch: 49 | Batch: 85 | Loss: 0.08482589446545455\n",
            "Epoch: 49 | Batch: 86 | Loss: 0.08818742754031486\n",
            "Epoch: 49 | Batch: 87 | Loss: 0.10504418788917882\n",
            "Epoch: 49 | Batch: 88 | Loss: 0.07062994158926371\n",
            "Epoch: 49 | Batch: 89 | Loss: 0.07711389249129098\n",
            "Epoch: 49 | Batch: 90 | Loss: 0.114559984931279\n",
            "Epoch: 49 | Batch: 91 | Loss: 0.1179027702526654\n",
            "Epoch: 49 | Batch: 92 | Loss: 0.08498490529366484\n",
            "Epoch: 49 | Batch: 93 | Loss: 0.13633004092819753\n",
            "Epoch: 49 | Batch: 94 | Loss: 0.14299012108851028\n",
            "Epoch: 49 | Batch: 95 | Loss: 0.09487196510608875\n",
            "Epoch: 49 | Batch: 96 | Loss: 0.13402224470237317\n",
            "Epoch: 49 | Batch: 97 | Loss: 0.08696967597295784\n",
            "Epoch: 49 | Batch: 98 | Loss: 0.12520351330562923\n",
            "Epoch: 49 | Batch: 99 | Loss: 0.07608294058188203\n",
            "Epoch: 49 | Batch: 100 | Loss: 0.09616163613978736\n",
            "Epoch: 49 | Batch: 101 | Loss: 0.0935012231146892\n",
            "Epoch: 49 | Batch: 102 | Loss: 0.09805529377427794\n",
            "Epoch: 49 | Batch: 103 | Loss: 0.08834805136378138\n",
            "Epoch: 49 | Batch: 104 | Loss: 0.12056418889991774\n",
            "Epoch: 49 | Batch: 105 | Loss: 0.08660334680489316\n",
            "Epoch: 49 | Batch: 106 | Loss: 0.08350841861916856\n",
            "Epoch: 49 | Batch: 107 | Loss: 0.08898168338684898\n",
            "Epoch: 49 | Batch: 108 | Loss: 0.08301500662132766\n",
            "Epoch: 49 | Batch: 109 | Loss: 0.07125071922276371\n",
            "Epoch: 49 | Batch: 110 | Loss: 0.10197623023310476\n",
            "Epoch: 49 | Batch: 111 | Loss: 0.13544902722635646\n",
            "Epoch: 49 | Batch: 112 | Loss: 0.059177505143022245\n",
            "Epoch: 49 | Batch: 113 | Loss: 0.09411617691833646\n",
            "Epoch: 49 | Batch: 114 | Loss: 0.08472081027752836\n",
            "Epoch: 49 | Batch: 115 | Loss: 0.07698398066687069\n",
            "Epoch: 49 | Batch: 116 | Loss: 0.1029624276005584\n",
            "Epoch: 49 | Batch: 117 | Loss: 0.11422787101072515\n",
            "Epoch: 49 | Batch: 118 | Loss: 0.07671078866950357\n",
            "Epoch: 49 | Batch: 119 | Loss: 0.12453007158605038\n",
            "Epoch: 49 | Batch: 120 | Loss: 0.08132615919471553\n",
            "Epoch: 49 | Batch: 121 | Loss: 0.11071209165215373\n",
            "Epoch: 49 | Batch: 122 | Loss: 0.06334958864353157\n",
            "Epoch: 49 | Batch: 123 | Loss: 0.09161340062976883\n",
            "Epoch: 49 | Batch: 124 | Loss: 0.07713024410144288\n",
            "Epoch: 49 | Batch: 125 | Loss: 0.0794846330100859\n",
            "Epoch: 49 | Batch: 126 | Loss: 0.06221792992354136\n",
            "Epoch: 49 | Batch: 127 | Loss: 0.08291718794465543\n",
            "Epoch: 49 | Batch: 128 | Loss: 0.08083032685451766\n",
            "Epoch: 49 | Batch: 129 | Loss: 0.07554529957361245\n",
            "Epoch: 49 | Batch: 130 | Loss: 0.07961859584420561\n",
            "Epoch: 49 | Batch: 131 | Loss: 0.0736310064678312\n",
            "Epoch: 49 | Batch: 132 | Loss: 0.14604915030964843\n",
            "Epoch: 49 | Batch: 133 | Loss: 0.085223009642442\n",
            "Epoch: 49 | Batch: 134 | Loss: 0.12115808310785073\n",
            "Epoch: 49 | Batch: 135 | Loss: 0.11906601380264245\n",
            "Epoch: 49 | Batch: 136 | Loss: 0.15482671283882832\n",
            "Epoch: 49 | Batch: 137 | Loss: 0.10403599389108512\n",
            "Epoch: 49 | Batch: 138 | Loss: 0.11615900571264372\n",
            "Epoch: 49 | Batch: 139 | Loss: 0.10693159546454431\n",
            "Epoch: 49 | Batch: 140 | Loss: 0.13495057962565893\n",
            "Epoch: 49 | Batch: 141 | Loss: 0.1284603674418992\n",
            "Epoch: 49 | Batch: 142 | Loss: 0.12177441695262436\n",
            "Epoch: 49 | Batch: 143 | Loss: 0.14364264746563188\n",
            "Epoch: 49 | Batch: 144 | Loss: 0.12236858940654313\n",
            "Epoch: 49 | Batch: 145 | Loss: 0.16321052215127713\n",
            "Epoch: 49 | Batch: 146 | Loss: 0.14915504915814082\n",
            "Epoch: 49 | Batch: 147 | Loss: 0.1114914291614458\n",
            "Epoch: 49 | Batch: 148 | Loss: 0.09281316456504977\n",
            "Epoch: 49 | Batch: 149 | Loss: 0.1249182088691756\n",
            "Epoch: 49 | Batch: 150 | Loss: 0.10958257062046364\n",
            "Epoch: 49 | Batch: 151 | Loss: 0.09411030562583689\n",
            "Epoch: 49 | Batch: 152 | Loss: 0.0963634983753543\n",
            "Epoch: 49 | Batch: 153 | Loss: 0.13884191629772655\n",
            "Epoch: 49 | Batch: 154 | Loss: 0.1063895726358931\n",
            "Epoch: 49 | Batch: 155 | Loss: 0.1299539083614329\n",
            "Epoch: 49 | Batch: 156 | Loss: 0.09994442686851245\n",
            "Epoch: 49 | Batch: 157 | Loss: 0.12764925860578263\n",
            "Epoch: 49 | Batch: 158 | Loss: 0.11510108880380765\n",
            "Epoch: 49 | Batch: 159 | Loss: 0.08891445829936928\n",
            "Epoch: 49 | Batch: 160 | Loss: 0.19214831601793497\n",
            "Epoch: 49 | Batch: 161 | Loss: 0.08174422322078391\n",
            "Epoch: 49 | Batch: 162 | Loss: 0.09946645722436269\n",
            "Epoch: 49 | Batch: 163 | Loss: 0.08930714730170602\n",
            "Epoch: 49 | Batch: 164 | Loss: 0.11227191229940017\n",
            "Epoch: 49 | Batch: 165 | Loss: 0.11018572400915208\n",
            "Epoch: 49 | Batch: 166 | Loss: 0.11303360150312608\n",
            "Epoch: 49 | Batch: 167 | Loss: 0.11083599750155625\n",
            "Epoch: 49 | Batch: 168 | Loss: 0.09790375669268676\n",
            "Epoch: 49 | Batch: 169 | Loss: 0.13636679184961822\n",
            "Epoch: 49 | Batch: 170 | Loss: 0.16415869122124332\n",
            "Epoch: 49 | Batch: 171 | Loss: 0.09571206702499499\n",
            "Epoch: 49 | Batch: 172 | Loss: 0.12775713945284223\n",
            "Epoch: 49 | Batch: 173 | Loss: 0.09682076111424323\n",
            "Epoch: 49 | Batch: 174 | Loss: 0.09015913804949757\n",
            "Epoch: 49 | Batch: 175 | Loss: 0.14088655370200795\n",
            "Epoch: 49 | Batch: 176 | Loss: 0.13133238920516105\n",
            "Epoch: 49 | Batch: 177 | Loss: 0.11236618732882257\n",
            "Epoch: 49 | Batch: 178 | Loss: 0.22167202052644872\n",
            "Epoch: 49 | Batch: 179 | Loss: 0.11290056246973998\n",
            "Epoch: 49 | Batch: 180 | Loss: 0.1284251994931535\n",
            "Epoch: 49 | Batch: 181 | Loss: 0.10605047290963643\n",
            "Epoch: 49 | Batch: 182 | Loss: 0.07920775547939292\n",
            "Epoch: 49 | Batch: 183 | Loss: 0.111744029115116\n",
            "Epoch: 49 | Batch: 184 | Loss: 0.11255463443482727\n",
            "Epoch: 49 | Batch: 185 | Loss: 0.1493898819603799\n",
            "Epoch: 49 | Batch: 186 | Loss: 0.10561148478417319\n",
            "Epoch: 49 | Batch: 187 | Loss: 0.09741622017589857\n",
            "Epoch: 49 | Batch: 188 | Loss: 0.12656475061507672\n",
            "Epoch: 49 | Batch: 189 | Loss: 0.11014385160669198\n",
            "Epoch: 49 | Batch: 190 | Loss: 0.0966762679176254\n",
            "Epoch: 49 | Batch: 191 | Loss: 0.12376333357677807\n",
            "Epoch: 49 | Batch: 192 | Loss: 0.13925194666543567\n",
            "Epoch: 49 | Batch: 193 | Loss: 0.12496003362356811\n",
            "Epoch: 49 | Batch: 194 | Loss: 0.11561415033138762\n",
            "Epoch: 49 | Batch: 195 | Loss: 0.14628834364813892\n",
            "Epoch: 49 | Batch: 196 | Loss: 0.10815679679284616\n",
            "Epoch: 49 | Batch: 197 | Loss: 0.1489575829076485\n",
            "Epoch: 49 | Batch: 198 | Loss: 0.11528073665016143\n",
            "Epoch: 49 | Batch: 199 | Loss: 0.11248026979600814\n",
            "Epoch: 49 | Batch: 200 | Loss: 0.09397938893984775\n",
            "Epoch: 49 | Batch: 201 | Loss: 0.08632802093301978\n",
            "Epoch: 49 | Batch: 202 | Loss: 0.11438588855933648\n",
            "Epoch: 49 | Batch: 203 | Loss: 0.1080396496746493\n",
            "Epoch: 49 | Batch: 204 | Loss: 0.12244509544125676\n",
            "Epoch: 49 | Batch: 205 | Loss: 0.10927335424714132\n",
            "Epoch: 49 | Batch: 206 | Loss: 0.15041813937448562\n",
            "Epoch: 49 | Batch: 207 | Loss: 0.10994371305288182\n",
            "Epoch: 49 | Batch: 208 | Loss: 0.11439910601887789\n",
            "Epoch: 49 | Batch: 209 | Loss: 0.13224423207764124\n",
            "Epoch: 49 | Batch: 210 | Loss: 0.10242425127286967\n",
            "Epoch: 49 | Batch: 211 | Loss: 0.09887085953062323\n",
            "Epoch: 49 | Batch: 212 | Loss: 0.07602013662560868\n",
            "Epoch: 49 | Batch: 213 | Loss: 0.10557960004685679\n",
            "Epoch: 49 | Batch: 214 | Loss: 0.08149035694574586\n",
            "Epoch: 49 | Batch: 215 | Loss: 0.09807999150194932\n",
            "Epoch: 49 | Batch: 216 | Loss: 0.10316091837467932\n",
            "Epoch: 49 | Batch: 217 | Loss: 0.12113907352494131\n",
            "Epoch: 49 | Batch: 218 | Loss: 0.1144437608055642\n",
            "Epoch: 49 | Batch: 219 | Loss: 0.10646793805993551\n",
            "Epoch: 49 | Batch: 220 | Loss: 0.09961414529830806\n",
            "Epoch: 49 | Batch: 221 | Loss: 0.1414423165985511\n",
            "Epoch: 49 | Batch: 222 | Loss: 0.11245190031988486\n",
            "Epoch: 49 | Batch: 223 | Loss: 0.13202288746153698\n",
            "Epoch: 49 | Batch: 224 | Loss: 0.10214737396339857\n",
            "Epoch: 49 | Batch: 225 | Loss: 0.08509157687895039\n",
            "Epoch: 49 | Batch: 226 | Loss: 0.09803376314590762\n",
            "Epoch: 49 | Batch: 227 | Loss: 0.07430845468917224\n",
            "Epoch: 49 | Batch: 228 | Loss: 0.10955071771856717\n",
            "Epoch: 49 | Batch: 229 | Loss: 0.09062907790875932\n",
            "Epoch: 49 | Batch: 230 | Loss: 0.12443643580355605\n",
            "Epoch: 49 | Batch: 231 | Loss: 0.08288864663943621\n",
            "Epoch: 49 | Batch: 232 | Loss: 0.1010102904614438\n",
            "Epoch: 49 | Batch: 233 | Loss: 0.07612269584513466\n",
            "Epoch: 49 | Batch: 234 | Loss: 0.09928203215707017\n",
            "Epoch: 49 | Batch: 235 | Loss: 0.07474054356384882\n",
            "Epoch: 49 | Batch: 236 | Loss: 0.08385338014182903\n",
            "Epoch: 49 | Batch: 237 | Loss: 0.07217287023986463\n",
            "Epoch: 49 | Batch: 238 | Loss: 0.1407154031590936\n",
            "Epoch: 49 | Batch: 239 | Loss: 0.09685164131454552\n",
            "Epoch: 49 | Batch: 240 | Loss: 0.07916916135736757\n",
            "Epoch: 49 | Batch: 241 | Loss: 0.11720559166065675\n",
            "Epoch: 49 | Batch: 242 | Loss: 0.08860623747389929\n",
            "Epoch: 49 | Batch: 243 | Loss: 0.10165514785442609\n",
            "Epoch: 49 | Batch: 244 | Loss: 0.08236712043318016\n",
            "Epoch: 49 | Batch: 245 | Loss: 0.09838936409562249\n",
            "Epoch: 49 | Batch: 246 | Loss: 0.07753411063077512\n",
            "Epoch: 49 | Batch: 247 | Loss: 0.09758027025840112\n",
            "Epoch: 49 | Batch: 248 | Loss: 0.10379501663201166\n",
            "Epoch: 49 | Batch: 249 | Loss: 0.10740202302754956\n",
            "Epoch: 49 | Batch: 250 | Loss: 0.07956297817735836\n",
            "Epoch: 49 | Batch: 251 | Loss: 0.10470141320363223\n",
            "Epoch: 49 | Batch: 252 | Loss: 0.11572591435352461\n",
            "Epoch: 49 | Batch: 253 | Loss: 0.07973604812805299\n",
            "Epoch: 49 | Batch: 254 | Loss: 0.10009719231207144\n",
            "Epoch: 49 | Batch: 255 | Loss: 0.0936778055138448\n",
            "Epoch: 49 | Batch: 256 | Loss: 0.08344821912372402\n",
            "Epoch: 49 | Batch: 257 | Loss: 0.06273084279248214\n",
            "Epoch: 49 | Batch: 258 | Loss: 0.07258128895912765\n",
            "Epoch: 49 | Batch: 259 | Loss: 0.08059409082224367\n",
            "Epoch: 49 | Batch: 260 | Loss: 0.10104453532808741\n",
            "Epoch: 49 | Batch: 261 | Loss: 0.07527469208291647\n",
            "Epoch: 49 | Batch: 262 | Loss: 0.07782459044485746\n",
            "Epoch: 49 | Batch: 263 | Loss: 0.11487519908622024\n",
            "Epoch: 49 | Batch: 264 | Loss: 0.10100115029856718\n",
            "Epoch: 49 | Batch: 265 | Loss: 0.06405490334409016\n",
            "Epoch: 49 | Batch: 266 | Loss: 0.07950162595660396\n",
            "Epoch: 49 | Batch: 267 | Loss: 0.0635101737435578\n",
            "Epoch: 49 | Batch: 268 | Loss: 0.06238849412599795\n",
            "Epoch: 49 | Batch: 269 | Loss: 0.11828416098445341\n",
            "Epoch: 49 | Batch: 270 | Loss: 0.08917153157873048\n",
            "Epoch: 49 | Batch: 271 | Loss: 0.06703601992524424\n",
            "Epoch: 49 | Batch: 272 | Loss: 0.09111346167688705\n",
            "Epoch: 49 | Batch: 273 | Loss: 0.11152203469301945\n",
            "Epoch: 49 | Batch: 274 | Loss: 0.09756471970862038\n",
            "Epoch: 49 | Batch: 275 | Loss: 0.0961649699003699\n",
            "Epoch: 49 | Batch: 276 | Loss: 0.130869314780387\n",
            "Epoch: 49 | Batch: 277 | Loss: 0.07897636953217847\n",
            "Epoch: 49 | Batch: 278 | Loss: 0.11103949124647605\n",
            "Epoch: 49 | Batch: 279 | Loss: 0.15807124390211205\n",
            "Epoch: 49 | Batch: 280 | Loss: 0.10630908653917537\n",
            "Epoch: 49 | Batch: 281 | Loss: 0.10516638878152294\n",
            "Epoch: 49 | Batch: 282 | Loss: 0.16747002398336008\n",
            "Epoch: 49 | Batch: 283 | Loss: 0.17537340902425988\n",
            "Epoch: 49 | Batch: 284 | Loss: 0.12444347422020768\n",
            "Epoch: 49 | Batch: 285 | Loss: 0.16369973063983065\n",
            "Epoch: 49 | Batch: 286 | Loss: 0.11601080844080741\n",
            "Epoch: 49 | Batch: 287 | Loss: 0.12192602751740701\n",
            "Epoch: 49 | Batch: 288 | Loss: 0.13030183529658362\n",
            "Epoch: 49 | Batch: 289 | Loss: 0.09715384145986408\n",
            "Epoch: 49 | Batch: 290 | Loss: 0.08583362077286105\n",
            "Epoch: 49 | Batch: 291 | Loss: 0.1265243708536036\n",
            "Epoch: 49 | Batch: 292 | Loss: 0.100893714546365\n",
            "Epoch: 49 | Batch: 293 | Loss: 0.14037996212449222\n",
            "Epoch: 49 | Batch: 294 | Loss: 0.17267147296399715\n",
            "Epoch: 49 | Batch: 295 | Loss: 0.12339553225082088\n",
            "Epoch: 49 | Batch: 296 | Loss: 0.12468294442470665\n",
            "Epoch: 49 | Batch: 297 | Loss: 0.1408164955613193\n",
            "Epoch: 49 | Batch: 298 | Loss: 0.10481891760478063\n",
            "Epoch: 49 | Batch: 299 | Loss: 0.11149854505523896\n",
            "Epoch: 49 | Batch: 300 | Loss: 0.11045828808482877\n",
            "Epoch: 49 | Batch: 301 | Loss: 0.11277827660740061\n",
            "Epoch: 49 | Batch: 302 | Loss: 0.09464903989455545\n",
            "Epoch: 49 | Batch: 303 | Loss: 0.09744367865727296\n",
            "Epoch: 49 | Batch: 304 | Loss: 0.0794089000280377\n",
            "Epoch: 49 | Batch: 305 | Loss: 0.09371059091545846\n",
            "Epoch: 49 | Batch: 306 | Loss: 0.11080727325021644\n",
            "Epoch: 49 | Batch: 307 | Loss: 0.13161791077746582\n",
            "Epoch: 49 | Batch: 308 | Loss: 0.13016012094065668\n",
            "Epoch: 49 | Batch: 309 | Loss: 0.10860870232102751\n",
            "Epoch: 49 | Batch: 310 | Loss: 0.12516620947729157\n",
            "Epoch: 49 | Batch: 311 | Loss: 0.11761769454434418\n",
            "Epoch: 49 | Batch: 312 | Loss: 0.15570541599092402\n",
            "Epoch: 49 | Batch: 313 | Loss: 0.09741092100467469\n",
            "Epoch: 49 | Batch: 314 | Loss: 0.09899302181248165\n",
            "Epoch: 49 | Batch: 315 | Loss: 0.09119244804634746\n",
            "Epoch: 49 | Batch: 316 | Loss: 0.12207163052206135\n",
            "Epoch: 49 | Batch: 317 | Loss: 0.08214080555394093\n",
            "Epoch: 49 | Batch: 318 | Loss: 0.08376603593125609\n",
            "Epoch: 49 | Batch: 319 | Loss: 0.12126735627141036\n",
            "Epoch: 49 | Batch: 320 | Loss: 0.09960612758024744\n",
            "Epoch: 49 | Batch: 321 | Loss: 0.09580492204642987\n",
            "Epoch: 49 | Batch: 322 | Loss: 0.094995787110985\n",
            "Epoch: 49 | Batch: 323 | Loss: 0.09823853228132791\n",
            "Epoch: 49 | Batch: 324 | Loss: 0.09467716201879395\n",
            "Epoch: 49 | Batch: 325 | Loss: 0.09718493980653356\n",
            "Epoch: 49 | Batch: 326 | Loss: 0.10191166209241545\n",
            "Epoch: 49 | Batch: 327 | Loss: 0.06279478856343457\n",
            "Epoch: 49 | Batch: 328 | Loss: 0.06150038977050454\n",
            "Epoch: 49 | Batch: 329 | Loss: 0.07563371158175652\n",
            "Epoch: 49 | Batch: 330 | Loss: 0.177161435754008\n",
            "Epoch: 49 | Batch: 331 | Loss: 0.07998049642092973\n",
            "Epoch: 49 | Batch: 332 | Loss: 0.10944995567899138\n",
            "Epoch: 49 | Batch: 333 | Loss: 0.1339059698711621\n",
            "Epoch: 49 | Batch: 334 | Loss: 0.13719408363386443\n",
            "Epoch: 49 | Batch: 335 | Loss: 0.09437649156620367\n",
            "Epoch: 49 | Batch: 336 | Loss: 0.09609473720673205\n",
            "Epoch: 49 | Batch: 337 | Loss: 0.1449752640620667\n",
            "Epoch: 49 | Batch: 338 | Loss: 0.08008372606937827\n",
            "Epoch: 49 | Batch: 339 | Loss: 0.07673559495418605\n",
            "Epoch: 49 | Batch: 340 | Loss: 0.07184379793170259\n",
            "Epoch: 49 | Batch: 341 | Loss: 0.09255810359752803\n",
            "Epoch: 49 | Batch: 342 | Loss: 0.09861475140555061\n",
            "Epoch: 49 | Batch: 343 | Loss: 0.09770130980329723\n",
            "Epoch: 49 | Batch: 344 | Loss: 0.16398004830628113\n",
            "Epoch: 49 | Batch: 345 | Loss: 0.1036895018189602\n",
            "Epoch: 49 | Batch: 346 | Loss: 0.1131513017858122\n",
            "Epoch: 49 | Batch: 347 | Loss: 0.08017027622053467\n",
            "Epoch: 49 | Batch: 348 | Loss: 0.08922166333885587\n",
            "Epoch: 49 | Batch: 349 | Loss: 0.1073451117823617\n",
            "Epoch: 49 | Batch: 350 | Loss: 0.09234516867103773\n",
            "Epoch: 49 | Batch: 351 | Loss: 0.08146912610189933\n",
            "Epoch: 49 | Batch: 352 | Loss: 0.06785595289499396\n",
            "Epoch: 49 | Batch: 353 | Loss: 0.10843528681417487\n",
            "Epoch: 49 | Batch: 354 | Loss: 0.08900916025450019\n",
            "Epoch: 49 | Batch: 355 | Loss: 0.12541619930204762\n",
            "Epoch: 49 | Batch: 356 | Loss: 0.08527220902209501\n",
            "Epoch: 49 | Batch: 357 | Loss: 0.10722988930912129\n",
            "Epoch: 49 | Batch: 358 | Loss: 0.10762436428433553\n",
            "Epoch: 49 | Batch: 359 | Loss: 0.08683865679098611\n",
            "Epoch: 49 | Batch: 360 | Loss: 0.08536644531050422\n",
            "Epoch: 49 | Batch: 361 | Loss: 0.09995592011982553\n",
            "Epoch: 49 | Batch: 362 | Loss: 0.14644955371552082\n",
            "Epoch: 49 | Batch: 363 | Loss: 0.08391679715637487\n",
            "Epoch: 49 | Batch: 364 | Loss: 0.16256139069868897\n",
            "Epoch: 49 | Batch: 365 | Loss: 0.10883686849436493\n",
            "Epoch: 49 | Batch: 366 | Loss: 0.09669398678647803\n",
            "Epoch: 49 | Batch: 367 | Loss: 0.08583475854038972\n",
            "Epoch: 49 | Batch: 368 | Loss: 0.11072561367436898\n",
            "Epoch: 49 | Batch: 369 | Loss: 0.1539149060606495\n",
            "Epoch: 49 | Batch: 370 | Loss: 0.09210144751471913\n",
            "Epoch: 49 | Batch: 371 | Loss: 0.08018908845280771\n",
            "Epoch: 49 | Batch: 372 | Loss: 0.1821946099375917\n",
            "Epoch: 49 | Batch: 373 | Loss: 0.09619491827224727\n",
            "Epoch: 49 | Batch: 374 | Loss: 0.11899759602809017\n",
            "Epoch: 49 | Batch: 375 | Loss: 0.14288851587976806\n",
            "Epoch: 49 | Batch: 376 | Loss: 0.0828237681120331\n",
            "Epoch: 49 | Batch: 377 | Loss: 0.10176018505383977\n",
            "Epoch: 49 | Batch: 378 | Loss: 0.17459140681922145\n",
            "Epoch: 49 | Batch: 379 | Loss: 0.0801121068997221\n",
            "Epoch: 49 | Batch: 380 | Loss: 0.10014106266387895\n",
            "Epoch: 49 | Batch: 381 | Loss: 0.10443222033464925\n",
            "Epoch: 49 | Batch: 382 | Loss: 0.10892764628372958\n",
            "Epoch: 49 | Batch: 383 | Loss: 0.08323276728002219\n",
            "Epoch: 49 | Batch: 384 | Loss: 0.1326097696445605\n",
            "Epoch: 49 | Batch: 385 | Loss: 0.100174458120727\n",
            "Epoch: 49 | Batch: 386 | Loss: 0.09667837454554382\n",
            "Epoch: 49 | Batch: 387 | Loss: 0.13063521889047905\n",
            "Epoch: 49 | Batch: 388 | Loss: 0.10435589258464689\n",
            "Epoch: 49 | Batch: 389 | Loss: 0.1156495708225069\n",
            "Epoch: 49 | Batch: 390 | Loss: 0.09384408466381601\n",
            "Epoch: 49 | Batch: 391 | Loss: 0.08042584764520441\n",
            "Epoch: 49 | Batch: 392 | Loss: 0.07494940233721258\n",
            "Epoch: 49 | Batch: 393 | Loss: 0.08033653031002083\n",
            "Epoch: 49 | Batch: 394 | Loss: 0.09439752996187374\n",
            "Epoch: 49 | Batch: 395 | Loss: 0.09693950133278748\n",
            "Epoch: 49 | Batch: 396 | Loss: 0.06913733881647104\n",
            "Epoch: 49 | Batch: 397 | Loss: 0.08720488625078912\n",
            "Epoch: 49 | Batch: 398 | Loss: 0.0667396052378443\n",
            "Epoch: 49 | Batch: 399 | Loss: 0.07919986663779574\n",
            "Epoch: 49 | Batch: 400 | Loss: 0.0724191823537901\n",
            "Epoch: 49 | Batch: 401 | Loss: 0.0858755757095928\n",
            "Epoch: 49 | Batch: 402 | Loss: 0.0886671606348513\n",
            "Epoch: 49 | Batch: 403 | Loss: 0.1633923589695713\n",
            "Epoch: 49 | Batch: 404 | Loss: 0.07185121885417213\n",
            "Epoch: 49 | Batch: 405 | Loss: 0.11494930732883646\n",
            "Epoch: 49 | Batch: 406 | Loss: 0.14044105151797792\n",
            "Epoch: 49 | Batch: 407 | Loss: 0.11061649724428034\n",
            "Epoch: 49 | Batch: 408 | Loss: 0.10232527800778818\n",
            "Epoch: 49 | Batch: 409 | Loss: 0.09818362470115805\n",
            "Epoch: 49 | Batch: 410 | Loss: 0.09277712668936328\n",
            "Epoch: 49 | Batch: 411 | Loss: 0.09635936455345678\n",
            "Epoch: 49 | Batch: 412 | Loss: 0.10492535469261505\n",
            "Epoch: 49 | Batch: 413 | Loss: 0.08811556684591385\n",
            "Epoch: 49 | Batch: 414 | Loss: 0.09327423296115153\n",
            "Epoch: 49 | Batch: 415 | Loss: 0.10946573738743001\n",
            "Epoch: 49 | Batch: 416 | Loss: 0.13093252245096645\n",
            "Epoch: 49 | Batch: 417 | Loss: 0.10188756446384736\n",
            "Epoch: 49 | Batch: 418 | Loss: 0.17895107311807978\n",
            "Epoch: 49 | Batch: 419 | Loss: 0.12265107410528844\n",
            "Epoch: 49 | Batch: 420 | Loss: 0.19500584072457386\n",
            "Epoch: 49 | Batch: 421 | Loss: 0.1782193277649486\n",
            "Epoch: 49 | Batch: 422 | Loss: 0.1411728469803109\n",
            "Epoch: 49 | Batch: 423 | Loss: 0.1537210589618742\n",
            "Epoch: 49 | Batch: 424 | Loss: 0.1454576553548999\n",
            "Epoch: 49 | Batch: 425 | Loss: 0.11477712686139471\n",
            "Epoch: 49 | Batch: 426 | Loss: 0.14705281096849043\n",
            "Epoch: 49 | Batch: 427 | Loss: 0.13290038244477342\n",
            "Epoch: 49 | Batch: 428 | Loss: 0.11992791650747557\n",
            "Epoch: 49 | Batch: 429 | Loss: 0.16248219701618463\n",
            "Epoch: 49 | Batch: 430 | Loss: 0.15266190646739647\n",
            "Epoch: 49 | Batch: 431 | Loss: 0.15007767060319496\n",
            "Epoch: 49 | Batch: 432 | Loss: 0.18066639623632796\n",
            "Epoch: 49 | Batch: 433 | Loss: 0.17708807180035133\n",
            "Epoch: 49 | Batch: 434 | Loss: 0.16861401884291782\n",
            "Epoch: 49 | Batch: 435 | Loss: 0.19183732112419244\n",
            "Epoch: 49 | Batch: 436 | Loss: 0.15483586796807913\n",
            "Epoch: 49 | Batch: 437 | Loss: 0.1532655748414323\n",
            "Epoch: 49 | Batch: 438 | Loss: 0.12217259609242227\n",
            "Epoch: 49 | Batch: 439 | Loss: 0.1353671736138166\n",
            "Epoch: 49 | Batch: 440 | Loss: 0.16298673419488224\n",
            "Epoch: 49 | Batch: 441 | Loss: 0.17472525588539378\n",
            "Epoch: 49 | Batch: 442 | Loss: 0.13944537973008056\n",
            "Epoch: 49 | Batch: 443 | Loss: 0.14435570436800343\n",
            "Epoch: 49 | Batch: 444 | Loss: 0.16784414029008043\n",
            "Epoch: 49 | Batch: 445 | Loss: 0.15432490291461043\n",
            "Epoch: 49 | Batch: 446 | Loss: 0.1927199294132449\n",
            "Epoch: 49 | Batch: 447 | Loss: 0.1921809784289798\n",
            "Epoch: 49 | Batch: 448 | Loss: 0.1427242678025916\n",
            "Epoch: 49 | Batch: 449 | Loss: 0.24393255835345312\n",
            "Epoch: 49 | Batch: 450 | Loss: 0.1537181583894046\n",
            "Epoch: 49 | Batch: 451 | Loss: 0.1698976847946676\n",
            "Epoch: 49 | Batch: 452 | Loss: 0.16534807638673063\n",
            "Epoch: 49 | Batch: 453 | Loss: 0.1612610413626567\n",
            "Epoch: 49 | Batch: 454 | Loss: 0.11588338119698972\n",
            "Epoch: 49 | Batch: 455 | Loss: 0.13993987369182015\n",
            "Epoch: 49 | Batch: 456 | Loss: 0.1622962992378283\n",
            "Epoch: 49 | Batch: 457 | Loss: 0.13500439677503834\n",
            "Epoch: 49 | Batch: 458 | Loss: 0.14680149978210513\n",
            "Epoch: 49 | Batch: 459 | Loss: 0.15112559346795812\n",
            "Epoch: 49 | Batch: 460 | Loss: 0.16119635497394463\n",
            "Epoch: 49 | Batch: 461 | Loss: 0.1778771183784295\n",
            "Epoch: 49 | Batch: 462 | Loss: 0.16303885335689455\n",
            "Epoch: 49 | Batch: 463 | Loss: 0.1529205902353888\n",
            "Epoch: 49 | Batch: 464 | Loss: 0.1766543759835193\n",
            "Epoch: 49 | Batch: 465 | Loss: 0.17163401119401805\n",
            "Epoch: 49 | Batch: 466 | Loss: 0.15150962995194311\n",
            "Epoch: 49 | Batch: 467 | Loss: 0.12042835708594046\n",
            "Epoch: 49 | Batch: 468 | Loss: 0.16573531009203843\n",
            "Epoch: 49 | Batch: 469 | Loss: 0.12198511155513495\n",
            "Epoch: 49 | Batch: 470 | Loss: 0.15461304662547432\n",
            "Epoch: 49 | Batch: 471 | Loss: 0.1532578809227933\n",
            "Epoch: 49 | Batch: 472 | Loss: 0.1413373432135155\n",
            "Epoch: 49 | Batch: 473 | Loss: 0.11759389451255121\n",
            "Epoch: 49 | Batch: 474 | Loss: 0.13585344632597665\n",
            "Epoch: 49 | Batch: 475 | Loss: 0.13584119843350995\n",
            "Epoch: 49 | Batch: 476 | Loss: 0.12202643769711807\n",
            "Epoch: 49 | Batch: 477 | Loss: 0.1171773126241763\n",
            "Epoch: 49 | Batch: 478 | Loss: 0.12234178270431555\n",
            "Epoch: 49 | Batch: 479 | Loss: 0.09170333192699548\n",
            "Epoch: 49 | Batch: 480 | Loss: 0.12037370662356106\n",
            "Epoch: 49 | Batch: 481 | Loss: 0.10862749187965941\n",
            "Epoch: 49 | Batch: 482 | Loss: 0.10239297646341705\n",
            "Epoch: 49 | Batch: 483 | Loss: 0.15035010045794744\n",
            "Epoch: 49 | Batch: 484 | Loss: 0.13168197953390562\n",
            "Epoch: 49 | Batch: 485 | Loss: 0.12767095826666408\n",
            "Epoch: 49 | Batch: 486 | Loss: 0.17214252765947907\n",
            "Epoch: 49 | Batch: 487 | Loss: 0.1657645505532211\n",
            "Epoch: 49 | Batch: 488 | Loss: 0.11716549305461572\n",
            "Epoch: 49 | Batch: 489 | Loss: 0.11645243427194249\n",
            "Epoch: 49 | Batch: 490 | Loss: 0.14832326548632996\n",
            "Epoch: 49 | Batch: 491 | Loss: 0.10662983225592783\n",
            "Epoch: 49 | Batch: 492 | Loss: 0.10725341241963635\n",
            "Epoch: 49 | Batch: 493 | Loss: 0.09190807308324567\n",
            "Epoch: 49 | Batch: 494 | Loss: 0.09162757705524524\n",
            "Epoch: 49 | Batch: 495 | Loss: 0.16095702243298746\n",
            "Epoch: 49 | Batch: 496 | Loss: 0.14331591326588455\n",
            "Epoch: 49 | Batch: 497 | Loss: 0.12679180460004014\n",
            "Epoch: 49 | Batch: 498 | Loss: 0.12377266014132708\n",
            "Epoch: 49 | Batch: 499 | Loss: 0.15153848956980745\n",
            "Epoch: 49 | Batch: 500 | Loss: 0.1360854449022475\n",
            "Epoch: 49 | Batch: 501 | Loss: 0.1260166460914609\n",
            "Epoch: 49 | Batch: 502 | Loss: 0.15101087354438456\n",
            "Epoch: 49 | Batch: 503 | Loss: 0.14044861044497836\n",
            "Epoch: 49 | Batch: 504 | Loss: 0.12470533609031079\n",
            "Epoch: 49 | Batch: 505 | Loss: 0.22142323776379313\n",
            "Epoch: 49 | Batch: 506 | Loss: 0.12300597729214982\n",
            "Epoch: 49 | Batch: 507 | Loss: 0.1478632894479676\n",
            "Epoch: 49 | Batch: 508 | Loss: 0.1628990512011827\n",
            "Epoch: 49 | Batch: 509 | Loss: 0.08080919742408371\n",
            "Epoch: 49 | Batch: 510 | Loss: 0.11856031889863501\n",
            "Epoch: 49 | Batch: 511 | Loss: 0.14584320490985037\n",
            "Epoch: 49 | Batch: 512 | Loss: 0.12373226495122555\n",
            "Epoch: 49 | Batch: 513 | Loss: 0.1384759431782035\n",
            "Epoch: 49 | Batch: 514 | Loss: 0.1562102274196474\n",
            "Epoch: 49 | Batch: 515 | Loss: 0.08533485369081842\n",
            "Epoch: 49 | Batch: 516 | Loss: 0.09699060318096236\n",
            "Epoch: 49 | Batch: 517 | Loss: 0.14186179438575297\n",
            "Epoch: 49 | Batch: 518 | Loss: 0.12478597008410844\n",
            "Epoch: 49 | Batch: 519 | Loss: 0.10885661422493441\n",
            "Epoch: 49 | Batch: 520 | Loss: 0.14740028576480865\n",
            "Epoch: 49 | Batch: 521 | Loss: 0.11776128288997256\n",
            "Epoch: 49 | Batch: 522 | Loss: 0.10986672672354862\n",
            "Epoch: 49 | Batch: 523 | Loss: 0.17555143903034215\n",
            "Epoch: 49 | Batch: 524 | Loss: 0.08559120036085693\n",
            "Epoch: 49 | Batch: 525 | Loss: 0.09441274146514483\n",
            "Epoch: 49 | Batch: 526 | Loss: 0.1261079375706299\n",
            "Epoch: 49 | Batch: 527 | Loss: 0.10367973094615321\n",
            "Epoch: 49 | Batch: 528 | Loss: 0.08073490076310408\n",
            "Epoch: 49 | Batch: 529 | Loss: 0.11931283334406473\n",
            "Epoch: 49 | Batch: 530 | Loss: 0.11760537433593517\n",
            "Epoch: 49 | Batch: 531 | Loss: 0.09203107676406526\n",
            "Epoch: 49 | Batch: 532 | Loss: 0.13681943789871676\n",
            "Epoch: 49 | Batch: 533 | Loss: 0.1280405228165516\n",
            "Epoch: 49 | Batch: 534 | Loss: 0.08806351540121585\n",
            "Epoch: 49 | Batch: 535 | Loss: 0.15238670166733673\n",
            "Epoch: 49 | Batch: 536 | Loss: 0.1785692801075575\n",
            "Epoch: 49 | Batch: 537 | Loss: 0.08346563934288828\n",
            "Epoch: 49 | Batch: 538 | Loss: 0.1472724598285567\n",
            "Epoch: 49 | Batch: 539 | Loss: 0.1498167359608443\n",
            "Epoch: 49 | Batch: 540 | Loss: 0.10761267867347263\n",
            "Epoch: 49 | Batch: 541 | Loss: 0.1575566078674428\n",
            "Epoch: 49 | Batch: 542 | Loss: 0.13306502875185322\n",
            "Epoch: 49 | Batch: 543 | Loss: 0.10316018939685992\n",
            "Epoch: 49 | Batch: 544 | Loss: 0.13378663753602701\n",
            "Epoch: 49 | Batch: 545 | Loss: 0.11266572221507642\n",
            "Epoch: 49 | Batch: 546 | Loss: 0.13277176349639966\n",
            "Epoch: 49 | Batch: 547 | Loss: 0.14331793295148423\n",
            "Epoch: 49 | Batch: 548 | Loss: 0.12298821407599878\n",
            "Epoch: 49 | Batch: 549 | Loss: 0.11312497013203493\n",
            "Epoch: 49 | Batch: 550 | Loss: 0.1338871415839294\n",
            "Epoch: 49 | Batch: 551 | Loss: 0.13188187520832415\n",
            "Epoch: 49 | Batch: 552 | Loss: 0.12998176702798545\n",
            "Epoch: 49 | Batch: 553 | Loss: 0.11022692169998398\n",
            "Epoch: 49 | Batch: 554 | Loss: 0.13968058020718283\n",
            "Epoch: 49 | Batch: 555 | Loss: 0.11858772504884346\n",
            "Epoch: 49 | Batch: 556 | Loss: 0.15121507969792702\n",
            "Epoch: 49 | Batch: 557 | Loss: 0.11250667519497826\n",
            "Epoch: 49 | Batch: 558 | Loss: 0.11946641928105234\n",
            "Epoch: 49 | Batch: 559 | Loss: 0.13045378156172172\n",
            "Epoch: 49 | Batch: 560 | Loss: 0.11170629151737296\n",
            "Epoch: 49 | Batch: 561 | Loss: 0.10614717337079599\n",
            "Epoch: 49 | Batch: 562 | Loss: 0.16519083332716783\n",
            "Epoch: 49 | Batch: 563 | Loss: 0.1007013612269625\n",
            "Epoch: 49 | Batch: 564 | Loss: 0.10122968536422627\n",
            "Epoch: 49 | Batch: 565 | Loss: 0.11141854244277263\n",
            "Epoch: 49 | Batch: 566 | Loss: 0.10016654537071543\n",
            "Epoch: 49 | Batch: 567 | Loss: 0.11179746103248027\n",
            "Epoch: 49 | Batch: 568 | Loss: 0.20280311491313877\n",
            "Epoch: 49 | Batch: 569 | Loss: 0.1315564278591857\n",
            "Epoch: 49 | Batch: 570 | Loss: 0.1516961109070231\n",
            "Epoch: 49 | Batch: 571 | Loss: 0.1765421050357908\n",
            "Epoch: 49 | Batch: 572 | Loss: 0.14260971732462918\n",
            "Epoch: 49 | Batch: 573 | Loss: 0.14561544703773394\n",
            "Epoch: 49 | Batch: 574 | Loss: 0.13543150144249427\n",
            "Epoch: 49 | Batch: 575 | Loss: 0.09952453699507496\n",
            "Epoch: 49 | Batch: 576 | Loss: 0.11725788028491255\n",
            "Epoch: 49 | Batch: 577 | Loss: 0.11915422526594002\n",
            "Epoch: 49 | Batch: 578 | Loss: 0.12975003948762118\n",
            "Epoch: 49 | Batch: 579 | Loss: 0.13313079864965877\n",
            "Epoch: 49 | Batch: 580 | Loss: 0.16792621350393683\n",
            "Epoch: 49 | Batch: 581 | Loss: 0.16204034444340176\n",
            "Epoch: 49 | Batch: 582 | Loss: 0.18696690135126132\n",
            "Epoch: 49 | Batch: 583 | Loss: 0.14345277312638083\n",
            "Epoch: 49 | Batch: 584 | Loss: 0.1351078582900195\n",
            "Epoch: 49 | Batch: 585 | Loss: 0.12257884207679627\n",
            "Epoch: 49 | Batch: 586 | Loss: 0.1097155455472015\n",
            "Epoch: 49 | Batch: 587 | Loss: 0.12674207046675448\n",
            "Epoch: 49 | Batch: 588 | Loss: 0.12991085239610856\n",
            "Epoch: 49 | Batch: 589 | Loss: 0.10323020046321267\n",
            "Epoch: 49 | Batch: 590 | Loss: 0.1091633582148124\n",
            "Epoch: 49 | Batch: 591 | Loss: 0.09391813740830776\n",
            "Epoch: 49 | Batch: 592 | Loss: 0.154407522248607\n",
            "Epoch: 49 | Batch: 593 | Loss: 0.10238726017007962\n",
            "Epoch: 49 | Batch: 594 | Loss: 0.11540137377489096\n",
            "Epoch: 49 | Batch: 595 | Loss: 0.14271941639992497\n",
            "Epoch: 49 | Batch: 596 | Loss: 0.10499861788860038\n",
            "Epoch: 49 | Batch: 597 | Loss: 0.10522102244523841\n",
            "Epoch: 49 | Batch: 598 | Loss: 0.1143951997546023\n",
            "Epoch: 49 | Batch: 599 | Loss: 0.09113944136860022\n",
            "Epoch: 49 | Batch: 600 | Loss: 0.07892365826862961\n",
            "Epoch: 49 | Batch: 601 | Loss: 0.12055709233011808\n",
            "Epoch: 49 | Batch: 602 | Loss: 0.09953182294080654\n",
            "Epoch: 49 | Batch: 603 | Loss: 0.09608319143721931\n",
            "Epoch: 49 | Batch: 604 | Loss: 0.10097186416087583\n",
            "Epoch: 49 | Batch: 605 | Loss: 0.10395415508345837\n",
            "Epoch: 49 | Batch: 606 | Loss: 0.08875333623356554\n",
            "Epoch: 49 | Batch: 607 | Loss: 0.12314947291849142\n",
            "Epoch: 49 | Batch: 608 | Loss: 0.09667295955469238\n",
            "Epoch: 49 | Batch: 609 | Loss: 0.09896599503903958\n",
            "Epoch: 49 | Batch: 610 | Loss: 0.0832891476951675\n",
            "Epoch: 49 | Batch: 611 | Loss: 0.14470150980344346\n",
            "Epoch: 49 | Batch: 612 | Loss: 0.08625287915533623\n",
            "Epoch: 49 | Batch: 613 | Loss: 0.07269554887914334\n",
            "Epoch: 49 | Batch: 614 | Loss: 0.12897318108759065\n",
            "Epoch: 49 | Batch: 615 | Loss: 0.11531678398815573\n",
            "Epoch: 49 | Batch: 616 | Loss: 0.08235204925371217\n",
            "Epoch: 49 | Batch: 617 | Loss: 0.10041145381058025\n",
            "Epoch: 49 | Batch: 618 | Loss: 0.11959370230023145\n",
            "Epoch: 49 | Batch: 619 | Loss: 0.1018330455587095\n",
            "Epoch: 49 | Batch: 620 | Loss: 0.09928856501808017\n",
            "Epoch: 49 | Batch: 621 | Loss: 0.09806129621313871\n",
            "Epoch: 49 | Batch: 622 | Loss: 0.10236136107183559\n",
            "Epoch: 49 | Batch: 623 | Loss: 0.05987414270712294\n",
            "Epoch: 49 | Batch: 624 | Loss: 0.0668022370001928\n",
            "Epoch: 49 | Batch: 625 | Loss: 0.09175197675010094\n",
            "Epoch: 49 | Batch: 626 | Loss: 0.07386826500358681\n",
            "Epoch: 49 | Batch: 627 | Loss: 0.09399101435444869\n",
            "Epoch: 49 | Batch: 628 | Loss: 0.1101525809106568\n",
            "Epoch: 49 | Batch: 629 | Loss: 0.0816487507160159\n",
            "Epoch: 49 | Batch: 630 | Loss: 0.08005856412732212\n",
            "Epoch: 49 | Batch: 631 | Loss: 0.08229589666496817\n",
            "Epoch: 49 | Batch: 632 | Loss: 0.08323164715663262\n",
            "Epoch: 49 | Batch: 633 | Loss: 0.06299283170317041\n",
            "Epoch: 49 | Batch: 634 | Loss: 0.06397374790776143\n",
            "Epoch: 49 | Batch: 635 | Loss: 0.12423891489952474\n",
            "Epoch: 49 | Batch: 636 | Loss: 0.08360363955049738\n",
            "Epoch: 49 | Batch: 637 | Loss: 0.12465221107495786\n",
            "Epoch: 49 | Batch: 638 | Loss: 0.10986825418703167\n",
            "Epoch: 49 | Batch: 639 | Loss: 0.10952801275528032\n",
            "Epoch: 49 | Batch: 640 | Loss: 0.09835425902197462\n",
            "Epoch: 49 | Batch: 641 | Loss: 0.10802056171661317\n",
            "Epoch: 49 | Batch: 642 | Loss: 0.10654591271008934\n",
            "Epoch: 49 | Batch: 643 | Loss: 0.13737777578027585\n",
            "Epoch: 49 | Batch: 644 | Loss: 0.08650265797879514\n",
            "Epoch: 49 | Batch: 645 | Loss: 0.13518303105271254\n",
            "Epoch: 49 | Batch: 646 | Loss: 0.09490493666826974\n",
            "Epoch: 49 | Batch: 647 | Loss: 0.09841354898950491\n",
            "Epoch: 49 | Batch: 648 | Loss: 0.09256964401391153\n",
            "Epoch: 49 | Batch: 649 | Loss: 0.09473038955098793\n",
            "Epoch: 49 | Batch: 650 | Loss: 0.09956122205669685\n",
            "Epoch: 49 | Batch: 651 | Loss: 0.08141571368488021\n",
            "Epoch: 49 | Batch: 652 | Loss: 0.11260694496650947\n",
            "Epoch: 49 | Batch: 653 | Loss: 0.08249275997071914\n",
            "Epoch: 49 | Batch: 654 | Loss: 0.08059185494098914\n",
            "Epoch: 49 | Batch: 655 | Loss: 0.12264741771369851\n",
            "Epoch: 49 | Batch: 656 | Loss: 0.08789386395048679\n",
            "Epoch: 49 | Batch: 657 | Loss: 0.10158426549766324\n",
            "Epoch: 49 | Batch: 658 | Loss: 0.08974042539164873\n",
            "Epoch: 49 | Batch: 659 | Loss: 0.11681241100803022\n",
            "Epoch: 49 | Batch: 660 | Loss: 0.10987643211979572\n",
            "Epoch: 49 | Batch: 661 | Loss: 0.12671108714144688\n",
            "Epoch: 49 | Batch: 662 | Loss: 0.10413418545029487\n",
            "Epoch: 49 | Batch: 663 | Loss: 0.114356523482497\n",
            "Epoch: 49 | Batch: 664 | Loss: 0.08723673173561547\n",
            "Epoch: 49 | Batch: 665 | Loss: 0.08879661263796826\n",
            "Epoch: 49 | Batch: 666 | Loss: 0.10511891493706804\n",
            "Epoch: 49 | Batch: 667 | Loss: 0.09747712618479257\n",
            "Epoch: 49 | Batch: 668 | Loss: 0.09388261695965619\n",
            "Epoch: 49 | Batch: 669 | Loss: 0.09752224486077576\n",
            "Epoch: 49 | Batch: 670 | Loss: 0.09483128415058717\n",
            "Epoch: 49 | Batch: 671 | Loss: 0.12436971303994432\n",
            "Epoch: 49 | Batch: 672 | Loss: 0.1003577872799347\n",
            "Epoch: 49 | Batch: 673 | Loss: 0.12382662032574203\n",
            "Epoch: 49 | Batch: 674 | Loss: 0.15490511164012993\n",
            "Epoch: 49 | Batch: 675 | Loss: 0.11374592827700167\n",
            "Epoch: 49 | Batch: 676 | Loss: 0.11831897613538622\n",
            "Epoch: 49 | Batch: 677 | Loss: 0.12742549181243773\n",
            "Epoch: 49 | Batch: 678 | Loss: 0.10346281923100631\n",
            "Epoch: 49 | Batch: 679 | Loss: 0.17583300739685337\n",
            "Epoch: 49 | Batch: 680 | Loss: 0.06510130233825184\n",
            "Epoch: 49 | Batch: 681 | Loss: 0.11389215472665253\n",
            "Epoch: 49 | Batch: 682 | Loss: 0.10060535684122748\n",
            "Epoch: 49 | Batch: 683 | Loss: 0.08444443418925454\n",
            "Epoch: 49 | Batch: 684 | Loss: 0.1372778189127177\n",
            "Epoch: 49 | Batch: 685 | Loss: 0.08497473589346283\n",
            "Epoch: 49 | Batch: 686 | Loss: 0.07982579356193542\n",
            "Epoch: 49 | Batch: 687 | Loss: 0.10451846499897062\n",
            "Epoch: 49 | Batch: 688 | Loss: 0.13630311728759176\n",
            "Epoch: 49 | Batch: 689 | Loss: 0.11631482485006389\n",
            "Epoch: 49 | Batch: 690 | Loss: 0.10819344344678362\n",
            "Epoch: 49 | Batch: 691 | Loss: 0.10890801386981361\n",
            "Epoch: 49 | Batch: 692 | Loss: 0.08076156417085881\n",
            "Epoch: 49 | Batch: 693 | Loss: 0.10006888012410466\n",
            "Epoch: 49 | Batch: 694 | Loss: 0.10640365746520576\n",
            "Epoch: 49 | Batch: 695 | Loss: 0.10125225245063196\n",
            "Epoch: 49 | Batch: 696 | Loss: 0.16121263656294624\n",
            "Epoch: 49 | Batch: 697 | Loss: 0.2180388457346833\n",
            "Epoch: 49 | Batch: 698 | Loss: 0.10532618667796619\n",
            "Epoch: 49 | Batch: 699 | Loss: 0.13191394987878585\n",
            "Epoch: 49 | Batch: 700 | Loss: 0.163974809560505\n",
            "Epoch: 49 | Batch: 701 | Loss: 0.1061850007987473\n",
            "Epoch: 49 | Batch: 702 | Loss: 0.07426804291577527\n",
            "Epoch: 49 | Batch: 703 | Loss: 0.1382999687757687\n",
            "Epoch: 49 | Batch: 704 | Loss: 0.08228478043130395\n",
            "Epoch: 49 | Batch: 705 | Loss: 0.10852897542122755\n",
            "Epoch: 49 | Batch: 706 | Loss: 0.10328942471873029\n",
            "Epoch: 49 | Batch: 707 | Loss: 0.10376347592351307\n",
            "Epoch: 49 | Batch: 708 | Loss: 0.11629119452306497\n",
            "Epoch: 49 | Batch: 709 | Loss: 0.08962220379085557\n",
            "Epoch: 49 | Batch: 710 | Loss: 0.14895140648460575\n",
            "Epoch: 49 | Batch: 711 | Loss: 0.10670180991158337\n",
            "Epoch: 49 | Batch: 712 | Loss: 0.08260395645184639\n",
            "Epoch: 49 | Batch: 713 | Loss: 0.1134478995009989\n",
            "Epoch: 49 | Batch: 714 | Loss: 0.06729633402335282\n",
            "Epoch: 49 | Batch: 715 | Loss: 0.09325735856582534\n",
            "Epoch: 49 | Batch: 716 | Loss: 0.09087360845394693\n",
            "Epoch: 49 | Batch: 717 | Loss: 0.0823972655230343\n",
            "Epoch: 49 | Batch: 718 | Loss: 0.14750175710265523\n",
            "Epoch: 49 | Batch: 719 | Loss: 0.08376949175883361\n",
            "Epoch: 49 | Batch: 720 | Loss: 0.10061894203160728\n",
            "Epoch: 49 | Batch: 721 | Loss: 0.07780902600208994\n",
            "Epoch: 49 | Batch: 722 | Loss: 0.07994277457118118\n",
            "Epoch: 49 | Batch: 723 | Loss: 0.10766001938965908\n",
            "Epoch: 49 | Batch: 724 | Loss: 0.08493383318483172\n",
            "Epoch: 49 | Batch: 725 | Loss: 0.08064644942140266\n",
            "Epoch: 49 | Batch: 726 | Loss: 0.09183401238316596\n",
            "Epoch: 49 | Batch: 727 | Loss: 0.08221946645720563\n",
            "Epoch: 49 | Batch: 728 | Loss: 0.08406207091482235\n",
            "Epoch: 49 | Batch: 729 | Loss: 0.08115999682863875\n",
            "Epoch: 49 | Batch: 730 | Loss: 0.08081418580802555\n",
            "Epoch: 49 | Batch: 731 | Loss: 0.09805796878485437\n",
            "Epoch: 49 | Batch: 732 | Loss: 0.10654822571208461\n",
            "Epoch: 49 | Batch: 733 | Loss: 0.08764493951103783\n",
            "Epoch: 49 | Batch: 734 | Loss: 0.08065927226481175\n",
            "Epoch: 49 | Batch: 735 | Loss: 0.06882443249599635\n",
            "Epoch: 49 | Batch: 736 | Loss: 0.07813072621767655\n",
            "Epoch: 49 | Batch: 737 | Loss: 0.08669687922189767\n",
            "Epoch: 49 | Batch: 738 | Loss: 0.08387649499443778\n",
            "Epoch: 49 | Batch: 739 | Loss: 0.10401159663039325\n",
            "Epoch: 49 | Batch: 740 | Loss: 0.09748408536153526\n",
            "Epoch: 49 | Batch: 741 | Loss: 0.1011785271778588\n",
            "Epoch: 49 | Batch: 742 | Loss: 0.09050175286940354\n",
            "Epoch: 49 | Batch: 743 | Loss: 0.10839620321282864\n",
            "Epoch: 49 | Batch: 744 | Loss: 0.09026736986446716\n",
            "Epoch: 49 | Batch: 745 | Loss: 0.11171890010105988\n",
            "Epoch: 49 | Batch: 746 | Loss: 0.12930901272528078\n",
            "Epoch: 49 | Batch: 747 | Loss: 0.14286021963698015\n",
            "Epoch: 49 | Batch: 748 | Loss: 0.11913029655878518\n",
            "Epoch: 49 | Batch: 749 | Loss: 0.0991222884940047\n",
            "Epoch: 49 | Batch: 750 | Loss: 0.17853429771516893\n",
            "Epoch: 49 | Batch: 751 | Loss: 0.0983077964234685\n",
            "Epoch: 49 | Batch: 752 | Loss: 0.09192130074130742\n",
            "Epoch: 49 | Batch: 753 | Loss: 0.11994304015141158\n",
            "Epoch: 49 | Batch: 754 | Loss: 0.11594310989989462\n",
            "Epoch: 49 | Batch: 755 | Loss: 0.12091377867877978\n",
            "Epoch: 49 | Batch: 756 | Loss: 0.09012618929213023\n",
            "Epoch: 49 | Batch: 757 | Loss: 0.17842339319914077\n",
            "Epoch: 49 | Batch: 758 | Loss: 0.09007454279884292\n",
            "Epoch: 49 | Batch: 759 | Loss: 0.10138928593848104\n",
            "Epoch: 49 | Batch: 760 | Loss: 0.19998116185610337\n",
            "Epoch: 49 | Batch: 761 | Loss: 0.08341876815691207\n",
            "Epoch: 49 | Batch: 762 | Loss: 0.1061147342742214\n",
            "Epoch: 49 | Batch: 763 | Loss: 0.14314207375824967\n",
            "Epoch: 49 | Batch: 764 | Loss: 0.215586164181971\n",
            "Epoch: 49 | Batch: 765 | Loss: 0.08355171673615075\n",
            "Epoch: 49 | Batch: 766 | Loss: 0.09522007268583231\n",
            "Epoch: 49 | Batch: 767 | Loss: 0.1010397807439957\n",
            "Epoch: 49 | Batch: 768 | Loss: 0.10769678483608275\n",
            "Epoch: 49 | Batch: 769 | Loss: 0.12009660621697868\n",
            "Epoch: 49 | Batch: 770 | Loss: 0.14574609458077353\n",
            "Epoch: 49 | Batch: 771 | Loss: 0.09574537630292221\n",
            "Epoch: 49 | Batch: 772 | Loss: 0.14737963691144396\n",
            "Epoch: 49 | Batch: 773 | Loss: 0.1320863968722422\n",
            "Epoch: 49 | Batch: 774 | Loss: 0.11720104202676532\n",
            "Epoch: 49 | Batch: 775 | Loss: 0.12501164244393825\n",
            "Epoch: 49 | Batch: 776 | Loss: 0.11959886074829712\n",
            "Epoch: 49 | Batch: 777 | Loss: 0.1634771372731806\n",
            "Epoch: 49 | Batch: 778 | Loss: 0.09871906913409692\n",
            "Epoch: 49 | Batch: 779 | Loss: 0.11900148295155155\n",
            "Epoch: 49 | Batch: 780 | Loss: 0.1478511625988732\n",
            "Epoch: 49 | Batch: 781 | Loss: 0.11110579531805659\n",
            "Epoch: 49 | Batch: 782 | Loss: 0.14371358187372876\n",
            "Epoch: 49 | Batch: 783 | Loss: 0.13231819940758782\n",
            "Epoch: 49 | Batch: 784 | Loss: 0.11093485767646093\n",
            "Epoch: 49 | Batch: 785 | Loss: 0.11581236105539178\n",
            "Epoch: 49 | Batch: 786 | Loss: 0.14705724540344928\n",
            "Epoch: 49 | Batch: 787 | Loss: 0.1467677358530688\n",
            "Epoch: 49 | Batch: 788 | Loss: 0.10683532503826026\n",
            "Epoch: 49 | Batch: 789 | Loss: 0.11486943266222618\n",
            "Epoch: 49 | Batch: 790 | Loss: 0.11440223506640224\n",
            "Epoch: 49 | Batch: 791 | Loss: 0.15611122785604703\n",
            "Epoch: 49 | Batch: 792 | Loss: 0.13071296414244077\n",
            "Epoch: 49 | Batch: 793 | Loss: 0.11918066773612696\n",
            "Epoch: 49 | Batch: 794 | Loss: 0.12109820690304887\n",
            "Epoch: 49 | Batch: 795 | Loss: 0.1138744803012535\n",
            "Epoch: 49 | Batch: 796 | Loss: 0.09532447662581842\n",
            "Epoch: 49 | Batch: 797 | Loss: 0.12911173500271086\n",
            "Epoch: 49 | Batch: 798 | Loss: 0.10066407415432962\n",
            "Epoch: 49 | Batch: 799 | Loss: 0.09042662750227667\n",
            "Epoch: 49 | Batch: 800 | Loss: 0.08988205001538889\n",
            "Epoch: 49 | Batch: 801 | Loss: 0.10579923060805325\n",
            "Epoch: 49 | Batch: 802 | Loss: 0.09373495897485937\n",
            "Epoch: 49 | Batch: 803 | Loss: 0.13200683446155653\n",
            "Epoch: 49 | Batch: 804 | Loss: 0.090963146428649\n",
            "Epoch: 49 | Batch: 805 | Loss: 0.10643981720948356\n",
            "Epoch: 49 | Batch: 806 | Loss: 0.10580020846907609\n",
            "Epoch: 49 | Batch: 807 | Loss: 0.07722824462852683\n",
            "Epoch: 49 | Batch: 808 | Loss: 0.09944602356486287\n",
            "Epoch: 49 | Batch: 809 | Loss: 0.08785263214624256\n",
            "Epoch: 49 | Batch: 810 | Loss: 0.0893493055836409\n",
            "Epoch: 49 | Batch: 811 | Loss: 0.08783482503149084\n",
            "Epoch: 49 | Batch: 812 | Loss: 0.09906601134250398\n",
            "Epoch: 49 | Batch: 813 | Loss: 0.10334403254107292\n",
            "Epoch: 49 | Batch: 814 | Loss: 0.10507673649710896\n",
            "Epoch: 49 | Batch: 815 | Loss: 0.08375854332821114\n",
            "Epoch: 49 | Batch: 816 | Loss: 0.10050051372746549\n",
            "Epoch: 49 | Batch: 817 | Loss: 0.10836637532736337\n",
            "Epoch: 49 | Batch: 818 | Loss: 0.07424756677922881\n",
            "Epoch: 49 | Batch: 819 | Loss: 0.0604271204745541\n",
            "Epoch: 49 | Batch: 820 | Loss: 0.08194146483145308\n",
            "Epoch: 49 | Batch: 821 | Loss: 0.10082576762006745\n",
            "Epoch: 49 | Batch: 822 | Loss: 0.06475857899224305\n",
            "Epoch: 49 | Batch: 823 | Loss: 0.09752336961896808\n",
            "Epoch: 49 | Batch: 824 | Loss: 0.10168157212764506\n",
            "Epoch: 49 | Batch: 825 | Loss: 0.09199142706039101\n",
            "Epoch: 49 | Batch: 826 | Loss: 0.08644235877276946\n",
            "Epoch: 49 | Batch: 827 | Loss: 0.0886809661839863\n",
            "Epoch: 49 | Batch: 828 | Loss: 0.09467189276520097\n",
            "Epoch: 49 | Batch: 829 | Loss: 0.08365932370023094\n",
            "Epoch: 49 | Batch: 830 | Loss: 0.08026337001799988\n",
            "Epoch: 49 | Batch: 831 | Loss: 0.08400557996074044\n",
            "Epoch: 49 | Batch: 832 | Loss: 0.0672293666193381\n",
            "Epoch: 49 | Batch: 833 | Loss: 0.10047007875505203\n",
            "Epoch: 49 | Batch: 834 | Loss: 0.07529219183322125\n",
            "Epoch: 49 | Batch: 835 | Loss: 0.13158713334968994\n",
            "Epoch: 49 | Batch: 836 | Loss: 0.08540044097081158\n",
            "Epoch: 49 | Batch: 837 | Loss: 0.10928980742082643\n",
            "Epoch: 49 | Batch: 838 | Loss: 0.17213762534254545\n",
            "Epoch: 49 | Batch: 839 | Loss: 0.15558235030840226\n",
            "Epoch: 49 | Batch: 840 | Loss: 0.15132100437425167\n",
            "Epoch: 49 | Batch: 841 | Loss: 0.11284346967237754\n",
            "Epoch: 49 | Batch: 842 | Loss: 0.18500223543689748\n",
            "Epoch: 49 | Batch: 843 | Loss: 0.1791974086545619\n",
            "Epoch: 49 | Batch: 844 | Loss: 0.1161350788373548\n",
            "Epoch: 49 | Batch: 845 | Loss: 0.23176964344108814\n",
            "Epoch: 49 | Batch: 846 | Loss: 0.16896151113434982\n",
            "Epoch: 49 | Batch: 847 | Loss: 0.11935376009195278\n",
            "Epoch: 49 | Batch: 848 | Loss: 0.18936042894571392\n",
            "Epoch: 49 | Batch: 849 | Loss: 0.17363578586334996\n",
            "Epoch: 49 | Batch: 850 | Loss: 0.12122601494615398\n",
            "Epoch: 49 | Batch: 851 | Loss: 0.2453436877840535\n",
            "Epoch: 49 | Batch: 852 | Loss: 0.15846656148420163\n",
            "Epoch: 49 | Batch: 853 | Loss: 0.11803533755702238\n",
            "Epoch: 49 | Batch: 854 | Loss: 0.23418766433146485\n",
            "Epoch: 49 | Batch: 855 | Loss: 0.1687706299349538\n",
            "Epoch: 49 | Batch: 856 | Loss: 0.17715088339160578\n",
            "Epoch: 49 | Batch: 857 | Loss: 0.14737828630386213\n",
            "Epoch: 49 | Batch: 858 | Loss: 0.11791960971267225\n",
            "Epoch: 49 | Batch: 859 | Loss: 0.16152071906711993\n",
            "Epoch: 49 | Batch: 860 | Loss: 0.11559370714317088\n",
            "Epoch: 49 | Batch: 861 | Loss: 0.12118302842301215\n",
            "Epoch: 49 | Batch: 862 | Loss: 0.12850154252492946\n",
            "Epoch: 49 | Batch: 863 | Loss: 0.1235968967985045\n",
            "Epoch: 49 | Batch: 864 | Loss: 0.14370237449089063\n",
            "Epoch: 49 | Batch: 865 | Loss: 0.3259996508938837\n",
            "Epoch: 49 | Batch: 866 | Loss: 0.5683951009524066\n",
            "Epoch: 49 | Batch: 867 | Loss: 0.31022473142973883\n",
            "Epoch: 49 | Batch: 868 | Loss: 0.20339700356179746\n",
            "Epoch: 49 | Batch: 869 | Loss: 0.42505568212343886\n",
            "Epoch: 49 | Batch: 870 | Loss: 0.7985675303970936\n",
            "Epoch: 49 | Batch: 871 | Loss: 1.5894010804138838\n",
            "Epoch: 49 | Batch: 872 | Loss: 0.49364341182439575\n",
            "Epoch: 49 | Batch: 873 | Loss: 0.8026518122723363\n",
            "Epoch: 49 | Batch: 874 | Loss: 0.5811216276125577\n",
            "Epoch: 49 | Batch: 875 | Loss: 0.378990181530042\n",
            "Epoch: 49 | Batch: 876 | Loss: 1.1066252161356036\n",
            "Epoch: 49 | Batch: 877 | Loss: 0.33305317483436536\n",
            "Epoch: 49 | Batch: 878 | Loss: 0.40696100865760243\n",
            "Epoch: 49 | Batch: 879 | Loss: 0.2962626549993719\n",
            "Epoch: 49 | Batch: 880 | Loss: 0.4367854362108171\n",
            "Epoch: 49 | Batch: 881 | Loss: 0.49717318897349383\n",
            "Epoch: 49 | Batch: 882 | Loss: 0.26323159957074693\n",
            "Epoch: 49 | Batch: 883 | Loss: 0.35866796422470815\n",
            "Epoch: 49 | Batch: 884 | Loss: 0.39148252381869075\n",
            "Epoch: 49 | Batch: 885 | Loss: 0.32384182698878305\n",
            "Epoch: 49 | Batch: 886 | Loss: 0.3087279331199016\n",
            "Epoch: 49 | Batch: 887 | Loss: 0.3989643017425933\n",
            "Epoch: 49 | Batch: 888 | Loss: 0.3214187582472481\n",
            "Epoch: 49 | Batch: 889 | Loss: 0.3312013108442289\n",
            "Epoch: 49 | Batch: 890 | Loss: 0.2865077638151158\n",
            "Epoch: 49 | Batch: 891 | Loss: 0.2788795713562426\n",
            "Epoch: 49 | Batch: 892 | Loss: 0.30339460960786857\n",
            "Epoch: 49 | Batch: 893 | Loss: 0.24793554863510836\n",
            "Epoch: 49 | Batch: 894 | Loss: 0.28130133727240625\n",
            "Epoch: 49 | Batch: 895 | Loss: 0.22590026727265544\n",
            "Epoch: 49 | Batch: 896 | Loss: 0.25463501861689464\n",
            "Epoch: 49 | Batch: 897 | Loss: 0.28912508525956004\n",
            "Epoch: 49 | Batch: 898 | Loss: 0.3002759969512977\n",
            "Epoch: 49 | Batch: 899 | Loss: 0.26457729688968545\n",
            "Epoch: 49 | Batch: 900 | Loss: 0.2732173885215138\n",
            "Epoch: 49 | Batch: 901 | Loss: 0.272368120866949\n",
            "Epoch: 49 | Batch: 902 | Loss: 0.241875831974389\n",
            "Epoch: 49 | Batch: 903 | Loss: 0.2619431409461627\n",
            "Epoch: 49 | Batch: 904 | Loss: 0.22178343190859606\n",
            "Epoch: 49 | Batch: 905 | Loss: 0.18013795725761778\n",
            "Epoch: 49 | Batch: 906 | Loss: 0.23095957876988793\n",
            "Epoch: 49 | Batch: 907 | Loss: 0.19548177967037644\n",
            "Epoch: 49 | Batch: 908 | Loss: 0.221642522028355\n",
            "Epoch: 49 | Batch: 909 | Loss: 0.1929798121024297\n",
            "Epoch: 49 | Batch: 910 | Loss: 0.21459707080041499\n",
            "Epoch: 49 | Batch: 911 | Loss: 0.18769382139211538\n",
            "Epoch: 49 | Batch: 912 | Loss: 0.19829514471442694\n",
            "Epoch: 49 | Batch: 913 | Loss: 0.1864070428904282\n",
            "Epoch: 49 | Batch: 914 | Loss: 0.18072350326017397\n",
            "Epoch: 49 | Batch: 915 | Loss: 0.19139068439614754\n",
            "Epoch: 49 | Batch: 916 | Loss: 0.20294510649777703\n",
            "Epoch: 49 | Batch: 917 | Loss: 0.1799735427604046\n",
            "Epoch: 49 | Batch: 918 | Loss: 0.17827740328505426\n",
            "Epoch: 49 | Batch: 919 | Loss: 0.16768393598551493\n",
            "Epoch: 49 | Batch: 920 | Loss: 0.17699345282589252\n",
            "Epoch: 49 | Batch: 921 | Loss: 0.1265390917134772\n",
            "Epoch: 49 | Batch: 922 | Loss: 0.13999351120378956\n",
            "Epoch: 49 | Batch: 923 | Loss: 0.16290714709840262\n",
            "Epoch: 49 | Batch: 924 | Loss: 0.16631447769419586\n",
            "Epoch: 49 | Batch: 925 | Loss: 0.14508139085148822\n",
            "Epoch: 49 | Batch: 926 | Loss: 0.1417216926758859\n",
            "Epoch: 49 | Batch: 927 | Loss: 0.16102455568050422\n",
            "Epoch: 49 | Batch: 928 | Loss: 0.15306975548037532\n",
            "Epoch: 49 | Batch: 929 | Loss: 0.165210050138264\n",
            "Epoch: 49 | Batch: 930 | Loss: 0.20971737888174696\n",
            "Epoch: 49 | Batch: 931 | Loss: 0.1418645938692083\n",
            "Epoch: 49 | Batch: 932 | Loss: 0.14537103566038706\n",
            "Epoch: 49 | Batch: 933 | Loss: 0.15054435276239037\n",
            "Epoch: 49 | Batch: 934 | Loss: 0.14216582549866097\n",
            "Epoch: 49 | Batch: 935 | Loss: 0.12992749095626904\n",
            "Epoch: 49 | Batch: 936 | Loss: 0.10751962298692302\n",
            "Epoch: 49 | Batch: 937 | Loss: 0.12111417334144785\n",
            "Epoch: 49 | Batch: 938 | Loss: 0.12619628911394448\n",
            "Epoch: 49 | Batch: 939 | Loss: 0.13558149637849334\n",
            "Epoch: 49 | Batch: 940 | Loss: 0.11167711443146822\n",
            "Epoch: 49 | Batch: 941 | Loss: 0.20774548656921987\n",
            "Epoch: 49 | Batch: 942 | Loss: 0.14648853808587453\n",
            "Epoch: 49 | Batch: 943 | Loss: 0.13416468813837693\n",
            "Epoch: 49 | Batch: 944 | Loss: 0.14068204578765134\n",
            "Epoch: 49 | Batch: 945 | Loss: 0.1301376397716042\n",
            "Epoch: 49 | Batch: 946 | Loss: 0.14380789592201926\n",
            "Epoch: 49 | Batch: 947 | Loss: 0.1009971659968352\n",
            "Epoch: 49 | Batch: 948 | Loss: 0.1602843717925847\n",
            "Epoch: 49 | Batch: 949 | Loss: 0.10348856632592045\n",
            "Epoch: 49 | Batch: 950 | Loss: 0.12141503872136497\n",
            "Epoch: 49 | Batch: 951 | Loss: 0.09816588609902671\n",
            "Epoch: 49 | Batch: 952 | Loss: 0.08798209734626398\n",
            "Epoch: 49 | Batch: 953 | Loss: 0.10247989060139567\n",
            "Epoch: 49 | Batch: 954 | Loss: 0.09130540853904956\n",
            "Epoch: 49 | Batch: 955 | Loss: 0.11504550831432339\n",
            "Epoch: 49 | Batch: 956 | Loss: 0.082729207144633\n",
            "Epoch: 49 | Batch: 957 | Loss: 0.1207218960493513\n",
            "Epoch: 49 | Batch: 958 | Loss: 0.09516559960431761\n",
            "Epoch: 49 | Batch: 959 | Loss: 0.09295977040294709\n",
            "Epoch: 49 | Batch: 960 | Loss: 0.10919095573716547\n",
            "Epoch: 49 | Batch: 961 | Loss: 0.0998508208355604\n",
            "Epoch: 49 | Batch: 962 | Loss: 0.08267991779491045\n",
            "Epoch: 49 | Batch: 963 | Loss: 0.07162307313258132\n",
            "Epoch: 49 | Batch: 964 | Loss: 0.09699280654709883\n",
            "Epoch: 49 | Batch: 965 | Loss: 0.09773511235643828\n",
            "Epoch: 49 | Batch: 966 | Loss: 0.12286555914925212\n",
            "Epoch: 49 | Batch: 967 | Loss: 0.07920892212786262\n",
            "Epoch: 49 | Batch: 968 | Loss: 0.07602097889135878\n",
            "Epoch: 49 | Batch: 969 | Loss: 0.08045681619648823\n",
            "Epoch: 49 | Batch: 970 | Loss: 0.06284972235452262\n",
            "Epoch: 49 | Batch: 971 | Loss: 0.08007080946155813\n",
            "Epoch: 49 | Batch: 972 | Loss: 0.12477429757925773\n",
            "Epoch: 49 | Batch: 973 | Loss: 0.08357879710538751\n",
            "Epoch: 49 | Batch: 974 | Loss: 0.08372124984530335\n",
            "Epoch: 49 | Batch: 975 | Loss: 0.07866959237211801\n",
            "Epoch: 49 | Batch: 976 | Loss: 0.07839154806711046\n",
            "Epoch: 49 | Batch: 977 | Loss: 0.08654110987143997\n",
            "Epoch: 49 | Batch: 978 | Loss: 0.08428419196915128\n",
            "Epoch: 49 | Batch: 979 | Loss: 0.058440069811061826\n",
            "Epoch: 49 | Batch: 980 | Loss: 0.09876496807061601\n",
            "Epoch: 49 | Batch: 981 | Loss: 0.10278687941134478\n",
            "Epoch: 49 | Batch: 982 | Loss: 0.1160332638352332\n",
            "Epoch: 49 | Batch: 983 | Loss: 0.1014049934621293\n",
            "Epoch: 49 | Batch: 984 | Loss: 0.09806900313388957\n",
            "Epoch: 49 | Batch: 985 | Loss: 0.09908446840118491\n",
            "Epoch: 49 | Batch: 986 | Loss: 0.09418323758945538\n",
            "Epoch: 49 | Batch: 987 | Loss: 0.08362995764712032\n",
            "Epoch: 49 | Batch: 988 | Loss: 0.09189303254894693\n",
            "Epoch: 49 | Batch: 989 | Loss: 0.1140086866100244\n",
            "Epoch: 49 | Batch: 990 | Loss: 0.07962116400577246\n",
            "Epoch: 49 | Batch: 991 | Loss: 0.08269782176748955\n",
            "Epoch: 49 | Batch: 992 | Loss: 0.06317090039418496\n",
            "Epoch: 49 | Batch: 993 | Loss: 0.07845945354442532\n",
            "Epoch: 49 | Batch: 994 | Loss: 0.05965442596116838\n",
            "Epoch: 49 | Batch: 995 | Loss: 0.0524211565878027\n",
            "Epoch: 49 | Batch: 996 | Loss: 0.07279469565494998\n",
            "Epoch: 49 | Batch: 997 | Loss: 0.09662209196796266\n",
            "Epoch: 49 | Batch: 998 | Loss: 0.07448089514934629\n",
            "Epoch: 49 | Batch: 999 | Loss: 0.05491104210942767\n",
            "Epoch: 49 | Batch: 1000 | Loss: 0.06393124058347484\n",
            "Epoch: 49 | Batch: 1001 | Loss: 0.07866104474408489\n",
            "Epoch: 49 | Batch: 1002 | Loss: 0.06246651006572619\n",
            "Epoch: 49 | Batch: 1003 | Loss: 0.05775368705511413\n",
            "Epoch: 49 | Batch: 1004 | Loss: 0.06309154664354677\n",
            "Epoch: 49 | Batch: 1005 | Loss: 0.07331277662872579\n",
            "Epoch: 49 | Batch: 1006 | Loss: 0.07098322261603546\n",
            "Epoch: 49 | Batch: 1007 | Loss: 0.04906852537888202\n",
            "Epoch: 49 | Batch: 1008 | Loss: 0.08677504463172316\n",
            "Epoch: 49 | Batch: 1009 | Loss: 0.0588155949253802\n",
            "Epoch: 49 | Batch: 1010 | Loss: 0.10657429364391985\n",
            "Epoch: 49 | Batch: 1011 | Loss: 0.06932445470949196\n",
            "Epoch: 49 | Batch: 1012 | Loss: 0.04826257517590787\n",
            "Epoch: 49 | Batch: 1013 | Loss: 0.09624339086201178\n",
            "Epoch: 49 | Batch: 1014 | Loss: 0.09506454866878544\n",
            "Epoch: 49 | Batch: 1015 | Loss: 0.10601868131196004\n",
            "Epoch: 49 | Batch: 1016 | Loss: 0.08153090938348953\n",
            "Epoch: 49 | Batch: 1017 | Loss: 0.12247326406706868\n",
            "Epoch: 49 | Batch: 1018 | Loss: 0.07488937161723608\n",
            "Epoch: 49 | Batch: 1019 | Loss: 0.06443719903917614\n",
            "Epoch: 49 | Batch: 1020 | Loss: 0.06555349491608597\n",
            "Epoch: 49 | Batch: 1021 | Loss: 0.08333107863018183\n",
            "Epoch: 49 | Batch: 1022 | Loss: 0.0596269270749673\n",
            "Epoch: 49 | Batch: 1023 | Loss: 0.06478070056913199\n",
            "Epoch: 49 | Batch: 1024 | Loss: 0.06308744402900479\n",
            "Epoch: 49 | Batch: 1025 | Loss: 0.09742215420931222\n",
            "Epoch: 49 | Batch: 1026 | Loss: 0.08240393297452822\n",
            "Epoch: 49 | Batch: 1027 | Loss: 0.08485543577511351\n",
            "Epoch: 49 | Batch: 1028 | Loss: 0.09318294671715907\n",
            "Epoch: 49 | Batch: 1029 | Loss: 0.07877421008953403\n",
            "Epoch: 49 | Batch: 1030 | Loss: 0.09950756711217901\n",
            "Epoch: 49 | Batch: 1031 | Loss: 0.12262856104885267\n",
            "Epoch: 49 | Batch: 1032 | Loss: 0.10965148827625215\n",
            "Epoch: 49 | Batch: 1033 | Loss: 0.08022444272142827\n",
            "Epoch: 49 | Batch: 1034 | Loss: 0.154977698546817\n",
            "Epoch: 49 | Batch: 1035 | Loss: 0.08898866547216916\n",
            "Epoch: 49 | Batch: 1036 | Loss: 0.10359279148837086\n",
            "Epoch: 49 | Batch: 1037 | Loss: 0.08355901176582511\n",
            "Epoch: 49 | Batch: 1038 | Loss: 0.09502565244390054\n",
            "Epoch: 49 | Batch: 1039 | Loss: 0.07538762057077725\n",
            "Epoch: 49 | Batch: 1040 | Loss: 0.06819567218217246\n",
            "Epoch: 49 | Batch: 1041 | Loss: 0.1071906918015828\n",
            "Epoch: 49 | Batch: 1042 | Loss: 0.07759676841678129\n",
            "Epoch: 49 | Batch: 1043 | Loss: 0.07197119682232928\n",
            "Epoch: 49 | Batch: 1044 | Loss: 0.09447349339717817\n",
            "Epoch: 49 | Batch: 1045 | Loss: 0.0836074737957121\n",
            "Epoch: 49 | Batch: 1046 | Loss: 0.07041325195294343\n",
            "Epoch: 49 | Batch: 1047 | Loss: 0.10095074527820298\n",
            "Epoch: 49 | Batch: 1048 | Loss: 0.10191625983369351\n",
            "Epoch: 49 | Batch: 1049 | Loss: 0.06746944068586942\n",
            "Epoch: 49 | Batch: 1050 | Loss: 0.07902812274295357\n",
            "Epoch: 49 | Batch: 1051 | Loss: 0.0991183911552533\n",
            "Epoch: 49 | Batch: 1052 | Loss: 0.10675490835934134\n",
            "Epoch: 49 | Batch: 1053 | Loss: 0.11888298181077632\n",
            "Epoch: 49 | Batch: 1054 | Loss: 0.12866016621743842\n",
            "Epoch: 49 | Batch: 1055 | Loss: 0.1343455589918113\n",
            "Epoch: 49 | Batch: 1056 | Loss: 0.09322272246045436\n",
            "Epoch: 49 | Batch: 1057 | Loss: 0.11455596960745913\n",
            "Epoch: 49 | Batch: 1058 | Loss: 0.1122839739657241\n",
            "Epoch: 49 | Batch: 1059 | Loss: 0.08586603112072103\n",
            "Epoch: 49 | Batch: 1060 | Loss: 0.1670995093732251\n",
            "Epoch: 49 | Batch: 1061 | Loss: 0.0841009617626139\n",
            "Epoch: 49 | Batch: 1062 | Loss: 0.08304589563933346\n",
            "Epoch: 49 | Batch: 1063 | Loss: 0.08667456945781307\n",
            "Epoch: 49 | Batch: 1064 | Loss: 0.07517805294089229\n",
            "Epoch: 49 | Batch: 1065 | Loss: 0.07563945601310024\n",
            "Epoch: 49 | Batch: 1066 | Loss: 0.08969989108443159\n",
            "Epoch: 49 | Batch: 1067 | Loss: 0.08227601068982232\n",
            "Epoch: 49 | Batch: 1068 | Loss: 0.08648776912055794\n",
            "Epoch: 49 | Batch: 1069 | Loss: 0.08764179067661282\n",
            "Epoch: 49 | Batch: 1070 | Loss: 0.07782855555599943\n",
            "Epoch: 49 | Batch: 1071 | Loss: 0.10038957491013206\n",
            "Epoch: 49 | Batch: 1072 | Loss: 0.08772376499496681\n",
            "Epoch: 49 | Batch: 1073 | Loss: 0.08435092130126971\n",
            "Epoch: 49 | Batch: 1074 | Loss: 0.0783870861757345\n",
            "Epoch: 49 | Batch: 1075 | Loss: 0.07351988004041682\n",
            "Epoch: 49 | Batch: 1076 | Loss: 0.07952943484084649\n",
            "Epoch: 49 | Batch: 1077 | Loss: 0.06474948096471247\n",
            "Epoch: 49 | Batch: 1078 | Loss: 0.07388478572880092\n",
            "Epoch: 49 | Batch: 1079 | Loss: 0.06953884382972483\n",
            "Epoch: 49 | Batch: 1080 | Loss: 0.09186968007823335\n",
            "Epoch: 49 | Batch: 1081 | Loss: 0.07727618807653677\n",
            "Epoch: 49 | Batch: 1082 | Loss: 0.0804900739320351\n",
            "Epoch: 49 | Batch: 1083 | Loss: 0.07872788877673545\n",
            "Epoch: 49 | Batch: 1084 | Loss: 0.08841007836763794\n",
            "Epoch: 49 | Batch: 1085 | Loss: 0.06843568049148005\n",
            "Epoch: 49 | Batch: 1086 | Loss: 0.14767851546727567\n",
            "Epoch: 49 | Batch: 1087 | Loss: 0.0874962696204013\n",
            "Epoch: 49 | Batch: 1088 | Loss: 0.08675120357081884\n",
            "Epoch: 49 | Batch: 1089 | Loss: 0.15735096791910927\n",
            "Epoch: 49 | Batch: 1090 | Loss: 0.07766804210311018\n",
            "Epoch: 49 | Batch: 1091 | Loss: 0.10794000290763678\n",
            "Epoch: 49 | Batch: 1092 | Loss: 0.08102833953162525\n",
            "Epoch: 49 | Batch: 1093 | Loss: 0.08456538051269463\n",
            "Epoch: 49 | Batch: 1094 | Loss: 0.09639913785148785\n",
            "Epoch: 49 | Batch: 1095 | Loss: 0.0999922826614423\n",
            "Epoch: 49 | Batch: 1096 | Loss: 0.09603435366084712\n",
            "Epoch: 49 | Batch: 1097 | Loss: 0.09836058377219013\n",
            "Epoch: 49 | Batch: 1098 | Loss: 0.12307828092671579\n",
            "Epoch: 49 | Batch: 1099 | Loss: 0.10627192703152956\n",
            "Epoch: 49 | Batch: 1100 | Loss: 0.07121043502742083\n",
            "Epoch: 49 | Batch: 1101 | Loss: 0.11069250546956713\n",
            "Epoch: 49 | Batch: 1102 | Loss: 0.08538295885968471\n",
            "Epoch: 49 | Batch: 1103 | Loss: 0.08537278124063782\n",
            "Epoch: 49 | Batch: 1104 | Loss: 0.07301823993839701\n",
            "Epoch: 49 | Batch: 1105 | Loss: 0.08328661575130797\n",
            "Epoch: 49 | Batch: 1106 | Loss: 0.081696342541147\n",
            "Epoch: 49 | Batch: 1107 | Loss: 0.07851500018532802\n",
            "Epoch: 49 | Batch: 1108 | Loss: 0.0924986519538217\n",
            "Epoch: 49 | Batch: 1109 | Loss: 0.07495274220713531\n",
            "Epoch: 49 | Batch: 1110 | Loss: 0.09708970389997379\n",
            "Epoch: 49 | Batch: 1111 | Loss: 0.11509953250412985\n",
            "Epoch: 49 | Batch: 1112 | Loss: 0.09250956542239229\n",
            "Epoch: 49 | Batch: 1113 | Loss: 0.10013833324058372\n",
            "Epoch: 49 | Batch: 1114 | Loss: 0.07717984923175478\n",
            "Epoch: 49 | Batch: 1115 | Loss: 0.08806278398536554\n",
            "Epoch: 49 | Batch: 1116 | Loss: 0.07404071885473494\n",
            "Epoch: 49 | Batch: 1117 | Loss: 0.08112508453934913\n",
            "Epoch: 49 | Batch: 1118 | Loss: 0.08402050821633111\n",
            "Epoch: 49 | Batch: 1119 | Loss: 0.06085421587722313\n",
            "Epoch: 49 | Batch: 1120 | Loss: 0.08229802362212045\n",
            "Epoch: 49 | Batch: 1121 | Loss: 0.1523682914472196\n",
            "Epoch: 49 | Batch: 1122 | Loss: 0.06551578420724692\n",
            "Epoch: 49 | Batch: 1123 | Loss: 0.10928456698531216\n",
            "Epoch: 49 | Batch: 1124 | Loss: 0.10915038133534756\n",
            "Epoch: 49 | Batch: 1125 | Loss: 0.10411384230563023\n",
            "Epoch: 49 | Batch: 1126 | Loss: 0.10847568256308082\n",
            "Epoch: 49 | Batch: 1127 | Loss: 0.1298695962382366\n",
            "Epoch: 49 | Batch: 1128 | Loss: 0.1251729393658479\n",
            "Epoch: 49 | Batch: 1129 | Loss: 0.06835341626317246\n",
            "Epoch: 49 | Batch: 1130 | Loss: 0.099600200292134\n",
            "Epoch: 49 | Batch: 1131 | Loss: 0.1398408500546297\n",
            "Epoch: 49 | Batch: 1132 | Loss: 0.11763844592553353\n",
            "Epoch: 49 | Batch: 1133 | Loss: 0.11866816096865368\n",
            "Epoch: 49 | Batch: 1134 | Loss: 0.09845189615495613\n",
            "Epoch: 49 | Batch: 1135 | Loss: 0.06678635336826863\n",
            "Epoch: 49 | Batch: 1136 | Loss: 0.12380331495875763\n",
            "Epoch: 49 | Batch: 1137 | Loss: 0.11658422222456316\n",
            "Epoch: 49 | Batch: 1138 | Loss: 0.1210241862776252\n",
            "Epoch: 49 | Batch: 1139 | Loss: 0.1174567371413559\n",
            "Epoch: 49 | Batch: 1140 | Loss: 0.1020582237641222\n",
            "Epoch: 49 | Batch: 1141 | Loss: 0.14570355699537518\n",
            "Epoch: 49 | Batch: 1142 | Loss: 0.09736620830225783\n",
            "Epoch: 49 | Batch: 1143 | Loss: 0.11309339641035673\n",
            "Epoch: 49 | Batch: 1144 | Loss: 0.18342313830471293\n",
            "Epoch: 49 | Batch: 1145 | Loss: 0.08402521422412557\n",
            "Epoch: 49 | Batch: 1146 | Loss: 0.1086904837089778\n",
            "Epoch: 49 | Batch: 1147 | Loss: 0.16176904401734107\n",
            "Epoch: 49 | Batch: 1148 | Loss: 0.08330213466081636\n",
            "Epoch: 49 | Batch: 1149 | Loss: 0.09311371567948279\n",
            "Epoch: 49 | Batch: 1150 | Loss: 0.15211451983201146\n",
            "Epoch: 49 | Batch: 1151 | Loss: 0.1850862112936329\n",
            "Epoch: 49 | Batch: 1152 | Loss: 0.09975546312556494\n",
            "Epoch: 49 | Batch: 1153 | Loss: 0.16191426712516965\n",
            "Epoch: 49 | Batch: 1154 | Loss: 0.13910087934286547\n",
            "Epoch: 49 | Batch: 1155 | Loss: 0.16205917181954305\n",
            "Epoch: 49 | Batch: 1156 | Loss: 0.15804193060370975\n",
            "Epoch: 49 | Batch: 1157 | Loss: 0.16652336791577987\n",
            "Epoch: 49 | Batch: 1158 | Loss: 0.086480637049349\n",
            "Epoch: 49 | Batch: 1159 | Loss: 0.08991274814438655\n",
            "Epoch: 49 | Batch: 1160 | Loss: 0.13421262390032068\n",
            "Epoch: 49 | Batch: 1161 | Loss: 0.07397477979731557\n",
            "Epoch: 49 | Batch: 1162 | Loss: 0.11110499653460199\n",
            "Epoch: 49 | Batch: 1163 | Loss: 0.1049217995426795\n",
            "Epoch: 49 | Batch: 1164 | Loss: 0.13777588823939113\n",
            "Epoch: 49 | Batch: 1165 | Loss: 0.09696287060548886\n",
            "Epoch: 49 | Batch: 1166 | Loss: 0.11277615820131015\n",
            "Epoch: 49 | Batch: 1167 | Loss: 0.11190714212377605\n",
            "Epoch: 49 | Batch: 1168 | Loss: 0.1876776094599491\n",
            "Epoch: 49 | Batch: 1169 | Loss: 0.10866781996993623\n",
            "Epoch: 49 | Batch: 1170 | Loss: 0.1110225171703276\n",
            "Epoch: 49 | Batch: 1171 | Loss: 0.10161473118686946\n",
            "Epoch: 49 | Batch: 1172 | Loss: 0.1786794182986329\n",
            "Epoch: 49 | Batch: 1173 | Loss: 0.11558733987138403\n",
            "Epoch: 49 | Batch: 1174 | Loss: 0.10747316010724382\n",
            "Epoch: 49 | Batch: 1175 | Loss: 0.09691802131155589\n",
            "Epoch: 49 | Batch: 1176 | Loss: 0.10249075077686859\n",
            "Epoch: 49 | Batch: 1177 | Loss: 0.14793074853968674\n",
            "Epoch: 49 | Batch: 1178 | Loss: 0.14538884847555916\n",
            "Epoch: 49 | Batch: 1179 | Loss: 0.13600548125557838\n",
            "Epoch: 49 | Batch: 1180 | Loss: 0.12895498982801074\n",
            "Epoch: 49 | Batch: 1181 | Loss: 0.14273634722911238\n",
            "Epoch: 49 | Batch: 1182 | Loss: 0.12222245693203497\n",
            "Epoch: 49 | Batch: 1183 | Loss: 0.10526972635556131\n",
            "Epoch: 49 | Batch: 1184 | Loss: 0.11414660151004516\n",
            "Epoch: 49 | Batch: 1185 | Loss: 0.10569909569139208\n",
            "Epoch: 49 | Batch: 1186 | Loss: 0.12680123459952292\n",
            "Epoch: 49 | Batch: 1187 | Loss: 0.09168950771882584\n",
            "Epoch: 49 | Batch: 1188 | Loss: 0.10508461057838184\n",
            "Epoch: 49 | Batch: 1189 | Loss: 0.09082469901679431\n",
            "Epoch: 49 | Batch: 1190 | Loss: 0.1089200115062174\n",
            "Epoch: 49 | Batch: 1191 | Loss: 0.10182254239874214\n",
            "Epoch: 49 | Batch: 1192 | Loss: 0.10104381564770579\n",
            "Epoch: 49 | Batch: 1193 | Loss: 0.08570356640979773\n",
            "Epoch: 49 | Batch: 1194 | Loss: 0.09818925769035954\n",
            "Epoch: 49 | Batch: 1195 | Loss: 0.11183453503480446\n",
            "Epoch: 49 | Batch: 1196 | Loss: 0.09345245417870253\n",
            "Epoch: 49 | Batch: 1197 | Loss: 0.07424230950498814\n",
            "Epoch: 49 | Batch: 1198 | Loss: 0.09172942495986744\n",
            "Epoch: 49 | Batch: 1199 | Loss: 0.08818226342655158\n",
            "Epoch: 49 | Batch: 1200 | Loss: 0.10513059992004589\n",
            "Epoch: 49 | Batch: 1201 | Loss: 0.07454563029043329\n",
            "Epoch: 49 | Batch: 1202 | Loss: 0.09770974776244805\n",
            "Epoch: 49 | Batch: 1203 | Loss: 0.10861754489634709\n",
            "Epoch: 49 | Batch: 1204 | Loss: 0.09819780081822534\n",
            "Epoch: 49 | Batch: 1205 | Loss: 0.09468371661630975\n",
            "Epoch: 49 | Batch: 1206 | Loss: 0.0850828547766668\n",
            "Epoch: 49 | Batch: 1207 | Loss: 0.06588958487185685\n",
            "Epoch: 49 | Batch: 1208 | Loss: 0.08732536486911262\n",
            "Epoch: 49 | Batch: 1209 | Loss: 0.1053443773216652\n",
            "Epoch: 49 | Batch: 1210 | Loss: 0.0722523736554436\n",
            "Epoch: 49 | Batch: 1211 | Loss: 0.09719645154867831\n",
            "Epoch: 49 | Batch: 1212 | Loss: 0.09038434429929584\n",
            "Epoch: 49 | Batch: 1213 | Loss: 0.15498012903394265\n",
            "Epoch: 49 | Batch: 1214 | Loss: 0.07155805909725055\n",
            "Epoch: 49 | Batch: 1215 | Loss: 0.06618147444565176\n",
            "Epoch: 49 | Batch: 1216 | Loss: 0.07468620164614143\n",
            "Epoch: 49 | Batch: 1217 | Loss: 0.08498263311471085\n",
            "Epoch: 49 | Batch: 1218 | Loss: 0.07724762419086986\n",
            "Epoch: 49 | Batch: 1219 | Loss: 0.08855723743194979\n",
            "Epoch: 49 | Batch: 1220 | Loss: 0.07596864152157928\n",
            "Epoch: 49 | Batch: 1221 | Loss: 0.08201610350677543\n",
            "Epoch: 49 | Batch: 1222 | Loss: 0.061958750772769626\n",
            "Epoch: 49 | Batch: 1223 | Loss: 0.06343610909296568\n",
            "Epoch: 49 | Batch: 1224 | Loss: 0.09798390278919789\n",
            "Epoch: 49 | Batch: 1225 | Loss: 0.06313039248930974\n",
            "Epoch: 49 | Batch: 1226 | Loss: 0.07967744239325757\n",
            "Epoch: 49 | Batch: 1227 | Loss: 0.10395941841698221\n",
            "Epoch: 49 | Batch: 1228 | Loss: 0.10168412914315607\n",
            "Epoch: 49 | Batch: 1229 | Loss: 0.0965019450301918\n",
            "Epoch: 49 | Batch: 1230 | Loss: 0.07711695244238445\n",
            "Epoch: 49 | Batch: 1231 | Loss: 0.060988669406732074\n",
            "Epoch: 49 | Batch: 1232 | Loss: 0.06793592900566228\n",
            "Epoch: 49 | Batch: 1233 | Loss: 0.08383735074136289\n",
            "Epoch: 49 | Batch: 1234 | Loss: 0.078722969635403\n",
            "Epoch: 49 | Batch: 1235 | Loss: 0.09113630155448443\n",
            "Epoch: 49 | Batch: 1236 | Loss: 0.08948167386655367\n",
            "Epoch: 49 | Batch: 1237 | Loss: 0.1138043672923921\n",
            "Epoch: 49 | Batch: 1238 | Loss: 0.07268008276500404\n",
            "Epoch: 49 | Batch: 1239 | Loss: 0.09981718356430146\n",
            "Epoch: 49 | Batch: 1240 | Loss: 0.0961726883285634\n",
            "Epoch: 49 | Batch: 1241 | Loss: 0.07669376244255\n",
            "Epoch: 49 | Batch: 1242 | Loss: 0.09357918834004626\n",
            "Epoch: 49 | Batch: 1243 | Loss: 0.06806499850481801\n",
            "Epoch: 49 | Batch: 1244 | Loss: 0.0766967024737503\n",
            "Epoch: 49 | Batch: 1245 | Loss: 0.1068364476154752\n",
            "Epoch: 49 | Batch: 1246 | Loss: 0.13705923115672108\n",
            "Epoch: 49 | Batch: 1247 | Loss: 0.08725761488052147\n",
            "Epoch: 49 | Batch: 1248 | Loss: 0.12910414016344066\n",
            "Epoch: 49 | Batch: 1249 | Loss: 0.17069371141006429\n",
            "Epoch: 49 | Batch: 1250 | Loss: 0.05850162475600118\n",
            "Epoch: 49 | Batch: 1251 | Loss: 0.07017106916146441\n",
            "Epoch: 49 | Batch: 1252 | Loss: 0.14881675033153094\n",
            "Epoch: 49 | Batch: 1253 | Loss: 0.09364990562232317\n",
            "Epoch: 49 | Batch: 1254 | Loss: 0.06423796260583366\n",
            "Epoch: 49 | Batch: 1255 | Loss: 0.10919504266860103\n",
            "Epoch: 49 | Batch: 1256 | Loss: 0.09391967943862009\n",
            "Epoch: 49 | Batch: 1257 | Loss: 0.08881883531261801\n",
            "Epoch: 49 | Batch: 1258 | Loss: 0.09070432180379401\n",
            "Epoch: 49 | Batch: 1259 | Loss: 0.11328526968302724\n",
            "Epoch: 49 | Batch: 1260 | Loss: 0.0851394984592973\n",
            "Epoch: 49 | Batch: 1261 | Loss: 0.05848060309057844\n",
            "Epoch: 49 | Batch: 1262 | Loss: 0.09888534820717057\n",
            "Epoch: 49 | Batch: 1263 | Loss: 0.1165951034256531\n",
            "Epoch: 49 | Batch: 1264 | Loss: 0.07566866915112622\n",
            "Epoch: 49 | Batch: 1265 | Loss: 0.09076144095729505\n",
            "Epoch: 49 | Batch: 1266 | Loss: 0.08502425838709074\n",
            "Epoch: 49 | Batch: 1267 | Loss: 0.087810924815384\n",
            "Epoch: 49 | Batch: 1268 | Loss: 0.05929472808386165\n",
            "Epoch: 49 | Batch: 1269 | Loss: 0.07301138157159626\n",
            "Epoch: 49 | Batch: 1270 | Loss: 0.06410495769109684\n",
            "Epoch: 49 | Batch: 1271 | Loss: 0.10014087325457889\n",
            "Epoch: 49 | Batch: 1272 | Loss: 0.0884541763914867\n",
            "Epoch: 49 | Batch: 1273 | Loss: 0.07813797222455506\n",
            "Epoch: 49 | Batch: 1274 | Loss: 0.06321645450556183\n",
            "Epoch: 49 | Batch: 1275 | Loss: 0.11800835593056208\n",
            "Epoch: 49 | Batch: 1276 | Loss: 0.08153783088977047\n",
            "Epoch: 49 | Batch: 1277 | Loss: 0.07699675354965838\n",
            "Epoch: 49 | Batch: 1278 | Loss: 0.0826333732266782\n",
            "Epoch: 49 | Batch: 1279 | Loss: 0.09895292935810013\n",
            "Epoch: 49 | Batch: 1280 | Loss: 0.06706272325613391\n",
            "Epoch: 49 | Batch: 1281 | Loss: 0.11018743298925239\n",
            "Epoch: 49 | Batch: 1282 | Loss: 0.11229900223064876\n",
            "Epoch: 49 | Batch: 1283 | Loss: 0.06794440844140393\n",
            "Epoch: 49 | Batch: 1284 | Loss: 0.08006102375979281\n",
            "Epoch: 49 | Batch: 1285 | Loss: 0.0940060670813356\n",
            "Epoch: 49 | Batch: 1286 | Loss: 0.0652324538391783\n",
            "Epoch: 49 | Batch: 1287 | Loss: 0.10969556088251048\n",
            "Epoch: 49 | Batch: 1288 | Loss: 0.06333244462679141\n",
            "Epoch: 49 | Batch: 1289 | Loss: 0.11079655688123123\n",
            "Epoch: 49 | Batch: 1290 | Loss: 0.06973131347249581\n",
            "Epoch: 49 | Batch: 1291 | Loss: 0.0977641060961092\n",
            "Epoch: 49 | Batch: 1292 | Loss: 0.09907641361828448\n",
            "Epoch: 49 | Batch: 1293 | Loss: 0.11389602338100716\n",
            "Epoch: 49 | Batch: 1294 | Loss: 0.08374116367936849\n",
            "Epoch: 49 | Batch: 1295 | Loss: 0.09693444177146107\n",
            "Epoch: 49 | Batch: 1296 | Loss: 0.0784838682984503\n",
            "Epoch: 49 | Batch: 1297 | Loss: 0.09810643882787284\n",
            "Epoch: 49 | Batch: 1298 | Loss: 0.12952180306162003\n",
            "Epoch: 49 | Batch: 1299 | Loss: 0.08464237388088734\n",
            "Epoch: 49 | Batch: 1300 | Loss: 0.08741266005410081\n",
            "Epoch: 49 | Batch: 1301 | Loss: 0.09225068198114317\n",
            "Epoch: 49 | Batch: 1302 | Loss: 0.08659747978257615\n",
            "Epoch: 49 | Batch: 1303 | Loss: 0.08878709269766585\n",
            "Epoch: 49 | Batch: 1304 | Loss: 0.09401938039236349\n",
            "Epoch: 49 | Batch: 1305 | Loss: 0.056382621192745466\n",
            "Epoch: 49 | Batch: 1306 | Loss: 0.0870358538572438\n",
            "Epoch: 49 | Batch: 1307 | Loss: 0.09119036682535127\n",
            "Epoch: 49 | Batch: 1308 | Loss: 0.07598413474726629\n",
            "Epoch: 49 | Batch: 1309 | Loss: 0.06368108244036985\n",
            "Epoch: 49 | Batch: 1310 | Loss: 0.09666336818599847\n",
            "Epoch: 49 | Batch: 1311 | Loss: 0.08074627668037368\n",
            "Epoch: 49 | Batch: 1312 | Loss: 0.0832557540724789\n",
            "Epoch: 49 | Batch: 1313 | Loss: 0.06431375673452247\n",
            "Epoch: 49 | Batch: 1314 | Loss: 0.0951839870677596\n",
            "Epoch: 49 | Batch: 1315 | Loss: 0.1055469596034475\n",
            "Epoch: 49 | Batch: 1316 | Loss: 0.09367867756027903\n",
            "Epoch: 49 | Batch: 1317 | Loss: 0.13128672894822374\n",
            "Epoch: 49 | Batch: 1318 | Loss: 0.08298416379611616\n",
            "Epoch: 49 | Batch: 1319 | Loss: 0.10617186141743609\n",
            "Epoch: 49 | Batch: 1320 | Loss: 0.14126811357191388\n",
            "Epoch: 49 | Batch: 1321 | Loss: 0.09646596689409129\n",
            "Epoch: 49 | Batch: 1322 | Loss: 0.07115631240615783\n",
            "Epoch: 49 | Batch: 1323 | Loss: 0.0847227141446068\n",
            "Epoch: 49 | Batch: 1324 | Loss: 0.08097099301411809\n",
            "Epoch: 49 | Batch: 1325 | Loss: 0.08781231861856628\n",
            "Epoch: 49 | Batch: 1326 | Loss: 0.09302990064829098\n",
            "Epoch: 49 | Batch: 1327 | Loss: 0.09868932833921154\n",
            "Epoch: 49 | Batch: 1328 | Loss: 0.10593345385674363\n",
            "Epoch: 49 | Batch: 1329 | Loss: 0.12063942076528925\n",
            "Epoch: 49 | Batch: 1330 | Loss: 0.11527640292294017\n",
            "Epoch: 49 | Batch: 1331 | Loss: 0.10950160844530617\n",
            "Epoch: 49 | Batch: 1332 | Loss: 0.09622053531398916\n",
            "Epoch: 49 | Batch: 1333 | Loss: 0.10942581913635793\n",
            "Epoch: 49 | Batch: 1334 | Loss: 0.08210047969152562\n",
            "Epoch: 49 | Batch: 1335 | Loss: 0.11464185219551092\n",
            "Epoch: 49 | Batch: 1336 | Loss: 0.08105325214592868\n",
            "Epoch: 49 | Batch: 1337 | Loss: 0.07419700263889581\n",
            "Epoch: 49 | Batch: 1338 | Loss: 0.09753535288605204\n",
            "Epoch: 49 | Batch: 1339 | Loss: 0.103251267727928\n",
            "Epoch: 49 | Batch: 1340 | Loss: 0.09868778518708718\n",
            "Epoch: 49 | Batch: 1341 | Loss: 0.10909618163968952\n",
            "Epoch: 49 | Batch: 1342 | Loss: 0.10063597745766689\n",
            "Epoch: 49 | Batch: 1343 | Loss: 0.12713663604111097\n",
            "Epoch: 49 | Batch: 1344 | Loss: 0.11658989597166308\n",
            "Epoch: 49 | Batch: 1345 | Loss: 0.0907885777857944\n",
            "Epoch: 49 | Batch: 1346 | Loss: 0.08439310334181763\n",
            "Epoch: 49 | Batch: 1347 | Loss: 0.11087321414664282\n",
            "Epoch: 49 | Batch: 1348 | Loss: 0.1228397752057841\n",
            "Epoch: 49 | Batch: 1349 | Loss: 0.1486032254068992\n",
            "Epoch: 49 | Batch: 1350 | Loss: 0.12711290736214215\n",
            "Epoch: 49 | Batch: 1351 | Loss: 0.11328320752713032\n",
            "Epoch: 49 | Batch: 1352 | Loss: 0.18731199284435063\n",
            "Epoch: 49 | Batch: 1353 | Loss: 0.14237068507358924\n",
            "Epoch: 49 | Batch: 1354 | Loss: 0.08204277378944946\n",
            "Epoch: 49 | Batch: 1355 | Loss: 0.09878347963234187\n",
            "Epoch: 49 | Batch: 1356 | Loss: 0.11404696744340735\n",
            "Epoch: 49 | Batch: 1357 | Loss: 0.09540229866513253\n",
            "Epoch: 49 | Batch: 1358 | Loss: 0.09510908728599382\n",
            "Epoch: 49 | Batch: 1359 | Loss: 0.1285925903419879\n",
            "Epoch: 49 | Batch: 1360 | Loss: 0.09023774170935053\n",
            "Epoch: 49 | Batch: 1361 | Loss: 0.10621835737491515\n",
            "Epoch: 49 | Batch: 1362 | Loss: 0.12059712006731006\n",
            "Epoch: 49 | Batch: 1363 | Loss: 0.1442210465433297\n",
            "Epoch: 49 | Batch: 1364 | Loss: 0.09030369817595699\n",
            "Epoch: 49 | Batch: 1365 | Loss: 0.103976294461048\n",
            "Epoch: 49 | Batch: 1366 | Loss: 0.12629325955811502\n",
            "Epoch: 49 | Batch: 1367 | Loss: 0.11744168729002549\n",
            "Epoch: 49 | Batch: 1368 | Loss: 0.10501795804060332\n",
            "Epoch: 49 | Batch: 1369 | Loss: 0.1434206495788791\n",
            "Epoch: 49 | Batch: 1370 | Loss: 0.08915397010013425\n",
            "Epoch: 49 | Batch: 1371 | Loss: 0.07842404697232461\n",
            "Epoch: 49 | Batch: 1372 | Loss: 0.09432582672879844\n",
            "Epoch: 49 | Batch: 1373 | Loss: 0.12343276428957457\n",
            "Epoch: 49 | Batch: 1374 | Loss: 0.0932905033089304\n",
            "Epoch: 49 | Batch: 1375 | Loss: 0.08472830027680228\n",
            "Epoch: 49 | Batch: 1376 | Loss: 0.09799993823111106\n",
            "Epoch: 49 | Batch: 1377 | Loss: 0.12778566186720725\n",
            "Epoch: 49 | Batch: 1378 | Loss: 0.0690131017799787\n",
            "Epoch: 49 | Batch: 1379 | Loss: 0.0714629936486855\n",
            "Epoch: 49 | Batch: 1380 | Loss: 0.13914403573068423\n",
            "Epoch: 49 | Batch: 1381 | Loss: 0.07526074405773586\n",
            "Epoch: 49 | Batch: 1382 | Loss: 0.08893093741551944\n",
            "Epoch: 49 | Batch: 1383 | Loss: 0.0940612329513166\n",
            "Epoch: 49 | Batch: 1384 | Loss: 0.09408213695967158\n",
            "Epoch: 49 | Batch: 1385 | Loss: 0.076591643407405\n",
            "Epoch: 49 | Batch: 1386 | Loss: 0.12955469261905994\n",
            "Epoch: 49 | Batch: 1387 | Loss: 0.11400207210391981\n",
            "Epoch: 49 | Batch: 1388 | Loss: 0.07268136425298485\n",
            "Epoch: 49 | Batch: 1389 | Loss: 0.08410206558974312\n",
            "Epoch: 49 | Batch: 1390 | Loss: 0.12167885929276141\n",
            "Epoch: 49 | Batch: 1391 | Loss: 0.07807988676346476\n",
            "Epoch: 49 | Batch: 1392 | Loss: 0.1061652921123434\n",
            "Epoch: 49 | Batch: 1393 | Loss: 0.12688326525154286\n",
            "Epoch: 49 | Batch: 1394 | Loss: 0.08590360519092236\n",
            "Epoch: 49 | Batch: 1395 | Loss: 0.09067178363087668\n",
            "Epoch: 49 | Batch: 1396 | Loss: 0.09934421650737829\n",
            "Epoch: 49 | Batch: 1397 | Loss: 0.21059767956809594\n",
            "Epoch: 49 | Batch: 1398 | Loss: 0.08269394768299672\n",
            "Epoch: 49 | Batch: 1399 | Loss: 0.11559312855597971\n",
            "Epoch: 49 | Batch: 1400 | Loss: 0.08871006127220749\n",
            "Epoch: 49 | Batch: 1401 | Loss: 0.10600078603288426\n",
            "Epoch: 49 | Batch: 1402 | Loss: 0.09864240545434395\n",
            "Epoch: 49 | Batch: 1403 | Loss: 0.08357280631772926\n",
            "Epoch: 49 | Batch: 1404 | Loss: 0.08107028007599772\n",
            "Epoch: 49 | Batch: 1405 | Loss: 0.0692286203080023\n",
            "Epoch: 49 | Batch: 1406 | Loss: 0.08932546371697941\n",
            "Epoch: 49 | Batch: 1407 | Loss: 0.06915092850721871\n",
            "Epoch: 49 | Batch: 1408 | Loss: 0.07338501582262813\n",
            "Epoch: 49 | Batch: 1409 | Loss: 0.12623781437587647\n",
            "Epoch: 49 | Batch: 1410 | Loss: 0.10212212690875125\n",
            "Epoch: 49 | Batch: 1411 | Loss: 0.08165419730327807\n",
            "Epoch: 49 | Batch: 1412 | Loss: 0.11350026520476994\n",
            "Epoch: 49 | Batch: 1413 | Loss: 0.13149870356514637\n",
            "Epoch: 49 | Batch: 1414 | Loss: 0.08724693782499246\n",
            "Epoch: 49 | Batch: 1415 | Loss: 0.12708898980985175\n",
            "Epoch: 49 | Batch: 1416 | Loss: 0.0674209684194951\n",
            "Epoch: 49 | Batch: 1417 | Loss: 0.10408083100671828\n",
            "Epoch: 49 | Batch: 1418 | Loss: 0.08633853698996244\n",
            "Epoch: 49 | Batch: 1419 | Loss: 0.1118493823417501\n",
            "Epoch: 49 | Batch: 1420 | Loss: 0.10257237710714\n",
            "Epoch: 49 | Batch: 1421 | Loss: 0.08202898455747834\n",
            "Epoch: 49 | Batch: 1422 | Loss: 0.10654646380358307\n",
            "Epoch: 49 | Batch: 1423 | Loss: 0.1142714875829255\n",
            "Epoch: 49 | Batch: 1424 | Loss: 0.0915763059122847\n",
            "Epoch: 49 | Batch: 1425 | Loss: 0.09238715558953933\n",
            "Epoch: 49 | Batch: 1426 | Loss: 0.11068001157001317\n",
            "Epoch: 49 | Batch: 1427 | Loss: 0.11191647671345033\n",
            "Epoch: 49 | Batch: 1428 | Loss: 0.10964470568813692\n",
            "Epoch: 49 | Batch: 1429 | Loss: 0.10339973292011892\n",
            "Epoch: 49 | Batch: 1430 | Loss: 0.10908640362107834\n",
            "Epoch: 49 | Batch: 1431 | Loss: 0.1271010065173498\n",
            "Epoch: 49 | Batch: 1432 | Loss: 0.0927358472609069\n",
            "Epoch: 49 | Batch: 1433 | Loss: 0.09294819872165493\n",
            "Epoch: 49 | Batch: 1434 | Loss: 0.09503206640780926\n",
            "Epoch: 49 | Batch: 1435 | Loss: 0.0951734194049989\n",
            "Epoch: 49 | Batch: 1436 | Loss: 0.09689613523130992\n",
            "Epoch: 49 | Batch: 1437 | Loss: 0.07262996205848783\n",
            "Epoch: 49 | Batch: 1438 | Loss: 0.08122736919747534\n",
            "Epoch: 49 | Batch: 1439 | Loss: 0.10735404756328878\n",
            "Epoch: 49 | Batch: 1440 | Loss: 0.08070065538174975\n",
            "Epoch: 49 | Batch: 1441 | Loss: 0.09518521781767252\n",
            "Epoch: 49 | Batch: 1442 | Loss: 0.07819452829272217\n",
            "Epoch: 49 | Batch: 1443 | Loss: 0.08623845110162337\n",
            "Epoch: 49 | Batch: 1444 | Loss: 0.0985292902233017\n",
            "Epoch: 49 | Batch: 1445 | Loss: 0.06824576640812816\n",
            "Epoch: 49 | Batch: 1446 | Loss: 0.08611822380226608\n",
            "Epoch: 49 | Batch: 1447 | Loss: 0.06704967341653525\n",
            "Epoch: 49 | Batch: 1448 | Loss: 0.12339625727046627\n",
            "Epoch: 49 | Batch: 1449 | Loss: 0.06149655432549647\n",
            "Epoch: 49 | Batch: 1450 | Loss: 0.06161743063445036\n",
            "Epoch: 49 | Batch: 1451 | Loss: 0.0764664399999434\n",
            "Epoch: 49 | Batch: 1452 | Loss: 0.07027533337991226\n",
            "Epoch: 49 | Batch: 1453 | Loss: 0.1288526795124272\n",
            "Epoch: 49 | Batch: 1454 | Loss: 0.07439030386000395\n",
            "Epoch: 49 | Batch: 1455 | Loss: 0.09052148488921373\n",
            "Epoch: 49 | Batch: 1456 | Loss: 0.10942923802145517\n",
            "Epoch: 49 | Batch: 1457 | Loss: 0.1273394381058857\n",
            "Epoch: 49 | Batch: 1458 | Loss: 0.10613849233705716\n",
            "Epoch: 49 | Batch: 1459 | Loss: 0.09414908635251162\n",
            "Epoch: 49 | Batch: 1460 | Loss: 0.0979405093558254\n",
            "Epoch: 49 | Batch: 1461 | Loss: 0.086418063626423\n",
            "Epoch: 49 | Batch: 1462 | Loss: 0.10434532026072399\n",
            "Epoch: 49 | Batch: 1463 | Loss: 0.07651356942715834\n",
            "Epoch: 49 | Batch: 1464 | Loss: 0.07846365119238588\n",
            "Epoch: 49 | Batch: 1465 | Loss: 0.0770591465960812\n",
            "Epoch: 49 | Batch: 1466 | Loss: 0.06618101423631653\n",
            "Epoch: 49 | Batch: 1467 | Loss: 0.08931396814116134\n",
            "Epoch: 49 | Batch: 1468 | Loss: 0.05950241456218088\n",
            "Epoch: 49 | Batch: 1469 | Loss: 0.0695649684247033\n",
            "Epoch: 49 | Batch: 1470 | Loss: 0.06809174709132029\n",
            "Epoch: 49 | Batch: 1471 | Loss: 0.08076989162113156\n",
            "Epoch: 49 | Batch: 1472 | Loss: 0.12435122284400817\n",
            "Epoch: 49 | Batch: 1473 | Loss: 0.10591273880117301\n",
            "Epoch: 49 | Batch: 1474 | Loss: 0.11685657391424395\n",
            "Epoch: 49 | Batch: 1475 | Loss: 0.07868337599754054\n",
            "Epoch: 49 | Batch: 1476 | Loss: 0.15382230412868364\n",
            "Epoch: 49 | Batch: 1477 | Loss: 0.08745212507240087\n",
            "Epoch: 49 | Batch: 1478 | Loss: 0.10013969036688296\n",
            "Epoch: 49 | Batch: 1479 | Loss: 0.11148783900698431\n",
            "Epoch: 49 | Batch: 1480 | Loss: 0.07548650662296993\n",
            "Epoch: 49 | Batch: 1481 | Loss: 0.07120811038182234\n",
            "Epoch: 49 | Batch: 1482 | Loss: 0.10108967087680898\n",
            "Epoch: 49 | Batch: 1483 | Loss: 0.12466976551369109\n",
            "Epoch: 49 | Batch: 1484 | Loss: 0.09637758069504825\n",
            "Epoch: 49 | Batch: 1485 | Loss: 0.1301081374277555\n",
            "Epoch: 49 | Batch: 1486 | Loss: 0.09150503763786771\n",
            "Epoch: 49 | Batch: 1487 | Loss: 0.10619210129396078\n",
            "Epoch: 49 | Batch: 1488 | Loss: 0.09720815256382953\n",
            "Epoch: 49 | Batch: 1489 | Loss: 0.05652385801209945\n",
            "Epoch: 49 | Batch: 1490 | Loss: 0.07898126430943367\n",
            "Epoch: 49 | Batch: 1491 | Loss: 0.15019810657731958\n",
            "Epoch: 49 | Batch: 1492 | Loss: 0.08362740517080033\n",
            "Epoch: 49 | Batch: 1493 | Loss: 0.09710950895883724\n",
            "Epoch: 49 | Batch: 1494 | Loss: 0.09762526771154932\n",
            "Epoch: 49 | Batch: 1495 | Loss: 0.1478683625534158\n",
            "Epoch: 49 | Batch: 1496 | Loss: 0.0653123071146027\n",
            "Epoch: 49 | Batch: 1497 | Loss: 0.0650769827493706\n",
            "Epoch: 49 | Batch: 1498 | Loss: 0.04753696832241138\n",
            "Epoch: 49 | Batch: 1499 | Loss: 0.1132065256926415\n",
            "Epoch: 49 | Batch: 1500 | Loss: 0.0795004486434796\n",
            "Epoch: 49 | Batch: 1501 | Loss: 0.08180413046333715\n",
            "Epoch: 49 | Batch: 1502 | Loss: 0.09278168154992159\n",
            "Epoch: 49 | Batch: 1503 | Loss: 0.12988730698709808\n",
            "Epoch: 49 | Batch: 1504 | Loss: 0.10754948315815199\n",
            "Epoch: 49 | Batch: 1505 | Loss: 0.14506158323222357\n",
            "Epoch: 49 | Batch: 1506 | Loss: 0.13400265732242408\n",
            "Epoch: 49 | Batch: 1507 | Loss: 0.07624835700676735\n",
            "Epoch: 49 | Batch: 1508 | Loss: 0.12466253902467515\n",
            "Epoch: 49 | Batch: 1509 | Loss: 0.1376116440649768\n",
            "Epoch: 49 | Batch: 1510 | Loss: 0.06690102502934653\n",
            "Epoch: 49 | Batch: 1511 | Loss: 0.11077801743215515\n",
            "Epoch: 49 | Batch: 1512 | Loss: 0.11147764578281133\n",
            "Epoch: 49 | Batch: 1513 | Loss: 0.11166791362971897\n",
            "Epoch: 49 | Batch: 1514 | Loss: 0.11768810978801407\n",
            "Epoch: 49 | Batch: 1515 | Loss: 0.13148889106183898\n",
            "Epoch: 49 | Batch: 1516 | Loss: 0.12868500125005747\n",
            "Epoch: 49 | Batch: 1517 | Loss: 0.11193821223978871\n",
            "Epoch: 49 | Batch: 1518 | Loss: 0.10489973017757431\n",
            "Epoch: 49 | Batch: 1519 | Loss: 0.14654455345517176\n",
            "Epoch: 49 | Batch: 1520 | Loss: 0.06902680246219942\n",
            "Epoch: 49 | Batch: 1521 | Loss: 0.11526760280490003\n",
            "Epoch: 49 | Batch: 1522 | Loss: 0.13475254280364396\n",
            "Epoch: 49 | Batch: 1523 | Loss: 0.10738155702568411\n",
            "Epoch: 49 | Batch: 1524 | Loss: 0.1296937826318379\n",
            "Epoch: 49 | Batch: 1525 | Loss: 0.09531872256839995\n",
            "Epoch: 49 | Batch: 1526 | Loss: 0.11544842860391555\n",
            "Epoch: 49 | Batch: 1527 | Loss: 0.090544781002832\n",
            "Epoch: 49 | Batch: 1528 | Loss: 0.14289531876490785\n",
            "Epoch: 49 | Batch: 1529 | Loss: 0.07229295180946477\n",
            "Epoch: 49 | Batch: 1530 | Loss: 0.08007216973681089\n",
            "Epoch: 49 | Batch: 1531 | Loss: 0.09132207273377703\n",
            "Epoch: 49 | Batch: 1532 | Loss: 0.15337213996853918\n",
            "Epoch: 49 | Batch: 1533 | Loss: 0.0748698122192554\n",
            "Epoch: 49 | Batch: 1534 | Loss: 0.0946068444751865\n",
            "Epoch: 49 | Batch: 1535 | Loss: 0.09349125817857436\n",
            "Epoch: 49 | Batch: 1536 | Loss: 0.08196417767729315\n",
            "Epoch: 49 | Batch: 1537 | Loss: 0.10287274294792956\n",
            "Epoch: 49 | Batch: 1538 | Loss: 0.09472038153405166\n",
            "Epoch: 49 | Batch: 1539 | Loss: 0.12672742629513697\n",
            "Epoch: 49 | Batch: 1540 | Loss: 0.12940670255494485\n",
            "Epoch: 49 | Batch: 1541 | Loss: 0.1170321100336657\n",
            "Epoch: 49 | Batch: 1542 | Loss: 0.12515089965005283\n",
            "Epoch: 49 | Batch: 1543 | Loss: 0.12750711586529903\n",
            "Epoch: 49 | Batch: 1544 | Loss: 0.11368935813463674\n",
            "Epoch: 49 | Batch: 1545 | Loss: 0.078908688937638\n",
            "Epoch: 49 | Batch: 1546 | Loss: 0.06880219038868673\n",
            "Epoch: 49 | Batch: 1547 | Loss: 0.07423222426871255\n",
            "Epoch: 49 | Batch: 1548 | Loss: 0.08423821074632104\n",
            "Epoch: 49 | Batch: 1549 | Loss: 0.08083479542252381\n",
            "Epoch: 49 | Batch: 1550 | Loss: 0.09961986989003924\n",
            "Epoch: 49 | Batch: 1551 | Loss: 0.1013632509558208\n",
            "Epoch: 49 | Batch: 1552 | Loss: 0.08013443342448937\n",
            "Epoch: 49 | Batch: 1553 | Loss: 0.07625325839364024\n",
            "Epoch: 49 | Batch: 1554 | Loss: 0.08180454059423062\n",
            "Epoch: 49 | Batch: 1555 | Loss: 0.10210381039480487\n",
            "Epoch: 49 | Batch: 1556 | Loss: 0.10900859904596374\n",
            "Epoch: 49 | Batch: 1557 | Loss: 0.09000744020010173\n",
            "Epoch: 49 | Batch: 1558 | Loss: 0.1064555919205302\n",
            "Epoch: 49 | Batch: 1559 | Loss: 0.10592710592934398\n",
            "Epoch: 49 | Batch: 1560 | Loss: 0.082791880035152\n",
            "Epoch: 49 | Batch: 1561 | Loss: 0.09182509458981064\n",
            "Epoch: 49 | Batch: 1562 | Loss: 0.11870079082708201\n",
            "Epoch: 49 | Batch: 1563 | Loss: 0.16764059255564212\n",
            "Epoch: 49 | Batch: 1564 | Loss: 0.1510632905559326\n",
            "Epoch: 49 | Batch: 1565 | Loss: 0.12322759192742583\n",
            "Epoch: 49 | Batch: 1566 | Loss: 0.11834043347874146\n",
            "Epoch: 49 | Batch: 1567 | Loss: 0.10594354040982348\n",
            "Epoch: 49 | Batch: 1568 | Loss: 0.07929614641618933\n",
            "Epoch: 49 | Batch: 1569 | Loss: 0.07718787039312303\n",
            "Epoch: 49 | Batch: 1570 | Loss: 0.07437373019121171\n",
            "Epoch: 49 | Batch: 1571 | Loss: 0.09553278267577772\n",
            "Epoch: 49 | Batch: 1572 | Loss: 0.10696936413547402\n",
            "Epoch: 49 | Batch: 1573 | Loss: 0.08610623468713785\n",
            "Epoch: 49 | Batch: 1574 | Loss: 0.09693038006096427\n",
            "Epoch: 49 | Batch: 1575 | Loss: 0.12025460568671614\n",
            "Epoch: 49 | Batch: 1576 | Loss: 0.10043330870243519\n",
            "Epoch: 49 | Batch: 1577 | Loss: 0.14079996257860133\n",
            "Epoch: 49 | Batch: 1578 | Loss: 0.1121332443932567\n",
            "Epoch: 49 | Batch: 1579 | Loss: 0.08382006574198042\n",
            "Epoch: 49 | Batch: 1580 | Loss: 0.09270509765874355\n",
            "Epoch: 49 | Batch: 1581 | Loss: 0.23503991682529363\n",
            "Epoch: 49 | Batch: 1582 | Loss: 0.09971889400467651\n",
            "Epoch: 49 | Batch: 1583 | Loss: 0.14975686083929443\n",
            "Epoch: 49 | Batch: 1584 | Loss: 0.15579549943180176\n",
            "Epoch: 49 | Batch: 1585 | Loss: 0.1058372686776379\n",
            "Epoch: 49 | Batch: 1586 | Loss: 0.10866738788852749\n",
            "Epoch: 49 | Batch: 1587 | Loss: 0.1335465942966616\n",
            "Epoch: 49 | Batch: 1588 | Loss: 0.12503273676602705\n",
            "Epoch: 49 | Batch: 1589 | Loss: 0.11652005133916679\n",
            "Epoch: 49 | Batch: 1590 | Loss: 0.15818897219012268\n",
            "Epoch: 49 | Batch: 1591 | Loss: 0.12325970593150201\n",
            "Epoch: 49 | Batch: 1592 | Loss: 0.11807214839099817\n",
            "Epoch: 49 | Batch: 1593 | Loss: 0.1472916426358235\n",
            "Epoch: 49 | Batch: 1594 | Loss: 0.16716572011445144\n",
            "Epoch: 49 | Batch: 1595 | Loss: 0.08346759971089093\n",
            "Epoch: 49 | Batch: 1596 | Loss: 0.16669615954920808\n",
            "Epoch: 49 | Batch: 1597 | Loss: 0.15915241504507155\n",
            "Epoch: 49 | Batch: 1598 | Loss: 0.11996872189483154\n",
            "Epoch: 49 | Batch: 1599 | Loss: 0.0930572912937695\n",
            "Epoch: 49 | Batch: 1600 | Loss: 0.10045998337046094\n",
            "Epoch: 49 | Batch: 1601 | Loss: 0.08888820588986268\n",
            "Epoch: 49 | Batch: 1602 | Loss: 0.09405129747541333\n",
            "Epoch: 49 | Batch: 1603 | Loss: 0.0890169529693452\n",
            "Epoch: 49 | Batch: 1604 | Loss: 0.12317221455699272\n",
            "Epoch: 49 | Batch: 1605 | Loss: 0.1397355782623018\n",
            "Epoch: 49 | Batch: 1606 | Loss: 0.15641144214841107\n",
            "Epoch: 49 | Batch: 1607 | Loss: 0.12521675776287605\n",
            "Epoch: 49 | Batch: 1608 | Loss: 0.15301684069865013\n",
            "Epoch: 49 | Batch: 1609 | Loss: 0.1222038547643229\n",
            "Epoch: 49 | Batch: 1610 | Loss: 0.0958984157340274\n",
            "Epoch: 49 | Batch: 1611 | Loss: 0.11289977901627463\n",
            "Epoch: 49 | Batch: 1612 | Loss: 0.09302836080501231\n",
            "Epoch: 49 | Batch: 1613 | Loss: 0.07324303397187154\n",
            "Epoch: 49 | Batch: 1614 | Loss: 0.14034047720966242\n",
            "Epoch: 49 | Batch: 1615 | Loss: 0.0768047323510409\n",
            "Epoch: 49 | Batch: 1616 | Loss: 0.091401053580717\n",
            "Epoch: 49 | Batch: 1617 | Loss: 0.09778228400919749\n",
            "Epoch: 49 | Batch: 1618 | Loss: 0.10103966034833449\n",
            "Epoch: 49 | Batch: 1619 | Loss: 0.09602856478874869\n",
            "Epoch: 49 | Batch: 1620 | Loss: 0.09226296366828006\n",
            "Epoch: 49 | Batch: 1621 | Loss: 0.10978906088510809\n",
            "Epoch: 49 | Batch: 1622 | Loss: 0.10895781628049016\n",
            "Epoch: 49 | Batch: 1623 | Loss: 0.07699579217796584\n",
            "Epoch: 49 | Batch: 1624 | Loss: 0.09828743341649354\n",
            "Epoch: 49 | Batch: 1625 | Loss: 0.07734454014518637\n",
            "Epoch: 49 | Batch: 1626 | Loss: 0.11380255991676823\n",
            "Epoch: 49 | Batch: 1627 | Loss: 0.124440326319601\n",
            "Epoch: 49 | Batch: 1628 | Loss: 0.10861868178409112\n",
            "Epoch: 49 | Batch: 1629 | Loss: 0.10439408780335474\n",
            "Epoch: 49 | Batch: 1630 | Loss: 0.10835832166654524\n",
            "Epoch: 49 | Batch: 1631 | Loss: 0.08371119443351654\n",
            "Epoch: 49 | Batch: 1632 | Loss: 0.07265634105808924\n",
            "Epoch: 49 | Batch: 1633 | Loss: 0.08058261697161714\n",
            "Epoch: 49 | Batch: 1634 | Loss: 0.1134574439047743\n",
            "Epoch: 49 | Batch: 1635 | Loss: 0.10990278399696152\n",
            "Epoch: 49 | Batch: 1636 | Loss: 0.07804962212231656\n",
            "Epoch: 49 | Batch: 1637 | Loss: 0.09309497472567366\n",
            "Epoch: 49 | Batch: 1638 | Loss: 0.07958224237720235\n",
            "Epoch: 49 | Batch: 1639 | Loss: 0.0937075459232693\n",
            "Epoch: 49 | Batch: 1640 | Loss: 0.07455482542147934\n",
            "Epoch: 49 | Batch: 1641 | Loss: 0.08707774482001795\n",
            "Epoch: 49 | Batch: 1642 | Loss: 0.07754332722362836\n",
            "Epoch: 49 | Batch: 1643 | Loss: 0.10678123439716658\n",
            "Epoch: 49 | Batch: 1644 | Loss: 0.10089927491500801\n",
            "Epoch: 49 | Batch: 1645 | Loss: 0.09830080351524523\n",
            "Epoch: 49 | Batch: 1646 | Loss: 0.09173340501518149\n",
            "Epoch: 49 | Batch: 1647 | Loss: 0.08921066770001541\n",
            "Epoch: 49 | Batch: 1648 | Loss: 0.0939586404354092\n",
            "Epoch: 49 | Batch: 1649 | Loss: 0.07052863497342497\n",
            "Epoch: 49 | Batch: 1650 | Loss: 0.07949894042590963\n",
            "Epoch: 49 | Batch: 1651 | Loss: 0.07890199976937717\n",
            "Epoch: 49 | Batch: 1652 | Loss: 0.10780492824514545\n",
            "Epoch: 49 | Batch: 1653 | Loss: 0.08417607388922463\n",
            "Epoch: 49 | Batch: 1654 | Loss: 0.07260015583278176\n",
            "Epoch: 49 | Batch: 1655 | Loss: 0.09216302558008256\n",
            "Epoch: 49 | Batch: 1656 | Loss: 0.12154508840659356\n",
            "Epoch: 49 | Batch: 1657 | Loss: 0.08014628669683871\n",
            "Epoch: 49 | Batch: 1658 | Loss: 0.08710739318956481\n",
            "Epoch: 49 | Batch: 1659 | Loss: 0.0603919213919352\n",
            "Epoch: 49 | Batch: 1660 | Loss: 0.12238267299600541\n",
            "Epoch: 49 | Batch: 1661 | Loss: 0.10218438521535213\n",
            "Epoch: 49 | Batch: 1662 | Loss: 0.06982028864521571\n",
            "Epoch: 49 | Batch: 1663 | Loss: 0.0818050786330807\n",
            "Epoch: 49 | Batch: 1664 | Loss: 0.07667740153106888\n",
            "Epoch: 49 | Batch: 1665 | Loss: 0.10107688510359852\n",
            "Epoch: 49 | Batch: 1666 | Loss: 0.08136216154961742\n",
            "Epoch: 49 | Batch: 1667 | Loss: 0.09267988478440019\n",
            "Epoch: 49 | Batch: 1668 | Loss: 0.07727465449271832\n",
            "Epoch: 49 | Batch: 1669 | Loss: 0.07425941437658382\n",
            "Epoch: 49 | Batch: 1670 | Loss: 0.06928502944372288\n",
            "Epoch: 49 | Batch: 1671 | Loss: 0.10949105692274243\n",
            "Epoch: 49 | Batch: 1672 | Loss: 0.06696437783657182\n",
            "Epoch: 49 | Batch: 1673 | Loss: 0.06485862130834735\n",
            "Epoch: 49 | Batch: 1674 | Loss: 0.08985943846378266\n",
            "Epoch: 49 | Batch: 1675 | Loss: 0.10346143910087856\n",
            "Epoch: 49 | Batch: 1676 | Loss: 0.0818315329442025\n",
            "Epoch: 49 | Batch: 1677 | Loss: 0.10268188491241947\n",
            "Epoch: 49 | Batch: 1678 | Loss: 0.0982346836222932\n",
            "Epoch: 49 | Batch: 1679 | Loss: 0.06781871131810065\n",
            "Epoch: 49 | Batch: 1680 | Loss: 0.10726180423184109\n",
            "Epoch: 49 | Batch: 1681 | Loss: 0.07794913276610221\n",
            "Epoch: 49 | Batch: 1682 | Loss: 0.08898869001835304\n",
            "Epoch: 49 | Batch: 1683 | Loss: 0.08101767150229289\n",
            "Epoch: 49 | Batch: 1684 | Loss: 0.11570796883732595\n",
            "Epoch: 49 | Batch: 1685 | Loss: 0.07582416267009415\n",
            "Epoch: 49 | Batch: 1686 | Loss: 0.09773878229511662\n",
            "Epoch: 49 | Batch: 1687 | Loss: 0.11024430516865147\n",
            "Epoch: 49 | Batch: 1688 | Loss: 0.0824479318171984\n",
            "Epoch: 49 | Batch: 1689 | Loss: 0.08687849061969502\n",
            "Epoch: 49 | Batch: 1690 | Loss: 0.11317695221918779\n",
            "Epoch: 49 | Batch: 1691 | Loss: 0.09864715057661086\n",
            "Epoch: 49 | Batch: 1692 | Loss: 0.09371831901848612\n",
            "Epoch: 49 | Batch: 1693 | Loss: 0.09047644013221906\n",
            "Epoch: 49 | Batch: 1694 | Loss: 0.10312060240092036\n",
            "Epoch: 49 | Batch: 1695 | Loss: 0.071116690042102\n",
            "Epoch: 49 | Batch: 1696 | Loss: 0.14625521495830499\n",
            "Epoch: 49 | Batch: 1697 | Loss: 0.1052636315709469\n",
            "Epoch: 49 | Batch: 1698 | Loss: 0.11554251646461958\n",
            "Epoch: 49 | Batch: 1699 | Loss: 0.10302956218871849\n",
            "Epoch: 49 | Batch: 1700 | Loss: 0.1025789605396108\n",
            "Epoch: 49 | Batch: 1701 | Loss: 0.09140736401189475\n",
            "Epoch: 49 | Batch: 1702 | Loss: 0.09745009469435345\n",
            "Epoch: 49 | Batch: 1703 | Loss: 0.08628254516840916\n",
            "Epoch: 49 | Batch: 1704 | Loss: 0.07122426438148816\n",
            "Epoch: 49 | Batch: 1705 | Loss: 0.09114618803480155\n",
            "Epoch: 49 | Batch: 1706 | Loss: 0.08775757537413062\n",
            "Epoch: 49 | Batch: 1707 | Loss: 0.1257117326536803\n",
            "Epoch: 49 | Batch: 1708 | Loss: 0.1016055150463573\n",
            "Epoch: 49 | Batch: 1709 | Loss: 0.1222543003568416\n",
            "Epoch: 49 | Batch: 1710 | Loss: 0.14188231619986005\n",
            "Epoch: 49 | Batch: 1711 | Loss: 0.09315782385896751\n",
            "Epoch: 49 | Batch: 1712 | Loss: 0.08304879398967821\n",
            "Epoch: 49 | Batch: 1713 | Loss: 0.0827763925342346\n",
            "Epoch: 49 | Batch: 1714 | Loss: 0.10401925178310033\n",
            "Epoch: 49 | Batch: 1715 | Loss: 0.07949471063807247\n",
            "Epoch: 49 | Batch: 1716 | Loss: 0.1321396793127819\n",
            "Epoch: 49 | Batch: 1717 | Loss: 0.09812689652568801\n",
            "Epoch: 49 | Batch: 1718 | Loss: 0.11952147253000481\n",
            "Epoch: 49 | Batch: 1719 | Loss: 0.11283887988000249\n",
            "Epoch: 49 | Batch: 1720 | Loss: 0.1436772308887999\n",
            "Epoch: 49 | Batch: 1721 | Loss: 0.11181697069990784\n",
            "Epoch: 49 | Batch: 1722 | Loss: 0.09189880569825677\n",
            "Epoch: 49 | Batch: 1723 | Loss: 0.08363971456862188\n",
            "Epoch: 49 | Batch: 1724 | Loss: 0.09257209419784385\n",
            "Epoch: 49 | Batch: 1725 | Loss: 0.07837941333195639\n",
            "Epoch: 49 | Batch: 1726 | Loss: 0.08922682405501854\n",
            "Epoch: 49 | Batch: 1727 | Loss: 0.13126702380719518\n",
            "Epoch: 49 | Batch: 1728 | Loss: 0.10441884575799114\n",
            "Epoch: 49 | Batch: 1729 | Loss: 0.12061257636461609\n",
            "Epoch: 49 | Batch: 1730 | Loss: 0.13560267093161416\n",
            "Epoch: 49 | Batch: 1731 | Loss: 0.10007447675555393\n",
            "Epoch: 49 | Batch: 1732 | Loss: 0.08967123323587872\n",
            "Epoch: 49 | Batch: 1733 | Loss: 0.07722585704493456\n",
            "Epoch: 49 | Batch: 1734 | Loss: 0.10401488622487653\n",
            "Epoch: 49 | Batch: 1735 | Loss: 0.11663936951358042\n",
            "Epoch: 49 | Batch: 1736 | Loss: 0.16383468510110316\n",
            "Epoch: 49 | Batch: 1737 | Loss: 0.12849016100042548\n",
            "Epoch: 49 | Batch: 1738 | Loss: 0.11049994668670865\n",
            "Epoch: 49 | Batch: 1739 | Loss: 0.08485130824387767\n",
            "Epoch: 49 | Batch: 1740 | Loss: 0.13580046818848357\n",
            "Epoch: 49 | Batch: 1741 | Loss: 0.10587982754768585\n",
            "Epoch: 49 | Batch: 1742 | Loss: 0.09159249779539219\n",
            "Epoch: 49 | Batch: 1743 | Loss: 0.10567197671639483\n",
            "Epoch: 49 | Batch: 1744 | Loss: 0.07822630171669881\n",
            "Epoch: 49 | Batch: 1745 | Loss: 0.07728594884238803\n",
            "Epoch: 49 | Batch: 1746 | Loss: 0.0985472333285375\n",
            "Epoch: 49 | Batch: 1747 | Loss: 0.09061065107224386\n",
            "Epoch: 49 | Batch: 1748 | Loss: 0.0889702032419344\n",
            "Epoch: 49 | Batch: 1749 | Loss: 0.11314984869223596\n",
            "Epoch: 49 | Batch: 1750 | Loss: 0.09996586406179234\n",
            "Epoch: 49 | Batch: 1751 | Loss: 0.09056645933262591\n",
            "Epoch: 49 | Batch: 1752 | Loss: 0.09600098456892321\n",
            "Epoch: 49 | Batch: 1753 | Loss: 0.1050509298766025\n",
            "Epoch: 49 | Batch: 1754 | Loss: 0.08838733345074573\n",
            "Epoch: 49 | Batch: 1755 | Loss: 0.08121668445568372\n",
            "Epoch: 49 | Batch: 1756 | Loss: 0.07806769596620157\n",
            "Epoch: 49 | Batch: 1757 | Loss: 0.10427314418120429\n",
            "Epoch: 49 | Batch: 1758 | Loss: 0.11640091070808445\n",
            "Epoch: 49 | Batch: 1759 | Loss: 0.11064956946415605\n",
            "Epoch: 49 | Batch: 1760 | Loss: 0.1036796867069811\n",
            "Epoch: 49 | Batch: 1761 | Loss: 0.11188875279832716\n",
            "Epoch: 49 | Batch: 1762 | Loss: 0.12887338604389645\n",
            "Epoch: 49 | Batch: 1763 | Loss: 0.10845592504954085\n",
            "Epoch: 49 | Batch: 1764 | Loss: 0.11179937117079225\n",
            "Epoch: 49 | Batch: 1765 | Loss: 0.0704890941974983\n",
            "Epoch: 49 | Batch: 1766 | Loss: 0.18226104141550115\n",
            "Epoch: 49 | Batch: 1767 | Loss: 0.10383604823979659\n",
            "Epoch: 49 | Batch: 1768 | Loss: 0.14755707712535\n",
            "Epoch: 49 | Batch: 1769 | Loss: 0.1563870540860226\n",
            "Epoch: 49 | Batch: 1770 | Loss: 0.13442666623027064\n",
            "Epoch: 49 | Batch: 1771 | Loss: 0.1875487103062352\n",
            "Epoch: 49 | Batch: 1772 | Loss: 0.16856980411502037\n",
            "Epoch: 49 | Batch: 1773 | Loss: 0.10888293394826389\n",
            "Epoch: 49 | Batch: 1774 | Loss: 0.15119008278008061\n",
            "Epoch: 49 | Batch: 1775 | Loss: 0.13807935008746003\n",
            "Epoch: 49 | Batch: 1776 | Loss: 0.10802918950441591\n",
            "Epoch: 49 | Batch: 1777 | Loss: 0.09577913702956078\n",
            "Epoch: 49 | Batch: 1778 | Loss: 0.15791442963759664\n",
            "Epoch: 49 | Batch: 1779 | Loss: 0.1270266071036083\n",
            "Epoch: 49 | Batch: 1780 | Loss: 0.13849024928860304\n",
            "Epoch: 49 | Batch: 1781 | Loss: 0.15923816805844832\n",
            "Epoch: 49 | Batch: 1782 | Loss: 0.18853624840651945\n",
            "Epoch: 49 | Batch: 1783 | Loss: 0.12812552019171558\n",
            "Epoch: 49 | Batch: 1784 | Loss: 0.15046887300795864\n",
            "Epoch: 49 | Batch: 1785 | Loss: 0.1528124177088423\n",
            "Epoch: 49 | Batch: 1786 | Loss: 0.1492959965069806\n",
            "Epoch: 49 | Batch: 1787 | Loss: 0.14625063555193388\n",
            "Epoch: 49 | Batch: 1788 | Loss: 0.12192033481236497\n",
            "Epoch: 49 | Batch: 1789 | Loss: 0.0995802430604313\n",
            "Epoch: 49 | Batch: 1790 | Loss: 0.12238084990938333\n",
            "Epoch: 49 | Batch: 1791 | Loss: 0.11499640775371095\n",
            "Epoch: 49 | Batch: 1792 | Loss: 0.1309552032114334\n",
            "Epoch: 49 | Batch: 1793 | Loss: 0.12094079868377959\n",
            "Epoch: 49 | Batch: 1794 | Loss: 0.2045604501909535\n",
            "Epoch: 49 | Batch: 1795 | Loss: 0.14874281380759588\n",
            "Epoch: 49 | Batch: 1796 | Loss: 0.15986544106962125\n",
            "Epoch: 49 | Batch: 1797 | Loss: 0.17318153432972672\n",
            "Epoch: 49 | Batch: 1798 | Loss: 0.17335747015274144\n",
            "Epoch: 49 | Batch: 1799 | Loss: 0.16968972253668074\n",
            "Epoch: 49 | Batch: 1800 | Loss: 0.18776325073442507\n",
            "Epoch: 49 | Batch: 1801 | Loss: 0.1676434766140674\n",
            "Epoch: 49 | Batch: 1802 | Loss: 0.14879267781201605\n",
            "Epoch: 49 | Batch: 1803 | Loss: 0.1211561240539683\n",
            "Epoch: 49 | Batch: 1804 | Loss: 0.1971174309648681\n",
            "Epoch: 49 | Batch: 1805 | Loss: 0.14275420776004732\n",
            "Epoch: 49 | Batch: 1806 | Loss: 0.160466302373351\n",
            "Epoch: 49 | Batch: 1807 | Loss: 0.16189375055931274\n",
            "Epoch: 49 | Batch: 1808 | Loss: 0.16929412363489604\n",
            "Epoch: 49 | Batch: 1809 | Loss: 0.18116590013476458\n",
            "Epoch: 49 | Batch: 1810 | Loss: 0.17253975966497204\n",
            "Epoch: 49 | Batch: 1811 | Loss: 0.18127978243909265\n",
            "Epoch: 49 | Batch: 1812 | Loss: 0.20472864399682905\n",
            "Epoch: 49 | Batch: 1813 | Loss: 0.14861574198814168\n",
            "Epoch: 49 | Batch: 1814 | Loss: 0.156359634945068\n",
            "Epoch: 49 | Batch: 1815 | Loss: 0.15920179413341345\n",
            "Epoch: 49 | Batch: 1816 | Loss: 0.1860004536362893\n",
            "Epoch: 49 | Batch: 1817 | Loss: 0.13485021420557225\n",
            "Epoch: 49 | Batch: 1818 | Loss: 0.1247037253043381\n",
            "Epoch: 49 | Batch: 1819 | Loss: 0.15041373368631844\n",
            "Epoch: 49 | Batch: 1820 | Loss: 0.11070527013754242\n",
            "Epoch: 49 | Batch: 1821 | Loss: 0.12404086234743086\n",
            "Epoch: 49 | Batch: 1822 | Loss: 0.13125353583708854\n",
            "Epoch: 49 | Batch: 1823 | Loss: 0.13256467903610752\n",
            "Epoch: 49 | Batch: 1824 | Loss: 0.12055655781135691\n",
            "Epoch: 49 | Batch: 1825 | Loss: 0.1369046365058998\n",
            "Epoch: 49 | Batch: 1826 | Loss: 0.13811779522410172\n",
            "Epoch: 49 | Batch: 1827 | Loss: 0.154558946328745\n",
            "Epoch: 49 | Batch: 1828 | Loss: 0.1105869246294893\n",
            "Epoch: 49 | Batch: 1829 | Loss: 0.13536312530549824\n",
            "Epoch: 49 | Batch: 1830 | Loss: 0.12195263892086569\n",
            "Epoch: 49 | Batch: 1831 | Loss: 0.14528120023860344\n",
            "Epoch: 49 | Batch: 1832 | Loss: 0.13063533032262203\n",
            "Epoch: 49 | Batch: 1833 | Loss: 0.11063494846430795\n",
            "Epoch: 49 | Batch: 1834 | Loss: 0.12554344194768677\n",
            "Epoch: 49 | Batch: 1835 | Loss: 0.17217284454916132\n",
            "Epoch: 49 | Batch: 1836 | Loss: 0.12086079428445604\n",
            "Epoch: 49 | Batch: 1837 | Loss: 0.16235879531762618\n",
            "Epoch: 49 | Batch: 1838 | Loss: 0.10995263305765811\n",
            "Epoch: 49 | Batch: 1839 | Loss: 0.14335955729294658\n",
            "Epoch: 49 | Batch: 1840 | Loss: 0.10936918132172607\n",
            "Epoch: 49 | Batch: 1841 | Loss: 0.12195295353112154\n",
            "Epoch: 49 | Batch: 1842 | Loss: 0.16894073633266055\n",
            "Epoch: 49 | Batch: 1843 | Loss: 0.13115921545238854\n",
            "Epoch: 49 | Batch: 1844 | Loss: 0.1366160252083316\n",
            "Epoch: 49 | Batch: 1845 | Loss: 0.13007239462051567\n",
            "Epoch: 49 | Batch: 1846 | Loss: 0.157350968231316\n",
            "Epoch: 49 | Batch: 1847 | Loss: 0.13795770594778267\n",
            "Epoch: 49 | Batch: 1848 | Loss: 0.11505428313685842\n",
            "Epoch: 49 | Batch: 1849 | Loss: 0.13005544119804185\n",
            "Epoch: 49 | Batch: 1850 | Loss: 0.1492173471427788\n",
            "Epoch: 49 | Batch: 1851 | Loss: 0.11667432636962609\n",
            "Epoch: 49 | Batch: 1852 | Loss: 0.12401170890325428\n",
            "Epoch: 49 | Batch: 1853 | Loss: 0.14814018724865816\n",
            "Epoch: 49 | Batch: 1854 | Loss: 0.1084905246483978\n",
            "Epoch: 49 | Batch: 1855 | Loss: 0.11904507223774013\n",
            "Epoch: 49 | Batch: 1856 | Loss: 0.1189673776634464\n",
            "Epoch: 49 | Batch: 1857 | Loss: 0.13225553848571095\n",
            "Epoch: 49 | Batch: 1858 | Loss: 0.13654050724785655\n",
            "Epoch: 49 | Batch: 1859 | Loss: 0.12597187521267567\n",
            "Epoch: 49 | Batch: 1860 | Loss: 0.13647301277417806\n",
            "Epoch: 49 | Batch: 1861 | Loss: 0.11977135498897812\n",
            "Epoch: 49 | Batch: 1862 | Loss: 0.1132649971518841\n",
            "Epoch: 49 | Batch: 1863 | Loss: 0.10343914643954377\n",
            "Epoch: 49 | Batch: 1864 | Loss: 0.10292804148870344\n",
            "Epoch: 49 | Batch: 1865 | Loss: 0.09028151616506189\n",
            "Epoch: 49 | Batch: 1866 | Loss: 0.08276649981715511\n",
            "Epoch: 49 | Batch: 1867 | Loss: 0.09735044859548642\n",
            "Epoch: 49 | Batch: 1868 | Loss: 0.12118654726786297\n",
            "Epoch: 49 | Batch: 1869 | Loss: 0.09903787036436379\n",
            "Epoch: 49 | Batch: 1870 | Loss: 0.0895826882673038\n",
            "Epoch: 49 | Batch: 1871 | Loss: 0.11043535519597336\n",
            "Epoch: 49 | Batch: 1872 | Loss: 0.09829847156438129\n",
            "Epoch: 49 | Batch: 1873 | Loss: 0.0844262129144457\n",
            "Epoch: 49 | Batch: 1874 | Loss: 0.07973796807283305\n",
            "Epoch: 49 | Batch: 1875 | Loss: 0.0879215040549845\n",
            "Epoch: 49 | Batch: 1876 | Loss: 0.07870290796519624\n",
            "Epoch: 49 | Batch: 1877 | Loss: 0.11463640891940631\n",
            "Epoch: 49 | Batch: 1878 | Loss: 0.06358647576591961\n",
            "Epoch: 49 | Batch: 1879 | Loss: 0.06341397327133366\n",
            "Epoch: 49 | Batch: 1880 | Loss: 0.08639970679033313\n",
            "Epoch: 49 | Batch: 1881 | Loss: 0.09188320577409177\n",
            "Epoch: 49 | Batch: 1882 | Loss: 0.08555514579696945\n",
            "Epoch: 49 | Batch: 1883 | Loss: 0.09458713384278278\n",
            "Epoch: 49 | Batch: 1884 | Loss: 0.11880609627487372\n",
            "Epoch: 49 | Batch: 1885 | Loss: 0.08138477465725745\n",
            "Epoch: 49 | Batch: 1886 | Loss: 0.12890699698742183\n",
            "Epoch: 49 | Batch: 1887 | Loss: 0.0925828933128458\n",
            "Epoch: 49 | Batch: 1888 | Loss: 0.07711504972471012\n",
            "Epoch: 49 | Batch: 1889 | Loss: 0.1509180001482227\n",
            "Epoch: 49 | Batch: 1890 | Loss: 0.12434385195145448\n",
            "Epoch: 49 | Batch: 1891 | Loss: 0.09311209717893419\n",
            "Epoch: 49 | Batch: 1892 | Loss: 0.13978990217753104\n",
            "Epoch: 49 | Batch: 1893 | Loss: 0.1239582191099915\n",
            "Epoch: 49 | Batch: 1894 | Loss: 0.10427485257365648\n",
            "Epoch: 49 | Batch: 1895 | Loss: 0.08864615767290927\n",
            "Epoch: 49 | Batch: 1896 | Loss: 0.11283002289355878\n",
            "Epoch: 49 | Batch: 1897 | Loss: 0.09662503084332195\n",
            "Epoch: 49 | Batch: 1898 | Loss: 0.13388615383732363\n",
            "Epoch: 49 | Batch: 1899 | Loss: 0.11305299691814152\n",
            "Epoch: 49 | Batch: 1900 | Loss: 0.10559979610907441\n",
            "Epoch: 49 | Batch: 1901 | Loss: 0.09873522368453662\n",
            "Epoch: 49 | Batch: 1902 | Loss: 0.11297046156063639\n",
            "Epoch: 49 | Batch: 1903 | Loss: 0.0822585269367967\n",
            "Epoch: 49 | Batch: 1904 | Loss: 0.0722178682608565\n",
            "Epoch: 49 | Batch: 1905 | Loss: 0.09362993283598656\n",
            "Epoch: 49 | Batch: 1906 | Loss: 0.07823347281092528\n",
            "Epoch: 49 | Batch: 1907 | Loss: 0.08377605936831689\n",
            "Epoch: 49 | Batch: 1908 | Loss: 0.08518163842107407\n",
            "Epoch: 49 | Batch: 1909 | Loss: 0.07108265035209237\n",
            "Epoch: 49 | Batch: 1910 | Loss: 0.12579286644738033\n",
            "Epoch: 49 | Batch: 1911 | Loss: 0.10094283464413273\n",
            "Epoch: 49 | Batch: 1912 | Loss: 0.09058662881944593\n",
            "Epoch: 49 | Batch: 1913 | Loss: 0.11892692617744181\n",
            "Epoch: 49 | Batch: 1914 | Loss: 0.09528266777298708\n",
            "Epoch: 49 | Batch: 1915 | Loss: 0.10449010521649071\n",
            "Epoch: 49 | Batch: 1916 | Loss: 0.12013227712520169\n",
            "Epoch: 49 | Batch: 1917 | Loss: 0.08617078087966631\n",
            "Epoch: 49 | Batch: 1918 | Loss: 0.08185130568294002\n",
            "Epoch: 49 | Batch: 1919 | Loss: 0.10147677190733898\n",
            "Epoch: 49 | Batch: 1920 | Loss: 0.09122635033014004\n",
            "Epoch: 49 | Batch: 1921 | Loss: 0.1031752966332718\n",
            "Epoch: 49 | Batch: 1922 | Loss: 0.10024576040911892\n",
            "Epoch: 49 | Batch: 1923 | Loss: 0.10232806260110822\n",
            "Epoch: 49 | Batch: 1924 | Loss: 0.09904266951725782\n",
            "Epoch: 49 | Batch: 1925 | Loss: 0.09730080864263438\n",
            "Epoch: 49 | Batch: 1926 | Loss: 0.1048202287731724\n",
            "Epoch: 49 | Batch: 1927 | Loss: 0.11147707658647302\n",
            "Epoch: 49 | Batch: 1928 | Loss: 0.08756567123690764\n",
            "Epoch: 49 | Batch: 1929 | Loss: 0.09051438350260321\n",
            "Epoch: 49 | Batch: 1930 | Loss: 0.14523869795480576\n",
            "Epoch: 49 | Batch: 1931 | Loss: 0.12166134276431044\n",
            "Epoch: 49 | Batch: 1932 | Loss: 0.08313287298801986\n",
            "Epoch: 49 | Batch: 1933 | Loss: 0.14368790802124654\n",
            "Epoch: 49 | Batch: 1934 | Loss: 0.10958208322189408\n",
            "Epoch: 49 | Batch: 1935 | Loss: 0.10949478795121642\n",
            "Epoch: 49 | Batch: 1936 | Loss: 0.10542516560877842\n",
            "Epoch: 49 | Batch: 1937 | Loss: 0.12159718380795499\n",
            "Epoch: 49 | Batch: 1938 | Loss: 0.11539210285419316\n",
            "Epoch: 49 | Batch: 1939 | Loss: 0.10446298678616384\n",
            "Epoch: 49 | Batch: 1940 | Loss: 0.10906862509170079\n",
            "Epoch: 49 | Batch: 1941 | Loss: 0.10337896811586526\n",
            "Epoch: 49 | Batch: 1942 | Loss: 0.12322256212420828\n",
            "Epoch: 49 | Batch: 1943 | Loss: 0.10268775278841849\n",
            "Epoch: 49 | Batch: 1944 | Loss: 0.12772193053895498\n",
            "Epoch: 49 | Batch: 1945 | Loss: 0.10361679057626308\n",
            "Epoch: 49 | Batch: 1946 | Loss: 0.1312555265697758\n",
            "Epoch: 49 | Batch: 1947 | Loss: 0.11296152985217314\n",
            "Epoch: 49 | Batch: 1948 | Loss: 0.09342031537791604\n",
            "Epoch: 49 | Batch: 1949 | Loss: 0.10395755585223194\n",
            "Epoch: 49 | Batch: 1950 | Loss: 0.08589025732919689\n",
            "Epoch: 49 | Batch: 1951 | Loss: 0.09418838778017483\n",
            "Epoch: 49 | Batch: 1952 | Loss: 0.08746866600443771\n",
            "Epoch: 49 | Batch: 1953 | Loss: 0.08306057074225853\n",
            "Epoch: 49 | Batch: 1954 | Loss: 0.1019865986802092\n",
            "Epoch: 49 | Batch: 1955 | Loss: 0.10154801965976983\n",
            "Epoch: 49 | Batch: 1956 | Loss: 0.11899239422342953\n",
            "Epoch: 49 | Batch: 1957 | Loss: 0.18151790526024686\n",
            "Epoch: 49 | Batch: 1958 | Loss: 0.13237446811007075\n",
            "Epoch: 49 | Batch: 1959 | Loss: 0.11556338842916525\n",
            "Epoch: 49 | Batch: 1960 | Loss: 0.1284256110305413\n",
            "Epoch: 49 | Batch: 1961 | Loss: 0.1300108440235836\n",
            "Epoch: 49 | Batch: 1962 | Loss: 0.09665542432205741\n",
            "Epoch: 49 | Batch: 1963 | Loss: 0.16229867840384393\n",
            "Epoch: 49 | Batch: 1964 | Loss: 0.11366415201679067\n",
            "Epoch: 49 | Batch: 1965 | Loss: 0.1410659932078897\n",
            "Epoch: 49 | Batch: 1966 | Loss: 0.10518469070062024\n",
            "Epoch: 49 | Batch: 1967 | Loss: 0.12831374794709172\n",
            "Epoch: 49 | Batch: 1968 | Loss: 0.11914139473481422\n",
            "Epoch: 49 | Batch: 1969 | Loss: 0.11063237195442761\n",
            "Epoch: 49 | Batch: 1970 | Loss: 0.09558402063632121\n",
            "Epoch: 49 | Batch: 1971 | Loss: 0.14085720531371293\n",
            "Epoch: 49 | Batch: 1972 | Loss: 0.09815942865826394\n",
            "Epoch: 49 | Batch: 1973 | Loss: 0.11240787323256668\n",
            "Epoch: 49 | Batch: 1974 | Loss: 0.13924590806869508\n",
            "Epoch: 49 | Batch: 1975 | Loss: 0.11561312570298099\n",
            "Epoch: 49 | Batch: 1976 | Loss: 0.16288654221444104\n",
            "Epoch: 49 | Batch: 1977 | Loss: 0.2881193547047952\n",
            "Epoch: 49 | Batch: 1978 | Loss: 0.1370256127126655\n",
            "Epoch: 49 | Batch: 1979 | Loss: 0.09549676662061236\n",
            "Epoch: 49 | Batch: 1980 | Loss: 0.10323856725791544\n",
            "Epoch: 49 | Batch: 1981 | Loss: 0.115003063766285\n",
            "Epoch: 49 | Batch: 1982 | Loss: 0.08989050908406482\n",
            "Epoch: 49 | Batch: 1983 | Loss: 0.1447409072624319\n",
            "Epoch: 49 | Batch: 1984 | Loss: 0.08963916477231791\n",
            "Epoch: 49 | Batch: 1985 | Loss: 0.11246423658495389\n",
            "Epoch: 49 | Batch: 1986 | Loss: 0.12741276419714165\n",
            "Epoch: 49 | Batch: 1987 | Loss: 0.12128044686753761\n",
            "Epoch: 49 | Batch: 1988 | Loss: 0.13219826249402203\n",
            "Epoch: 49 | Batch: 1989 | Loss: 0.1045255540214784\n",
            "Epoch: 49 | Batch: 1990 | Loss: 0.11412249343412928\n",
            "Epoch: 49 | Batch: 1991 | Loss: 0.1063068136013815\n",
            "Epoch: 49 | Batch: 1992 | Loss: 0.08292533972974764\n",
            "Epoch: 49 | Batch: 1993 | Loss: 0.07924240416091181\n",
            "Epoch: 49 | Batch: 1994 | Loss: 0.13236379401009654\n",
            "Epoch: 49 | Batch: 1995 | Loss: 0.08186613700369241\n",
            "Epoch: 49 | Batch: 1996 | Loss: 0.1457840761036156\n",
            "Epoch: 49 | Batch: 1997 | Loss: 0.12077044631692672\n",
            "Epoch: 49 | Batch: 1998 | Loss: 0.15284816669992474\n",
            "Epoch: 49 | Batch: 1999 | Loss: 0.13402092179865288\n",
            "Epoch: 49 | Batch: 2000 | Loss: 0.10682462880962984\n",
            "Epoch: 49 | Batch: 2001 | Loss: 0.15013503382129306\n",
            "Epoch: 49 | Batch: 2002 | Loss: 0.1287257478950716\n",
            "Epoch: 49 | Batch: 2003 | Loss: 0.12898437433878773\n",
            "Epoch: 49 | Batch: 2004 | Loss: 0.1046217653112023\n",
            "Epoch: 49 | Batch: 2005 | Loss: 0.10248677704348741\n",
            "Epoch: 49 | Batch: 2006 | Loss: 0.09306222501947396\n",
            "Epoch: 49 | Batch: 2007 | Loss: 0.09155195072782339\n",
            "Epoch: 49 | Batch: 2008 | Loss: 0.0813888727540754\n",
            "Epoch: 49 | Batch: 2009 | Loss: 0.12153110451630302\n",
            "Epoch: 49 | Batch: 2010 | Loss: 0.09467280166835645\n",
            "Epoch: 49 | Batch: 2011 | Loss: 0.10590816612623033\n",
            "Epoch: 49 | Batch: 2012 | Loss: 0.09553062871690163\n",
            "Epoch: 49 | Batch: 2013 | Loss: 0.08322656646592297\n",
            "Epoch: 49 | Batch: 2014 | Loss: 0.09330606184040476\n",
            "Epoch: 49 | Batch: 2015 | Loss: 0.09215856034863762\n",
            "Epoch: 49 | Batch: 2016 | Loss: 0.07819533948598872\n",
            "Epoch: 49 | Batch: 2017 | Loss: 0.11845962954407555\n",
            "Epoch: 49 | Batch: 2018 | Loss: 0.06639482967128349\n",
            "Epoch: 49 | Batch: 2019 | Loss: 0.11461180969925694\n",
            "Epoch: 49 | Batch: 2020 | Loss: 0.0697631342669486\n",
            "Epoch: 49 | Batch: 2021 | Loss: 0.059227718348566015\n",
            "Epoch: 49 | Batch: 2022 | Loss: 0.08098000880347041\n",
            "Epoch: 49 | Batch: 2023 | Loss: 0.10412990922816655\n",
            "Epoch: 49 | Batch: 2024 | Loss: 0.10464930293204268\n",
            "Epoch: 49 | Batch: 2025 | Loss: 0.08563683427568294\n",
            "Epoch: 49 | Batch: 2026 | Loss: 0.08997258557852619\n",
            "Epoch: 49 | Batch: 2027 | Loss: 0.10371121896076001\n",
            "Epoch: 49 | Batch: 2028 | Loss: 0.0786141316995363\n",
            "Epoch: 49 | Batch: 2029 | Loss: 0.08575606475753206\n",
            "Epoch: 49 | Batch: 2030 | Loss: 0.07862467971680069\n",
            "Epoch: 49 | Batch: 2031 | Loss: 0.08351977513804928\n",
            "Epoch: 49 | Batch: 2032 | Loss: 0.09552508401192121\n",
            "Epoch: 49 | Batch: 2033 | Loss: 0.0781917689107986\n",
            "Epoch: 49 | Batch: 2034 | Loss: 0.09982927813462988\n",
            "Epoch: 49 | Batch: 2035 | Loss: 0.07262099482692834\n",
            "Epoch: 49 | Batch: 2036 | Loss: 0.07427800172520681\n",
            "Epoch: 49 | Batch: 2037 | Loss: 0.05137692282307171\n",
            "Epoch: 49 | Batch: 2038 | Loss: 0.05271061900824454\n",
            "Epoch: 49 | Batch: 2039 | Loss: 0.06600491659221018\n",
            "Epoch: 49 | Batch: 2040 | Loss: 0.08584528355184029\n",
            "Epoch: 49 | Batch: 2041 | Loss: 0.07395505654551798\n",
            "Epoch: 49 | Batch: 2042 | Loss: 0.07569274822430201\n",
            "Epoch: 49 | Batch: 2043 | Loss: 0.0882673984810828\n",
            "Epoch: 49 | Batch: 2044 | Loss: 0.08318195062828447\n",
            "Epoch: 49 | Batch: 2045 | Loss: 0.06406911800106642\n",
            "Epoch: 49 | Batch: 2046 | Loss: 0.10187364448201375\n",
            "Epoch: 49 | Batch: 2047 | Loss: 0.07608097349839696\n",
            "Epoch: 49 | Batch: 2048 | Loss: 0.09162752777661329\n",
            "Epoch: 49 | Batch: 2049 | Loss: 0.09670594172313673\n",
            "Epoch: 49 | Batch: 2050 | Loss: 0.11269095658811384\n",
            "Epoch: 49 | Batch: 2051 | Loss: 0.06947953400007427\n",
            "Epoch: 49 | Batch: 2052 | Loss: 0.09562543456000794\n",
            "Epoch: 49 | Batch: 2053 | Loss: 0.09293406097631128\n",
            "Epoch: 49 | Batch: 2054 | Loss: 0.0741901145473595\n",
            "Epoch: 49 | Batch: 2055 | Loss: 0.081569241773469\n",
            "Epoch: 49 | Batch: 2056 | Loss: 0.147623491224561\n",
            "Epoch: 49 | Batch: 2057 | Loss: 0.07458816622303972\n",
            "Epoch: 49 | Batch: 2058 | Loss: 0.09578246870746779\n",
            "Epoch: 49 | Batch: 2059 | Loss: 0.09508143963139307\n",
            "Epoch: 49 | Batch: 2060 | Loss: 0.08139657790986636\n",
            "Epoch: 49 | Batch: 2061 | Loss: 0.08513479610933378\n",
            "Epoch: 49 | Batch: 2062 | Loss: 0.10249400910393268\n",
            "Epoch: 49 | Batch: 2063 | Loss: 0.08603148063828836\n",
            "Epoch: 49 | Batch: 2064 | Loss: 0.08593997091035149\n",
            "Epoch: 49 | Batch: 2065 | Loss: 0.08441576432178285\n",
            "Epoch: 49 | Batch: 2066 | Loss: 0.06326407331582082\n",
            "Epoch: 49 | Batch: 2067 | Loss: 0.09862880517243361\n",
            "Epoch: 49 | Batch: 2068 | Loss: 0.07058653559052018\n",
            "Epoch: 49 | Batch: 2069 | Loss: 0.11870850390438123\n",
            "Epoch: 49 | Batch: 2070 | Loss: 0.1344653070148838\n",
            "Epoch: 49 | Batch: 2071 | Loss: 0.0641335875815863\n",
            "Epoch: 49 | Batch: 2072 | Loss: 0.09929066582449247\n",
            "Epoch: 49 | Batch: 2073 | Loss: 0.0768284234291892\n",
            "Epoch: 49 | Batch: 2074 | Loss: 0.08324332322512727\n",
            "Epoch: 49 | Batch: 2075 | Loss: 0.07173922554536304\n",
            "Epoch: 49 | Batch: 2076 | Loss: 0.11211566316604794\n",
            "Epoch: 49 | Batch: 2077 | Loss: 0.08576688159694976\n",
            "Epoch: 49 | Batch: 2078 | Loss: 0.12160897750438907\n",
            "Epoch: 49 | Batch: 2079 | Loss: 0.1358517695774203\n",
            "Epoch: 49 | Batch: 2080 | Loss: 0.10984426791728627\n",
            "Epoch: 49 | Batch: 2081 | Loss: 0.09685097640594514\n",
            "Epoch: 49 | Batch: 2082 | Loss: 0.11709150676472169\n",
            "Epoch: 49 | Batch: 2083 | Loss: 0.10961809996139246\n",
            "Epoch: 49 | Batch: 2084 | Loss: 0.11565020847789409\n",
            "Epoch: 49 | Batch: 2085 | Loss: 0.10880454939063386\n",
            "Epoch: 49 | Batch: 2086 | Loss: 0.12507794403244882\n",
            "Epoch: 49 | Batch: 2087 | Loss: 0.10410360993868885\n",
            "Epoch: 49 | Batch: 2088 | Loss: 0.1852267690308937\n",
            "Epoch: 49 | Batch: 2089 | Loss: 0.12093819069857537\n",
            "Epoch: 49 | Batch: 2090 | Loss: 0.13695245089638844\n",
            "Epoch: 49 | Batch: 2091 | Loss: 0.1363474597997735\n",
            "Epoch: 49 | Batch: 2092 | Loss: 0.12998350229158406\n",
            "Epoch: 49 | Batch: 2093 | Loss: 0.14429628499486413\n",
            "Epoch: 49 | Batch: 2094 | Loss: 0.1445712993448891\n",
            "Epoch: 49 | Batch: 2095 | Loss: 0.14878156611774604\n",
            "Epoch: 49 | Batch: 2096 | Loss: 0.13500831881461758\n",
            "Epoch: 49 | Batch: 2097 | Loss: 0.1399746894182251\n",
            "Epoch: 49 | Batch: 2098 | Loss: 0.1609990073914243\n",
            "Epoch: 49 | Batch: 2099 | Loss: 0.12891600694404542\n",
            "Epoch: 49 | Batch: 2100 | Loss: 0.12330370201398996\n",
            "Epoch: 49 | Batch: 2101 | Loss: 0.1635449978955691\n",
            "Epoch: 49 | Batch: 2102 | Loss: 0.10887957120238717\n",
            "Epoch: 49 | Batch: 2103 | Loss: 0.10423116206185633\n",
            "Epoch: 49 | Batch: 2104 | Loss: 0.1363454970725062\n",
            "Epoch: 49 | Batch: 2105 | Loss: 0.11293860670766437\n",
            "Epoch: 49 | Batch: 2106 | Loss: 0.1687480989256252\n",
            "Epoch: 49 | Batch: 2107 | Loss: 0.12975050250607645\n",
            "Epoch: 49 | Batch: 2108 | Loss: 0.13566689694528433\n",
            "Epoch: 49 | Batch: 2109 | Loss: 0.15692250525214946\n",
            "Epoch: 49 | Batch: 2110 | Loss: 0.14188329035291108\n",
            "Epoch: 49 | Batch: 2111 | Loss: 0.13277831486506042\n",
            "Epoch: 49 | Batch: 2112 | Loss: 0.1624000567801881\n",
            "Epoch: 49 | Batch: 2113 | Loss: 0.20432626646966742\n",
            "Epoch: 49 | Batch: 2114 | Loss: 0.10316274230081605\n",
            "Epoch: 49 | Batch: 2115 | Loss: 0.1312353193206598\n",
            "Epoch: 49 | Batch: 2116 | Loss: 0.19607150968242967\n",
            "Epoch: 49 | Batch: 2117 | Loss: 0.09561518679272425\n",
            "Epoch: 49 | Batch: 2118 | Loss: 0.17018205638537584\n",
            "Epoch: 49 | Batch: 2119 | Loss: 0.1734315284841172\n",
            "Epoch: 49 | Batch: 2120 | Loss: 0.13867453672935334\n",
            "Epoch: 49 | Batch: 2121 | Loss: 0.15874892990038458\n",
            "Epoch: 49 | Batch: 2122 | Loss: 0.1468635499910259\n",
            "Epoch: 49 | Batch: 2123 | Loss: 0.16614375821615582\n",
            "Epoch: 49 | Batch: 2124 | Loss: 0.1458709877744505\n",
            "Epoch: 49 | Batch: 2125 | Loss: 0.11407474213230892\n",
            "Epoch: 49 | Batch: 2126 | Loss: 0.13679063488570292\n",
            "Epoch: 49 | Batch: 2127 | Loss: 0.15274309590283602\n",
            "Epoch: 49 | Batch: 2128 | Loss: 0.12290168449457688\n",
            "Epoch: 49 | Batch: 2129 | Loss: 0.132107990791547\n",
            "Epoch: 49 | Batch: 2130 | Loss: 0.1154492690536495\n",
            "Epoch: 49 | Batch: 2131 | Loss: 0.1604880491862293\n",
            "Epoch: 49 | Batch: 2132 | Loss: 0.12611520870274165\n",
            "Epoch: 49 | Batch: 2133 | Loss: 0.15775192723290857\n",
            "Epoch: 49 | Batch: 2134 | Loss: 0.15630930155503123\n",
            "Epoch: 49 | Batch: 2135 | Loss: 0.18203189578674606\n",
            "Epoch: 49 | Batch: 2136 | Loss: 0.12547200017642365\n",
            "Epoch: 49 | Batch: 2137 | Loss: 0.12591982048116945\n",
            "Epoch: 49 | Batch: 2138 | Loss: 0.11149695271905813\n",
            "Epoch: 49 | Batch: 2139 | Loss: 0.11379000841720963\n",
            "Epoch: 49 | Batch: 2140 | Loss: 0.16077212732595056\n",
            "Epoch: 49 | Batch: 2141 | Loss: 0.13234816433579522\n",
            "Epoch: 49 | Batch: 2142 | Loss: 0.13925807555791964\n",
            "Epoch: 49 | Batch: 2143 | Loss: 0.10076249232195758\n",
            "Epoch: 49 | Batch: 2144 | Loss: 0.12284792213224817\n",
            "Epoch: 49 | Batch: 2145 | Loss: 0.13761740505587727\n",
            "Epoch: 49 | Batch: 2146 | Loss: 0.17401445682817332\n",
            "Epoch: 49 | Batch: 2147 | Loss: 0.16989838017467673\n",
            "Epoch: 49 | Batch: 2148 | Loss: 0.14284473859108832\n",
            "Epoch: 49 | Batch: 2149 | Loss: 0.19245442791839734\n",
            "Epoch: 49 | Batch: 2150 | Loss: 0.1405309204212363\n",
            "Epoch: 49 | Batch: 2151 | Loss: 0.1490714809166208\n",
            "Epoch: 49 | Batch: 2152 | Loss: 0.13086022116426105\n",
            "Epoch: 49 | Batch: 2153 | Loss: 0.0868233337950317\n",
            "Epoch: 49 | Batch: 2154 | Loss: 0.14393906094846898\n",
            "Epoch: 49 | Batch: 2155 | Loss: 0.10498165725848196\n",
            "Epoch: 49 | Batch: 2156 | Loss: 0.12312093877329007\n",
            "Epoch: 49 | Batch: 2157 | Loss: 0.12155661034399712\n",
            "Epoch: 49 | Batch: 2158 | Loss: 0.09717887444112179\n",
            "Epoch: 49 | Batch: 2159 | Loss: 0.12462939341529325\n",
            "Epoch: 49 | Batch: 2160 | Loss: 0.14554418453060636\n",
            "Epoch: 49 | Batch: 2161 | Loss: 0.12561376535493304\n",
            "Epoch: 49 | Batch: 2162 | Loss: 0.104969679940206\n",
            "Epoch: 49 | Batch: 2163 | Loss: 0.13471504239683404\n",
            "Epoch: 49 | Batch: 2164 | Loss: 0.12761331534085443\n",
            "Epoch: 49 | Batch: 2165 | Loss: 0.085812375545521\n",
            "Epoch: 49 | Batch: 2166 | Loss: 0.07993883050579584\n",
            "Epoch: 49 | Batch: 2167 | Loss: 0.11943911122469604\n",
            "Epoch: 49 | Batch: 2168 | Loss: 0.10135557862012695\n",
            "Epoch: 49 | Batch: 2169 | Loss: 0.08880466503203996\n",
            "Epoch: 49 | Batch: 2170 | Loss: 0.11796414290917484\n",
            "Epoch: 49 | Batch: 2171 | Loss: 0.10264508414245158\n",
            "Epoch: 49 | Batch: 2172 | Loss: 0.08749591425744718\n",
            "Epoch: 49 | Batch: 2173 | Loss: 0.13180419294040752\n",
            "Epoch: 49 | Batch: 2174 | Loss: 0.06884292433676961\n",
            "Epoch: 49 | Batch: 2175 | Loss: 0.11216503429433562\n",
            "Epoch: 49 | Batch: 2176 | Loss: 0.1305033554435867\n",
            "Epoch: 49 | Batch: 2177 | Loss: 0.12916340941510399\n",
            "Epoch: 49 | Batch: 2178 | Loss: 0.07822247969999607\n",
            "Epoch: 49 | Batch: 2179 | Loss: 0.10718425455157712\n",
            "Epoch: 49 | Batch: 2180 | Loss: 0.08404345015472464\n",
            "Epoch: 49 | Batch: 2181 | Loss: 0.0722534856229487\n",
            "Epoch: 49 | Batch: 2182 | Loss: 0.13147321321154673\n",
            "Epoch: 49 | Batch: 2183 | Loss: 0.09082497762864723\n",
            "Epoch: 49 | Batch: 2184 | Loss: 0.2063393908953327\n",
            "Epoch: 49 | Batch: 2185 | Loss: 0.12122712799964419\n",
            "Epoch: 49 | Batch: 2186 | Loss: 0.08875103339237761\n",
            "Epoch: 49 | Batch: 2187 | Loss: 0.09677770298544455\n",
            "Epoch: 49 | Batch: 2188 | Loss: 0.1291911414231849\n",
            "Epoch: 49 | Batch: 2189 | Loss: 0.08631096382497451\n",
            "Epoch: 49 | Batch: 2190 | Loss: 0.08642415485460556\n",
            "Epoch: 49 | Batch: 2191 | Loss: 0.06588919351466099\n",
            "Epoch: 50 | Batch: 1 | Loss: 0.12863138781351\n",
            "Epoch: 50 | Batch: 2 | Loss: 0.12050072684249855\n",
            "Epoch: 50 | Batch: 3 | Loss: 0.08851806415295516\n",
            "Epoch: 50 | Batch: 4 | Loss: 0.10960335216618428\n",
            "Epoch: 50 | Batch: 5 | Loss: 0.08637815460133652\n",
            "Epoch: 50 | Batch: 6 | Loss: 0.09869644882822123\n",
            "Epoch: 50 | Batch: 7 | Loss: 0.07932789275461022\n",
            "Epoch: 50 | Batch: 8 | Loss: 0.10107380499675334\n",
            "Epoch: 50 | Batch: 9 | Loss: 0.07328723561209102\n",
            "Epoch: 50 | Batch: 10 | Loss: 0.08430759764741526\n",
            "Epoch: 50 | Batch: 11 | Loss: 0.08268251792808418\n",
            "Epoch: 50 | Batch: 12 | Loss: 0.07638675567138228\n",
            "Epoch: 50 | Batch: 13 | Loss: 0.07675694021919922\n",
            "Epoch: 50 | Batch: 14 | Loss: 0.10774529272373165\n",
            "Epoch: 50 | Batch: 15 | Loss: 0.09587097460207761\n",
            "Epoch: 50 | Batch: 16 | Loss: 0.07297395184370459\n",
            "Epoch: 50 | Batch: 17 | Loss: 0.1018284786079839\n",
            "Epoch: 50 | Batch: 18 | Loss: 0.10451434121437672\n",
            "Epoch: 50 | Batch: 19 | Loss: 0.14711074391102064\n",
            "Epoch: 50 | Batch: 20 | Loss: 0.07892595417078559\n",
            "Epoch: 50 | Batch: 21 | Loss: 0.09904065366017722\n",
            "Epoch: 50 | Batch: 22 | Loss: 0.08998021689387398\n",
            "Epoch: 50 | Batch: 23 | Loss: 0.09227683335249498\n",
            "Epoch: 50 | Batch: 24 | Loss: 0.08970550598739033\n",
            "Epoch: 50 | Batch: 25 | Loss: 0.07420037317927608\n",
            "Epoch: 50 | Batch: 26 | Loss: 0.0808784233171836\n",
            "Epoch: 50 | Batch: 27 | Loss: 0.15954096951528743\n",
            "Epoch: 50 | Batch: 28 | Loss: 0.08176137930997784\n",
            "Epoch: 50 | Batch: 29 | Loss: 0.09263664720718462\n",
            "Epoch: 50 | Batch: 30 | Loss: 0.1216458626362225\n",
            "Epoch: 50 | Batch: 31 | Loss: 0.07590204617389826\n",
            "Epoch: 50 | Batch: 32 | Loss: 0.08191619478143627\n",
            "Epoch: 50 | Batch: 33 | Loss: 0.08574486508852686\n",
            "Epoch: 50 | Batch: 34 | Loss: 0.08439594375637417\n",
            "Epoch: 50 | Batch: 35 | Loss: 0.09950356417073425\n",
            "Epoch: 50 | Batch: 36 | Loss: 0.09142899147829356\n",
            "Epoch: 50 | Batch: 37 | Loss: 0.11573358658571045\n",
            "Epoch: 50 | Batch: 38 | Loss: 0.10255402152464746\n",
            "Epoch: 50 | Batch: 39 | Loss: 0.12567100456736613\n",
            "Epoch: 50 | Batch: 40 | Loss: 0.1205296979672921\n",
            "Epoch: 50 | Batch: 41 | Loss: 0.11041494416486561\n",
            "Epoch: 50 | Batch: 42 | Loss: 0.09442034683843252\n",
            "Epoch: 50 | Batch: 43 | Loss: 0.07860118676254953\n",
            "Epoch: 50 | Batch: 44 | Loss: 0.08334492860143049\n",
            "Epoch: 50 | Batch: 45 | Loss: 0.11221729315910534\n",
            "Epoch: 50 | Batch: 46 | Loss: 0.08904277665855012\n",
            "Epoch: 50 | Batch: 47 | Loss: 0.13081686109209645\n",
            "Epoch: 50 | Batch: 48 | Loss: 0.16270075988841326\n",
            "Epoch: 50 | Batch: 49 | Loss: 0.16816141928707967\n",
            "Epoch: 50 | Batch: 50 | Loss: 0.14796478550289005\n",
            "Epoch: 50 | Batch: 51 | Loss: 0.15125302274443614\n",
            "Epoch: 50 | Batch: 52 | Loss: 0.11906287010529111\n",
            "Epoch: 50 | Batch: 53 | Loss: 0.16115924347734784\n",
            "Epoch: 50 | Batch: 54 | Loss: 0.12633392954707712\n",
            "Epoch: 50 | Batch: 55 | Loss: 0.10420797016876049\n",
            "Epoch: 50 | Batch: 56 | Loss: 0.1924458698297034\n",
            "Epoch: 50 | Batch: 57 | Loss: 0.1347075752805904\n",
            "Epoch: 50 | Batch: 58 | Loss: 0.14340694456783043\n",
            "Epoch: 50 | Batch: 59 | Loss: 0.19659591903006904\n",
            "Epoch: 50 | Batch: 60 | Loss: 0.1619979819927625\n",
            "Epoch: 50 | Batch: 61 | Loss: 0.1485669492710864\n",
            "Epoch: 50 | Batch: 62 | Loss: 0.1522205762910268\n",
            "Epoch: 50 | Batch: 63 | Loss: 0.15614750681226733\n",
            "Epoch: 50 | Batch: 64 | Loss: 0.13133120918161859\n",
            "Epoch: 50 | Batch: 65 | Loss: 0.15880948167154668\n",
            "Epoch: 50 | Batch: 66 | Loss: 0.13429541349520863\n",
            "Epoch: 50 | Batch: 67 | Loss: 0.13297570130247696\n",
            "Epoch: 50 | Batch: 68 | Loss: 0.1298811013589673\n",
            "Epoch: 50 | Batch: 69 | Loss: 0.10399266802570253\n",
            "Epoch: 50 | Batch: 70 | Loss: 0.11814489927456162\n",
            "Epoch: 50 | Batch: 71 | Loss: 0.13695690510691377\n",
            "Epoch: 50 | Batch: 72 | Loss: 0.10902652825400364\n",
            "Epoch: 50 | Batch: 73 | Loss: 0.11481007809368403\n",
            "Epoch: 50 | Batch: 74 | Loss: 0.13956151474740192\n",
            "Epoch: 50 | Batch: 75 | Loss: 0.13090546056460434\n",
            "Epoch: 50 | Batch: 76 | Loss: 0.15479882691931854\n",
            "Epoch: 50 | Batch: 77 | Loss: 0.1280791615630473\n",
            "Epoch: 50 | Batch: 78 | Loss: 0.15839360056918325\n",
            "Epoch: 50 | Batch: 79 | Loss: 0.12955711050244859\n",
            "Epoch: 50 | Batch: 80 | Loss: 0.1118843645283113\n",
            "Epoch: 50 | Batch: 81 | Loss: 0.10675927410308683\n",
            "Epoch: 50 | Batch: 82 | Loss: 0.1309241841906092\n",
            "Epoch: 50 | Batch: 83 | Loss: 0.10278202557642091\n",
            "Epoch: 50 | Batch: 84 | Loss: 0.1407173488295822\n",
            "Epoch: 50 | Batch: 85 | Loss: 0.16409565252857825\n",
            "Epoch: 50 | Batch: 86 | Loss: 0.12347908130167147\n",
            "Epoch: 50 | Batch: 87 | Loss: 0.11951776787577367\n",
            "Epoch: 50 | Batch: 88 | Loss: 0.12950386668998604\n",
            "Epoch: 50 | Batch: 89 | Loss: 0.11887450155805991\n",
            "Epoch: 50 | Batch: 90 | Loss: 0.12919675789184676\n",
            "Epoch: 50 | Batch: 91 | Loss: 0.10701921883397839\n",
            "Epoch: 50 | Batch: 92 | Loss: 0.10134577823761795\n",
            "Epoch: 50 | Batch: 93 | Loss: 0.0910445606639571\n",
            "Epoch: 50 | Batch: 94 | Loss: 0.13504766111067285\n",
            "Epoch: 50 | Batch: 95 | Loss: 0.10100351847477382\n",
            "Epoch: 50 | Batch: 96 | Loss: 0.1156221184923244\n",
            "Epoch: 50 | Batch: 97 | Loss: 0.14241971855913377\n",
            "Epoch: 50 | Batch: 98 | Loss: 0.07754968397894384\n",
            "Epoch: 50 | Batch: 99 | Loss: 0.08839434096567272\n",
            "Epoch: 50 | Batch: 100 | Loss: 0.1473212603976265\n",
            "Epoch: 50 | Batch: 101 | Loss: 0.1303440430078632\n",
            "Epoch: 50 | Batch: 102 | Loss: 0.08620494572663782\n",
            "Epoch: 50 | Batch: 103 | Loss: 0.1231046938616114\n",
            "Epoch: 50 | Batch: 104 | Loss: 0.12883660369356748\n",
            "Epoch: 50 | Batch: 105 | Loss: 0.1429655173497263\n",
            "Epoch: 50 | Batch: 106 | Loss: 0.17554125194107656\n",
            "Epoch: 50 | Batch: 107 | Loss: 0.10490034826062802\n",
            "Epoch: 50 | Batch: 108 | Loss: 0.12528145999204907\n",
            "Epoch: 50 | Batch: 109 | Loss: 0.181024327228164\n",
            "Epoch: 50 | Batch: 110 | Loss: 0.10205760007561472\n",
            "Epoch: 50 | Batch: 111 | Loss: 0.1230662864851113\n",
            "Epoch: 50 | Batch: 112 | Loss: 0.13547416638954554\n",
            "Epoch: 50 | Batch: 113 | Loss: 0.10173532229626572\n",
            "Epoch: 50 | Batch: 114 | Loss: 0.09389174128375904\n",
            "Epoch: 50 | Batch: 115 | Loss: 0.11956952180982688\n",
            "Epoch: 50 | Batch: 116 | Loss: 0.08707901698047527\n",
            "Epoch: 50 | Batch: 117 | Loss: 0.15741371070599777\n",
            "Epoch: 50 | Batch: 118 | Loss: 0.0991891496743178\n",
            "Epoch: 50 | Batch: 119 | Loss: 0.13522297693681928\n",
            "Epoch: 50 | Batch: 120 | Loss: 0.15248981236730974\n",
            "Epoch: 50 | Batch: 121 | Loss: 0.13244605180591879\n",
            "Epoch: 50 | Batch: 122 | Loss: 0.10709222470299291\n",
            "Epoch: 50 | Batch: 123 | Loss: 0.11044462518435211\n",
            "Epoch: 50 | Batch: 124 | Loss: 0.15816395960813384\n",
            "Epoch: 50 | Batch: 125 | Loss: 0.10188702872668443\n",
            "Epoch: 50 | Batch: 126 | Loss: 0.13548859648479541\n",
            "Epoch: 50 | Batch: 127 | Loss: 0.09729261821318261\n",
            "Epoch: 50 | Batch: 128 | Loss: 0.1120407267341492\n",
            "Epoch: 50 | Batch: 129 | Loss: 0.12105222009841905\n",
            "Epoch: 50 | Batch: 130 | Loss: 0.10934156203420775\n",
            "Epoch: 50 | Batch: 131 | Loss: 0.09354177462829694\n",
            "Epoch: 50 | Batch: 132 | Loss: 0.15526856488108823\n",
            "Epoch: 50 | Batch: 133 | Loss: 0.14808982002715465\n",
            "Epoch: 50 | Batch: 134 | Loss: 0.10844914826411023\n",
            "Epoch: 50 | Batch: 135 | Loss: 0.14512705179055127\n",
            "Epoch: 50 | Batch: 136 | Loss: 0.1528050923871188\n",
            "Epoch: 50 | Batch: 137 | Loss: 0.1136562388095689\n",
            "Epoch: 50 | Batch: 138 | Loss: 0.12253820140919519\n",
            "Epoch: 50 | Batch: 139 | Loss: 0.11556852524135908\n",
            "Epoch: 50 | Batch: 140 | Loss: 0.09633133675791408\n",
            "Epoch: 50 | Batch: 141 | Loss: 0.12825363781061355\n",
            "Epoch: 50 | Batch: 142 | Loss: 0.11899163967408233\n",
            "Epoch: 50 | Batch: 143 | Loss: 0.10979305979626319\n",
            "Epoch: 50 | Batch: 144 | Loss: 0.1060879916014554\n",
            "Epoch: 50 | Batch: 145 | Loss: 0.11474885478115943\n",
            "Epoch: 50 | Batch: 146 | Loss: 0.1054124627787587\n",
            "Epoch: 50 | Batch: 147 | Loss: 0.11244132542645155\n",
            "Epoch: 50 | Batch: 148 | Loss: 0.10643186439888216\n",
            "Epoch: 50 | Batch: 149 | Loss: 0.13056412142351428\n",
            "Epoch: 50 | Batch: 150 | Loss: 0.11854850333264626\n",
            "Epoch: 50 | Batch: 151 | Loss: 0.15595551562319002\n",
            "Epoch: 50 | Batch: 152 | Loss: 0.12053978945932911\n",
            "Epoch: 50 | Batch: 153 | Loss: 0.12446066929458924\n",
            "Epoch: 50 | Batch: 154 | Loss: 0.09883659485478556\n",
            "Epoch: 50 | Batch: 155 | Loss: 0.14008999598707467\n",
            "Epoch: 50 | Batch: 156 | Loss: 0.11130258759182027\n",
            "Epoch: 50 | Batch: 157 | Loss: 0.1310057038441078\n",
            "Epoch: 50 | Batch: 158 | Loss: 0.12676017079961835\n",
            "Epoch: 50 | Batch: 159 | Loss: 0.14163890379737576\n",
            "Epoch: 50 | Batch: 160 | Loss: 0.11988702258690688\n",
            "Epoch: 50 | Batch: 161 | Loss: 0.09938702309671996\n",
            "Epoch: 50 | Batch: 162 | Loss: 0.07482698859837722\n",
            "Epoch: 50 | Batch: 163 | Loss: 0.10855371842966814\n",
            "Epoch: 50 | Batch: 164 | Loss: 0.11516478649057527\n",
            "Epoch: 50 | Batch: 165 | Loss: 0.09547487689576287\n",
            "Epoch: 50 | Batch: 166 | Loss: 0.13058986121724842\n",
            "Epoch: 50 | Batch: 167 | Loss: 0.09835026616598702\n",
            "Epoch: 50 | Batch: 168 | Loss: 0.10427805646986357\n",
            "Epoch: 50 | Batch: 169 | Loss: 0.12256234190851165\n",
            "Epoch: 50 | Batch: 170 | Loss: 0.10494732283439248\n",
            "Epoch: 50 | Batch: 171 | Loss: 0.09451399758546569\n",
            "Epoch: 50 | Batch: 172 | Loss: 0.08790892275795387\n",
            "Epoch: 50 | Batch: 173 | Loss: 0.09377284263739533\n",
            "Epoch: 50 | Batch: 174 | Loss: 0.09628853915006905\n",
            "Epoch: 50 | Batch: 175 | Loss: 0.08543241657026553\n",
            "Epoch: 50 | Batch: 176 | Loss: 0.09886746752875214\n",
            "Epoch: 50 | Batch: 177 | Loss: 0.10349218815081547\n",
            "Epoch: 50 | Batch: 178 | Loss: 0.11104401399354884\n",
            "Epoch: 50 | Batch: 179 | Loss: 0.07954170122764606\n",
            "Epoch: 50 | Batch: 180 | Loss: 0.09613507089966913\n",
            "Epoch: 50 | Batch: 181 | Loss: 0.07277898359275231\n",
            "Epoch: 50 | Batch: 182 | Loss: 0.07565991662840205\n",
            "Epoch: 50 | Batch: 183 | Loss: 0.07787921941785717\n",
            "Epoch: 50 | Batch: 184 | Loss: 0.11183366540887993\n",
            "Epoch: 50 | Batch: 185 | Loss: 0.09880358795230304\n",
            "Epoch: 50 | Batch: 186 | Loss: 0.0645440528282515\n",
            "Epoch: 50 | Batch: 187 | Loss: 0.08973359156964872\n",
            "Epoch: 50 | Batch: 188 | Loss: 0.10475632565835194\n",
            "Epoch: 50 | Batch: 189 | Loss: 0.09889095022072768\n",
            "Epoch: 50 | Batch: 190 | Loss: 0.07594545609126166\n",
            "Epoch: 50 | Batch: 191 | Loss: 0.09464654758030389\n",
            "Epoch: 50 | Batch: 192 | Loss: 0.08585509825676756\n",
            "Epoch: 50 | Batch: 193 | Loss: 0.11705075455398513\n",
            "Epoch: 50 | Batch: 194 | Loss: 0.079111688012268\n",
            "Epoch: 50 | Batch: 195 | Loss: 0.11173587536815247\n",
            "Epoch: 50 | Batch: 196 | Loss: 0.0934508597965355\n",
            "Epoch: 50 | Batch: 197 | Loss: 0.07964869980815195\n",
            "Epoch: 50 | Batch: 198 | Loss: 0.07634676584233477\n",
            "Epoch: 50 | Batch: 199 | Loss: 0.09501713098423839\n",
            "Epoch: 50 | Batch: 200 | Loss: 0.07677815382871928\n",
            "Epoch: 50 | Batch: 201 | Loss: 0.10385534503034566\n",
            "Epoch: 50 | Batch: 202 | Loss: 0.09969496366716973\n",
            "Epoch: 50 | Batch: 203 | Loss: 0.10797432236291023\n",
            "Epoch: 50 | Batch: 204 | Loss: 0.1012688646463232\n",
            "Epoch: 50 | Batch: 205 | Loss: 0.10015356097535842\n",
            "Epoch: 50 | Batch: 206 | Loss: 0.12256872743317086\n",
            "Epoch: 50 | Batch: 207 | Loss: 0.11971780556394468\n",
            "Epoch: 50 | Batch: 208 | Loss: 0.09457488669403624\n",
            "Epoch: 50 | Batch: 209 | Loss: 0.10102490623295267\n",
            "Epoch: 50 | Batch: 210 | Loss: 0.10916761077391311\n",
            "Epoch: 50 | Batch: 211 | Loss: 0.11365822731648374\n",
            "Epoch: 50 | Batch: 212 | Loss: 0.08475436813939645\n",
            "Epoch: 50 | Batch: 213 | Loss: 0.07686026141953045\n",
            "Epoch: 50 | Batch: 214 | Loss: 0.09371281056321434\n",
            "Epoch: 50 | Batch: 215 | Loss: 0.12683761873875116\n",
            "Epoch: 50 | Batch: 216 | Loss: 0.11199800512284844\n",
            "Epoch: 50 | Batch: 217 | Loss: 0.12047207291578316\n",
            "Epoch: 50 | Batch: 218 | Loss: 0.07405872514555491\n",
            "Epoch: 50 | Batch: 219 | Loss: 0.12110913867838033\n",
            "Epoch: 50 | Batch: 220 | Loss: 0.09619194999602715\n",
            "Epoch: 50 | Batch: 221 | Loss: 0.08031254235407609\n",
            "Epoch: 50 | Batch: 222 | Loss: 0.12126764335098447\n",
            "Epoch: 50 | Batch: 223 | Loss: 0.07923027585854148\n",
            "Epoch: 50 | Batch: 224 | Loss: 0.09748558252450151\n",
            "Epoch: 50 | Batch: 225 | Loss: 0.08390065842041597\n",
            "Epoch: 50 | Batch: 226 | Loss: 0.07589143464432956\n",
            "Epoch: 50 | Batch: 227 | Loss: 0.09173554704325695\n",
            "Epoch: 50 | Batch: 228 | Loss: 0.0882703418509613\n",
            "Epoch: 50 | Batch: 229 | Loss: 0.08930509484698293\n",
            "Epoch: 50 | Batch: 230 | Loss: 0.10569598775975558\n",
            "Epoch: 50 | Batch: 231 | Loss: 0.10537188861108077\n",
            "Epoch: 50 | Batch: 232 | Loss: 0.10476474524607554\n",
            "Epoch: 50 | Batch: 233 | Loss: 0.11298668203787451\n",
            "Epoch: 50 | Batch: 234 | Loss: 0.09040435379142522\n",
            "Epoch: 50 | Batch: 235 | Loss: 0.14428237459657697\n",
            "Epoch: 50 | Batch: 236 | Loss: 0.07830688930537626\n",
            "Epoch: 50 | Batch: 237 | Loss: 0.08489344086152578\n",
            "Epoch: 50 | Batch: 238 | Loss: 0.10785269618858687\n",
            "Epoch: 50 | Batch: 239 | Loss: 0.08956195937222422\n",
            "Epoch: 50 | Batch: 240 | Loss: 0.08162181615820208\n",
            "Epoch: 50 | Batch: 241 | Loss: 0.09065577057512336\n",
            "Epoch: 50 | Batch: 242 | Loss: 0.09467639601305247\n",
            "Epoch: 50 | Batch: 243 | Loss: 0.10889043217183877\n",
            "Epoch: 50 | Batch: 244 | Loss: 0.0869711580765663\n",
            "Epoch: 50 | Batch: 245 | Loss: 0.08060666940847512\n",
            "Epoch: 50 | Batch: 246 | Loss: 0.059002685013220674\n",
            "Epoch: 50 | Batch: 247 | Loss: 0.08853065672872693\n",
            "Epoch: 50 | Batch: 248 | Loss: 0.060880692671479754\n",
            "Epoch: 50 | Batch: 249 | Loss: 0.08139135507252232\n",
            "Epoch: 50 | Batch: 250 | Loss: 0.0984281105367305\n",
            "Epoch: 50 | Batch: 251 | Loss: 0.1109936052130233\n",
            "Epoch: 50 | Batch: 252 | Loss: 0.10176509483115305\n",
            "Epoch: 50 | Batch: 253 | Loss: 0.10816930357458174\n",
            "Epoch: 50 | Batch: 254 | Loss: 0.1355707694753704\n",
            "Epoch: 50 | Batch: 255 | Loss: 0.13024152989950621\n",
            "Epoch: 50 | Batch: 256 | Loss: 0.14214820615804097\n",
            "Epoch: 50 | Batch: 257 | Loss: 0.15015727241818405\n",
            "Epoch: 50 | Batch: 258 | Loss: 0.09361202563336429\n",
            "Epoch: 50 | Batch: 259 | Loss: 0.1729603722528122\n",
            "Epoch: 50 | Batch: 260 | Loss: 0.14964754204679054\n",
            "Epoch: 50 | Batch: 261 | Loss: 0.12422213586860799\n",
            "Epoch: 50 | Batch: 262 | Loss: 0.15310084989789652\n",
            "Epoch: 50 | Batch: 263 | Loss: 0.16115456683981058\n",
            "Epoch: 50 | Batch: 264 | Loss: 0.17499942252687617\n",
            "Epoch: 50 | Batch: 265 | Loss: 0.15434259009658063\n",
            "Epoch: 50 | Batch: 266 | Loss: 0.13216046789638491\n",
            "Epoch: 50 | Batch: 267 | Loss: 0.12140288757598808\n",
            "Epoch: 50 | Batch: 268 | Loss: 0.15696862886722224\n",
            "Epoch: 50 | Batch: 269 | Loss: 0.11264081005084237\n",
            "Epoch: 50 | Batch: 270 | Loss: 0.11428088500589814\n",
            "Epoch: 50 | Batch: 271 | Loss: 0.09307893678377652\n",
            "Epoch: 50 | Batch: 272 | Loss: 0.11348154224913083\n",
            "Epoch: 50 | Batch: 273 | Loss: 0.10294831493524546\n",
            "Epoch: 50 | Batch: 274 | Loss: 0.08503717493214542\n",
            "Epoch: 50 | Batch: 275 | Loss: 0.10024770469761424\n",
            "Epoch: 50 | Batch: 276 | Loss: 0.10469799069295435\n",
            "Epoch: 50 | Batch: 277 | Loss: 0.1154063753901112\n",
            "Epoch: 50 | Batch: 278 | Loss: 0.11733009432664268\n",
            "Epoch: 50 | Batch: 279 | Loss: 0.1846389087014333\n",
            "Epoch: 50 | Batch: 280 | Loss: 0.1257257300932494\n",
            "Epoch: 50 | Batch: 281 | Loss: 0.10405522653324821\n",
            "Epoch: 50 | Batch: 282 | Loss: 0.13959250002891443\n",
            "Epoch: 50 | Batch: 283 | Loss: 0.09809726107753752\n",
            "Epoch: 50 | Batch: 284 | Loss: 0.07844898265560094\n",
            "Epoch: 50 | Batch: 285 | Loss: 0.08897090365440638\n",
            "Epoch: 50 | Batch: 286 | Loss: 0.104949968058765\n",
            "Epoch: 50 | Batch: 287 | Loss: 0.09500154138902239\n",
            "Epoch: 50 | Batch: 288 | Loss: 0.08906320193054182\n",
            "Epoch: 50 | Batch: 289 | Loss: 0.12842775629457492\n",
            "Epoch: 50 | Batch: 290 | Loss: 0.11898277480041453\n",
            "Epoch: 50 | Batch: 291 | Loss: 0.1016967101154809\n",
            "Epoch: 50 | Batch: 292 | Loss: 0.19013022399049367\n",
            "Epoch: 50 | Batch: 293 | Loss: 0.1107852561746356\n",
            "Epoch: 50 | Batch: 294 | Loss: 0.09077529774570021\n",
            "Epoch: 50 | Batch: 295 | Loss: 0.09725397078850213\n",
            "Epoch: 50 | Batch: 296 | Loss: 0.0957017126300729\n",
            "Epoch: 50 | Batch: 297 | Loss: 0.11771437088047582\n",
            "Epoch: 50 | Batch: 298 | Loss: 0.09363212852719244\n",
            "Epoch: 50 | Batch: 299 | Loss: 0.13654294584584584\n",
            "Epoch: 50 | Batch: 300 | Loss: 0.1345360616102905\n",
            "Epoch: 50 | Batch: 301 | Loss: 0.12203505471757072\n",
            "Epoch: 50 | Batch: 302 | Loss: 0.11279929874629382\n",
            "Epoch: 50 | Batch: 303 | Loss: 0.11907122453441364\n",
            "Epoch: 50 | Batch: 304 | Loss: 0.11302720834923671\n",
            "Epoch: 50 | Batch: 305 | Loss: 0.1293115239175464\n",
            "Epoch: 50 | Batch: 306 | Loss: 0.125196371736166\n",
            "Epoch: 50 | Batch: 307 | Loss: 0.10223771603779862\n",
            "Epoch: 50 | Batch: 308 | Loss: 0.1286970781704945\n",
            "Epoch: 50 | Batch: 309 | Loss: 0.14216785664366227\n",
            "Epoch: 50 | Batch: 310 | Loss: 0.0884324240620302\n",
            "Epoch: 50 | Batch: 311 | Loss: 0.09417060227758929\n",
            "Epoch: 50 | Batch: 312 | Loss: 0.12419664912806061\n",
            "Epoch: 50 | Batch: 313 | Loss: 0.12251617101680959\n",
            "Epoch: 50 | Batch: 314 | Loss: 0.13461192995223287\n",
            "Epoch: 50 | Batch: 315 | Loss: 0.10640237050467524\n",
            "Epoch: 50 | Batch: 316 | Loss: 0.11039863166172882\n",
            "Epoch: 50 | Batch: 317 | Loss: 0.10914679535190502\n",
            "Epoch: 50 | Batch: 318 | Loss: 0.16372178102280277\n",
            "Epoch: 50 | Batch: 319 | Loss: 0.09621948124267593\n",
            "Epoch: 50 | Batch: 320 | Loss: 0.07237050331997058\n",
            "Epoch: 50 | Batch: 321 | Loss: 0.09750227954969051\n",
            "Epoch: 50 | Batch: 322 | Loss: 0.11355580660314141\n",
            "Epoch: 50 | Batch: 323 | Loss: 0.07060844830513688\n",
            "Epoch: 50 | Batch: 324 | Loss: 0.09174511857388802\n",
            "Epoch: 50 | Batch: 325 | Loss: 0.105626810439787\n",
            "Epoch: 50 | Batch: 326 | Loss: 0.09797439144653938\n",
            "Epoch: 50 | Batch: 327 | Loss: 0.10910845877855488\n",
            "Epoch: 50 | Batch: 328 | Loss: 0.08895863234584644\n",
            "Epoch: 50 | Batch: 329 | Loss: 0.0778946750477045\n",
            "Epoch: 50 | Batch: 330 | Loss: 0.10716801723907976\n",
            "Epoch: 50 | Batch: 331 | Loss: 0.08555087147584495\n",
            "Epoch: 50 | Batch: 332 | Loss: 0.07468797391811585\n",
            "Epoch: 50 | Batch: 333 | Loss: 0.08265899619298642\n",
            "Epoch: 50 | Batch: 334 | Loss: 0.0928631755974742\n",
            "Epoch: 50 | Batch: 335 | Loss: 0.08341224820289367\n",
            "Epoch: 50 | Batch: 336 | Loss: 0.09921899530018599\n",
            "Epoch: 50 | Batch: 337 | Loss: 0.09470565336912096\n",
            "Epoch: 50 | Batch: 338 | Loss: 0.10167673214831582\n",
            "Epoch: 50 | Batch: 339 | Loss: 0.07635396228856153\n",
            "Epoch: 50 | Batch: 340 | Loss: 0.09100784298646925\n",
            "Epoch: 50 | Batch: 341 | Loss: 0.07583188703314155\n",
            "Epoch: 50 | Batch: 342 | Loss: 0.09437836750019617\n",
            "Epoch: 50 | Batch: 343 | Loss: 0.10317299382726747\n",
            "Epoch: 50 | Batch: 344 | Loss: 0.13175530414790249\n",
            "Epoch: 50 | Batch: 345 | Loss: 0.07949936747397801\n",
            "Epoch: 50 | Batch: 346 | Loss: 0.13921710287107672\n",
            "Epoch: 50 | Batch: 347 | Loss: 0.07372466767883987\n",
            "Epoch: 50 | Batch: 348 | Loss: 0.13558806940249635\n",
            "Epoch: 50 | Batch: 349 | Loss: 0.1580196780812384\n",
            "Epoch: 50 | Batch: 350 | Loss: 0.09000997023499951\n",
            "Epoch: 50 | Batch: 351 | Loss: 0.12367217009166387\n",
            "Epoch: 50 | Batch: 352 | Loss: 0.10358001790540353\n",
            "Epoch: 50 | Batch: 353 | Loss: 0.10694364888541474\n",
            "Epoch: 50 | Batch: 354 | Loss: 0.10391678081146072\n",
            "Epoch: 50 | Batch: 355 | Loss: 0.10609113861435819\n",
            "Epoch: 50 | Batch: 356 | Loss: 0.12855803116853098\n",
            "Epoch: 50 | Batch: 357 | Loss: 0.1307165555779798\n",
            "Epoch: 50 | Batch: 358 | Loss: 0.10633225569544508\n",
            "Epoch: 50 | Batch: 359 | Loss: 0.09824800973965811\n",
            "Epoch: 50 | Batch: 360 | Loss: 0.11206869726941149\n",
            "Epoch: 50 | Batch: 361 | Loss: 0.11210714887278868\n",
            "Epoch: 50 | Batch: 362 | Loss: 0.08107456286872865\n",
            "Epoch: 50 | Batch: 363 | Loss: 0.09821277245853748\n",
            "Epoch: 50 | Batch: 364 | Loss: 0.07287655787955957\n",
            "Epoch: 50 | Batch: 365 | Loss: 0.1080770381805286\n",
            "Epoch: 50 | Batch: 366 | Loss: 0.10292925774145575\n",
            "Epoch: 50 | Batch: 367 | Loss: 0.07197642356774173\n",
            "Epoch: 50 | Batch: 368 | Loss: 0.10490433527022863\n",
            "Epoch: 50 | Batch: 369 | Loss: 0.1272950820464829\n",
            "Epoch: 50 | Batch: 370 | Loss: 0.10519679704054283\n",
            "Epoch: 50 | Batch: 371 | Loss: 0.12255087057565824\n",
            "Epoch: 50 | Batch: 372 | Loss: 0.10451001072392224\n",
            "Epoch: 50 | Batch: 373 | Loss: 0.11837323583326437\n",
            "Epoch: 50 | Batch: 374 | Loss: 0.11671889809853438\n",
            "Epoch: 50 | Batch: 375 | Loss: 0.10176163864106907\n",
            "Epoch: 50 | Batch: 376 | Loss: 0.13013324507163643\n",
            "Epoch: 50 | Batch: 377 | Loss: 0.1116776755637062\n",
            "Epoch: 50 | Batch: 378 | Loss: 0.12345688980871675\n",
            "Epoch: 50 | Batch: 379 | Loss: 0.0867208922016998\n",
            "Epoch: 50 | Batch: 380 | Loss: 0.22768579324339122\n",
            "Epoch: 50 | Batch: 381 | Loss: 0.10887216071275255\n",
            "Epoch: 50 | Batch: 382 | Loss: 0.14094783705635933\n",
            "Epoch: 50 | Batch: 383 | Loss: 0.16747497576126114\n",
            "Epoch: 50 | Batch: 384 | Loss: 0.12954184172835176\n",
            "Epoch: 50 | Batch: 385 | Loss: 0.15779442621094664\n",
            "Epoch: 50 | Batch: 386 | Loss: 0.1351256345112818\n",
            "Epoch: 50 | Batch: 387 | Loss: 0.10618374062755995\n",
            "Epoch: 50 | Batch: 388 | Loss: 0.12895432639384574\n",
            "Epoch: 50 | Batch: 389 | Loss: 0.13182385216249254\n",
            "Epoch: 50 | Batch: 390 | Loss: 0.1338717695073987\n",
            "Epoch: 50 | Batch: 391 | Loss: 0.10952052271216269\n",
            "Epoch: 50 | Batch: 392 | Loss: 0.15391117421578188\n",
            "Epoch: 50 | Batch: 393 | Loss: 0.13398195756244896\n",
            "Epoch: 50 | Batch: 394 | Loss: 0.10317127941042809\n",
            "Epoch: 50 | Batch: 395 | Loss: 0.1522465307999139\n",
            "Epoch: 50 | Batch: 396 | Loss: 0.13241656494658735\n",
            "Epoch: 50 | Batch: 397 | Loss: 0.14547732537681157\n",
            "Epoch: 50 | Batch: 398 | Loss: 0.13333950642222836\n",
            "Epoch: 50 | Batch: 399 | Loss: 0.11226712600323996\n",
            "Epoch: 50 | Batch: 400 | Loss: 0.10093515561841199\n",
            "Epoch: 50 | Batch: 401 | Loss: 0.1040546162674049\n",
            "Epoch: 50 | Batch: 402 | Loss: 0.0777442704190029\n",
            "Epoch: 50 | Batch: 403 | Loss: 0.09231076556281911\n",
            "Epoch: 50 | Batch: 404 | Loss: 0.10712162691179758\n",
            "Epoch: 50 | Batch: 405 | Loss: 0.11227842673666491\n",
            "Epoch: 50 | Batch: 406 | Loss: 0.10727811262810877\n",
            "Epoch: 50 | Batch: 407 | Loss: 0.09445377123816215\n",
            "Epoch: 50 | Batch: 408 | Loss: 0.10097846488910514\n",
            "Epoch: 50 | Batch: 409 | Loss: 0.1055563808010723\n",
            "Epoch: 50 | Batch: 410 | Loss: 0.09578839314512269\n",
            "Epoch: 50 | Batch: 411 | Loss: 0.08463056983468498\n",
            "Epoch: 50 | Batch: 412 | Loss: 0.08060418847719229\n",
            "Epoch: 50 | Batch: 413 | Loss: 0.10307343794848295\n",
            "Epoch: 50 | Batch: 414 | Loss: 0.07579758298775774\n",
            "Epoch: 50 | Batch: 415 | Loss: 0.08007745179055223\n",
            "Epoch: 50 | Batch: 416 | Loss: 0.09591064338001686\n",
            "Epoch: 50 | Batch: 417 | Loss: 0.09933482540741428\n",
            "Epoch: 50 | Batch: 418 | Loss: 0.09099548919535685\n",
            "Epoch: 50 | Batch: 419 | Loss: 0.08929801125916427\n",
            "Epoch: 50 | Batch: 420 | Loss: 0.09022710439894335\n",
            "Epoch: 50 | Batch: 421 | Loss: 0.06385027399916599\n",
            "Epoch: 50 | Batch: 422 | Loss: 0.1461675519718075\n",
            "Epoch: 50 | Batch: 423 | Loss: 0.06736141856654584\n",
            "Epoch: 50 | Batch: 424 | Loss: 0.09461429288829469\n",
            "Epoch: 50 | Batch: 425 | Loss: 0.1043012292050055\n",
            "Epoch: 50 | Batch: 426 | Loss: 0.07386987686212793\n",
            "Epoch: 50 | Batch: 427 | Loss: 0.1064573340091674\n",
            "Epoch: 50 | Batch: 428 | Loss: 0.07269600971871223\n",
            "Epoch: 50 | Batch: 429 | Loss: 0.06856628754158348\n",
            "Epoch: 50 | Batch: 430 | Loss: 0.088762736719318\n",
            "Epoch: 50 | Batch: 431 | Loss: 0.09013808716994225\n",
            "Epoch: 50 | Batch: 432 | Loss: 0.09270237338428006\n",
            "Epoch: 50 | Batch: 433 | Loss: 0.09028444206454364\n",
            "Epoch: 50 | Batch: 434 | Loss: 0.07261928138858714\n",
            "Epoch: 50 | Batch: 435 | Loss: 0.07688097303411218\n",
            "Epoch: 50 | Batch: 436 | Loss: 0.1135603635294277\n",
            "Epoch: 50 | Batch: 437 | Loss: 0.07576700022303455\n",
            "Epoch: 50 | Batch: 438 | Loss: 0.11358078813145722\n",
            "Epoch: 50 | Batch: 439 | Loss: 0.10110582245161576\n",
            "Epoch: 50 | Batch: 440 | Loss: 0.0870101715953801\n",
            "Epoch: 50 | Batch: 441 | Loss: 0.09713471851402293\n",
            "Epoch: 50 | Batch: 442 | Loss: 0.08879162569748592\n",
            "Epoch: 50 | Batch: 443 | Loss: 0.09808091786845562\n",
            "Epoch: 50 | Batch: 444 | Loss: 0.1343742562949762\n",
            "Epoch: 50 | Batch: 445 | Loss: 0.12502638824463394\n",
            "Epoch: 50 | Batch: 446 | Loss: 0.11042830077911185\n",
            "Epoch: 50 | Batch: 447 | Loss: 0.1340590085241654\n",
            "Epoch: 50 | Batch: 448 | Loss: 0.12758522290605745\n",
            "Epoch: 50 | Batch: 449 | Loss: 0.11725714255381396\n",
            "Epoch: 50 | Batch: 450 | Loss: 0.11948492951217106\n",
            "Epoch: 50 | Batch: 451 | Loss: 0.09747744637745384\n",
            "Epoch: 50 | Batch: 452 | Loss: 0.1324017001901162\n",
            "Epoch: 50 | Batch: 453 | Loss: 0.12074622335749616\n",
            "Epoch: 50 | Batch: 454 | Loss: 0.10429407768037777\n",
            "Epoch: 50 | Batch: 455 | Loss: 0.11671147490220701\n",
            "Epoch: 50 | Batch: 456 | Loss: 0.09848273581444147\n",
            "Epoch: 50 | Batch: 457 | Loss: 0.08147091643703085\n",
            "Epoch: 50 | Batch: 458 | Loss: 0.11928016104494757\n",
            "Epoch: 50 | Batch: 459 | Loss: 0.1052305308467788\n",
            "Epoch: 50 | Batch: 460 | Loss: 0.10502991545988889\n",
            "Epoch: 50 | Batch: 461 | Loss: 0.12049128444375609\n",
            "Epoch: 50 | Batch: 462 | Loss: 0.129595202616542\n",
            "Epoch: 50 | Batch: 463 | Loss: 0.09639244236598205\n",
            "Epoch: 50 | Batch: 464 | Loss: 0.10340572629465586\n",
            "Epoch: 50 | Batch: 465 | Loss: 0.10880721528544118\n",
            "Epoch: 50 | Batch: 466 | Loss: 0.11747885522132835\n",
            "Epoch: 50 | Batch: 467 | Loss: 0.13515955849490335\n",
            "Epoch: 50 | Batch: 468 | Loss: 0.13369125184462982\n",
            "Epoch: 50 | Batch: 469 | Loss: 0.08850123995939876\n",
            "Epoch: 50 | Batch: 470 | Loss: 0.10237550570072085\n",
            "Epoch: 50 | Batch: 471 | Loss: 0.08694216049471086\n",
            "Epoch: 50 | Batch: 472 | Loss: 0.12026302834010467\n",
            "Epoch: 50 | Batch: 473 | Loss: 0.08914299775240922\n",
            "Epoch: 50 | Batch: 474 | Loss: 0.10196522411758521\n",
            "Epoch: 50 | Batch: 475 | Loss: 0.07997202281222104\n",
            "Epoch: 50 | Batch: 476 | Loss: 0.08699433853611852\n",
            "Epoch: 50 | Batch: 477 | Loss: 0.07271936966902692\n",
            "Epoch: 50 | Batch: 478 | Loss: 0.084716053639489\n",
            "Epoch: 50 | Batch: 479 | Loss: 0.11303584934069226\n",
            "Epoch: 50 | Batch: 480 | Loss: 0.0774921172927486\n",
            "Epoch: 50 | Batch: 481 | Loss: 0.0834426108730148\n",
            "Epoch: 50 | Batch: 482 | Loss: 0.0781017432074427\n",
            "Epoch: 50 | Batch: 483 | Loss: 0.09869005658744567\n",
            "Epoch: 50 | Batch: 484 | Loss: 0.11431064881371926\n",
            "Epoch: 50 | Batch: 485 | Loss: 0.08890404341927657\n",
            "Epoch: 50 | Batch: 486 | Loss: 0.1277169946854609\n",
            "Epoch: 50 | Batch: 487 | Loss: 0.15174614087223476\n",
            "Epoch: 50 | Batch: 488 | Loss: 0.09363321457082874\n",
            "Epoch: 50 | Batch: 489 | Loss: 0.1339804161865114\n",
            "Epoch: 50 | Batch: 490 | Loss: 0.10262457035129205\n",
            "Epoch: 50 | Batch: 491 | Loss: 0.07959331207249556\n",
            "Epoch: 50 | Batch: 492 | Loss: 0.07793240058421932\n",
            "Epoch: 50 | Batch: 493 | Loss: 0.08528973973398354\n",
            "Epoch: 50 | Batch: 494 | Loss: 0.11732847411141736\n",
            "Epoch: 50 | Batch: 495 | Loss: 0.09113632645713121\n",
            "Epoch: 50 | Batch: 496 | Loss: 0.08287486888322276\n",
            "Epoch: 50 | Batch: 497 | Loss: 0.0695534396010252\n",
            "Epoch: 50 | Batch: 498 | Loss: 0.08923952178793153\n",
            "Epoch: 50 | Batch: 499 | Loss: 0.0798439919636236\n",
            "Epoch: 50 | Batch: 500 | Loss: 0.063893404642692\n",
            "Epoch: 50 | Batch: 501 | Loss: 0.07868766159698447\n",
            "Epoch: 50 | Batch: 502 | Loss: 0.09765864756405895\n",
            "Epoch: 50 | Batch: 503 | Loss: 0.06226339173864953\n",
            "Epoch: 50 | Batch: 504 | Loss: 0.10442484562800823\n",
            "Epoch: 50 | Batch: 505 | Loss: 0.09527969979018835\n",
            "Epoch: 50 | Batch: 506 | Loss: 0.09244811760935252\n",
            "Epoch: 50 | Batch: 507 | Loss: 0.1132317337859136\n",
            "Epoch: 50 | Batch: 508 | Loss: 0.09808009553375878\n",
            "Epoch: 50 | Batch: 509 | Loss: 0.14297985469221597\n",
            "Epoch: 50 | Batch: 510 | Loss: 0.11771557814935235\n",
            "Epoch: 50 | Batch: 511 | Loss: 0.09295099320707398\n",
            "Epoch: 50 | Batch: 512 | Loss: 0.10961999511288875\n",
            "Epoch: 50 | Batch: 513 | Loss: 0.09483037491119084\n",
            "Epoch: 50 | Batch: 514 | Loss: 0.079808601250309\n",
            "Epoch: 50 | Batch: 515 | Loss: 0.10917380580556614\n",
            "Epoch: 50 | Batch: 516 | Loss: 0.10590745734611558\n",
            "Epoch: 50 | Batch: 517 | Loss: 0.10535314970141511\n",
            "Epoch: 50 | Batch: 518 | Loss: 0.11506488646611973\n",
            "Epoch: 50 | Batch: 519 | Loss: 0.16298042110880284\n",
            "Epoch: 50 | Batch: 520 | Loss: 0.12276125041781975\n",
            "Epoch: 50 | Batch: 521 | Loss: 0.13173964451784165\n",
            "Epoch: 50 | Batch: 522 | Loss: 0.09783480483055121\n",
            "Epoch: 50 | Batch: 523 | Loss: 0.1083668345124358\n",
            "Epoch: 50 | Batch: 524 | Loss: 0.09377461497097431\n",
            "Epoch: 50 | Batch: 525 | Loss: 0.0970624438590812\n",
            "Epoch: 50 | Batch: 526 | Loss: 0.13799121142370552\n",
            "Epoch: 50 | Batch: 527 | Loss: 0.1103079758891164\n",
            "Epoch: 50 | Batch: 528 | Loss: 0.10868312613763435\n",
            "Epoch: 50 | Batch: 529 | Loss: 0.14406196922611425\n",
            "Epoch: 50 | Batch: 530 | Loss: 0.1689678633634636\n",
            "Epoch: 50 | Batch: 531 | Loss: 0.15716919981430502\n",
            "Epoch: 50 | Batch: 532 | Loss: 0.17270989669522613\n",
            "Epoch: 50 | Batch: 533 | Loss: 0.1362955283036296\n",
            "Epoch: 50 | Batch: 534 | Loss: 0.14171710619555736\n",
            "Epoch: 50 | Batch: 535 | Loss: 0.10730555070876438\n",
            "Epoch: 50 | Batch: 536 | Loss: 0.11962441793855547\n",
            "Epoch: 50 | Batch: 537 | Loss: 0.11681361597622793\n",
            "Epoch: 50 | Batch: 538 | Loss: 0.09934567000204934\n",
            "Epoch: 50 | Batch: 539 | Loss: 0.19768353481883053\n",
            "Epoch: 50 | Batch: 540 | Loss: 0.13079940110606728\n",
            "Epoch: 50 | Batch: 541 | Loss: 0.10539185032138226\n",
            "Epoch: 50 | Batch: 542 | Loss: 0.13745452480345566\n",
            "Epoch: 50 | Batch: 543 | Loss: 0.1017942547314876\n",
            "Epoch: 50 | Batch: 544 | Loss: 0.09452407328645965\n",
            "Epoch: 50 | Batch: 545 | Loss: 0.0952516486605579\n",
            "Epoch: 50 | Batch: 546 | Loss: 0.09779159358049684\n",
            "Epoch: 50 | Batch: 547 | Loss: 0.13282417133271762\n",
            "Epoch: 50 | Batch: 548 | Loss: 0.1165362775137733\n",
            "Epoch: 50 | Batch: 549 | Loss: 0.09042571196601537\n",
            "Epoch: 50 | Batch: 550 | Loss: 0.08694718663536513\n",
            "Epoch: 50 | Batch: 551 | Loss: 0.0845928767155976\n",
            "Epoch: 50 | Batch: 552 | Loss: 0.11877233626198264\n",
            "Epoch: 50 | Batch: 553 | Loss: 0.09814888504648184\n",
            "Epoch: 50 | Batch: 554 | Loss: 0.13365009773400024\n",
            "Epoch: 50 | Batch: 555 | Loss: 0.162067590295978\n",
            "Epoch: 50 | Batch: 556 | Loss: 0.10422767346393616\n",
            "Epoch: 50 | Batch: 557 | Loss: 0.11210797322468388\n",
            "Epoch: 50 | Batch: 558 | Loss: 0.12529141393403428\n",
            "Epoch: 50 | Batch: 559 | Loss: 0.11916839311532194\n",
            "Epoch: 50 | Batch: 560 | Loss: 0.14212063982248757\n",
            "Epoch: 50 | Batch: 561 | Loss: 0.15805901775081585\n",
            "Epoch: 50 | Batch: 562 | Loss: 0.18682125637070124\n",
            "Epoch: 50 | Batch: 563 | Loss: 0.10954699403835982\n",
            "Epoch: 50 | Batch: 564 | Loss: 0.1386559753745917\n",
            "Epoch: 50 | Batch: 565 | Loss: 0.15513810755679502\n",
            "Epoch: 50 | Batch: 566 | Loss: 0.13310540212350627\n",
            "Epoch: 50 | Batch: 567 | Loss: 0.1138805918019759\n",
            "Epoch: 50 | Batch: 568 | Loss: 0.1553366209352883\n",
            "Epoch: 50 | Batch: 569 | Loss: 0.12712878083069395\n",
            "Epoch: 50 | Batch: 570 | Loss: 0.11771555734838181\n",
            "Epoch: 50 | Batch: 571 | Loss: 0.13836427517616035\n",
            "Epoch: 50 | Batch: 572 | Loss: 0.15613289531928354\n",
            "Epoch: 50 | Batch: 573 | Loss: 0.11812251245467209\n",
            "Epoch: 50 | Batch: 574 | Loss: 0.18000893065439402\n",
            "Epoch: 50 | Batch: 575 | Loss: 0.12357378422354064\n",
            "Epoch: 50 | Batch: 576 | Loss: 0.13016475960240473\n",
            "Epoch: 50 | Batch: 577 | Loss: 0.13543865268610708\n",
            "Epoch: 50 | Batch: 578 | Loss: 0.1438449064146016\n",
            "Epoch: 50 | Batch: 579 | Loss: 0.11769426445383059\n",
            "Epoch: 50 | Batch: 580 | Loss: 0.14016136315980346\n",
            "Epoch: 50 | Batch: 581 | Loss: 0.1420270995356641\n",
            "Epoch: 50 | Batch: 582 | Loss: 0.1111710325410844\n",
            "Epoch: 50 | Batch: 583 | Loss: 0.09912560825858371\n",
            "Epoch: 50 | Batch: 584 | Loss: 0.12891424400301937\n",
            "Epoch: 50 | Batch: 585 | Loss: 0.11231302294368227\n",
            "Epoch: 50 | Batch: 586 | Loss: 0.13739444792559413\n",
            "Epoch: 50 | Batch: 587 | Loss: 0.12715703157093203\n",
            "Epoch: 50 | Batch: 588 | Loss: 0.15908700680169777\n",
            "Epoch: 50 | Batch: 589 | Loss: 0.14032413709580815\n",
            "Epoch: 50 | Batch: 590 | Loss: 0.1471477909901316\n",
            "Epoch: 50 | Batch: 591 | Loss: 0.11135756261530655\n",
            "Epoch: 50 | Batch: 592 | Loss: 0.15405293142797463\n",
            "Epoch: 50 | Batch: 593 | Loss: 0.1280972784999955\n",
            "Epoch: 50 | Batch: 594 | Loss: 0.13525486947126075\n",
            "Epoch: 50 | Batch: 595 | Loss: 0.12225545644012523\n",
            "Epoch: 50 | Batch: 596 | Loss: 0.14778778308894291\n",
            "Epoch: 50 | Batch: 597 | Loss: 0.15688397998280196\n",
            "Epoch: 50 | Batch: 598 | Loss: 0.14709051381925314\n",
            "Epoch: 50 | Batch: 599 | Loss: 0.13698613263325407\n",
            "Epoch: 50 | Batch: 600 | Loss: 0.16203560432874098\n",
            "Epoch: 50 | Batch: 601 | Loss: 0.15308062968340255\n",
            "Epoch: 50 | Batch: 602 | Loss: 0.1482951105008439\n",
            "Epoch: 50 | Batch: 603 | Loss: 0.12505501282111525\n",
            "Epoch: 50 | Batch: 604 | Loss: 0.10708987656804231\n",
            "Epoch: 50 | Batch: 605 | Loss: 0.1330584893197389\n",
            "Epoch: 50 | Batch: 606 | Loss: 0.12972058290175767\n",
            "Epoch: 50 | Batch: 607 | Loss: 0.11273136234120698\n",
            "Epoch: 50 | Batch: 608 | Loss: 0.13018568159356164\n",
            "Epoch: 50 | Batch: 609 | Loss: 0.2794299924631264\n",
            "Epoch: 50 | Batch: 610 | Loss: 0.12860803115330027\n",
            "Epoch: 50 | Batch: 611 | Loss: 0.10387124996827304\n",
            "Epoch: 50 | Batch: 612 | Loss: 0.17363732647902236\n",
            "Epoch: 50 | Batch: 613 | Loss: 0.16352425058331438\n",
            "Epoch: 50 | Batch: 614 | Loss: 0.14073619250042207\n",
            "Epoch: 50 | Batch: 615 | Loss: 0.14163753286731612\n",
            "Epoch: 50 | Batch: 616 | Loss: 0.1515213558450867\n",
            "Epoch: 50 | Batch: 617 | Loss: 0.18204594709466243\n",
            "Epoch: 50 | Batch: 618 | Loss: 0.17563969922974498\n",
            "Epoch: 50 | Batch: 619 | Loss: 0.14878877008943608\n",
            "Epoch: 50 | Batch: 620 | Loss: 0.1270011308023147\n",
            "Epoch: 50 | Batch: 621 | Loss: 0.16156026594075207\n",
            "Epoch: 50 | Batch: 622 | Loss: 0.1438614377951692\n",
            "Epoch: 50 | Batch: 623 | Loss: 0.15217894397624687\n",
            "Epoch: 50 | Batch: 624 | Loss: 0.1337646490249304\n",
            "Epoch: 50 | Batch: 625 | Loss: 0.1795805497388852\n",
            "Epoch: 50 | Batch: 626 | Loss: 0.09547750306215419\n",
            "Epoch: 50 | Batch: 627 | Loss: 0.09719266720154679\n",
            "Epoch: 50 | Batch: 628 | Loss: 0.23869906844229907\n",
            "Epoch: 50 | Batch: 629 | Loss: 0.13064493497428936\n",
            "Epoch: 50 | Batch: 630 | Loss: 0.1788131809492569\n",
            "Epoch: 50 | Batch: 631 | Loss: 0.16958333969529127\n",
            "Epoch: 50 | Batch: 632 | Loss: 0.1575588900828339\n",
            "Epoch: 50 | Batch: 633 | Loss: 0.17126223055206963\n",
            "Epoch: 50 | Batch: 634 | Loss: 0.1581727278568571\n",
            "Epoch: 50 | Batch: 635 | Loss: 0.14945401108428136\n",
            "Epoch: 50 | Batch: 636 | Loss: 0.14394417917794167\n",
            "Epoch: 50 | Batch: 637 | Loss: 0.15057716057874032\n",
            "Epoch: 50 | Batch: 638 | Loss: 0.1258836577581875\n",
            "Epoch: 50 | Batch: 639 | Loss: 0.10856793662223926\n",
            "Epoch: 50 | Batch: 640 | Loss: 0.09994513254550569\n",
            "Epoch: 50 | Batch: 641 | Loss: 0.14291300389684358\n",
            "Epoch: 50 | Batch: 642 | Loss: 0.10627482763963367\n",
            "Epoch: 50 | Batch: 643 | Loss: 0.11871304069973343\n",
            "Epoch: 50 | Batch: 644 | Loss: 0.12994512232016603\n",
            "Epoch: 50 | Batch: 645 | Loss: 0.1443496049611366\n",
            "Epoch: 50 | Batch: 646 | Loss: 0.13378001827031757\n",
            "Epoch: 50 | Batch: 647 | Loss: 0.1455895345360114\n",
            "Epoch: 50 | Batch: 648 | Loss: 0.16069841561828785\n",
            "Epoch: 50 | Batch: 649 | Loss: 0.13344006470597086\n",
            "Epoch: 50 | Batch: 650 | Loss: 0.14562750653132883\n",
            "Epoch: 50 | Batch: 651 | Loss: 0.13201180695144657\n",
            "Epoch: 50 | Batch: 652 | Loss: 0.1624848245340711\n",
            "Epoch: 50 | Batch: 653 | Loss: 0.1119394573272305\n",
            "Epoch: 50 | Batch: 654 | Loss: 0.13534418994155245\n",
            "Epoch: 50 | Batch: 655 | Loss: 0.12880677951318958\n",
            "Epoch: 50 | Batch: 656 | Loss: 0.10931457388721992\n",
            "Epoch: 50 | Batch: 657 | Loss: 0.1298074942429534\n",
            "Epoch: 50 | Batch: 658 | Loss: 0.13731238003324617\n",
            "Epoch: 50 | Batch: 659 | Loss: 0.12496449722251181\n",
            "Epoch: 50 | Batch: 660 | Loss: 0.11703514755416591\n",
            "Epoch: 50 | Batch: 661 | Loss: 0.1212485245003593\n",
            "Epoch: 50 | Batch: 662 | Loss: 0.12261459721486258\n",
            "Epoch: 50 | Batch: 663 | Loss: 0.10195029183174195\n",
            "Epoch: 50 | Batch: 664 | Loss: 0.09440366270761848\n",
            "Epoch: 50 | Batch: 665 | Loss: 0.14717452343910664\n",
            "Epoch: 50 | Batch: 666 | Loss: 0.09770829329950231\n",
            "Epoch: 50 | Batch: 667 | Loss: 0.12427124719959581\n",
            "Epoch: 50 | Batch: 668 | Loss: 0.11971109388713694\n",
            "Epoch: 50 | Batch: 669 | Loss: 0.13475552877116603\n",
            "Epoch: 50 | Batch: 670 | Loss: 0.18731356240411975\n",
            "Epoch: 50 | Batch: 671 | Loss: 0.12806360830959299\n",
            "Epoch: 50 | Batch: 672 | Loss: 0.11298165314522113\n",
            "Epoch: 50 | Batch: 673 | Loss: 0.11790574266879889\n",
            "Epoch: 50 | Batch: 674 | Loss: 0.09919063852290844\n",
            "Epoch: 50 | Batch: 675 | Loss: 0.09210337310532886\n",
            "Epoch: 50 | Batch: 676 | Loss: 0.09241110617744638\n",
            "Epoch: 50 | Batch: 677 | Loss: 0.09930188214778528\n",
            "Epoch: 50 | Batch: 678 | Loss: 0.10381513665452047\n",
            "Epoch: 50 | Batch: 679 | Loss: 0.07836654333211873\n",
            "Epoch: 50 | Batch: 680 | Loss: 0.09885694191858332\n",
            "Epoch: 50 | Batch: 681 | Loss: 0.09840287471932546\n",
            "Epoch: 50 | Batch: 682 | Loss: 0.1055535899420503\n",
            "Epoch: 50 | Batch: 683 | Loss: 0.07881405536449673\n",
            "Epoch: 50 | Batch: 684 | Loss: 0.10648029036769008\n",
            "Epoch: 50 | Batch: 685 | Loss: 0.09811720266021064\n",
            "Epoch: 50 | Batch: 686 | Loss: 0.08798104640356491\n",
            "Epoch: 50 | Batch: 687 | Loss: 0.11776785222969804\n",
            "Epoch: 50 | Batch: 688 | Loss: 0.10755358499458936\n",
            "Epoch: 50 | Batch: 689 | Loss: 0.07912375312230463\n",
            "Epoch: 50 | Batch: 690 | Loss: 0.11259727861635774\n",
            "Epoch: 50 | Batch: 691 | Loss: 0.1088969321841041\n",
            "Epoch: 50 | Batch: 692 | Loss: 0.12081827814700369\n",
            "Epoch: 50 | Batch: 693 | Loss: 0.10388904414475789\n",
            "Epoch: 50 | Batch: 694 | Loss: 0.08718304765416787\n",
            "Epoch: 50 | Batch: 695 | Loss: 0.12269926216009025\n",
            "Epoch: 50 | Batch: 696 | Loss: 0.14129480544292475\n",
            "Epoch: 50 | Batch: 697 | Loss: 0.1321926750905217\n",
            "Epoch: 50 | Batch: 698 | Loss: 0.10266851800236551\n",
            "Epoch: 50 | Batch: 699 | Loss: 0.10640866697397425\n",
            "Epoch: 50 | Batch: 700 | Loss: 0.10670803114406974\n",
            "Epoch: 50 | Batch: 701 | Loss: 0.10183288644015001\n",
            "Epoch: 50 | Batch: 702 | Loss: 0.12906136233270074\n",
            "Epoch: 50 | Batch: 703 | Loss: 0.13564956571759382\n",
            "Epoch: 50 | Batch: 704 | Loss: 0.09481218506791904\n",
            "Epoch: 50 | Batch: 705 | Loss: 0.11403354056579205\n",
            "Epoch: 50 | Batch: 706 | Loss: 0.09360430921185281\n",
            "Epoch: 50 | Batch: 707 | Loss: 0.08635060866312486\n",
            "Epoch: 50 | Batch: 708 | Loss: 0.11836930622485128\n",
            "Epoch: 50 | Batch: 709 | Loss: 0.13101841828961247\n",
            "Epoch: 50 | Batch: 710 | Loss: 0.09671506546462516\n",
            "Epoch: 50 | Batch: 711 | Loss: 0.12939562873710297\n",
            "Epoch: 50 | Batch: 712 | Loss: 0.11668427685528794\n",
            "Epoch: 50 | Batch: 713 | Loss: 0.11441602869545112\n",
            "Epoch: 50 | Batch: 714 | Loss: 0.09329587476344109\n",
            "Epoch: 50 | Batch: 715 | Loss: 0.06481064350018231\n",
            "Epoch: 50 | Batch: 716 | Loss: 0.12099462586131446\n",
            "Epoch: 50 | Batch: 717 | Loss: 0.09481169021959676\n",
            "Epoch: 50 | Batch: 718 | Loss: 0.15863572815675991\n",
            "Epoch: 50 | Batch: 719 | Loss: 0.1750520970059566\n",
            "Epoch: 50 | Batch: 720 | Loss: 0.11280614066329525\n",
            "Epoch: 50 | Batch: 721 | Loss: 0.11917221837942987\n",
            "Epoch: 50 | Batch: 722 | Loss: 0.12123730866199184\n",
            "Epoch: 50 | Batch: 723 | Loss: 0.1207896842329124\n",
            "Epoch: 50 | Batch: 724 | Loss: 0.10925278226405775\n",
            "Epoch: 50 | Batch: 725 | Loss: 0.17104151350828195\n",
            "Epoch: 50 | Batch: 726 | Loss: 0.10889147114485515\n",
            "Epoch: 50 | Batch: 727 | Loss: 0.17591600655460182\n",
            "Epoch: 50 | Batch: 728 | Loss: 0.0951954097130691\n",
            "Epoch: 50 | Batch: 729 | Loss: 0.1850823637759429\n",
            "Epoch: 50 | Batch: 730 | Loss: 0.12509054946397882\n",
            "Epoch: 50 | Batch: 731 | Loss: 0.12206754903267962\n",
            "Epoch: 50 | Batch: 732 | Loss: 0.14990095462255773\n",
            "Epoch: 50 | Batch: 733 | Loss: 0.1232608133271555\n",
            "Epoch: 50 | Batch: 734 | Loss: 0.1054659719264685\n",
            "Epoch: 50 | Batch: 735 | Loss: 0.10299119335676332\n",
            "Epoch: 50 | Batch: 736 | Loss: 0.11302444130964984\n",
            "Epoch: 50 | Batch: 737 | Loss: 0.12624632198478805\n",
            "Epoch: 50 | Batch: 738 | Loss: 0.10245529733755254\n",
            "Epoch: 50 | Batch: 739 | Loss: 0.10087574891367596\n",
            "Epoch: 50 | Batch: 740 | Loss: 0.08535155016809853\n",
            "Epoch: 50 | Batch: 741 | Loss: 0.0927493362515856\n",
            "Epoch: 50 | Batch: 742 | Loss: 0.10386739398385891\n",
            "Epoch: 50 | Batch: 743 | Loss: 0.12957835357706668\n",
            "Epoch: 50 | Batch: 744 | Loss: 0.15749828795987747\n",
            "Epoch: 50 | Batch: 745 | Loss: 0.09640824122657171\n",
            "Epoch: 50 | Batch: 746 | Loss: 0.08394062936645075\n",
            "Epoch: 50 | Batch: 747 | Loss: 0.1007086370645118\n",
            "Epoch: 50 | Batch: 748 | Loss: 0.13009660827728192\n",
            "Epoch: 50 | Batch: 749 | Loss: 0.1082711514795634\n",
            "Epoch: 50 | Batch: 750 | Loss: 0.11093623094614716\n",
            "Epoch: 50 | Batch: 751 | Loss: 0.06962058798714867\n",
            "Epoch: 50 | Batch: 752 | Loss: 0.0965936477011943\n",
            "Epoch: 50 | Batch: 753 | Loss: 0.14634849024425706\n",
            "Epoch: 50 | Batch: 754 | Loss: 0.12663323587458447\n",
            "Epoch: 50 | Batch: 755 | Loss: 0.1192498324428293\n",
            "Epoch: 50 | Batch: 756 | Loss: 0.1286246732686032\n",
            "Epoch: 50 | Batch: 757 | Loss: 0.12114784930639082\n",
            "Epoch: 50 | Batch: 758 | Loss: 0.10668846895453601\n",
            "Epoch: 50 | Batch: 759 | Loss: 0.19803651677022416\n",
            "Epoch: 50 | Batch: 760 | Loss: 0.09892610831142326\n",
            "Epoch: 50 | Batch: 761 | Loss: 0.10784924052308052\n",
            "Epoch: 50 | Batch: 762 | Loss: 0.11846605928952876\n",
            "Epoch: 50 | Batch: 763 | Loss: 0.10228850143331314\n",
            "Epoch: 50 | Batch: 764 | Loss: 0.11363509121316026\n",
            "Epoch: 50 | Batch: 765 | Loss: 0.1505966875256576\n",
            "Epoch: 50 | Batch: 766 | Loss: 0.12004725348345832\n",
            "Epoch: 50 | Batch: 767 | Loss: 0.11635289722391234\n",
            "Epoch: 50 | Batch: 768 | Loss: 0.13862203834921627\n",
            "Epoch: 50 | Batch: 769 | Loss: 0.10966745056634813\n",
            "Epoch: 50 | Batch: 770 | Loss: 0.12170434669767935\n",
            "Epoch: 50 | Batch: 771 | Loss: 0.12268585368163838\n",
            "Epoch: 50 | Batch: 772 | Loss: 0.10345622382498287\n",
            "Epoch: 50 | Batch: 773 | Loss: 0.11189175121485795\n",
            "Epoch: 50 | Batch: 774 | Loss: 0.10530286790412928\n",
            "Epoch: 50 | Batch: 775 | Loss: 0.10944051649368894\n",
            "Epoch: 50 | Batch: 776 | Loss: 0.107862071632119\n",
            "Epoch: 50 | Batch: 777 | Loss: 0.11061331524334739\n",
            "Epoch: 50 | Batch: 778 | Loss: 0.11233452824892498\n",
            "Epoch: 50 | Batch: 779 | Loss: 0.14357257657082242\n",
            "Epoch: 50 | Batch: 780 | Loss: 0.12585724507123072\n",
            "Epoch: 50 | Batch: 781 | Loss: 0.17846917256077494\n",
            "Epoch: 50 | Batch: 782 | Loss: 0.10455331335297985\n",
            "Epoch: 50 | Batch: 783 | Loss: 0.12098431871620235\n",
            "Epoch: 50 | Batch: 784 | Loss: 0.14705922523303544\n",
            "Epoch: 50 | Batch: 785 | Loss: 0.11307263861078107\n",
            "Epoch: 50 | Batch: 786 | Loss: 0.09746301127694854\n",
            "Epoch: 50 | Batch: 787 | Loss: 0.1222524253445549\n",
            "Epoch: 50 | Batch: 788 | Loss: 0.1047773267345647\n",
            "Epoch: 50 | Batch: 789 | Loss: 0.12230599872838688\n",
            "Epoch: 50 | Batch: 790 | Loss: 0.1251853184921815\n",
            "Epoch: 50 | Batch: 791 | Loss: 0.1442864945347089\n",
            "Epoch: 50 | Batch: 792 | Loss: 0.1581408814503114\n",
            "Epoch: 50 | Batch: 793 | Loss: 0.15592805208410634\n",
            "Epoch: 50 | Batch: 794 | Loss: 0.13098001306380183\n",
            "Epoch: 50 | Batch: 795 | Loss: 0.09381274727891686\n",
            "Epoch: 50 | Batch: 796 | Loss: 0.12646255934363337\n",
            "Epoch: 50 | Batch: 797 | Loss: 0.11145021540310188\n",
            "Epoch: 50 | Batch: 798 | Loss: 0.11872591129617856\n",
            "Epoch: 50 | Batch: 799 | Loss: 0.1416010410290785\n",
            "Epoch: 50 | Batch: 800 | Loss: 0.13702627468376366\n",
            "Epoch: 50 | Batch: 801 | Loss: 0.1069063966288279\n",
            "Epoch: 50 | Batch: 802 | Loss: 0.12760460325107656\n",
            "Epoch: 50 | Batch: 803 | Loss: 0.1461001770392137\n",
            "Epoch: 50 | Batch: 804 | Loss: 0.1368068701336493\n",
            "Epoch: 50 | Batch: 805 | Loss: 0.12108574056950147\n",
            "Epoch: 50 | Batch: 806 | Loss: 0.1633070766574627\n",
            "Epoch: 50 | Batch: 807 | Loss: 0.10387058047941977\n",
            "Epoch: 50 | Batch: 808 | Loss: 0.10025356708086691\n",
            "Epoch: 50 | Batch: 809 | Loss: 0.16719711041017127\n",
            "Epoch: 50 | Batch: 810 | Loss: 0.12810471036161164\n",
            "Epoch: 50 | Batch: 811 | Loss: 0.10603630461884506\n",
            "Epoch: 50 | Batch: 812 | Loss: 0.1301388482764739\n",
            "Epoch: 50 | Batch: 813 | Loss: 0.15762949318987773\n",
            "Epoch: 50 | Batch: 814 | Loss: 0.10597386778346966\n",
            "Epoch: 50 | Batch: 815 | Loss: 0.08765685000418678\n",
            "Epoch: 50 | Batch: 816 | Loss: 0.10826746199554843\n",
            "Epoch: 50 | Batch: 817 | Loss: 0.10501047175782245\n",
            "Epoch: 50 | Batch: 818 | Loss: 0.11641898546468735\n",
            "Epoch: 50 | Batch: 819 | Loss: 0.14061394053499454\n",
            "Epoch: 50 | Batch: 820 | Loss: 0.11710204809468702\n",
            "Epoch: 50 | Batch: 821 | Loss: 0.1308164193735732\n",
            "Epoch: 50 | Batch: 822 | Loss: 0.12252830728321143\n",
            "Epoch: 50 | Batch: 823 | Loss: 0.12111021484393578\n",
            "Epoch: 50 | Batch: 824 | Loss: 0.13958434609394818\n",
            "Epoch: 50 | Batch: 825 | Loss: 0.27436831444659393\n",
            "Epoch: 50 | Batch: 826 | Loss: 0.11411342653362609\n",
            "Epoch: 50 | Batch: 827 | Loss: 0.09952646656732753\n",
            "Epoch: 50 | Batch: 828 | Loss: 0.10471663961237267\n",
            "Epoch: 50 | Batch: 829 | Loss: 0.09841924421366857\n",
            "Epoch: 50 | Batch: 830 | Loss: 0.12756731652899675\n",
            "Epoch: 50 | Batch: 831 | Loss: 0.13847209503917904\n",
            "Epoch: 50 | Batch: 832 | Loss: 0.09006413657365542\n",
            "Epoch: 50 | Batch: 833 | Loss: 0.1044149042544554\n",
            "Epoch: 50 | Batch: 834 | Loss: 0.1905537569786213\n",
            "Epoch: 50 | Batch: 835 | Loss: 0.17062902876021097\n",
            "Epoch: 50 | Batch: 836 | Loss: 0.1172931190564144\n",
            "Epoch: 50 | Batch: 837 | Loss: 0.15528658650012528\n",
            "Epoch: 50 | Batch: 838 | Loss: 0.12733673083246433\n",
            "Epoch: 50 | Batch: 839 | Loss: 0.15061719812408048\n",
            "Epoch: 50 | Batch: 840 | Loss: 0.15279906266855092\n",
            "Epoch: 50 | Batch: 841 | Loss: 0.10545564690388137\n",
            "Epoch: 50 | Batch: 842 | Loss: 0.10661377968456007\n",
            "Epoch: 50 | Batch: 843 | Loss: 0.1376178673061937\n",
            "Epoch: 50 | Batch: 844 | Loss: 0.11364390251324613\n",
            "Epoch: 50 | Batch: 845 | Loss: 0.11719043601040137\n",
            "Epoch: 50 | Batch: 846 | Loss: 0.1711359553900346\n",
            "Epoch: 50 | Batch: 847 | Loss: 0.14118071027439177\n",
            "Epoch: 50 | Batch: 848 | Loss: 0.1574247942625538\n",
            "Epoch: 50 | Batch: 849 | Loss: 0.1368928127316986\n",
            "Epoch: 50 | Batch: 850 | Loss: 0.1915767220569568\n",
            "Epoch: 50 | Batch: 851 | Loss: 0.1292770669415134\n",
            "Epoch: 50 | Batch: 852 | Loss: 0.1747338884076471\n",
            "Epoch: 50 | Batch: 853 | Loss: 0.14507853423998832\n",
            "Epoch: 50 | Batch: 854 | Loss: 0.1268466494238485\n",
            "Epoch: 50 | Batch: 855 | Loss: 0.12150833670066793\n",
            "Epoch: 50 | Batch: 856 | Loss: 0.10978994883708225\n",
            "Epoch: 50 | Batch: 857 | Loss: 0.12337888659346033\n",
            "Epoch: 50 | Batch: 858 | Loss: 0.18858962510188784\n",
            "Epoch: 50 | Batch: 859 | Loss: 0.13988614574696198\n",
            "Epoch: 50 | Batch: 860 | Loss: 0.11273979338462489\n",
            "Epoch: 50 | Batch: 861 | Loss: 0.14899904488653176\n",
            "Epoch: 50 | Batch: 862 | Loss: 0.15948456252939985\n",
            "Epoch: 50 | Batch: 863 | Loss: 0.1528015711328447\n",
            "Epoch: 50 | Batch: 864 | Loss: 0.1220327012556601\n",
            "Epoch: 50 | Batch: 865 | Loss: 0.13637348677938188\n",
            "Epoch: 50 | Batch: 866 | Loss: 0.08233868091320448\n",
            "Epoch: 50 | Batch: 867 | Loss: 0.0951510902009519\n",
            "Epoch: 50 | Batch: 868 | Loss: 0.07675527532939522\n",
            "Epoch: 50 | Batch: 869 | Loss: 0.09823068235922316\n",
            "Epoch: 50 | Batch: 870 | Loss: 0.11557679464751652\n",
            "Epoch: 50 | Batch: 871 | Loss: 0.1219292953232137\n",
            "Epoch: 50 | Batch: 872 | Loss: 0.08257484965163381\n",
            "Epoch: 50 | Batch: 873 | Loss: 0.11781548186746434\n",
            "Epoch: 50 | Batch: 874 | Loss: 0.08287340983082775\n",
            "Epoch: 50 | Batch: 875 | Loss: 0.10831665578881708\n",
            "Epoch: 50 | Batch: 876 | Loss: 0.1117243855212223\n",
            "Epoch: 50 | Batch: 877 | Loss: 0.11140553234321778\n",
            "Epoch: 50 | Batch: 878 | Loss: 0.0822037530509857\n",
            "Epoch: 50 | Batch: 879 | Loss: 0.08571910418165532\n",
            "Epoch: 50 | Batch: 880 | Loss: 0.07960098316648645\n",
            "Epoch: 50 | Batch: 881 | Loss: 0.06522184289596208\n",
            "Epoch: 50 | Batch: 882 | Loss: 0.07700190621461811\n",
            "Epoch: 50 | Batch: 883 | Loss: 0.07977508047900196\n",
            "Epoch: 50 | Batch: 884 | Loss: 0.07032915547200914\n",
            "Epoch: 50 | Batch: 885 | Loss: 0.09233392476776986\n",
            "Epoch: 50 | Batch: 886 | Loss: 0.08399735410793971\n",
            "Epoch: 50 | Batch: 887 | Loss: 0.13585540957865977\n",
            "Epoch: 50 | Batch: 888 | Loss: 0.08382305304380205\n",
            "Epoch: 50 | Batch: 889 | Loss: 0.0688897491781888\n",
            "Epoch: 50 | Batch: 890 | Loss: 0.14884756320484088\n",
            "Epoch: 50 | Batch: 891 | Loss: 0.10940523848470243\n",
            "Epoch: 50 | Batch: 892 | Loss: 0.08786019145575696\n",
            "Epoch: 50 | Batch: 893 | Loss: 0.09295924537000994\n",
            "Epoch: 50 | Batch: 894 | Loss: 0.1285402362218473\n",
            "Epoch: 50 | Batch: 895 | Loss: 0.1451618021982854\n",
            "Epoch: 50 | Batch: 896 | Loss: 0.15602543787191403\n",
            "Epoch: 50 | Batch: 897 | Loss: 0.14158344312304097\n",
            "Epoch: 50 | Batch: 898 | Loss: 0.11984034346817211\n",
            "Epoch: 50 | Batch: 899 | Loss: 0.151599757549916\n",
            "Epoch: 50 | Batch: 900 | Loss: 0.14667491675189143\n",
            "Epoch: 50 | Batch: 901 | Loss: 0.12273506598584828\n",
            "Epoch: 50 | Batch: 902 | Loss: 0.12929892357002418\n",
            "Epoch: 50 | Batch: 903 | Loss: 0.136904233236517\n",
            "Epoch: 50 | Batch: 904 | Loss: 0.13903016373758303\n",
            "Epoch: 50 | Batch: 905 | Loss: 0.10840557842836657\n",
            "Epoch: 50 | Batch: 906 | Loss: 0.10767172901024336\n",
            "Epoch: 50 | Batch: 907 | Loss: 0.10119765515000673\n",
            "Epoch: 50 | Batch: 908 | Loss: 0.13157786500626656\n",
            "Epoch: 50 | Batch: 909 | Loss: 0.14248439254933648\n",
            "Epoch: 50 | Batch: 910 | Loss: 0.12746080393628742\n",
            "Epoch: 50 | Batch: 911 | Loss: 0.11628300814948875\n",
            "Epoch: 50 | Batch: 912 | Loss: 0.17097797745437077\n",
            "Epoch: 50 | Batch: 913 | Loss: 0.12879835830678155\n",
            "Epoch: 50 | Batch: 914 | Loss: 0.19398674638781283\n",
            "Epoch: 50 | Batch: 915 | Loss: 0.12860177592297126\n",
            "Epoch: 50 | Batch: 916 | Loss: 0.13768005107475795\n",
            "Epoch: 50 | Batch: 917 | Loss: 0.09674075854003125\n",
            "Epoch: 50 | Batch: 918 | Loss: 0.11706400717991206\n",
            "Epoch: 50 | Batch: 919 | Loss: 0.18613398818971694\n",
            "Epoch: 50 | Batch: 920 | Loss: 0.13119272465726656\n",
            "Epoch: 50 | Batch: 921 | Loss: 0.15415458262905155\n",
            "Epoch: 50 | Batch: 922 | Loss: 0.17001787332987833\n",
            "Epoch: 50 | Batch: 923 | Loss: 0.16020180876372547\n",
            "Epoch: 50 | Batch: 924 | Loss: 0.18072257288445723\n",
            "Epoch: 50 | Batch: 925 | Loss: 0.14904173379454044\n",
            "Epoch: 50 | Batch: 926 | Loss: 0.17830428278764415\n",
            "Epoch: 50 | Batch: 927 | Loss: 0.19790920438807563\n",
            "Epoch: 50 | Batch: 928 | Loss: 0.08827294717157139\n",
            "Epoch: 50 | Batch: 929 | Loss: 0.09228437616739607\n",
            "Epoch: 50 | Batch: 930 | Loss: 0.11586085533642812\n",
            "Epoch: 50 | Batch: 931 | Loss: 0.1786203386913543\n",
            "Epoch: 50 | Batch: 932 | Loss: 0.14232741767515145\n",
            "Epoch: 50 | Batch: 933 | Loss: 0.141705109339736\n",
            "Epoch: 50 | Batch: 934 | Loss: 0.14935754272445323\n",
            "Epoch: 50 | Batch: 935 | Loss: 0.18761615013247032\n",
            "Epoch: 50 | Batch: 936 | Loss: 0.13345261403417522\n",
            "Epoch: 50 | Batch: 937 | Loss: 0.13185664863894359\n",
            "Epoch: 50 | Batch: 938 | Loss: 0.13004923385718326\n",
            "Epoch: 50 | Batch: 939 | Loss: 0.13028925985891637\n",
            "Epoch: 50 | Batch: 940 | Loss: 0.09954563688428282\n",
            "Epoch: 50 | Batch: 941 | Loss: 0.12583035761321743\n",
            "Epoch: 50 | Batch: 942 | Loss: 0.11246390145783311\n",
            "Epoch: 50 | Batch: 943 | Loss: 0.09776702612255367\n",
            "Epoch: 50 | Batch: 944 | Loss: 0.15429361486265633\n",
            "Epoch: 50 | Batch: 945 | Loss: 0.11246994932843313\n",
            "Epoch: 50 | Batch: 946 | Loss: 0.1500389943188637\n",
            "Epoch: 50 | Batch: 947 | Loss: 0.17449203723390178\n",
            "Epoch: 50 | Batch: 948 | Loss: 0.1520619241315825\n",
            "Epoch: 50 | Batch: 949 | Loss: 0.14076881853773437\n",
            "Epoch: 50 | Batch: 950 | Loss: 0.15486446113315627\n",
            "Epoch: 50 | Batch: 951 | Loss: 0.14032900001406357\n",
            "Epoch: 50 | Batch: 952 | Loss: 0.15247947706851966\n",
            "Epoch: 50 | Batch: 953 | Loss: 0.15705525577088753\n",
            "Epoch: 50 | Batch: 954 | Loss: 0.09737910053387153\n",
            "Epoch: 50 | Batch: 955 | Loss: 0.09832101423753054\n",
            "Epoch: 50 | Batch: 956 | Loss: 0.09604633406627403\n",
            "Epoch: 50 | Batch: 957 | Loss: 0.145364784757697\n",
            "Epoch: 50 | Batch: 958 | Loss: 0.11802351424569336\n",
            "Epoch: 50 | Batch: 959 | Loss: 0.14150018441888396\n",
            "Epoch: 50 | Batch: 960 | Loss: 0.116496810301843\n",
            "Epoch: 50 | Batch: 961 | Loss: 0.12145301188242034\n",
            "Epoch: 50 | Batch: 962 | Loss: 0.16155246096257245\n",
            "Epoch: 50 | Batch: 963 | Loss: 0.12973530073726341\n",
            "Epoch: 50 | Batch: 964 | Loss: 0.11097290760318157\n",
            "Epoch: 50 | Batch: 965 | Loss: 0.16094305383316576\n",
            "Epoch: 50 | Batch: 966 | Loss: 0.14155878144585077\n",
            "Epoch: 50 | Batch: 967 | Loss: 0.14736207865319265\n",
            "Epoch: 50 | Batch: 968 | Loss: 0.13567763651835307\n",
            "Epoch: 50 | Batch: 969 | Loss: 0.11038300638914136\n",
            "Epoch: 50 | Batch: 970 | Loss: 0.0814092037086522\n",
            "Epoch: 50 | Batch: 971 | Loss: 0.08719075867651284\n",
            "Epoch: 50 | Batch: 972 | Loss: 0.14534837727034827\n",
            "Epoch: 50 | Batch: 973 | Loss: 0.08580562935158662\n",
            "Epoch: 50 | Batch: 974 | Loss: 0.16501702723035888\n",
            "Epoch: 50 | Batch: 975 | Loss: 0.13317895457198994\n",
            "Epoch: 50 | Batch: 976 | Loss: 0.12375214653543708\n",
            "Epoch: 50 | Batch: 977 | Loss: 0.16195644515090182\n",
            "Epoch: 50 | Batch: 978 | Loss: 0.14929155225882063\n",
            "Epoch: 50 | Batch: 979 | Loss: 0.09774373474188261\n",
            "Epoch: 50 | Batch: 980 | Loss: 0.10559003659632696\n",
            "Epoch: 50 | Batch: 981 | Loss: 0.1147682419058606\n",
            "Epoch: 50 | Batch: 982 | Loss: 0.11070363730348987\n",
            "Epoch: 50 | Batch: 983 | Loss: 0.0824799526638416\n",
            "Epoch: 50 | Batch: 984 | Loss: 0.1341007012888078\n",
            "Epoch: 50 | Batch: 985 | Loss: 0.1509677480615586\n",
            "Epoch: 50 | Batch: 986 | Loss: 0.08279244196166544\n",
            "Epoch: 50 | Batch: 987 | Loss: 0.17371319373238148\n",
            "Epoch: 50 | Batch: 988 | Loss: 0.1315968106930368\n",
            "Epoch: 50 | Batch: 989 | Loss: 0.09815376564427888\n",
            "Epoch: 50 | Batch: 990 | Loss: 0.17066544620618318\n",
            "Epoch: 50 | Batch: 991 | Loss: 0.11831476218003521\n",
            "Epoch: 50 | Batch: 992 | Loss: 0.09998746498807572\n",
            "Epoch: 50 | Batch: 993 | Loss: 0.15914280318657273\n",
            "Epoch: 50 | Batch: 994 | Loss: 0.10404474014093276\n",
            "Epoch: 50 | Batch: 995 | Loss: 0.1903651500459662\n",
            "Epoch: 50 | Batch: 996 | Loss: 0.08029462999779738\n",
            "Epoch: 50 | Batch: 997 | Loss: 0.14832257073722113\n",
            "Epoch: 50 | Batch: 998 | Loss: 0.12667733620526558\n",
            "Epoch: 50 | Batch: 999 | Loss: 0.14582680179895977\n",
            "Epoch: 50 | Batch: 1000 | Loss: 0.13375479462675624\n",
            "Epoch: 50 | Batch: 1001 | Loss: 0.14186033720165858\n",
            "Epoch: 50 | Batch: 1002 | Loss: 0.140367716483278\n",
            "Epoch: 50 | Batch: 1003 | Loss: 0.1367864733867784\n",
            "Epoch: 50 | Batch: 1004 | Loss: 0.11245107928081251\n",
            "Epoch: 50 | Batch: 1005 | Loss: 0.10521363895878108\n",
            "Epoch: 50 | Batch: 1006 | Loss: 0.10551518698811808\n",
            "Epoch: 50 | Batch: 1007 | Loss: 0.10020223193900286\n",
            "Epoch: 50 | Batch: 1008 | Loss: 0.08899788987469438\n",
            "Epoch: 50 | Batch: 1009 | Loss: 0.09630781880354355\n",
            "Epoch: 50 | Batch: 1010 | Loss: 0.12493245264285581\n",
            "Epoch: 50 | Batch: 1011 | Loss: 0.13043807432324156\n",
            "Epoch: 50 | Batch: 1012 | Loss: 0.13313134615445815\n",
            "Epoch: 50 | Batch: 1013 | Loss: 0.1623928286644465\n",
            "Epoch: 50 | Batch: 1014 | Loss: 0.11729809273378813\n",
            "Epoch: 50 | Batch: 1015 | Loss: 0.12995580478151902\n",
            "Epoch: 50 | Batch: 1016 | Loss: 0.11751067575943884\n",
            "Epoch: 50 | Batch: 1017 | Loss: 0.09812226056525616\n",
            "Epoch: 50 | Batch: 1018 | Loss: 0.08508651379265217\n",
            "Epoch: 50 | Batch: 1019 | Loss: 0.117982169172175\n",
            "Epoch: 50 | Batch: 1020 | Loss: 0.09103248752564182\n",
            "Epoch: 50 | Batch: 1021 | Loss: 0.08925572010534918\n",
            "Epoch: 50 | Batch: 1022 | Loss: 0.10782546091410436\n",
            "Epoch: 50 | Batch: 1023 | Loss: 0.06878394340681467\n",
            "Epoch: 50 | Batch: 1024 | Loss: 0.08650738243196085\n",
            "Epoch: 50 | Batch: 1025 | Loss: 0.07510067010457872\n",
            "Epoch: 50 | Batch: 1026 | Loss: 0.10089559130772215\n",
            "Epoch: 50 | Batch: 1027 | Loss: 0.06856264609685568\n",
            "Epoch: 50 | Batch: 1028 | Loss: 0.08334635951267927\n",
            "Epoch: 50 | Batch: 1029 | Loss: 0.06369999944915831\n",
            "Epoch: 50 | Batch: 1030 | Loss: 0.0676708181047497\n",
            "Epoch: 50 | Batch: 1031 | Loss: 0.10557345177304558\n",
            "Epoch: 50 | Batch: 1032 | Loss: 0.07113026618370145\n",
            "Epoch: 50 | Batch: 1033 | Loss: 0.10760663293922397\n",
            "Epoch: 50 | Batch: 1034 | Loss: 0.11383129167122635\n",
            "Epoch: 50 | Batch: 1035 | Loss: 0.07946373958308672\n",
            "Epoch: 50 | Batch: 1036 | Loss: 0.10175575852055282\n",
            "Epoch: 50 | Batch: 1037 | Loss: 0.07798495777037903\n",
            "Epoch: 50 | Batch: 1038 | Loss: 0.0721415465521885\n",
            "Epoch: 50 | Batch: 1039 | Loss: 0.15556111433153588\n",
            "Epoch: 50 | Batch: 1040 | Loss: 0.09220661911142294\n",
            "Epoch: 50 | Batch: 1041 | Loss: 0.0964004934500269\n",
            "Epoch: 50 | Batch: 1042 | Loss: 0.08216467207144598\n",
            "Epoch: 50 | Batch: 1043 | Loss: 0.08360195719208716\n",
            "Epoch: 50 | Batch: 1044 | Loss: 0.07667463380788106\n",
            "Epoch: 50 | Batch: 1045 | Loss: 0.12553575434105124\n",
            "Epoch: 50 | Batch: 1046 | Loss: 0.0766011371835684\n",
            "Epoch: 50 | Batch: 1047 | Loss: 0.08619851484857632\n",
            "Epoch: 50 | Batch: 1048 | Loss: 0.08156516037771899\n",
            "Epoch: 50 | Batch: 1049 | Loss: 0.10382587138129191\n",
            "Epoch: 50 | Batch: 1050 | Loss: 0.11301637026065535\n",
            "Epoch: 50 | Batch: 1051 | Loss: 0.08786220320851776\n",
            "Epoch: 50 | Batch: 1052 | Loss: 0.09160149527873132\n",
            "Epoch: 50 | Batch: 1053 | Loss: 0.13392898715318324\n",
            "Epoch: 50 | Batch: 1054 | Loss: 0.0834723402487215\n",
            "Epoch: 50 | Batch: 1055 | Loss: 0.12167652156459956\n",
            "Epoch: 50 | Batch: 1056 | Loss: 0.116771193102834\n",
            "Epoch: 50 | Batch: 1057 | Loss: 0.09627004175477566\n",
            "Epoch: 50 | Batch: 1058 | Loss: 0.09798345127065533\n",
            "Epoch: 50 | Batch: 1059 | Loss: 0.09185938585521297\n",
            "Epoch: 50 | Batch: 1060 | Loss: 0.11564632556806886\n",
            "Epoch: 50 | Batch: 1061 | Loss: 0.10674978312430125\n",
            "Epoch: 50 | Batch: 1062 | Loss: 0.09665959388604772\n",
            "Epoch: 50 | Batch: 1063 | Loss: 0.1419288780008534\n",
            "Epoch: 50 | Batch: 1064 | Loss: 0.11025910183661014\n",
            "Epoch: 50 | Batch: 1065 | Loss: 0.09469649562724489\n",
            "Epoch: 50 | Batch: 1066 | Loss: 0.10863741514055753\n",
            "Epoch: 50 | Batch: 1067 | Loss: 0.08112973180226547\n",
            "Epoch: 50 | Batch: 1068 | Loss: 0.10945903450246992\n",
            "Epoch: 50 | Batch: 1069 | Loss: 0.08469979728744036\n",
            "Epoch: 50 | Batch: 1070 | Loss: 0.07752273646892711\n",
            "Epoch: 50 | Batch: 1071 | Loss: 0.12219503179862555\n",
            "Epoch: 50 | Batch: 1072 | Loss: 0.09916210509552628\n",
            "Epoch: 50 | Batch: 1073 | Loss: 0.0953470810491409\n",
            "Epoch: 50 | Batch: 1074 | Loss: 0.14543329246700884\n",
            "Epoch: 50 | Batch: 1075 | Loss: 0.0863589624766436\n",
            "Epoch: 50 | Batch: 1076 | Loss: 0.07748462153521499\n",
            "Epoch: 50 | Batch: 1077 | Loss: 0.10845998741465446\n",
            "Epoch: 50 | Batch: 1078 | Loss: 0.08427831807026401\n",
            "Epoch: 50 | Batch: 1079 | Loss: 0.09722036523897035\n",
            "Epoch: 50 | Batch: 1080 | Loss: 0.09124971447343555\n",
            "Epoch: 50 | Batch: 1081 | Loss: 0.1072920795166023\n",
            "Epoch: 50 | Batch: 1082 | Loss: 0.08249747231682727\n",
            "Epoch: 50 | Batch: 1083 | Loss: 0.08607511083892533\n",
            "Epoch: 50 | Batch: 1084 | Loss: 0.06789493987965342\n",
            "Epoch: 50 | Batch: 1085 | Loss: 0.08256273407196263\n",
            "Epoch: 50 | Batch: 1086 | Loss: 0.09867595422997341\n",
            "Epoch: 50 | Batch: 1087 | Loss: 0.08555065510063364\n",
            "Epoch: 50 | Batch: 1088 | Loss: 0.06396785856935393\n",
            "Epoch: 50 | Batch: 1089 | Loss: 0.14399522946062582\n",
            "Epoch: 50 | Batch: 1090 | Loss: 0.09055744311934248\n",
            "Epoch: 50 | Batch: 1091 | Loss: 0.08760958139597048\n",
            "Epoch: 50 | Batch: 1092 | Loss: 0.0762127934975407\n",
            "Epoch: 50 | Batch: 1093 | Loss: 0.07985500170943725\n",
            "Epoch: 50 | Batch: 1094 | Loss: 0.083545717083666\n",
            "Epoch: 50 | Batch: 1095 | Loss: 0.09547845176114159\n",
            "Epoch: 50 | Batch: 1096 | Loss: 0.06640323452317765\n",
            "Epoch: 50 | Batch: 1097 | Loss: 0.05937829515151645\n",
            "Epoch: 50 | Batch: 1098 | Loss: 0.09421951442642057\n",
            "Epoch: 50 | Batch: 1099 | Loss: 0.11496258365279412\n",
            "Epoch: 50 | Batch: 1100 | Loss: 0.09213092314353463\n",
            "Epoch: 50 | Batch: 1101 | Loss: 0.0799818732677341\n",
            "Epoch: 50 | Batch: 1102 | Loss: 0.12973881777765875\n",
            "Epoch: 50 | Batch: 1103 | Loss: 0.06796204183157496\n",
            "Epoch: 50 | Batch: 1104 | Loss: 0.16709090334695997\n",
            "Epoch: 50 | Batch: 1105 | Loss: 0.06580409175761655\n",
            "Epoch: 50 | Batch: 1106 | Loss: 0.08046753505028839\n",
            "Epoch: 50 | Batch: 1107 | Loss: 0.07379252907535327\n",
            "Epoch: 50 | Batch: 1108 | Loss: 0.07864355868889719\n",
            "Epoch: 50 | Batch: 1109 | Loss: 0.06376799042166563\n",
            "Epoch: 50 | Batch: 1110 | Loss: 0.10094030791916858\n",
            "Epoch: 50 | Batch: 1111 | Loss: 0.08603462837114559\n",
            "Epoch: 50 | Batch: 1112 | Loss: 0.08853843690422349\n",
            "Epoch: 50 | Batch: 1113 | Loss: 0.15816485427705637\n",
            "Epoch: 50 | Batch: 1114 | Loss: 0.16453140811399208\n",
            "Epoch: 50 | Batch: 1115 | Loss: 0.1099272318425416\n",
            "Epoch: 50 | Batch: 1116 | Loss: 0.16320475844279347\n",
            "Epoch: 50 | Batch: 1117 | Loss: 0.1772949144242127\n",
            "Epoch: 50 | Batch: 1118 | Loss: 0.11493675259274107\n",
            "Epoch: 50 | Batch: 1119 | Loss: 0.1393595961159404\n",
            "Epoch: 50 | Batch: 1120 | Loss: 0.10135978315711008\n",
            "Epoch: 50 | Batch: 1121 | Loss: 0.13031862745740053\n",
            "Epoch: 50 | Batch: 1122 | Loss: 0.16992661677330534\n",
            "Epoch: 50 | Batch: 1123 | Loss: 0.18077546453572657\n",
            "Epoch: 50 | Batch: 1124 | Loss: 0.1442959652880499\n",
            "Epoch: 50 | Batch: 1125 | Loss: 0.24361180137103491\n",
            "Epoch: 50 | Batch: 1126 | Loss: 0.1520725142402381\n",
            "Epoch: 50 | Batch: 1127 | Loss: 0.26686514105164927\n",
            "Epoch: 50 | Batch: 1128 | Loss: 0.22325448561816028\n",
            "Epoch: 50 | Batch: 1129 | Loss: 0.16365423567531362\n",
            "Epoch: 50 | Batch: 1130 | Loss: 0.19937873866537437\n",
            "Epoch: 50 | Batch: 1131 | Loss: 0.12693678996213142\n",
            "Epoch: 50 | Batch: 1132 | Loss: 0.16388807609842543\n",
            "Epoch: 50 | Batch: 1133 | Loss: 0.1243351630764184\n",
            "Epoch: 50 | Batch: 1134 | Loss: 0.19129018715699675\n",
            "Epoch: 50 | Batch: 1135 | Loss: 0.1348364723434553\n",
            "Epoch: 50 | Batch: 1136 | Loss: 0.13932240691072595\n",
            "Epoch: 50 | Batch: 1137 | Loss: 0.1565634198112668\n",
            "Epoch: 50 | Batch: 1138 | Loss: 0.1531817535843452\n",
            "Epoch: 50 | Batch: 1139 | Loss: 0.12511847883975566\n",
            "Epoch: 50 | Batch: 1140 | Loss: 0.1143239023732633\n",
            "Epoch: 50 | Batch: 1141 | Loss: 0.12546859541182676\n",
            "Epoch: 50 | Batch: 1142 | Loss: 0.14735225637807056\n",
            "Epoch: 50 | Batch: 1143 | Loss: 0.13811853323360196\n",
            "Epoch: 50 | Batch: 1144 | Loss: 0.1531209198005032\n",
            "Epoch: 50 | Batch: 1145 | Loss: 0.13407120620505675\n",
            "Epoch: 50 | Batch: 1146 | Loss: 0.14726280315363344\n",
            "Epoch: 50 | Batch: 1147 | Loss: 0.13721735864069473\n",
            "Epoch: 50 | Batch: 1148 | Loss: 0.14524226422436792\n",
            "Epoch: 50 | Batch: 1149 | Loss: 0.09733489682326751\n",
            "Epoch: 50 | Batch: 1150 | Loss: 0.1216749022710168\n",
            "Epoch: 50 | Batch: 1151 | Loss: 0.10378708200917691\n",
            "Epoch: 50 | Batch: 1152 | Loss: 0.12541375565002977\n",
            "Epoch: 50 | Batch: 1153 | Loss: 0.14741179447788055\n",
            "Epoch: 50 | Batch: 1154 | Loss: 0.12280253827504534\n",
            "Epoch: 50 | Batch: 1155 | Loss: 0.12471340031311409\n",
            "Epoch: 50 | Batch: 1156 | Loss: 0.15164664041474218\n",
            "Epoch: 50 | Batch: 1157 | Loss: 0.12638576991269634\n",
            "Epoch: 50 | Batch: 1158 | Loss: 0.1306517632006661\n",
            "Epoch: 50 | Batch: 1159 | Loss: 0.13253470210433216\n",
            "Epoch: 50 | Batch: 1160 | Loss: 0.1236765839618834\n",
            "Epoch: 50 | Batch: 1161 | Loss: 0.13485785935470224\n",
            "Epoch: 50 | Batch: 1162 | Loss: 0.1257756297417667\n",
            "Epoch: 50 | Batch: 1163 | Loss: 0.10380608315443574\n",
            "Epoch: 50 | Batch: 1164 | Loss: 0.12039501449977796\n",
            "Epoch: 50 | Batch: 1165 | Loss: 0.10712750088051977\n",
            "Epoch: 50 | Batch: 1166 | Loss: 0.10711166065906066\n",
            "Epoch: 50 | Batch: 1167 | Loss: 0.09775470671725867\n",
            "Epoch: 50 | Batch: 1168 | Loss: 0.10073657350523421\n",
            "Epoch: 50 | Batch: 1169 | Loss: 0.10120358231978528\n",
            "Epoch: 50 | Batch: 1170 | Loss: 0.10833053411201726\n",
            "Epoch: 50 | Batch: 1171 | Loss: 0.11826717234430248\n",
            "Epoch: 50 | Batch: 1172 | Loss: 0.11186820541535032\n",
            "Epoch: 50 | Batch: 1173 | Loss: 0.12891904688849265\n",
            "Epoch: 50 | Batch: 1174 | Loss: 0.14067448347664224\n",
            "Epoch: 50 | Batch: 1175 | Loss: 0.10707722596693967\n",
            "Epoch: 50 | Batch: 1176 | Loss: 0.11539310068560266\n",
            "Epoch: 50 | Batch: 1177 | Loss: 0.08282944882616042\n",
            "Epoch: 50 | Batch: 1178 | Loss: 0.08687335971676158\n",
            "Epoch: 50 | Batch: 1179 | Loss: 0.13551612103707725\n",
            "Epoch: 50 | Batch: 1180 | Loss: 0.08426314062237981\n",
            "Epoch: 50 | Batch: 1181 | Loss: 0.13515231516978057\n",
            "Epoch: 50 | Batch: 1182 | Loss: 0.123153992973869\n",
            "Epoch: 50 | Batch: 1183 | Loss: 0.10373371330167336\n",
            "Epoch: 50 | Batch: 1184 | Loss: 0.11282294145436454\n",
            "Epoch: 50 | Batch: 1185 | Loss: 0.14112316900148208\n",
            "Epoch: 50 | Batch: 1186 | Loss: 0.10955183666650492\n",
            "Epoch: 50 | Batch: 1187 | Loss: 0.0989685535217229\n",
            "Epoch: 50 | Batch: 1188 | Loss: 0.0933179616470407\n",
            "Epoch: 50 | Batch: 1189 | Loss: 0.08629286799466399\n",
            "Epoch: 50 | Batch: 1190 | Loss: 0.10751448912406214\n",
            "Epoch: 50 | Batch: 1191 | Loss: 0.09210867269318904\n",
            "Epoch: 50 | Batch: 1192 | Loss: 0.11392204501442435\n",
            "Epoch: 50 | Batch: 1193 | Loss: 0.1347090741854997\n",
            "Epoch: 50 | Batch: 1194 | Loss: 0.11739246432756316\n",
            "Epoch: 50 | Batch: 1195 | Loss: 0.11302627691967963\n",
            "Epoch: 50 | Batch: 1196 | Loss: 0.13879585556685708\n",
            "Epoch: 50 | Batch: 1197 | Loss: 0.10618962107960932\n",
            "Epoch: 50 | Batch: 1198 | Loss: 0.15049793985813423\n",
            "Epoch: 50 | Batch: 1199 | Loss: 0.12748054888847968\n",
            "Epoch: 50 | Batch: 1200 | Loss: 0.0880079198064088\n",
            "Epoch: 50 | Batch: 1201 | Loss: 0.08605522511576102\n",
            "Epoch: 50 | Batch: 1202 | Loss: 0.0836968583500157\n",
            "Epoch: 50 | Batch: 1203 | Loss: 0.09594527825844149\n",
            "Epoch: 50 | Batch: 1204 | Loss: 0.10894381325869065\n",
            "Epoch: 50 | Batch: 1205 | Loss: 0.08953370402810062\n",
            "Epoch: 50 | Batch: 1206 | Loss: 0.16173784822014148\n",
            "Epoch: 50 | Batch: 1207 | Loss: 0.1070559668488607\n",
            "Epoch: 50 | Batch: 1208 | Loss: 0.09307609070700346\n",
            "Epoch: 50 | Batch: 1209 | Loss: 0.07726180013995175\n",
            "Epoch: 50 | Batch: 1210 | Loss: 0.0821056338189404\n",
            "Epoch: 50 | Batch: 1211 | Loss: 0.07843477897317597\n",
            "Epoch: 50 | Batch: 1212 | Loss: 0.07214233631711177\n",
            "Epoch: 50 | Batch: 1213 | Loss: 0.11350806352438997\n",
            "Epoch: 50 | Batch: 1214 | Loss: 0.07328585464222205\n",
            "Epoch: 50 | Batch: 1215 | Loss: 0.0859795985033722\n",
            "Epoch: 50 | Batch: 1216 | Loss: 0.09401389711890934\n",
            "Epoch: 50 | Batch: 1217 | Loss: 0.10003311392067236\n",
            "Epoch: 50 | Batch: 1218 | Loss: 0.10159434391306722\n",
            "Epoch: 50 | Batch: 1219 | Loss: 0.09284187997906604\n",
            "Epoch: 50 | Batch: 1220 | Loss: 0.10448178751762083\n",
            "Epoch: 50 | Batch: 1221 | Loss: 0.0767556618878753\n",
            "Epoch: 50 | Batch: 1222 | Loss: 0.09548436532281356\n",
            "Epoch: 50 | Batch: 1223 | Loss: 0.11929737844086706\n",
            "Epoch: 50 | Batch: 1224 | Loss: 0.10796408921983952\n",
            "Epoch: 50 | Batch: 1225 | Loss: 0.06434782852707474\n",
            "Epoch: 50 | Batch: 1226 | Loss: 0.10170348176128213\n",
            "Epoch: 50 | Batch: 1227 | Loss: 0.12233679394806006\n",
            "Epoch: 50 | Batch: 1228 | Loss: 0.06057308582248215\n",
            "Epoch: 50 | Batch: 1229 | Loss: 0.1086994177383641\n",
            "Epoch: 50 | Batch: 1230 | Loss: 0.09437199160304183\n",
            "Epoch: 50 | Batch: 1231 | Loss: 0.06583373191276867\n",
            "Epoch: 50 | Batch: 1232 | Loss: 0.08413174980212373\n",
            "Epoch: 50 | Batch: 1233 | Loss: 0.06105574189402485\n",
            "Epoch: 50 | Batch: 1234 | Loss: 0.07969789892051266\n",
            "Epoch: 50 | Batch: 1235 | Loss: 0.06697198997936687\n",
            "Epoch: 50 | Batch: 1236 | Loss: 0.0966159306947029\n",
            "Epoch: 50 | Batch: 1237 | Loss: 0.1146935909044316\n",
            "Epoch: 50 | Batch: 1238 | Loss: 0.06817010230534895\n",
            "Epoch: 50 | Batch: 1239 | Loss: 0.12179941571578295\n",
            "Epoch: 50 | Batch: 1240 | Loss: 0.10925282078242468\n",
            "Epoch: 50 | Batch: 1241 | Loss: 0.08685451252602566\n",
            "Epoch: 50 | Batch: 1242 | Loss: 0.10297696400606332\n",
            "Epoch: 50 | Batch: 1243 | Loss: 0.095932504160433\n",
            "Epoch: 50 | Batch: 1244 | Loss: 0.0880200638284582\n",
            "Epoch: 50 | Batch: 1245 | Loss: 0.09961554716750694\n",
            "Epoch: 50 | Batch: 1246 | Loss: 0.09267846755795639\n",
            "Epoch: 50 | Batch: 1247 | Loss: 0.08958471617803027\n",
            "Epoch: 50 | Batch: 1248 | Loss: 0.11370898447609112\n",
            "Epoch: 50 | Batch: 1249 | Loss: 0.08541585467585233\n",
            "Epoch: 50 | Batch: 1250 | Loss: 0.08132194635984083\n",
            "Epoch: 50 | Batch: 1251 | Loss: 0.06169465251495957\n",
            "Epoch: 50 | Batch: 1252 | Loss: 0.08737709399099217\n",
            "Epoch: 50 | Batch: 1253 | Loss: 0.0728361058150237\n",
            "Epoch: 50 | Batch: 1254 | Loss: 0.11022963639972452\n",
            "Epoch: 50 | Batch: 1255 | Loss: 0.10203237562795052\n",
            "Epoch: 50 | Batch: 1256 | Loss: 0.08469660897551354\n",
            "Epoch: 50 | Batch: 1257 | Loss: 0.06701855514497168\n",
            "Epoch: 50 | Batch: 1258 | Loss: 0.10396041043207808\n",
            "Epoch: 50 | Batch: 1259 | Loss: 0.08377672300535748\n",
            "Epoch: 50 | Batch: 1260 | Loss: 0.08967663947540422\n",
            "Epoch: 50 | Batch: 1261 | Loss: 0.10377748406537507\n",
            "Epoch: 50 | Batch: 1262 | Loss: 0.0957084559942963\n",
            "Epoch: 50 | Batch: 1263 | Loss: 0.055400067041027394\n",
            "Epoch: 50 | Batch: 1264 | Loss: 0.08616257629775595\n",
            "Epoch: 50 | Batch: 1265 | Loss: 0.09803209664663906\n",
            "Epoch: 50 | Batch: 1266 | Loss: 0.0783901136375404\n",
            "Epoch: 50 | Batch: 1267 | Loss: 0.08569172857446644\n",
            "Epoch: 50 | Batch: 1268 | Loss: 0.07988302285628125\n",
            "Epoch: 50 | Batch: 1269 | Loss: 0.07192802064988615\n",
            "Epoch: 50 | Batch: 1270 | Loss: 0.10351435587623509\n",
            "Epoch: 50 | Batch: 1271 | Loss: 0.09281905783142287\n",
            "Epoch: 50 | Batch: 1272 | Loss: 0.08993038724004149\n",
            "Epoch: 50 | Batch: 1273 | Loss: 0.08023896075338482\n",
            "Epoch: 50 | Batch: 1274 | Loss: 0.08390974414533642\n",
            "Epoch: 50 | Batch: 1275 | Loss: 0.09677924097347325\n",
            "Epoch: 50 | Batch: 1276 | Loss: 0.13390144964510298\n",
            "Epoch: 50 | Batch: 1277 | Loss: 0.11286700908615638\n",
            "Epoch: 50 | Batch: 1278 | Loss: 0.09819342012283992\n",
            "Epoch: 50 | Batch: 1279 | Loss: 0.14094587611729698\n",
            "Epoch: 50 | Batch: 1280 | Loss: 0.09097063601844536\n",
            "Epoch: 50 | Batch: 1281 | Loss: 0.11686312922424003\n",
            "Epoch: 50 | Batch: 1282 | Loss: 0.11108941800087349\n",
            "Epoch: 50 | Batch: 1283 | Loss: 0.11503331075668091\n",
            "Epoch: 50 | Batch: 1284 | Loss: 0.13159377885082743\n",
            "Epoch: 50 | Batch: 1285 | Loss: 0.13346097989449324\n",
            "Epoch: 50 | Batch: 1286 | Loss: 0.10446027388579329\n",
            "Epoch: 50 | Batch: 1287 | Loss: 0.14634651971210938\n",
            "Epoch: 50 | Batch: 1288 | Loss: 0.0860356245155998\n",
            "Epoch: 50 | Batch: 1289 | Loss: 0.10184889163752031\n",
            "Epoch: 50 | Batch: 1290 | Loss: 0.10060258330900801\n",
            "Epoch: 50 | Batch: 1291 | Loss: 0.1148359325991761\n",
            "Epoch: 50 | Batch: 1292 | Loss: 0.13334284702419458\n",
            "Epoch: 50 | Batch: 1293 | Loss: 0.10091972668692484\n",
            "Epoch: 50 | Batch: 1294 | Loss: 0.11314172967010677\n",
            "Epoch: 50 | Batch: 1295 | Loss: 0.12757475506550994\n",
            "Epoch: 50 | Batch: 1296 | Loss: 0.09975941458145528\n",
            "Epoch: 50 | Batch: 1297 | Loss: 0.13707833770850752\n",
            "Epoch: 50 | Batch: 1298 | Loss: 0.11646174951781224\n",
            "Epoch: 50 | Batch: 1299 | Loss: 0.09606546484271873\n",
            "Epoch: 50 | Batch: 1300 | Loss: 0.12497450434702714\n",
            "Epoch: 50 | Batch: 1301 | Loss: 0.10405891158951007\n",
            "Epoch: 50 | Batch: 1302 | Loss: 0.13170007236087283\n",
            "Epoch: 50 | Batch: 1303 | Loss: 0.15013368769106966\n",
            "Epoch: 50 | Batch: 1304 | Loss: 0.09497237852252333\n",
            "Epoch: 50 | Batch: 1305 | Loss: 0.1081228202873363\n",
            "Epoch: 50 | Batch: 1306 | Loss: 0.17371655420945648\n",
            "Epoch: 50 | Batch: 1307 | Loss: 0.1052226945328276\n",
            "Epoch: 50 | Batch: 1308 | Loss: 0.07575669487795969\n",
            "Epoch: 50 | Batch: 1309 | Loss: 0.1254212550378899\n",
            "Epoch: 50 | Batch: 1310 | Loss: 0.10447501071814189\n",
            "Epoch: 50 | Batch: 1311 | Loss: 0.08917580345773056\n",
            "Epoch: 50 | Batch: 1312 | Loss: 0.09953413618943857\n",
            "Epoch: 50 | Batch: 1313 | Loss: 0.10972120542128383\n",
            "Epoch: 50 | Batch: 1314 | Loss: 0.10400796572811338\n",
            "Epoch: 50 | Batch: 1315 | Loss: 0.15159837446498198\n",
            "Epoch: 50 | Batch: 1316 | Loss: 0.1362710794452391\n",
            "Epoch: 50 | Batch: 1317 | Loss: 0.13414068047658506\n",
            "Epoch: 50 | Batch: 1318 | Loss: 0.08911021753827573\n",
            "Epoch: 50 | Batch: 1319 | Loss: 0.10198602015722141\n",
            "Epoch: 50 | Batch: 1320 | Loss: 0.1090226914434167\n",
            "Epoch: 50 | Batch: 1321 | Loss: 0.11823132238800327\n",
            "Epoch: 50 | Batch: 1322 | Loss: 0.09372769925972244\n",
            "Epoch: 50 | Batch: 1323 | Loss: 0.10224193732433345\n",
            "Epoch: 50 | Batch: 1324 | Loss: 0.11022300101591656\n",
            "Epoch: 50 | Batch: 1325 | Loss: 0.09334541886093103\n",
            "Epoch: 50 | Batch: 1326 | Loss: 0.09568253778008964\n",
            "Epoch: 50 | Batch: 1327 | Loss: 0.09208991552424606\n",
            "Epoch: 50 | Batch: 1328 | Loss: 0.12476520391023037\n",
            "Epoch: 50 | Batch: 1329 | Loss: 0.1086868489077659\n",
            "Epoch: 50 | Batch: 1330 | Loss: 0.0991887811286579\n",
            "Epoch: 50 | Batch: 1331 | Loss: 0.11589769813137027\n",
            "Epoch: 50 | Batch: 1332 | Loss: 0.12684114390194384\n",
            "Epoch: 50 | Batch: 1333 | Loss: 0.1439549020072644\n",
            "Epoch: 50 | Batch: 1334 | Loss: 0.1531017469555732\n",
            "Epoch: 50 | Batch: 1335 | Loss: 0.13906040669529413\n",
            "Epoch: 50 | Batch: 1336 | Loss: 0.10114217776000256\n",
            "Epoch: 50 | Batch: 1337 | Loss: 0.11720690771070844\n",
            "Epoch: 50 | Batch: 1338 | Loss: 0.11268285595266309\n",
            "Epoch: 50 | Batch: 1339 | Loss: 0.09011995240949153\n",
            "Epoch: 50 | Batch: 1340 | Loss: 0.07734449308170356\n",
            "Epoch: 50 | Batch: 1341 | Loss: 0.11282983030529814\n",
            "Epoch: 50 | Batch: 1342 | Loss: 0.11401970824461989\n",
            "Epoch: 50 | Batch: 1343 | Loss: 0.11346592405682267\n",
            "Epoch: 50 | Batch: 1344 | Loss: 0.1679423261649294\n",
            "Epoch: 50 | Batch: 1345 | Loss: 0.11419688186482901\n",
            "Epoch: 50 | Batch: 1346 | Loss: 0.1504145491814398\n",
            "Epoch: 50 | Batch: 1347 | Loss: 0.14806237499481598\n",
            "Epoch: 50 | Batch: 1348 | Loss: 0.12377343432386444\n",
            "Epoch: 50 | Batch: 1349 | Loss: 0.12695175949821141\n",
            "Epoch: 50 | Batch: 1350 | Loss: 0.09886419914428318\n",
            "Epoch: 50 | Batch: 1351 | Loss: 0.07836000857029718\n",
            "Epoch: 50 | Batch: 1352 | Loss: 0.09700967672178075\n",
            "Epoch: 50 | Batch: 1353 | Loss: 0.09792194275592953\n",
            "Epoch: 50 | Batch: 1354 | Loss: 0.10322419128584495\n",
            "Epoch: 50 | Batch: 1355 | Loss: 0.11217275567508438\n",
            "Epoch: 50 | Batch: 1356 | Loss: 0.11893859251723105\n",
            "Epoch: 50 | Batch: 1357 | Loss: 0.09445212693789895\n",
            "Epoch: 50 | Batch: 1358 | Loss: 0.14930972104669774\n",
            "Epoch: 50 | Batch: 1359 | Loss: 0.12428857421483723\n",
            "Epoch: 50 | Batch: 1360 | Loss: 0.1406952460331638\n",
            "Epoch: 50 | Batch: 1361 | Loss: 0.1444154316434305\n",
            "Epoch: 50 | Batch: 1362 | Loss: 0.10599144889255123\n",
            "Epoch: 50 | Batch: 1363 | Loss: 0.10599183656270621\n",
            "Epoch: 50 | Batch: 1364 | Loss: 0.09956350948881318\n",
            "Epoch: 50 | Batch: 1365 | Loss: 0.08642700888724301\n",
            "Epoch: 50 | Batch: 1366 | Loss: 0.12537065497727876\n",
            "Epoch: 50 | Batch: 1367 | Loss: 0.10021385499440821\n",
            "Epoch: 50 | Batch: 1368 | Loss: 0.11411313931217283\n",
            "Epoch: 50 | Batch: 1369 | Loss: 0.11204885360422207\n",
            "Epoch: 50 | Batch: 1370 | Loss: 0.1018312925718174\n",
            "Epoch: 50 | Batch: 1371 | Loss: 0.1404044204932078\n",
            "Epoch: 50 | Batch: 1372 | Loss: 0.14835626643823316\n",
            "Epoch: 50 | Batch: 1373 | Loss: 0.11202980703047796\n",
            "Epoch: 50 | Batch: 1374 | Loss: 0.09597828821405079\n",
            "Epoch: 50 | Batch: 1375 | Loss: 0.10352933853536782\n",
            "Epoch: 50 | Batch: 1376 | Loss: 0.09115441284862308\n",
            "Epoch: 50 | Batch: 1377 | Loss: 0.09143703213651166\n",
            "Epoch: 50 | Batch: 1378 | Loss: 0.08401828858504853\n",
            "Epoch: 50 | Batch: 1379 | Loss: 0.11431623602573086\n",
            "Epoch: 50 | Batch: 1380 | Loss: 0.12017491728738672\n",
            "Epoch: 50 | Batch: 1381 | Loss: 0.0878270121174802\n",
            "Epoch: 50 | Batch: 1382 | Loss: 0.13232548395981233\n",
            "Epoch: 50 | Batch: 1383 | Loss: 0.08588539790175939\n",
            "Epoch: 50 | Batch: 1384 | Loss: 0.1201176525642628\n",
            "Epoch: 50 | Batch: 1385 | Loss: 0.101830371669754\n",
            "Epoch: 50 | Batch: 1386 | Loss: 0.06811853489714775\n",
            "Epoch: 50 | Batch: 1387 | Loss: 0.0818927404339339\n",
            "Epoch: 50 | Batch: 1388 | Loss: 0.1232785920667648\n",
            "Epoch: 50 | Batch: 1389 | Loss: 0.08198395830056261\n",
            "Epoch: 50 | Batch: 1390 | Loss: 0.13685872737758598\n",
            "Epoch: 50 | Batch: 1391 | Loss: 0.153092140976048\n",
            "Epoch: 50 | Batch: 1392 | Loss: 0.1192962563462095\n",
            "Epoch: 50 | Batch: 1393 | Loss: 0.15186999350045777\n",
            "Epoch: 50 | Batch: 1394 | Loss: 0.09178199521628344\n",
            "Epoch: 50 | Batch: 1395 | Loss: 0.13414758698906457\n",
            "Epoch: 50 | Batch: 1396 | Loss: 0.11678760264116168\n",
            "Epoch: 50 | Batch: 1397 | Loss: 0.08866483894228833\n",
            "Epoch: 50 | Batch: 1398 | Loss: 0.09128958455374966\n",
            "Epoch: 50 | Batch: 1399 | Loss: 0.09285431739855052\n",
            "Epoch: 50 | Batch: 1400 | Loss: 0.10432653967334254\n",
            "Epoch: 50 | Batch: 1401 | Loss: 0.1017821786383997\n",
            "Epoch: 50 | Batch: 1402 | Loss: 0.14515451905266247\n",
            "Epoch: 50 | Batch: 1403 | Loss: 0.09398930919572124\n",
            "Epoch: 50 | Batch: 1404 | Loss: 0.08227812089730432\n",
            "Epoch: 50 | Batch: 1405 | Loss: 0.12144211899890701\n",
            "Epoch: 50 | Batch: 1406 | Loss: 0.10804402094109988\n",
            "Epoch: 50 | Batch: 1407 | Loss: 0.08724440755912088\n",
            "Epoch: 50 | Batch: 1408 | Loss: 0.08998374839681536\n",
            "Epoch: 50 | Batch: 1409 | Loss: 0.08706605989540309\n",
            "Epoch: 50 | Batch: 1410 | Loss: 0.12151145174494787\n",
            "Epoch: 50 | Batch: 1411 | Loss: 0.08333549695737852\n",
            "Epoch: 50 | Batch: 1412 | Loss: 0.14588680110164484\n",
            "Epoch: 50 | Batch: 1413 | Loss: 0.07563625812670254\n",
            "Epoch: 50 | Batch: 1414 | Loss: 0.09478675048215365\n",
            "Epoch: 50 | Batch: 1415 | Loss: 0.10634274338455887\n",
            "Epoch: 50 | Batch: 1416 | Loss: 0.10474434637707311\n",
            "Epoch: 50 | Batch: 1417 | Loss: 0.09774837837555622\n",
            "Epoch: 50 | Batch: 1418 | Loss: 0.11356699533039792\n",
            "Epoch: 50 | Batch: 1419 | Loss: 0.09881501089458727\n",
            "Epoch: 50 | Batch: 1420 | Loss: 0.09566700043584397\n",
            "Epoch: 50 | Batch: 1421 | Loss: 0.11179480595757209\n",
            "Epoch: 50 | Batch: 1422 | Loss: 0.0978266910998423\n",
            "Epoch: 50 | Batch: 1423 | Loss: 0.11674145612869256\n",
            "Epoch: 50 | Batch: 1424 | Loss: 0.11092799470075641\n",
            "Epoch: 50 | Batch: 1425 | Loss: 0.09942220860650401\n",
            "Epoch: 50 | Batch: 1426 | Loss: 0.11735722904817478\n",
            "Epoch: 50 | Batch: 1427 | Loss: 0.11863889395050334\n",
            "Epoch: 50 | Batch: 1428 | Loss: 0.11065360385047775\n",
            "Epoch: 50 | Batch: 1429 | Loss: 0.1236897548401197\n",
            "Epoch: 50 | Batch: 1430 | Loss: 0.09591433330641164\n",
            "Epoch: 50 | Batch: 1431 | Loss: 0.08674202723445927\n",
            "Epoch: 50 | Batch: 1432 | Loss: 0.08755843404159214\n",
            "Epoch: 50 | Batch: 1433 | Loss: 0.08829146018742241\n",
            "Epoch: 50 | Batch: 1434 | Loss: 0.06645861604988161\n",
            "Epoch: 50 | Batch: 1435 | Loss: 0.09426235705352543\n",
            "Epoch: 50 | Batch: 1436 | Loss: 0.12151759196856322\n",
            "Epoch: 50 | Batch: 1437 | Loss: 0.08967926103720833\n",
            "Epoch: 50 | Batch: 1438 | Loss: 0.12194735474755958\n",
            "Epoch: 50 | Batch: 1439 | Loss: 0.09974295711146462\n",
            "Epoch: 50 | Batch: 1440 | Loss: 0.10777436554192085\n",
            "Epoch: 50 | Batch: 1441 | Loss: 0.14461194911212194\n",
            "Epoch: 50 | Batch: 1442 | Loss: 0.10094287477753766\n",
            "Epoch: 50 | Batch: 1443 | Loss: 0.1111256706373996\n",
            "Epoch: 50 | Batch: 1444 | Loss: 0.12358708024338763\n",
            "Epoch: 50 | Batch: 1445 | Loss: 0.09738875088305211\n",
            "Epoch: 50 | Batch: 1446 | Loss: 0.11202667539789947\n",
            "Epoch: 50 | Batch: 1447 | Loss: 0.10835033636500467\n",
            "Epoch: 50 | Batch: 1448 | Loss: 0.1228517949417931\n",
            "Epoch: 50 | Batch: 1449 | Loss: 0.10015601925966668\n",
            "Epoch: 50 | Batch: 1450 | Loss: 0.1045840050331521\n",
            "Epoch: 50 | Batch: 1451 | Loss: 0.10658636000699735\n",
            "Epoch: 50 | Batch: 1452 | Loss: 0.12170001931926362\n",
            "Epoch: 50 | Batch: 1453 | Loss: 0.09101520892487118\n",
            "Epoch: 50 | Batch: 1454 | Loss: 0.134760584025711\n",
            "Epoch: 50 | Batch: 1455 | Loss: 0.11431342789764065\n",
            "Epoch: 50 | Batch: 1456 | Loss: 0.09124609898492479\n",
            "Epoch: 50 | Batch: 1457 | Loss: 0.12133665468970257\n",
            "Epoch: 50 | Batch: 1458 | Loss: 0.11565586216985549\n",
            "Epoch: 50 | Batch: 1459 | Loss: 0.12731108852689058\n",
            "Epoch: 50 | Batch: 1460 | Loss: 0.10417829021046304\n",
            "Epoch: 50 | Batch: 1461 | Loss: 0.11624142242259619\n",
            "Epoch: 50 | Batch: 1462 | Loss: 0.12028829741984383\n",
            "Epoch: 50 | Batch: 1463 | Loss: 0.11030504708904432\n",
            "Epoch: 50 | Batch: 1464 | Loss: 0.08140845060544037\n",
            "Epoch: 50 | Batch: 1465 | Loss: 0.07206949395682327\n",
            "Epoch: 50 | Batch: 1466 | Loss: 0.12017120643913666\n",
            "Epoch: 50 | Batch: 1467 | Loss: 0.09764938657802263\n",
            "Epoch: 50 | Batch: 1468 | Loss: 0.08303042842608432\n",
            "Epoch: 50 | Batch: 1469 | Loss: 0.10336909929918281\n",
            "Epoch: 50 | Batch: 1470 | Loss: 0.11857826850012655\n",
            "Epoch: 50 | Batch: 1471 | Loss: 0.11582110292732428\n",
            "Epoch: 50 | Batch: 1472 | Loss: 0.11133448391122064\n",
            "Epoch: 50 | Batch: 1473 | Loss: 0.09758801069480841\n",
            "Epoch: 50 | Batch: 1474 | Loss: 0.08959119887812948\n",
            "Epoch: 50 | Batch: 1475 | Loss: 0.08824439230453557\n",
            "Epoch: 50 | Batch: 1476 | Loss: 0.06867736524986072\n",
            "Epoch: 50 | Batch: 1477 | Loss: 0.1258212676953357\n",
            "Epoch: 50 | Batch: 1478 | Loss: 0.10917578491165181\n",
            "Epoch: 50 | Batch: 1479 | Loss: 0.0759382772950741\n",
            "Epoch: 50 | Batch: 1480 | Loss: 0.10412531737361572\n",
            "Epoch: 50 | Batch: 1481 | Loss: 0.10170134360978766\n",
            "Epoch: 50 | Batch: 1482 | Loss: 0.07621488791377154\n",
            "Epoch: 50 | Batch: 1483 | Loss: 0.09468768574450254\n",
            "Epoch: 50 | Batch: 1484 | Loss: 0.0844864364816015\n",
            "Epoch: 50 | Batch: 1485 | Loss: 0.12414264159037983\n",
            "Epoch: 50 | Batch: 1486 | Loss: 0.08372511979248386\n",
            "Epoch: 50 | Batch: 1487 | Loss: 0.1158570826488638\n",
            "Epoch: 50 | Batch: 1488 | Loss: 0.10750967405943873\n",
            "Epoch: 50 | Batch: 1489 | Loss: 0.08765690340463697\n",
            "Epoch: 50 | Batch: 1490 | Loss: 0.08990848406653176\n",
            "Epoch: 50 | Batch: 1491 | Loss: 0.09285013011809062\n",
            "Epoch: 50 | Batch: 1492 | Loss: 0.13462892878498747\n",
            "Epoch: 50 | Batch: 1493 | Loss: 0.09509140828661511\n",
            "Epoch: 50 | Batch: 1494 | Loss: 0.11240802925479407\n",
            "Epoch: 50 | Batch: 1495 | Loss: 0.08212657470085173\n",
            "Epoch: 50 | Batch: 1496 | Loss: 0.08854830382256054\n",
            "Epoch: 50 | Batch: 1497 | Loss: 0.12118399253108253\n",
            "Epoch: 50 | Batch: 1498 | Loss: 0.07899279454531333\n",
            "Epoch: 50 | Batch: 1499 | Loss: 0.10401399999956376\n",
            "Epoch: 50 | Batch: 1500 | Loss: 0.10167864185845861\n",
            "Epoch: 50 | Batch: 1501 | Loss: 0.09174641467621819\n",
            "Epoch: 50 | Batch: 1502 | Loss: 0.07782878413987382\n",
            "Epoch: 50 | Batch: 1503 | Loss: 0.09096932170140776\n",
            "Epoch: 50 | Batch: 1504 | Loss: 0.09781329761721835\n",
            "Epoch: 50 | Batch: 1505 | Loss: 0.07968262990832463\n",
            "Epoch: 50 | Batch: 1506 | Loss: 0.08556054195436505\n",
            "Epoch: 50 | Batch: 1507 | Loss: 0.08182546710656213\n",
            "Epoch: 50 | Batch: 1508 | Loss: 0.07689241693965027\n",
            "Epoch: 50 | Batch: 1509 | Loss: 0.08151412445883992\n",
            "Epoch: 50 | Batch: 1510 | Loss: 0.13121639873159013\n",
            "Epoch: 50 | Batch: 1511 | Loss: 0.13982983863091114\n",
            "Epoch: 50 | Batch: 1512 | Loss: 0.1039833120552221\n",
            "Epoch: 50 | Batch: 1513 | Loss: 0.13482055470227677\n",
            "Epoch: 50 | Batch: 1514 | Loss: 0.12509646763697224\n",
            "Epoch: 50 | Batch: 1515 | Loss: 0.10360762798087637\n",
            "Epoch: 50 | Batch: 1516 | Loss: 0.12721345117865768\n",
            "Epoch: 50 | Batch: 1517 | Loss: 0.10570824206852752\n",
            "Epoch: 50 | Batch: 1518 | Loss: 0.10744552385721426\n",
            "Epoch: 50 | Batch: 1519 | Loss: 0.10651139377243175\n",
            "Epoch: 50 | Batch: 1520 | Loss: 0.09558169007765158\n",
            "Epoch: 50 | Batch: 1521 | Loss: 0.11670619004040925\n",
            "Epoch: 50 | Batch: 1522 | Loss: 0.14358379207000121\n",
            "Epoch: 50 | Batch: 1523 | Loss: 0.13358528085359617\n",
            "Epoch: 50 | Batch: 1524 | Loss: 0.12616339509155686\n",
            "Epoch: 50 | Batch: 1525 | Loss: 0.12526380721599376\n",
            "Epoch: 50 | Batch: 1526 | Loss: 0.13427531385312103\n",
            "Epoch: 50 | Batch: 1527 | Loss: 0.13779867270617607\n",
            "Epoch: 50 | Batch: 1528 | Loss: 0.1174815314632494\n",
            "Epoch: 50 | Batch: 1529 | Loss: 0.11908001909944518\n",
            "Epoch: 50 | Batch: 1530 | Loss: 0.18859565115209187\n",
            "Epoch: 50 | Batch: 1531 | Loss: 0.11072988432046062\n",
            "Epoch: 50 | Batch: 1532 | Loss: 0.15877317976822714\n",
            "Epoch: 50 | Batch: 1533 | Loss: 0.15521236158032264\n",
            "Epoch: 50 | Batch: 1534 | Loss: 0.16897109371648905\n",
            "Epoch: 50 | Batch: 1535 | Loss: 0.15830527071922124\n",
            "Epoch: 50 | Batch: 1536 | Loss: 0.19285129741082724\n",
            "Epoch: 50 | Batch: 1537 | Loss: 0.1496066754689142\n",
            "Epoch: 50 | Batch: 1538 | Loss: 0.16804397226582093\n",
            "Epoch: 50 | Batch: 1539 | Loss: 0.15289412299113658\n",
            "Epoch: 50 | Batch: 1540 | Loss: 0.1347647552436227\n",
            "Epoch: 50 | Batch: 1541 | Loss: 0.11741696753803027\n",
            "Epoch: 50 | Batch: 1542 | Loss: 0.1116287539953702\n",
            "Epoch: 50 | Batch: 1543 | Loss: 0.18522400740912742\n",
            "Epoch: 50 | Batch: 1544 | Loss: 0.1230088846394985\n",
            "Epoch: 50 | Batch: 1545 | Loss: 0.116487334649648\n",
            "Epoch: 50 | Batch: 1546 | Loss: 0.11253140893007513\n",
            "Epoch: 50 | Batch: 1547 | Loss: 0.12966807109550346\n",
            "Epoch: 50 | Batch: 1548 | Loss: 0.13961971522612238\n",
            "Epoch: 50 | Batch: 1549 | Loss: 0.11520839663125768\n",
            "Epoch: 50 | Batch: 1550 | Loss: 0.18235848128976853\n",
            "Epoch: 50 | Batch: 1551 | Loss: 0.14582272296808796\n",
            "Epoch: 50 | Batch: 1552 | Loss: 0.14630692297345507\n",
            "Epoch: 50 | Batch: 1553 | Loss: 0.1433666939169828\n",
            "Epoch: 50 | Batch: 1554 | Loss: 0.15770877552904033\n",
            "Epoch: 50 | Batch: 1555 | Loss: 0.1432402940338932\n",
            "Epoch: 50 | Batch: 1556 | Loss: 0.14419821645223652\n",
            "Epoch: 50 | Batch: 1557 | Loss: 0.0985971092367233\n",
            "Epoch: 50 | Batch: 1558 | Loss: 0.10292700322571256\n",
            "Epoch: 50 | Batch: 1559 | Loss: 0.15531299354962066\n",
            "Epoch: 50 | Batch: 1560 | Loss: 0.09514801162040509\n",
            "Epoch: 50 | Batch: 1561 | Loss: 0.11370800896504894\n",
            "Epoch: 50 | Batch: 1562 | Loss: 0.1274944121949431\n",
            "Epoch: 50 | Batch: 1563 | Loss: 0.1506220477476996\n",
            "Epoch: 50 | Batch: 1564 | Loss: 0.1339144143914528\n",
            "Epoch: 50 | Batch: 1565 | Loss: 0.17158274658941736\n",
            "Epoch: 50 | Batch: 1566 | Loss: 0.11022665153033628\n",
            "Epoch: 50 | Batch: 1567 | Loss: 0.13802113674714675\n",
            "Epoch: 50 | Batch: 1568 | Loss: 0.13444932603166826\n",
            "Epoch: 50 | Batch: 1569 | Loss: 0.13252886348173257\n",
            "Epoch: 50 | Batch: 1570 | Loss: 0.09016046157733626\n",
            "Epoch: 50 | Batch: 1571 | Loss: 0.11383217775308627\n",
            "Epoch: 50 | Batch: 1572 | Loss: 0.10748165858318398\n",
            "Epoch: 50 | Batch: 1573 | Loss: 0.08412664457090771\n",
            "Epoch: 50 | Batch: 1574 | Loss: 0.12034416492063246\n",
            "Epoch: 50 | Batch: 1575 | Loss: 0.15955530249726108\n",
            "Epoch: 50 | Batch: 1576 | Loss: 0.09423391469035573\n",
            "Epoch: 50 | Batch: 1577 | Loss: 0.17032743850116178\n",
            "Epoch: 50 | Batch: 1578 | Loss: 0.14435014052554238\n",
            "Epoch: 50 | Batch: 1579 | Loss: 0.13787177484501523\n",
            "Epoch: 50 | Batch: 1580 | Loss: 0.12141256689329366\n",
            "Epoch: 50 | Batch: 1581 | Loss: 0.11844842103774111\n",
            "Epoch: 50 | Batch: 1582 | Loss: 0.10393649409963714\n",
            "Epoch: 50 | Batch: 1583 | Loss: 0.09993037378174441\n",
            "Epoch: 50 | Batch: 1584 | Loss: 0.09028098922238584\n",
            "Epoch: 50 | Batch: 1585 | Loss: 0.11844244591565684\n",
            "Epoch: 50 | Batch: 1586 | Loss: 0.08122160501742585\n",
            "Epoch: 50 | Batch: 1587 | Loss: 0.11913376595812475\n",
            "Epoch: 50 | Batch: 1588 | Loss: 0.09601260810101925\n",
            "Epoch: 50 | Batch: 1589 | Loss: 0.10933934271345451\n",
            "Epoch: 50 | Batch: 1590 | Loss: 0.10034840564809586\n",
            "Epoch: 50 | Batch: 1591 | Loss: 0.12446485786039432\n",
            "Epoch: 50 | Batch: 1592 | Loss: 0.10695856861095959\n",
            "Epoch: 50 | Batch: 1593 | Loss: 0.123844943175446\n",
            "Epoch: 50 | Batch: 1594 | Loss: 0.09838192709249749\n",
            "Epoch: 50 | Batch: 1595 | Loss: 0.11361224947460265\n",
            "Epoch: 50 | Batch: 1596 | Loss: 0.0887878930720293\n",
            "Epoch: 50 | Batch: 1597 | Loss: 0.09574290614851895\n",
            "Epoch: 50 | Batch: 1598 | Loss: 0.1103576731597398\n",
            "Epoch: 50 | Batch: 1599 | Loss: 0.13487779245198667\n",
            "Epoch: 50 | Batch: 1600 | Loss: 0.09356269803545135\n",
            "Epoch: 50 | Batch: 1601 | Loss: 0.10482776498927092\n",
            "Epoch: 50 | Batch: 1602 | Loss: 0.1253337277823512\n",
            "Epoch: 50 | Batch: 1603 | Loss: 0.11539747097656158\n",
            "Epoch: 50 | Batch: 1604 | Loss: 0.10682171592375887\n",
            "Epoch: 50 | Batch: 1605 | Loss: 0.11975363248762\n",
            "Epoch: 50 | Batch: 1606 | Loss: 0.09795759757159139\n",
            "Epoch: 50 | Batch: 1607 | Loss: 0.10897019787099124\n",
            "Epoch: 50 | Batch: 1608 | Loss: 0.08407543213959937\n",
            "Epoch: 50 | Batch: 1609 | Loss: 0.09779291576891319\n",
            "Epoch: 50 | Batch: 1610 | Loss: 0.10055111799286458\n",
            "Epoch: 50 | Batch: 1611 | Loss: 0.11450447589612199\n",
            "Epoch: 50 | Batch: 1612 | Loss: 0.11041254241780069\n",
            "Epoch: 50 | Batch: 1613 | Loss: 0.15034916372359292\n",
            "Epoch: 50 | Batch: 1614 | Loss: 0.13574327009726692\n",
            "Epoch: 50 | Batch: 1615 | Loss: 0.12702270746335756\n",
            "Epoch: 50 | Batch: 1616 | Loss: 0.12115986912367237\n",
            "Epoch: 50 | Batch: 1617 | Loss: 0.09672442086245847\n",
            "Epoch: 50 | Batch: 1618 | Loss: 0.09965093369640593\n",
            "Epoch: 50 | Batch: 1619 | Loss: 0.1570072416391158\n",
            "Epoch: 50 | Batch: 1620 | Loss: 0.11380414888667756\n",
            "Epoch: 50 | Batch: 1621 | Loss: 0.1519361032985931\n",
            "Epoch: 50 | Batch: 1622 | Loss: 0.13565883888980262\n",
            "Epoch: 50 | Batch: 1623 | Loss: 0.12301973619871512\n",
            "Epoch: 50 | Batch: 1624 | Loss: 0.17102537434525444\n",
            "Epoch: 50 | Batch: 1625 | Loss: 0.1320580704282887\n",
            "Epoch: 50 | Batch: 1626 | Loss: 0.11553194789589227\n",
            "Epoch: 50 | Batch: 1627 | Loss: 0.11379676634174843\n",
            "Epoch: 50 | Batch: 1628 | Loss: 0.11712481357165092\n",
            "Epoch: 50 | Batch: 1629 | Loss: 0.11643249493630171\n",
            "Epoch: 50 | Batch: 1630 | Loss: 0.09306045335528744\n",
            "Epoch: 50 | Batch: 1631 | Loss: 0.11672874748179535\n",
            "Epoch: 50 | Batch: 1632 | Loss: 0.10531757564714381\n",
            "Epoch: 50 | Batch: 1633 | Loss: 0.074270709656531\n",
            "Epoch: 50 | Batch: 1634 | Loss: 0.10750995026864989\n",
            "Epoch: 50 | Batch: 1635 | Loss: 0.12895214505277716\n",
            "Epoch: 50 | Batch: 1636 | Loss: 0.16343560410113933\n",
            "Epoch: 50 | Batch: 1637 | Loss: 0.15116756807285867\n",
            "Epoch: 50 | Batch: 1638 | Loss: 0.1326005202812876\n",
            "Epoch: 50 | Batch: 1639 | Loss: 0.19680574083231858\n",
            "Epoch: 50 | Batch: 1640 | Loss: 0.14837079182101875\n",
            "Epoch: 50 | Batch: 1641 | Loss: 0.11630623100021459\n",
            "Epoch: 50 | Batch: 1642 | Loss: 0.177247498507219\n",
            "Epoch: 50 | Batch: 1643 | Loss: 0.11071841872830288\n",
            "Epoch: 50 | Batch: 1644 | Loss: 0.14877519013862356\n",
            "Epoch: 50 | Batch: 1645 | Loss: 0.1694505248636703\n",
            "Epoch: 50 | Batch: 1646 | Loss: 0.1406332986841868\n",
            "Epoch: 50 | Batch: 1647 | Loss: 0.18452695835156818\n",
            "Epoch: 50 | Batch: 1648 | Loss: 0.14494648199308446\n",
            "Epoch: 50 | Batch: 1649 | Loss: 0.1483858607772628\n",
            "Epoch: 50 | Batch: 1650 | Loss: 0.1230196569837189\n",
            "Epoch: 50 | Batch: 1651 | Loss: 0.15411371933945084\n",
            "Epoch: 50 | Batch: 1652 | Loss: 0.13241986881462714\n",
            "Epoch: 50 | Batch: 1653 | Loss: 0.10637141885141024\n",
            "Epoch: 50 | Batch: 1654 | Loss: 0.12326884407396824\n",
            "Epoch: 50 | Batch: 1655 | Loss: 0.1372798921911237\n",
            "Epoch: 50 | Batch: 1656 | Loss: 0.10683597857767635\n",
            "Epoch: 50 | Batch: 1657 | Loss: 0.11645526399138378\n",
            "Epoch: 50 | Batch: 1658 | Loss: 0.14056333324297066\n",
            "Epoch: 50 | Batch: 1659 | Loss: 0.11140686660487781\n",
            "Epoch: 50 | Batch: 1660 | Loss: 0.142767784924741\n",
            "Epoch: 50 | Batch: 1661 | Loss: 0.13544856074389\n",
            "Epoch: 50 | Batch: 1662 | Loss: 0.10322266949890142\n",
            "Epoch: 50 | Batch: 1663 | Loss: 0.1786927291695578\n",
            "Epoch: 50 | Batch: 1664 | Loss: 0.14039243475985325\n",
            "Epoch: 50 | Batch: 1665 | Loss: 0.17110039217919265\n",
            "Epoch: 50 | Batch: 1666 | Loss: 0.13699054021247467\n",
            "Epoch: 50 | Batch: 1667 | Loss: 0.16437018595204067\n",
            "Epoch: 50 | Batch: 1668 | Loss: 0.13318406623558082\n",
            "Epoch: 50 | Batch: 1669 | Loss: 0.14206392937497275\n",
            "Epoch: 50 | Batch: 1670 | Loss: 0.1507932881485006\n",
            "Epoch: 50 | Batch: 1671 | Loss: 0.1222607891473601\n",
            "Epoch: 50 | Batch: 1672 | Loss: 0.1407178031895231\n",
            "Epoch: 50 | Batch: 1673 | Loss: 0.12041161550174899\n",
            "Epoch: 50 | Batch: 1674 | Loss: 0.1438502153141078\n",
            "Epoch: 50 | Batch: 1675 | Loss: 0.1288640192691186\n",
            "Epoch: 50 | Batch: 1676 | Loss: 0.14492093745810541\n",
            "Epoch: 50 | Batch: 1677 | Loss: 0.13702820802705856\n",
            "Epoch: 50 | Batch: 1678 | Loss: 0.11016480964088571\n",
            "Epoch: 50 | Batch: 1679 | Loss: 0.166735100376045\n",
            "Epoch: 50 | Batch: 1680 | Loss: 0.1249328139618131\n",
            "Epoch: 50 | Batch: 1681 | Loss: 0.10248990179901235\n",
            "Epoch: 50 | Batch: 1682 | Loss: 0.12423418315047607\n",
            "Epoch: 50 | Batch: 1683 | Loss: 0.10980518871500139\n",
            "Epoch: 50 | Batch: 1684 | Loss: 0.11193087402366218\n",
            "Epoch: 50 | Batch: 1685 | Loss: 0.17768649047165827\n",
            "Epoch: 50 | Batch: 1686 | Loss: 0.14053806975608468\n",
            "Epoch: 50 | Batch: 1687 | Loss: 0.13285392713809385\n",
            "Epoch: 50 | Batch: 1688 | Loss: 0.14140034154945336\n",
            "Epoch: 50 | Batch: 1689 | Loss: 0.15321368877939012\n",
            "Epoch: 50 | Batch: 1690 | Loss: 0.16715124166768708\n",
            "Epoch: 50 | Batch: 1691 | Loss: 0.21553132403099262\n",
            "Epoch: 50 | Batch: 1692 | Loss: 0.1073823142215547\n",
            "Epoch: 50 | Batch: 1693 | Loss: 0.12089333870233317\n",
            "Epoch: 50 | Batch: 1694 | Loss: 0.1099697392827572\n",
            "Epoch: 50 | Batch: 1695 | Loss: 0.09664175777236315\n",
            "Epoch: 50 | Batch: 1696 | Loss: 0.09171670398451617\n",
            "Epoch: 50 | Batch: 1697 | Loss: 0.08915781003860637\n",
            "Epoch: 50 | Batch: 1698 | Loss: 0.1210988018468083\n",
            "Epoch: 50 | Batch: 1699 | Loss: 0.10634269991662905\n",
            "Epoch: 50 | Batch: 1700 | Loss: 0.11168170730361128\n",
            "Epoch: 50 | Batch: 1701 | Loss: 0.10966319048178547\n",
            "Epoch: 50 | Batch: 1702 | Loss: 0.11491126703021169\n",
            "Epoch: 50 | Batch: 1703 | Loss: 0.10878909638190074\n",
            "Epoch: 50 | Batch: 1704 | Loss: 0.14630056906085492\n",
            "Epoch: 50 | Batch: 1705 | Loss: 0.11346592300301256\n",
            "Epoch: 50 | Batch: 1706 | Loss: 0.1210876734806139\n",
            "Epoch: 50 | Batch: 1707 | Loss: 0.10950008845158468\n",
            "Epoch: 50 | Batch: 1708 | Loss: 0.08824976641037022\n",
            "Epoch: 50 | Batch: 1709 | Loss: 0.09284399493390023\n",
            "Epoch: 50 | Batch: 1710 | Loss: 0.09399116871518629\n",
            "Epoch: 50 | Batch: 1711 | Loss: 0.08758572349773686\n",
            "Epoch: 50 | Batch: 1712 | Loss: 0.10930341890011554\n",
            "Epoch: 50 | Batch: 1713 | Loss: 0.10197507522839111\n",
            "Epoch: 50 | Batch: 1714 | Loss: 0.10331831766810676\n",
            "Epoch: 50 | Batch: 1715 | Loss: 0.1215725149451095\n",
            "Epoch: 50 | Batch: 1716 | Loss: 0.1499091897697199\n",
            "Epoch: 50 | Batch: 1717 | Loss: 0.11815108209836789\n",
            "Epoch: 50 | Batch: 1718 | Loss: 0.0853071103222534\n",
            "Epoch: 50 | Batch: 1719 | Loss: 0.09817945186859234\n",
            "Epoch: 50 | Batch: 1720 | Loss: 0.14629151521573625\n",
            "Epoch: 50 | Batch: 1721 | Loss: 0.07942806764337373\n",
            "Epoch: 50 | Batch: 1722 | Loss: 0.10650570574716386\n",
            "Epoch: 50 | Batch: 1723 | Loss: 0.10434446649676889\n",
            "Epoch: 50 | Batch: 1724 | Loss: 0.09567054549512385\n",
            "Epoch: 50 | Batch: 1725 | Loss: 0.0661148980156404\n",
            "Epoch: 50 | Batch: 1726 | Loss: 0.07691062904607057\n",
            "Epoch: 50 | Batch: 1727 | Loss: 0.07115791702975842\n",
            "Epoch: 50 | Batch: 1728 | Loss: 0.10591738124479641\n",
            "Epoch: 50 | Batch: 1729 | Loss: 0.07611491650642907\n",
            "Epoch: 50 | Batch: 1730 | Loss: 0.11063664913963792\n",
            "Epoch: 50 | Batch: 1731 | Loss: 0.10697660270042683\n",
            "Epoch: 50 | Batch: 1732 | Loss: 0.12916528309742809\n",
            "Epoch: 50 | Batch: 1733 | Loss: 0.11270682105106633\n",
            "Epoch: 50 | Batch: 1734 | Loss: 0.12012131608831425\n",
            "Epoch: 50 | Batch: 1735 | Loss: 0.06905224707583647\n",
            "Epoch: 50 | Batch: 1736 | Loss: 0.07383656839653929\n",
            "Epoch: 50 | Batch: 1737 | Loss: 0.09445204179184716\n",
            "Epoch: 50 | Batch: 1738 | Loss: 0.09022552494163133\n",
            "Epoch: 50 | Batch: 1739 | Loss: 0.09164764045754795\n",
            "Epoch: 50 | Batch: 1740 | Loss: 0.09162249688266638\n",
            "Epoch: 50 | Batch: 1741 | Loss: 0.11751759161417778\n",
            "Epoch: 50 | Batch: 1742 | Loss: 0.0982911276191661\n",
            "Epoch: 50 | Batch: 1743 | Loss: 0.10117979808505467\n",
            "Epoch: 50 | Batch: 1744 | Loss: 0.14658607048201577\n",
            "Epoch: 50 | Batch: 1745 | Loss: 0.0819349972713787\n",
            "Epoch: 50 | Batch: 1746 | Loss: 0.09003772359202614\n",
            "Epoch: 50 | Batch: 1747 | Loss: 0.12414324511607461\n",
            "Epoch: 50 | Batch: 1748 | Loss: 0.10057802007024946\n",
            "Epoch: 50 | Batch: 1749 | Loss: 0.10831623974758417\n",
            "Epoch: 50 | Batch: 1750 | Loss: 0.13988243826970553\n",
            "Epoch: 50 | Batch: 1751 | Loss: 0.0854427875347738\n",
            "Epoch: 50 | Batch: 1752 | Loss: 0.12566741402687093\n",
            "Epoch: 50 | Batch: 1753 | Loss: 0.1438504858345343\n",
            "Epoch: 50 | Batch: 1754 | Loss: 0.11795691100870517\n",
            "Epoch: 50 | Batch: 1755 | Loss: 0.07743174524596991\n",
            "Epoch: 50 | Batch: 1756 | Loss: 0.1338359091169771\n",
            "Epoch: 50 | Batch: 1757 | Loss: 0.15710238616044445\n",
            "Epoch: 50 | Batch: 1758 | Loss: 0.09529901949633232\n",
            "Epoch: 50 | Batch: 1759 | Loss: 0.1945145911817789\n",
            "Epoch: 50 | Batch: 1760 | Loss: 0.08079233448097664\n",
            "Epoch: 50 | Batch: 1761 | Loss: 0.1041839856791015\n",
            "Epoch: 50 | Batch: 1762 | Loss: 0.10954968376795265\n",
            "Epoch: 50 | Batch: 1763 | Loss: 0.09505534646605832\n",
            "Epoch: 50 | Batch: 1764 | Loss: 0.1067824143761068\n",
            "Epoch: 50 | Batch: 1765 | Loss: 0.10948840464169748\n",
            "Epoch: 50 | Batch: 1766 | Loss: 0.10470607069213236\n",
            "Epoch: 50 | Batch: 1767 | Loss: 0.12403669381139532\n",
            "Epoch: 50 | Batch: 1768 | Loss: 0.14375430495359537\n",
            "Epoch: 50 | Batch: 1769 | Loss: 0.11057964814278508\n",
            "Epoch: 50 | Batch: 1770 | Loss: 0.17948827100207743\n",
            "Epoch: 50 | Batch: 1771 | Loss: 0.14755438356062234\n",
            "Epoch: 50 | Batch: 1772 | Loss: 0.1460533330608067\n",
            "Epoch: 50 | Batch: 1773 | Loss: 0.15238782608955384\n",
            "Epoch: 50 | Batch: 1774 | Loss: 0.19473695726607168\n",
            "Epoch: 50 | Batch: 1775 | Loss: 0.12603875676751583\n",
            "Epoch: 50 | Batch: 1776 | Loss: 0.1291455874777973\n",
            "Epoch: 50 | Batch: 1777 | Loss: 0.12575747743224294\n",
            "Epoch: 50 | Batch: 1778 | Loss: 0.40818532224904847\n",
            "Epoch: 50 | Batch: 1779 | Loss: 0.5968857462044835\n",
            "Epoch: 50 | Batch: 1780 | Loss: 2.5090125762824482\n",
            "Epoch: 50 | Batch: 1781 | Loss: 0.9194379630122639\n",
            "Epoch: 50 | Batch: 1782 | Loss: 4.602349791232039\n",
            "Epoch: 50 | Batch: 1783 | Loss: 0.22452469618036275\n",
            "Epoch: 50 | Batch: 1784 | Loss: 1.51020878170226\n",
            "Epoch: 50 | Batch: 1785 | Loss: 3.295763047924679\n",
            "Epoch: 50 | Batch: 1786 | Loss: 0.720898760670488\n",
            "Epoch: 50 | Batch: 1787 | Loss: 0.8938668816050751\n",
            "Epoch: 50 | Batch: 1788 | Loss: 1.2160233553541813\n",
            "Epoch: 50 | Batch: 1789 | Loss: 1.0543254451314397\n",
            "Epoch: 50 | Batch: 1790 | Loss: 0.8253149115045127\n",
            "Epoch: 50 | Batch: 1791 | Loss: 0.5267418393093012\n",
            "Epoch: 50 | Batch: 1792 | Loss: 0.8109707170381208\n",
            "Epoch: 50 | Batch: 1793 | Loss: 0.5218897495075355\n",
            "Epoch: 50 | Batch: 1794 | Loss: 0.5705451426366904\n",
            "Epoch: 50 | Batch: 1795 | Loss: 0.5233503183681758\n",
            "Epoch: 50 | Batch: 1796 | Loss: 0.520842302586584\n",
            "Epoch: 50 | Batch: 1797 | Loss: 0.5171785992780998\n",
            "Epoch: 50 | Batch: 1798 | Loss: 0.6361531015497044\n",
            "Epoch: 50 | Batch: 1799 | Loss: 0.5264506333971279\n",
            "Epoch: 50 | Batch: 1800 | Loss: 0.5253807952038181\n",
            "Epoch: 50 | Batch: 1801 | Loss: 0.5181136947488878\n",
            "Epoch: 50 | Batch: 1802 | Loss: 0.64876554556024\n",
            "Epoch: 50 | Batch: 1803 | Loss: 0.7032527932773724\n",
            "Epoch: 50 | Batch: 1804 | Loss: 0.7731085639723843\n",
            "Epoch: 50 | Batch: 1805 | Loss: 0.6938696919561335\n",
            "Epoch: 50 | Batch: 1806 | Loss: 0.5612664968542639\n",
            "Epoch: 50 | Batch: 1807 | Loss: 0.5754770840932549\n",
            "Epoch: 50 | Batch: 1808 | Loss: 0.6203414250613842\n",
            "Epoch: 50 | Batch: 1809 | Loss: 0.44153543718825183\n",
            "Epoch: 50 | Batch: 1810 | Loss: 0.5452435394738671\n",
            "Epoch: 50 | Batch: 1811 | Loss: 0.42898728657523877\n",
            "Epoch: 50 | Batch: 1812 | Loss: 0.4005493708079245\n",
            "Epoch: 50 | Batch: 1813 | Loss: 0.4049920433569043\n",
            "Epoch: 50 | Batch: 1814 | Loss: 0.4384500321106807\n",
            "Epoch: 50 | Batch: 1815 | Loss: 0.4249016913177404\n",
            "Epoch: 50 | Batch: 1816 | Loss: 0.5233184114172378\n",
            "Epoch: 50 | Batch: 1817 | Loss: 0.3631364250714233\n",
            "Epoch: 50 | Batch: 1818 | Loss: 0.5244406117160597\n",
            "Epoch: 50 | Batch: 1819 | Loss: 0.41746945041699624\n",
            "Epoch: 50 | Batch: 1820 | Loss: 0.4211564896259849\n",
            "Epoch: 50 | Batch: 1821 | Loss: 0.3889846772125129\n",
            "Epoch: 50 | Batch: 1822 | Loss: 0.3664431363154901\n",
            "Epoch: 50 | Batch: 1823 | Loss: 0.36417332647037154\n",
            "Epoch: 50 | Batch: 1824 | Loss: 0.32052265865029206\n",
            "Epoch: 50 | Batch: 1825 | Loss: 0.2731558530868604\n",
            "Epoch: 50 | Batch: 1826 | Loss: 0.2768832576804666\n",
            "Epoch: 50 | Batch: 1827 | Loss: 0.26618045253961\n",
            "Epoch: 50 | Batch: 1828 | Loss: 0.3082638652130174\n",
            "Epoch: 50 | Batch: 1829 | Loss: 0.232291904701459\n",
            "Epoch: 50 | Batch: 1830 | Loss: 0.2570438071055963\n",
            "Epoch: 50 | Batch: 1831 | Loss: 0.22705743207898516\n",
            "Epoch: 50 | Batch: 1832 | Loss: 0.24644678065546266\n",
            "Epoch: 50 | Batch: 1833 | Loss: 0.20784632512008405\n",
            "Epoch: 50 | Batch: 1834 | Loss: 0.2844943659911287\n",
            "Epoch: 50 | Batch: 1835 | Loss: 0.22084287228609217\n",
            "Epoch: 50 | Batch: 1836 | Loss: 0.23083870523464595\n",
            "Epoch: 50 | Batch: 1837 | Loss: 0.23875548434861485\n",
            "Epoch: 50 | Batch: 1838 | Loss: 0.30692497977558975\n",
            "Epoch: 50 | Batch: 1839 | Loss: 0.3005011381077621\n",
            "Epoch: 50 | Batch: 1840 | Loss: 0.31179862459717034\n",
            "Epoch: 50 | Batch: 1841 | Loss: 0.15800219583986014\n",
            "Epoch: 50 | Batch: 1842 | Loss: 0.3293447953465816\n",
            "Epoch: 50 | Batch: 1843 | Loss: 0.1994226336303751\n",
            "Epoch: 50 | Batch: 1844 | Loss: 0.2951075509443489\n",
            "Epoch: 50 | Batch: 1845 | Loss: 0.19492720385073864\n",
            "Epoch: 50 | Batch: 1846 | Loss: 0.3083830169619984\n",
            "Epoch: 50 | Batch: 1847 | Loss: 0.17853920284948613\n",
            "Epoch: 50 | Batch: 1848 | Loss: 0.2790806656567165\n",
            "Epoch: 50 | Batch: 1849 | Loss: 0.17078853193654261\n",
            "Epoch: 50 | Batch: 1850 | Loss: 0.292060746849596\n",
            "Epoch: 50 | Batch: 1851 | Loss: 0.16422298101347813\n",
            "Epoch: 50 | Batch: 1852 | Loss: 0.21090272309303149\n",
            "Epoch: 50 | Batch: 1853 | Loss: 0.16963245709274394\n",
            "Epoch: 50 | Batch: 1854 | Loss: 0.19981123670296463\n",
            "Epoch: 50 | Batch: 1855 | Loss: 0.1395066817942111\n",
            "Epoch: 50 | Batch: 1856 | Loss: 0.16736574990238592\n",
            "Epoch: 50 | Batch: 1857 | Loss: 0.1391733013637984\n",
            "Epoch: 50 | Batch: 1858 | Loss: 0.13226234823671273\n",
            "Epoch: 50 | Batch: 1859 | Loss: 0.15311326348727858\n",
            "Epoch: 50 | Batch: 1860 | Loss: 0.1749910439754836\n",
            "Epoch: 50 | Batch: 1861 | Loss: 0.19744766160309546\n",
            "Epoch: 50 | Batch: 1862 | Loss: 0.1838000963718071\n",
            "Epoch: 50 | Batch: 1863 | Loss: 0.12371571547772284\n",
            "Epoch: 50 | Batch: 1864 | Loss: 0.12474022574545955\n",
            "Epoch: 50 | Batch: 1865 | Loss: 0.10749847352593869\n",
            "Epoch: 50 | Batch: 1866 | Loss: 0.1583408306876694\n",
            "Epoch: 50 | Batch: 1867 | Loss: 0.16283046843500068\n",
            "Epoch: 50 | Batch: 1868 | Loss: 0.15623679685307518\n",
            "Epoch: 50 | Batch: 1869 | Loss: 0.14175639738811338\n",
            "Epoch: 50 | Batch: 1870 | Loss: 0.1177046500532097\n",
            "Epoch: 50 | Batch: 1871 | Loss: 0.16642309104681313\n",
            "Epoch: 50 | Batch: 1872 | Loss: 0.10252000755294058\n",
            "Epoch: 50 | Batch: 1873 | Loss: 0.12386462658122517\n",
            "Epoch: 50 | Batch: 1874 | Loss: 0.11103970633304389\n",
            "Epoch: 50 | Batch: 1875 | Loss: 0.10539939028143347\n",
            "Epoch: 50 | Batch: 1876 | Loss: 0.07755073003121937\n",
            "Epoch: 50 | Batch: 1877 | Loss: 0.09774052068316767\n",
            "Epoch: 50 | Batch: 1878 | Loss: 0.11453097115851496\n",
            "Epoch: 50 | Batch: 1879 | Loss: 0.10414971490171165\n",
            "Epoch: 50 | Batch: 1880 | Loss: 0.10271188282193876\n",
            "Epoch: 50 | Batch: 1881 | Loss: 0.07712514990080131\n",
            "Epoch: 50 | Batch: 1882 | Loss: 0.12897384360388883\n",
            "Epoch: 50 | Batch: 1883 | Loss: 0.10182557034103425\n",
            "Epoch: 50 | Batch: 1884 | Loss: 0.10741672516979822\n",
            "Epoch: 50 | Batch: 1885 | Loss: 0.1181941280775209\n",
            "Epoch: 50 | Batch: 1886 | Loss: 0.06866583782857827\n",
            "Epoch: 50 | Batch: 1887 | Loss: 0.08140838340545321\n",
            "Epoch: 50 | Batch: 1888 | Loss: 0.09393681193292694\n",
            "Epoch: 50 | Batch: 1889 | Loss: 0.19181827471327306\n",
            "Epoch: 50 | Batch: 1890 | Loss: 0.13103776462977468\n",
            "Epoch: 50 | Batch: 1891 | Loss: 0.21955866599132445\n",
            "Epoch: 50 | Batch: 1892 | Loss: 0.16583225659678705\n",
            "Epoch: 50 | Batch: 1893 | Loss: 0.18547628165195454\n",
            "Epoch: 50 | Batch: 1894 | Loss: 0.13707456914460067\n",
            "Epoch: 50 | Batch: 1895 | Loss: 0.09847535519940266\n",
            "Epoch: 50 | Batch: 1896 | Loss: 0.12362072065194299\n",
            "Epoch: 50 | Batch: 1897 | Loss: 0.1181225637118525\n",
            "Epoch: 50 | Batch: 1898 | Loss: 0.11905197267798018\n",
            "Epoch: 50 | Batch: 1899 | Loss: 0.12938785254012614\n",
            "Epoch: 50 | Batch: 1900 | Loss: 0.1881431400893615\n",
            "Epoch: 50 | Batch: 1901 | Loss: 0.12464045565361989\n",
            "Epoch: 50 | Batch: 1902 | Loss: 0.2106213884315607\n",
            "Epoch: 50 | Batch: 1903 | Loss: 0.08191807046390964\n",
            "Epoch: 50 | Batch: 1904 | Loss: 0.2206573500140933\n",
            "Epoch: 50 | Batch: 1905 | Loss: 0.09284766324591362\n",
            "Epoch: 50 | Batch: 1906 | Loss: 0.1008350744288549\n",
            "Epoch: 50 | Batch: 1907 | Loss: 0.10073947253591525\n",
            "Epoch: 50 | Batch: 1908 | Loss: 0.0757565490262967\n",
            "Epoch: 50 | Batch: 1909 | Loss: 0.12488829411046595\n",
            "Epoch: 50 | Batch: 1910 | Loss: 0.10156930970432959\n",
            "Epoch: 50 | Batch: 1911 | Loss: 0.14429800390715633\n",
            "Epoch: 50 | Batch: 1912 | Loss: 0.11527976589015751\n",
            "Epoch: 50 | Batch: 1913 | Loss: 0.18184442335981704\n",
            "Epoch: 50 | Batch: 1914 | Loss: 0.10866013243913003\n",
            "Epoch: 50 | Batch: 1915 | Loss: 0.07949897794690863\n",
            "Epoch: 50 | Batch: 1916 | Loss: 0.08777057923788818\n",
            "Epoch: 50 | Batch: 1917 | Loss: 0.08722727436335617\n",
            "Epoch: 50 | Batch: 1918 | Loss: 0.10831429647305454\n",
            "Epoch: 50 | Batch: 1919 | Loss: 0.10260581634441002\n",
            "Epoch: 50 | Batch: 1920 | Loss: 0.13079034306735254\n",
            "Epoch: 50 | Batch: 1921 | Loss: 0.13550479747244462\n",
            "Epoch: 50 | Batch: 1922 | Loss: 0.17472160189151853\n",
            "Epoch: 50 | Batch: 1923 | Loss: 0.1090007590479282\n",
            "Epoch: 50 | Batch: 1924 | Loss: 0.09680168014143563\n",
            "Epoch: 50 | Batch: 1925 | Loss: 0.11805689198857264\n",
            "Epoch: 50 | Batch: 1926 | Loss: 0.08385099291453112\n",
            "Epoch: 50 | Batch: 1927 | Loss: 0.15793761194508316\n",
            "Epoch: 50 | Batch: 1928 | Loss: 0.10043708376531998\n",
            "Epoch: 50 | Batch: 1929 | Loss: 0.1232964635276532\n",
            "Epoch: 50 | Batch: 1930 | Loss: 0.08464995121517258\n",
            "Epoch: 50 | Batch: 1931 | Loss: 0.1365724707817127\n",
            "Epoch: 50 | Batch: 1932 | Loss: 0.14574456573523323\n",
            "Epoch: 50 | Batch: 1933 | Loss: 0.11641934408911697\n",
            "Epoch: 50 | Batch: 1934 | Loss: 0.12039620659647672\n",
            "Epoch: 50 | Batch: 1935 | Loss: 0.0999672538189072\n",
            "Epoch: 50 | Batch: 1936 | Loss: 0.13996593633444127\n",
            "Epoch: 50 | Batch: 1937 | Loss: 0.12381779403899912\n",
            "Epoch: 50 | Batch: 1938 | Loss: 0.17164496321769004\n",
            "Epoch: 50 | Batch: 1939 | Loss: 0.1973249368648987\n",
            "Epoch: 50 | Batch: 1940 | Loss: 0.09539324570771399\n",
            "Epoch: 50 | Batch: 1941 | Loss: 0.1207866367845322\n",
            "Epoch: 50 | Batch: 1942 | Loss: 0.20253517267909632\n",
            "Epoch: 50 | Batch: 1943 | Loss: 0.10069119068638585\n",
            "Epoch: 50 | Batch: 1944 | Loss: 0.11203495104830277\n",
            "Epoch: 50 | Batch: 1945 | Loss: 0.16037667780218529\n",
            "Epoch: 50 | Batch: 1946 | Loss: 0.15187602457627097\n",
            "Epoch: 50 | Batch: 1947 | Loss: 0.09167350528243931\n",
            "Epoch: 50 | Batch: 1948 | Loss: 0.1317123761377313\n",
            "Epoch: 50 | Batch: 1949 | Loss: 0.11238186021530891\n",
            "Epoch: 50 | Batch: 1950 | Loss: 0.08159298298674765\n",
            "Epoch: 50 | Batch: 1951 | Loss: 0.12260215205781332\n",
            "Epoch: 50 | Batch: 1952 | Loss: 0.10272681467583908\n",
            "Epoch: 50 | Batch: 1953 | Loss: 0.09214178242467816\n",
            "Epoch: 50 | Batch: 1954 | Loss: 0.1305066044448311\n",
            "Epoch: 50 | Batch: 1955 | Loss: 0.0900196062273953\n",
            "Epoch: 50 | Batch: 1956 | Loss: 0.09673713876487644\n",
            "Epoch: 50 | Batch: 1957 | Loss: 0.09293857458834498\n",
            "Epoch: 50 | Batch: 1958 | Loss: 0.10920646726562741\n",
            "Epoch: 50 | Batch: 1959 | Loss: 0.09749613799795857\n",
            "Epoch: 50 | Batch: 1960 | Loss: 0.0963975973387138\n",
            "Epoch: 50 | Batch: 1961 | Loss: 0.086895648347871\n",
            "Epoch: 50 | Batch: 1962 | Loss: 0.08874011456086804\n",
            "Epoch: 50 | Batch: 1963 | Loss: 0.09236774194265\n",
            "Epoch: 50 | Batch: 1964 | Loss: 0.09479002090643351\n",
            "Epoch: 50 | Batch: 1965 | Loss: 0.1009894755296099\n",
            "Epoch: 50 | Batch: 1966 | Loss: 0.10723136741662692\n",
            "Epoch: 50 | Batch: 1967 | Loss: 0.1787919151985714\n",
            "Epoch: 50 | Batch: 1968 | Loss: 0.0782814761095526\n",
            "Epoch: 50 | Batch: 1969 | Loss: 0.09241951386512429\n",
            "Epoch: 50 | Batch: 1970 | Loss: 0.1267410746788632\n",
            "Epoch: 50 | Batch: 1971 | Loss: 0.09746044108383581\n",
            "Epoch: 50 | Batch: 1972 | Loss: 0.13321822742498993\n",
            "Epoch: 50 | Batch: 1973 | Loss: 0.09673745200723952\n",
            "Epoch: 50 | Batch: 1974 | Loss: 0.10780586346423528\n",
            "Epoch: 50 | Batch: 1975 | Loss: 0.12437638106985195\n",
            "Epoch: 50 | Batch: 1976 | Loss: 0.11322827107837133\n",
            "Epoch: 50 | Batch: 1977 | Loss: 0.08549492649987281\n",
            "Epoch: 50 | Batch: 1978 | Loss: 0.09019154864954541\n",
            "Epoch: 50 | Batch: 1979 | Loss: 0.12492603170912282\n",
            "Epoch: 50 | Batch: 1980 | Loss: 0.10282160218110306\n",
            "Epoch: 50 | Batch: 1981 | Loss: 0.08513015970057855\n",
            "Epoch: 50 | Batch: 1982 | Loss: 0.12310865832359884\n",
            "Epoch: 50 | Batch: 1983 | Loss: 0.11052466535962331\n",
            "Epoch: 50 | Batch: 1984 | Loss: 0.0901937401902552\n",
            "Epoch: 50 | Batch: 1985 | Loss: 0.12207866951945809\n",
            "Epoch: 50 | Batch: 1986 | Loss: 0.08749589862643334\n",
            "Epoch: 50 | Batch: 1987 | Loss: 0.12426394026885335\n",
            "Epoch: 50 | Batch: 1988 | Loss: 0.09612251407854222\n",
            "Epoch: 50 | Batch: 1989 | Loss: 0.09481577342383118\n",
            "Epoch: 50 | Batch: 1990 | Loss: 0.0873125419695061\n",
            "Epoch: 50 | Batch: 1991 | Loss: 0.08683401250548442\n",
            "Epoch: 50 | Batch: 1992 | Loss: 0.10324486097274682\n",
            "Epoch: 50 | Batch: 1993 | Loss: 0.1094734361020358\n",
            "Epoch: 50 | Batch: 1994 | Loss: 0.1686202185657786\n",
            "Epoch: 50 | Batch: 1995 | Loss: 0.10457880250359054\n",
            "Epoch: 50 | Batch: 1996 | Loss: 0.1152871218726411\n",
            "Epoch: 50 | Batch: 1997 | Loss: 0.10176425931705199\n",
            "Epoch: 50 | Batch: 1998 | Loss: 0.09312213903676303\n",
            "Epoch: 50 | Batch: 1999 | Loss: 0.07087666186715608\n",
            "Epoch: 50 | Batch: 2000 | Loss: 0.05604962398812842\n",
            "Epoch: 50 | Batch: 2001 | Loss: 0.06448167301563705\n",
            "Epoch: 50 | Batch: 2002 | Loss: 0.0863378177530793\n",
            "Epoch: 50 | Batch: 2003 | Loss: 0.12567392955087814\n",
            "Epoch: 50 | Batch: 2004 | Loss: 0.07747136341071366\n",
            "Epoch: 50 | Batch: 2005 | Loss: 0.11633658196831718\n",
            "Epoch: 50 | Batch: 2006 | Loss: 0.10156600284925546\n",
            "Epoch: 50 | Batch: 2007 | Loss: 0.09452907952120265\n",
            "Epoch: 50 | Batch: 2008 | Loss: 0.10520219017211793\n",
            "Epoch: 50 | Batch: 2009 | Loss: 0.09215085412049494\n",
            "Epoch: 50 | Batch: 2010 | Loss: 0.10450064938828132\n",
            "Epoch: 50 | Batch: 2011 | Loss: 0.08939033617473302\n",
            "Epoch: 50 | Batch: 2012 | Loss: 0.080845557026053\n",
            "Epoch: 50 | Batch: 2013 | Loss: 0.08418774468064413\n",
            "Epoch: 50 | Batch: 2014 | Loss: 0.05901926907575265\n",
            "Epoch: 50 | Batch: 2015 | Loss: 0.09926945396759604\n",
            "Epoch: 50 | Batch: 2016 | Loss: 0.0998144490620783\n",
            "Epoch: 50 | Batch: 2017 | Loss: 0.057454264606886796\n",
            "Epoch: 50 | Batch: 2018 | Loss: 0.04914157148034276\n",
            "Epoch: 50 | Batch: 2019 | Loss: 0.06823586224941373\n",
            "Epoch: 50 | Batch: 2020 | Loss: 0.07186194163380641\n",
            "Epoch: 50 | Batch: 2021 | Loss: 0.07245392372218912\n",
            "Epoch: 50 | Batch: 2022 | Loss: 0.10239211195126932\n",
            "Epoch: 50 | Batch: 2023 | Loss: 0.11409668155146242\n",
            "Epoch: 50 | Batch: 2024 | Loss: 0.09217584599469225\n",
            "Epoch: 50 | Batch: 2025 | Loss: 0.07530757276627467\n",
            "Epoch: 50 | Batch: 2026 | Loss: 0.1327277525695114\n",
            "Epoch: 50 | Batch: 2027 | Loss: 0.06405728611205289\n",
            "Epoch: 50 | Batch: 2028 | Loss: 0.19183929963168664\n",
            "Epoch: 50 | Batch: 2029 | Loss: 0.22115076344109208\n",
            "Epoch: 50 | Batch: 2030 | Loss: 0.18099386916831464\n",
            "Epoch: 50 | Batch: 2031 | Loss: 0.21717487530394752\n",
            "Epoch: 50 | Batch: 2032 | Loss: 0.15476613606718054\n",
            "Epoch: 50 | Batch: 2033 | Loss: 0.24499033639550113\n",
            "Epoch: 50 | Batch: 2034 | Loss: 0.15105903591336223\n",
            "Epoch: 50 | Batch: 2035 | Loss: 0.22778935586080265\n",
            "Epoch: 50 | Batch: 2036 | Loss: 0.1235871071792668\n",
            "Epoch: 50 | Batch: 2037 | Loss: 0.1648083358696174\n",
            "Epoch: 50 | Batch: 2038 | Loss: 0.09784409254008049\n",
            "Epoch: 50 | Batch: 2039 | Loss: 0.11028383473503005\n",
            "Epoch: 50 | Batch: 2040 | Loss: 0.11564021917062833\n",
            "Epoch: 50 | Batch: 2041 | Loss: 0.12040449347356923\n",
            "Epoch: 50 | Batch: 2042 | Loss: 0.12803274683327273\n",
            "Epoch: 50 | Batch: 2043 | Loss: 0.10116711937690712\n",
            "Epoch: 50 | Batch: 2044 | Loss: 0.1260484568292915\n",
            "Epoch: 50 | Batch: 2045 | Loss: 0.08202302562931538\n",
            "Epoch: 50 | Batch: 2046 | Loss: 0.14121497744735634\n",
            "Epoch: 50 | Batch: 2047 | Loss: 0.102893050220039\n",
            "Epoch: 50 | Batch: 2048 | Loss: 0.07338225140897718\n",
            "Epoch: 50 | Batch: 2049 | Loss: 0.12221697669789167\n",
            "Epoch: 50 | Batch: 2050 | Loss: 0.13596335377536312\n",
            "Epoch: 50 | Batch: 2051 | Loss: 0.08564179225292165\n",
            "Epoch: 50 | Batch: 2052 | Loss: 0.10826822205663536\n",
            "Epoch: 50 | Batch: 2053 | Loss: 0.10521477135662564\n",
            "Epoch: 50 | Batch: 2054 | Loss: 0.1626470060982173\n",
            "Epoch: 50 | Batch: 2055 | Loss: 0.08129689386026216\n",
            "Epoch: 50 | Batch: 2056 | Loss: 0.09936058430028252\n",
            "Epoch: 50 | Batch: 2057 | Loss: 0.08290605927469119\n",
            "Epoch: 50 | Batch: 2058 | Loss: 0.14150855421935465\n",
            "Epoch: 50 | Batch: 2059 | Loss: 0.11306581995296994\n",
            "Epoch: 50 | Batch: 2060 | Loss: 0.09315994759097268\n",
            "Epoch: 50 | Batch: 2061 | Loss: 0.09752189712491527\n",
            "Epoch: 50 | Batch: 2062 | Loss: 0.1761147874683277\n",
            "Epoch: 50 | Batch: 2063 | Loss: 0.09219370820788492\n",
            "Epoch: 50 | Batch: 2064 | Loss: 0.09306057606441392\n",
            "Epoch: 50 | Batch: 2065 | Loss: 0.10265344199392794\n",
            "Epoch: 50 | Batch: 2066 | Loss: 0.10589773055244878\n",
            "Epoch: 50 | Batch: 2067 | Loss: 0.1713437978230375\n",
            "Epoch: 50 | Batch: 2068 | Loss: 0.07826910694459974\n",
            "Epoch: 50 | Batch: 2069 | Loss: 0.2108977848457532\n",
            "Epoch: 50 | Batch: 2070 | Loss: 0.09483833291492275\n",
            "Epoch: 50 | Batch: 2071 | Loss: 0.14609206759357676\n",
            "Epoch: 50 | Batch: 2072 | Loss: 0.09170607227717681\n",
            "Epoch: 50 | Batch: 2073 | Loss: 0.1539342426920756\n",
            "Epoch: 50 | Batch: 2074 | Loss: 0.09316359240476452\n",
            "Epoch: 50 | Batch: 2075 | Loss: 0.14349136036798577\n",
            "Epoch: 50 | Batch: 2076 | Loss: 0.12835273150857324\n",
            "Epoch: 50 | Batch: 2077 | Loss: 0.14741152690458031\n",
            "Epoch: 50 | Batch: 2078 | Loss: 0.1727452480520032\n",
            "Epoch: 50 | Batch: 2079 | Loss: 0.1732501389450495\n",
            "Epoch: 50 | Batch: 2080 | Loss: 0.11034422886686934\n",
            "Epoch: 50 | Batch: 2081 | Loss: 0.13797989573960934\n",
            "Epoch: 50 | Batch: 2082 | Loss: 0.073078004387925\n",
            "Epoch: 50 | Batch: 2083 | Loss: 0.09850367587728477\n",
            "Epoch: 50 | Batch: 2084 | Loss: 0.07508743082636143\n",
            "Epoch: 50 | Batch: 2085 | Loss: 0.08771384266231286\n",
            "Epoch: 50 | Batch: 2086 | Loss: 0.12914199647099733\n",
            "Epoch: 50 | Batch: 2087 | Loss: 0.16996432036958914\n",
            "Epoch: 50 | Batch: 2088 | Loss: 0.13270405638768684\n",
            "Epoch: 50 | Batch: 2089 | Loss: 0.22712162242502001\n",
            "Epoch: 50 | Batch: 2090 | Loss: 0.1140105725205818\n",
            "Epoch: 50 | Batch: 2091 | Loss: 0.14845630304365234\n",
            "Epoch: 50 | Batch: 2092 | Loss: 0.09888195729021003\n",
            "Epoch: 50 | Batch: 2093 | Loss: 0.09870228522977224\n",
            "Epoch: 50 | Batch: 2094 | Loss: 0.09843489385670715\n",
            "Epoch: 50 | Batch: 2095 | Loss: 0.10471407333040851\n",
            "Epoch: 50 | Batch: 2096 | Loss: 0.08276653013490788\n",
            "Epoch: 50 | Batch: 2097 | Loss: 0.0674446590943423\n",
            "Epoch: 50 | Batch: 2098 | Loss: 0.09063500731330565\n",
            "Epoch: 50 | Batch: 2099 | Loss: 0.07926937380861945\n",
            "Epoch: 50 | Batch: 2100 | Loss: 0.08176586962837298\n",
            "Epoch: 50 | Batch: 2101 | Loss: 0.10997226929457882\n",
            "Epoch: 50 | Batch: 2102 | Loss: 0.08652315228934276\n",
            "Epoch: 50 | Batch: 2103 | Loss: 0.09548984913968218\n",
            "Epoch: 50 | Batch: 2104 | Loss: 0.08920304415506733\n",
            "Epoch: 50 | Batch: 2105 | Loss: 0.12209599508282518\n",
            "Epoch: 50 | Batch: 2106 | Loss: 0.14623074004575232\n",
            "Epoch: 50 | Batch: 2107 | Loss: 0.10668198582997784\n",
            "Epoch: 50 | Batch: 2108 | Loss: 0.08696258350766403\n",
            "Epoch: 50 | Batch: 2109 | Loss: 0.08338715702563348\n",
            "Epoch: 50 | Batch: 2110 | Loss: 0.0983624115087809\n",
            "Epoch: 50 | Batch: 2111 | Loss: 0.10840330334859363\n",
            "Epoch: 50 | Batch: 2112 | Loss: 0.12489941162358612\n",
            "Epoch: 50 | Batch: 2113 | Loss: 0.093014924801639\n",
            "Epoch: 50 | Batch: 2114 | Loss: 0.08965575685803465\n",
            "Epoch: 50 | Batch: 2115 | Loss: 0.11384956893377708\n",
            "Epoch: 50 | Batch: 2116 | Loss: 0.11382113440085548\n",
            "Epoch: 50 | Batch: 2117 | Loss: 0.12437484495925832\n",
            "Epoch: 50 | Batch: 2118 | Loss: 0.10901203568262303\n",
            "Epoch: 50 | Batch: 2119 | Loss: 0.09661204525948741\n",
            "Epoch: 50 | Batch: 2120 | Loss: 0.09245797271525896\n",
            "Epoch: 50 | Batch: 2121 | Loss: 0.10647418811100612\n",
            "Epoch: 50 | Batch: 2122 | Loss: 0.10128821836539964\n",
            "Epoch: 50 | Batch: 2123 | Loss: 0.10121145570004383\n",
            "Epoch: 50 | Batch: 2124 | Loss: 0.0963809100219721\n",
            "Epoch: 50 | Batch: 2125 | Loss: 0.10943982559726466\n",
            "Epoch: 50 | Batch: 2126 | Loss: 0.20873046658100913\n",
            "Epoch: 50 | Batch: 2127 | Loss: 0.12101199067229437\n",
            "Epoch: 50 | Batch: 2128 | Loss: 0.12072062944798441\n",
            "Epoch: 50 | Batch: 2129 | Loss: 0.09499572200833342\n",
            "Epoch: 50 | Batch: 2130 | Loss: 0.13200582515955234\n",
            "Epoch: 50 | Batch: 2131 | Loss: 0.13481408948454698\n",
            "Epoch: 50 | Batch: 2132 | Loss: 0.12541257931868574\n",
            "Epoch: 50 | Batch: 2133 | Loss: 0.177394392587738\n",
            "Epoch: 50 | Batch: 2134 | Loss: 0.15311834144730885\n",
            "Epoch: 50 | Batch: 2135 | Loss: 0.1731028532612987\n",
            "Epoch: 50 | Batch: 2136 | Loss: 0.11551713486621557\n",
            "Epoch: 50 | Batch: 2137 | Loss: 0.15517639006267692\n",
            "Epoch: 50 | Batch: 2138 | Loss: 0.11593188154443657\n",
            "Epoch: 50 | Batch: 2139 | Loss: 0.18928575468453462\n",
            "Epoch: 50 | Batch: 2140 | Loss: 0.13745846432927003\n",
            "Epoch: 50 | Batch: 2141 | Loss: 0.174881351320854\n",
            "Epoch: 50 | Batch: 2142 | Loss: 0.12297139374164989\n",
            "Epoch: 50 | Batch: 2143 | Loss: 0.15217256411846575\n",
            "Epoch: 50 | Batch: 2144 | Loss: 0.12130312596145015\n",
            "Epoch: 50 | Batch: 2145 | Loss: 0.10666493336302608\n",
            "Epoch: 50 | Batch: 2146 | Loss: 0.11758991908893779\n",
            "Epoch: 50 | Batch: 2147 | Loss: 0.0999319997596966\n",
            "Epoch: 50 | Batch: 2148 | Loss: 0.10737694383395727\n",
            "Epoch: 50 | Batch: 2149 | Loss: 0.10790725895820895\n",
            "Epoch: 50 | Batch: 2150 | Loss: 0.11772663799085122\n",
            "Epoch: 50 | Batch: 2151 | Loss: 0.11057382067302704\n",
            "Epoch: 50 | Batch: 2152 | Loss: 0.12626549698542394\n",
            "Epoch: 50 | Batch: 2153 | Loss: 0.11828593306049501\n",
            "Epoch: 50 | Batch: 2154 | Loss: 0.14748664743723933\n",
            "Epoch: 50 | Batch: 2155 | Loss: 0.09461846191487965\n",
            "Epoch: 50 | Batch: 2156 | Loss: 0.1372716062798811\n",
            "Epoch: 50 | Batch: 2157 | Loss: 0.06957306525953744\n",
            "Epoch: 50 | Batch: 2158 | Loss: 0.16636578825090267\n",
            "Epoch: 50 | Batch: 2159 | Loss: 0.07863961855784277\n",
            "Epoch: 50 | Batch: 2160 | Loss: 0.1803480146910138\n",
            "Epoch: 50 | Batch: 2161 | Loss: 0.14497109103600503\n",
            "Epoch: 50 | Batch: 2162 | Loss: 0.09352914180501896\n",
            "Epoch: 50 | Batch: 2163 | Loss: 0.0933783096778405\n",
            "Epoch: 50 | Batch: 2164 | Loss: 0.12336473552788266\n",
            "Epoch: 50 | Batch: 2165 | Loss: 0.08812806754098354\n",
            "Epoch: 50 | Batch: 2166 | Loss: 0.10905868175538072\n",
            "Epoch: 50 | Batch: 2167 | Loss: 0.08139121714671285\n",
            "Epoch: 50 | Batch: 2168 | Loss: 0.10146392625241846\n",
            "Epoch: 50 | Batch: 2169 | Loss: 0.0624491479582837\n",
            "Epoch: 50 | Batch: 2170 | Loss: 0.09664796861649497\n",
            "Epoch: 50 | Batch: 2171 | Loss: 0.09089036086469227\n",
            "Epoch: 50 | Batch: 2172 | Loss: 0.06251121774012226\n",
            "Epoch: 50 | Batch: 2173 | Loss: 0.11670335690597414\n",
            "Epoch: 50 | Batch: 2174 | Loss: 0.0649403063256332\n",
            "Epoch: 50 | Batch: 2175 | Loss: 0.07564225605817745\n",
            "Epoch: 50 | Batch: 2176 | Loss: 0.09266905973153554\n",
            "Epoch: 50 | Batch: 2177 | Loss: 0.1010433615278117\n",
            "Epoch: 50 | Batch: 2178 | Loss: 0.08595713018030335\n",
            "Epoch: 50 | Batch: 2179 | Loss: 0.09467324443499667\n",
            "Epoch: 50 | Batch: 2180 | Loss: 0.08211846047499777\n",
            "Epoch: 50 | Batch: 2181 | Loss: 0.10285975837215999\n",
            "Epoch: 50 | Batch: 2182 | Loss: 0.09145206982450704\n",
            "Epoch: 50 | Batch: 2183 | Loss: 0.10647168855103888\n",
            "Epoch: 50 | Batch: 2184 | Loss: 0.06889479098726156\n",
            "Epoch: 50 | Batch: 2185 | Loss: 0.06954740603554868\n",
            "Epoch: 50 | Batch: 2186 | Loss: 0.07308189390697911\n",
            "Epoch: 50 | Batch: 2187 | Loss: 0.0852258745081754\n",
            "Epoch: 50 | Batch: 2188 | Loss: 0.07671196208541173\n",
            "Epoch: 50 | Batch: 2189 | Loss: 0.07317180205886137\n",
            "Epoch: 50 | Batch: 2190 | Loss: 0.07531390835789181\n",
            "Epoch: 50 | Batch: 2191 | Loss: 0.05192327813640691\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(model,X_test,Y_test,data_df_combined_clean)"
      ],
      "metadata": {
        "id": "xhTgXildCmxL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "outputId": "fd57d7d4-d061-4899-b25e-5bdedcf8a4b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The mean square error is: 255.273718\n",
            "MAPE is: 2.909383\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1Ku39tl0d5bd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}